{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FEATURE_DIR' from 'config' (/Users/liuyu/Desktop/g-forecast/config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-aff254b7f83f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil_log\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from config import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mRAW_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mFEATURE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FEATURE_DIR' from 'config' (/Users/liuyu/Desktop/g-forecast/config.py)"
     ]
    }
   ],
   "source": [
    "# -------------- #\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import load_data\n",
    "from util_log import logger\n",
    "\n",
    "from config import (\n",
    "    RAW_DATA_DIR,\n",
    "    FEATURE_DIR,\n",
    "    LAG_DICT,\n",
    "    SLIDING_DICT\n",
    ")\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid period. '2017-07-31' to '2017-08-16'\n",
    "SPLIT_DATE = datetime.date(2017,7, 31)\n",
    "\n",
    "def add_weekday(df):\n",
    "    df['weekday'] = df['date'].dt.weekday\n",
    "    return df\n",
    "\n",
    "def add_month(df):\n",
    "    df['month'] = df['date'].dt.add_month\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def item_info(df):\n",
    "    items_df = pd.read_csv(RAW_DATA_DIR+'items.csv')\n",
    "    df = df.merge(items_df, on='item_nbr')\n",
    "    return df\n",
    "\n",
    "def store_info(df):\n",
    "    stores_df = pd.read_csv(RAW_DATA_DIR+'stores.csv')\n",
    "    df = df.merge(items_df, on='store_nbr')\n",
    "    return df\n",
    "\n",
    "def transaction_info(df):\n",
    "    transactions_df = pd.read_csv(RAW_DATA_DIR+'transactions.csv')\n",
    "    df = df.merge(transactions_df, on = 'store_nbr')\n",
    "    return df\n",
    "\n",
    "def oil_info(df):\n",
    "    oil_df = pd.read_csv(RAW_DATA_DIR+'oil.csv',parse_dates=['date'])\n",
    "    df = df.merge(oil_df, on = 'date')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagging(df,\n",
    "            col,\n",
    "            lag_len):\n",
    "    \"\"\" Generate lagging features.\n",
    "    Args:\n",
    "        df: a DataFrame, contains all columns in cols_lag\n",
    "        len_lag: Int, the length of lagging features\n",
    "        cols_lag: List of String, the columns needs to generate lagging features \n",
    "\n",
    "    Returns:\n",
    "        df: a DataFrame with lagging features, for example 'Sales_lag_1'.\n",
    "    \"\"\"\n",
    "\n",
    "    for lag in lag_len:\n",
    "        df[col + '_lag_' + str(lag)] = df[col].shift(periods=lag)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get raw data\n"
     ]
    }
   ],
   "source": [
    "logger.debug('Get raw data')\n",
    "train_df, test_df = load_data.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagging(df,\n",
    "            col,\n",
    "            lag_len):\n",
    "    \"\"\" Generate lagging features.\n",
    "    Args:\n",
    "        df: a DataFrame, contains all columns in cols_lag\n",
    "        len_lag: Int, the length of lagging features\n",
    "        cols_lag: List of String, the columns needs to generate lagging features \n",
    "\n",
    "    Returns:\n",
    "        df: a DataFrame with lagging features, for example 'Sales_lag_1'.\n",
    "    \"\"\"\n",
    "\n",
    "    for lag in lag_len:\n",
    "        df[col + '_lag_' + str(lag)] = df[col].shift(periods=lag)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df,\n",
    "                   sliding_len,\n",
    "                   col\n",
    "                   ):\n",
    "    \"\"\" Generate sliding window features.\n",
    "    Args:\n",
    "        df: a DataFrame, contains all columns in cols_lag\n",
    "        len_sliding_window: Int, the length of sliding window, >2 \n",
    "        cols_sliding: List of String, the columns needs to generate sliding window features \n",
    "\n",
    "    Returns:\n",
    "        df: a DataFrame with sliding window features, for example 'unit_sales_mean_2'.\n",
    "    \"\"\"\n",
    "\n",
    "    def roll(data, roll_size, col):\n",
    "        roll = data[col].shift(1).rolling(roll_size)\n",
    "        data[col + '_mean_' + str(roll_size)] = roll.mean()\n",
    "        data[col + '_std_' + str(roll_size)] = roll.std()\n",
    "#         data[col + '_max_' + str(roll_size)] = roll.max()\n",
    "#         data[col + '_min_' + str(roll_size)] = roll.min()\n",
    "        return data\n",
    "\n",
    "    for roll_size in sliding_len:\n",
    "        df = roll(df, roll_size, col)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_missing_value(store_df,\n",
    "                          item_df,\n",
    "                          start_date,\n",
    "                          end_date):\n",
    "    \"\"\" filling missing value.\n",
    "    Args:\n",
    "        item_df: a DataFrame, contains only one store data with cols: 'Sales'\n",
    "\n",
    "    Returns:\n",
    "        df: a DataFrame. store_frame data filled\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "    item_nbr = item_df.item_nbr.unique()[0]\n",
    "    store_nbr = item_df.store_nbr.unique()[0]\n",
    "    unit_sales = 0\n",
    "    for date in date_range:\n",
    "        if item_df[item_df['date'] == date].shape[0] != 0:\n",
    "            continue\n",
    "        try:\n",
    "            onpromotion = store_df[store_df['date'] == date].dropna().unique()[0]\n",
    "        except:\n",
    "            onpromotion = False\n",
    "        item_df.loc[item_df.shape[0]] = [date, store_nbr, item_nbr, unit_sales, onpromotion]\n",
    "    item_df = item_df.sort_values('date')\n",
    "    item_df = item_df.reset_index(drop=True)\n",
    "    return item_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "store loop:   0%|          | 0/54 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:   0%|          | 0/3540 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  27%|██▋       | 955/3540 [05:00<13:32,  3.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  27%|██▋       | 955/3540 [05:14<13:32,  3.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  48%|████▊     | 1691/3540 [10:00<10:33,  2.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  48%|████▊     | 1691/3540 [10:14<10:33,  2.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  63%|██████▎   | 2228/3540 [15:01<08:54,  2.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  63%|██████▎   | 2228/3540 [15:14<08:54,  2.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  76%|███████▌  | 2696/3540 [20:01<06:43,  2.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  76%|███████▌  | 2696/3540 [20:14<06:43,  2.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  88%|████████▊ | 3121/3540 [25:01<03:48,  1.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:  88%|████████▊ | 3121/3540 [25:14<03:48,  1.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop: 100%|██████████| 3540/3540 [29:41<00:00,  1.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "store loop:   4%|▎         | 2/54 [30:11<13:05:09, 905.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "item loop:   0%|          | 0/3561 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "storeId_list = train_df['store_nbr'].unique()\n",
    "# logger.debug('Filling missing value, lag, sliding window')\n",
    "for storeId in tqdm(storeId_list, desc = 'store loop'):\n",
    "    if storeId==25:\n",
    "        continue\n",
    "    store_frame = train_df[train_df['store_nbr'] == storeId]\n",
    "    item_list = store_frame.item_nbr.unique()\n",
    "    count = 0\n",
    "    logger.debug(count)\n",
    "    for itemId in tqdm(item_list,mininterval = 300, desc = 'item loop'):\n",
    "        item_frame = store_frame[store_frame['item_nbr']==itemId]\n",
    "        item_frame = item_frame.sort_values(by=['date'])\n",
    "        item_frame = item_frame.reset_index(drop=True)\n",
    "\n",
    "        # missing \n",
    "        item_frame = filling_missing_value(store_frame, item_frame, '2017-05-01', '2017-08-15')        \n",
    "        # outlier filter\n",
    "        \n",
    "        for col in LAG_DICT:\n",
    "            lag_len = LAG_DICT[col]\n",
    "            item_frame = lagging(item_frame, col, lag_len)\n",
    "\n",
    "        for col in SLIDING_DICT:\n",
    "            sliding_len = SLIDING_DICT[col]\n",
    "            item_frame = sliding_window(item_frame,\n",
    "                                     sliding_len,\n",
    "                                     col) \n",
    "\n",
    "        if count == 0:\n",
    "            df = item_frame\n",
    "        else:\n",
    "            df = pd.concat([df, item_frame])\n",
    "        count += 1\n",
    "\n",
    "    df.to_csv(FEATUER_DIR+'{}_lag_sales.csv'.format(storeId), index=False)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(FEATUER_DIR+'25_lag_sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(df):\n",
    "    train_df = df[df['date']<SPLIT_DATE]\n",
    "    valid_df = df[df['date']>=SPLIT_DATE]\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \n",
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_valid_split(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_label(df):\n",
    "\n",
    "    features = df.drop(columns = ['date', 'store_nbr', 'item_nbr', 'unit_sales']).values\n",
    "    labels = df['unit_sales'].values\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = feature_label(train)\n",
    "valid_X, valid_y = feature_label(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [[1],[2],[3],[4]]\n",
    "\n",
    "train_y=[1,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =LGBMRegressor(\n",
    "#                 colsample_bytree = 0.8,\n",
    "#                 learning_rate= 0.08,  # [0.08, 0.1]\n",
    "#                 max_depth=6,\n",
    "#                 num_leaves= 30,\n",
    "#                 min_child_weight= 5,\n",
    "#                 n_estimators= 200,  # [300, 500],\n",
    "# #                 nthread = 4,\n",
    "#                 seed= 1337,\n",
    "#                 silent= 1,\n",
    "#                 subsample= 0.8\n",
    "#                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostRegressor(iterations= 50,\n",
    "#                 depth = 6,\n",
    "#                 learning_rate= 0.5,\n",
    "#                 loss_function ='RMSE',\n",
    "#                          verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3343208463934615"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,X.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('lgbm_importances-01.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
