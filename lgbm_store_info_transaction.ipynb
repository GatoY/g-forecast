{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from config import (\n",
    "    RAW_DATA_DIR,\n",
    "    FEATURE_DIR,\n",
    "    LAG_DICT,\n",
    "    SLIDING_DICT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve lightgbm error on MAC\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv(\n",
    "    RAW_DATA_DIR+'train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    RAW_DATA_DIR+'test.csv', usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    RAW_DATA_DIR+'items.csv',\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    RAW_DATA_DIR+'stores.csv',\n",
    ").set_index(\"store_nbr\")\n",
    "\n",
    "transactions_df = pd.read_csv(\n",
    "    RAW_DATA_DIR+'transactions.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Period\n",
    "\n",
    "2017-08-16 to 2017-08-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = date(2017, 8, 16)\n",
    "test_end = date(2017,8, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid starts from 2017-07-26 to 2017-08-10\n"
     ]
    }
   ],
   "source": [
    "valid_start = test_start - timedelta(16)\n",
    "while(1):\n",
    "    if valid_start.weekday() == test_start.weekday():\n",
    "        break\n",
    "    valid_start = valid_start-timedelta(days=1)\n",
    "valid_end = valid_start + timedelta(15)\n",
    "print('valid starts from {} to {}'.format(valid_start, valid_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Period\n",
    "\n",
    "Considering the more nearer peiods of sales data may have more in common, it would be better to find the nearest period as valid period.\n",
    "\n",
    "Based on the analysis before, we assume the sales data is periodically with the frequency of 7 days, so we want to keep that feature same\n",
    "in the train, valid and test period.\n",
    "\n",
    "So finally, we choose valid period:\n",
    "\n",
    "2017-07-26 to 2017-08-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_start = date(2017, 7, 26)\n",
    "valid_end = date(2017, 8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Period\n",
    "\n",
    "#### Earthquake happended on April 16, 2016. It may affect for the next several weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train datasets starts from 2016-10-05\n"
     ]
    }
   ],
   "source": [
    "# filter the period which is affected by earthquake.\n",
    "filter_date = date(2016,4,16) + timedelta(7*4)\n",
    "lag_max = 140\n",
    "train_start=  filter_date+timedelta(days=lag_max)\n",
    "\n",
    "while(1):\n",
    "    train_start = train_start + timedelta(1)\n",
    "    if train_start.weekday() == valid_start.weekday():\n",
    "        break\n",
    "print('train datasets starts from {}'.format(train_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = date(2017,2,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train[df_train['date']>=filter_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_train = df_train.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]]\n",
    "\n",
    "# missing onpromotions filling\n",
    "promo_train = promo_train.unstack(level=-1).fillna(False)\n",
    "promo_train.columns = promo_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing test onpromotions filling\n",
    "promo_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_test.columns = promo_test.columns.get_level_values(1)\n",
    "# filter those items/stores in promo_test but not in promo_train\n",
    "promo_test = promo_test.reindex(promo_train.index).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_features = pd.concat([promo_train, promo_test], axis=1)\n",
    "del promo_test, promo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\n",
    "    RAW_DATA_DIR+'transactions.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "df_train = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
    "# tmp = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
    "transactions_df = transactions_df.set_index([\"store_nbr\", \"date\"])[[\"transactions\"]].unstack(level=-1).fillna(0)\n",
    "transactions_df = transactions_df.reindex(df_train.index.get_level_values(0))\n",
    "transactions_df.columns = transactions_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_train.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['family'] = items['family'].astype('category')\n",
    "item_family_features = items.family.cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['class'] = items['class'].astype('category')\n",
    "item_class_features = items['class'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = stores.reindex(df_train.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['city'] = stores['city'].astype('category')\n",
    "store_city_features = stores['city'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['state'] = stores['state'].astype('category')\n",
    "store_state_features = stores['state'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['type'] = stores['type'].astype('category')\n",
    "store_type_features = stores['type'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['cluster'] = stores['cluster'].astype('category')\n",
    "store_cluster_features = stores['cluster'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = df_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = df_train.columns\n",
    "obj_list = pd.date_range(filter_date, test_start-timedelta(1))\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    df_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = promo_features.columns\n",
    "obj_list = pd.date_range(filter_date, test_end)\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    promo_features[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagging and sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG_DICT = {'unit_sales': [1,2,3,4,5,6,7,14,21,28,35,42,49,56,63],\n",
    "            'onpromotion': [2, 3,4,5,6, 7, 14, 21],\n",
    "            'transactions': [1, 2, 3, 4, 5, 6, 7, 14, 21]}\n",
    "\n",
    "SLIDING_DICT = {'unit_sales': [3, 4, 5, 6, 7, 14, 21, 30, 60, 63]}\n",
    "\n",
    "\n",
    "\n",
    "# initialise dirs\n",
    "RAW_DATA_DIR = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, \n",
    "                 start_time,\n",
    "                 minus,\n",
    "                 periods,\n",
    "                 freq='D'):\n",
    "    return df[pd.date_range(start_time - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def gen_dataset(df,\n",
    "                promo_features,\n",
    "                item_family_features,\n",
    "                item_class_features,\n",
    "                store_city_features,\n",
    "                store_state_features,\n",
    "                store_type_features,\n",
    "                store_cluster_features,\n",
    "                transactions_df,\n",
    "                start_time,\n",
    "                is_train=True):\n",
    "    # init\n",
    "    X = pd.DataFrame()\n",
    "\n",
    "    for i in LAG_DICT['unit_sales']:\n",
    "        X['lag_{}_sales'.format(i)] = get_timespan(df, start_time, i, 1).values.ravel()\n",
    "    \n",
    "    for i in LAG_DICT['onpromotion']:\n",
    "        X['sum_{}_promo'.format(i)] = get_timespan(promo_features, start_time, i, 1).sum(axis=1).ravel()\n",
    "\n",
    "    for i in SLIDING_DICT['unit_sales']:\n",
    "        X[\"mean_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).mean(axis=1).values\n",
    "        X[\"std_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).std(axis=1).values\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, start_time, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, start_time, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "\n",
    "    for i in LAG_DICT['transactions']:\n",
    "        X['lag_{}_transactions'.format(i)] = get_timespan(transactions_df, start_time, i, 1).values.ravel()\n",
    "\n",
    "    # for the next to-predict 16 days \n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_features[start_time + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X['item_family_features'] = item_family_features\n",
    "\n",
    "    X['item_class_features'] = item_class_features\n",
    "\n",
    "    X['store_city_features'] = store_city_features\n",
    "\n",
    "    X['store_state_features'] = store_state_features\n",
    "\n",
    "    X['store_type_features'] = store_type_features\n",
    "\n",
    "    X['store_cluster_features'] = store_cluster_features\n",
    "        \n",
    "    if is_train:\n",
    "        y = df[pd.date_range(start_time, periods=16)].values\n",
    "        return X, y\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train, valid and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No. of week:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No. of week: 100%|██████████| 24/24 [00:21<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "\n",
    "nbr_weeks = int((valid_start - train_start).days/7)\n",
    "\n",
    "X_l, y_l = [], []\n",
    "\n",
    "for i in tqdm(range(nbr_weeks), desc = 'No. of week'):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = gen_dataset(\n",
    "        df_train,\n",
    "        promo_features,\n",
    "        item_family_features,\n",
    "        item_class_features,\n",
    "        store_city_features,\n",
    "        store_state_features,\n",
    "        store_type_features,\n",
    "        store_cluster_features,\n",
    "        transactions_df,\n",
    "        train_start + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = gen_dataset(df_train,\n",
    "                           promo_features,\n",
    "                           item_family_features,\n",
    "                           item_class_features,\n",
    "                           store_city_features,\n",
    "                           store_state_features,\n",
    "                           store_type_features,\n",
    "                           store_cluster_features,\n",
    "                           transactions_df,\n",
    "                           valid_start)\n",
    "X_test = gen_dataset(df_train, \n",
    "                    promo_features,\n",
    "                    item_family_features,\n",
    "                    item_class_features,\n",
    "                    store_city_features,\n",
    "                    store_state_features,\n",
    "                    store_type_features,\n",
    "                    store_cluster_features,\n",
    "                    transactions_df,\n",
    "                    test_start, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 200\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = ['item_family_features',\n",
    "            'item_class_features',\n",
    "            'store_city_features',\n",
    "            'store_state_features',\n",
    "            'store_type_features',\n",
    "            'store_cluster_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05102\tvalid_1's l2: 1.00592\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.981373\tvalid_1's l2: 0.938532\n",
      "[3]\ttraining's l2: 0.919894\tvalid_1's l2: 0.879283\n",
      "[4]\ttraining's l2: 0.864084\tvalid_1's l2: 0.825476\n",
      "[5]\ttraining's l2: 0.813703\tvalid_1's l2: 0.776978\n",
      "[6]\ttraining's l2: 0.766517\tvalid_1's l2: 0.731337\n",
      "[7]\ttraining's l2: 0.723585\tvalid_1's l2: 0.690035\n",
      "[8]\ttraining's l2: 0.684655\tvalid_1's l2: 0.652411\n",
      "[9]\ttraining's l2: 0.650701\tvalid_1's l2: 0.619872\n",
      "[10]\ttraining's l2: 0.618776\tvalid_1's l2: 0.589183\n",
      "[11]\ttraining's l2: 0.589819\tvalid_1's l2: 0.561363\n",
      "[12]\ttraining's l2: 0.563715\tvalid_1's l2: 0.536369\n",
      "[13]\ttraining's l2: 0.539947\tvalid_1's l2: 0.513612\n",
      "[14]\ttraining's l2: 0.519278\tvalid_1's l2: 0.493935\n",
      "[15]\ttraining's l2: 0.499749\tvalid_1's l2: 0.475246\n",
      "[16]\ttraining's l2: 0.482751\tvalid_1's l2: 0.459138\n",
      "[17]\ttraining's l2: 0.467343\tvalid_1's l2: 0.444508\n",
      "[18]\ttraining's l2: 0.453455\tvalid_1's l2: 0.431288\n",
      "[19]\ttraining's l2: 0.439963\tvalid_1's l2: 0.418372\n",
      "[20]\ttraining's l2: 0.428527\tvalid_1's l2: 0.407596\n",
      "[21]\ttraining's l2: 0.418188\tvalid_1's l2: 0.397834\n",
      "[22]\ttraining's l2: 0.40791\tvalid_1's l2: 0.388005\n",
      "[23]\ttraining's l2: 0.399369\tvalid_1's l2: 0.380017\n",
      "[24]\ttraining's l2: 0.390833\tvalid_1's l2: 0.371839\n",
      "[25]\ttraining's l2: 0.38298\tvalid_1's l2: 0.364355\n",
      "[26]\ttraining's l2: 0.375922\tvalid_1's l2: 0.35768\n",
      "[27]\ttraining's l2: 0.370125\tvalid_1's l2: 0.352265\n",
      "[28]\ttraining's l2: 0.364139\tvalid_1's l2: 0.3466\n",
      "[29]\ttraining's l2: 0.359275\tvalid_1's l2: 0.342087\n",
      "[30]\ttraining's l2: 0.35483\tvalid_1's l2: 0.337987\n",
      "[31]\ttraining's l2: 0.350152\tvalid_1's l2: 0.333631\n",
      "[32]\ttraining's l2: 0.346019\tvalid_1's l2: 0.329799\n",
      "[33]\ttraining's l2: 0.342634\tvalid_1's l2: 0.326711\n",
      "[34]\ttraining's l2: 0.339054\tvalid_1's l2: 0.323297\n",
      "[35]\ttraining's l2: 0.335783\tvalid_1's l2: 0.320224\n",
      "[36]\ttraining's l2: 0.332796\tvalid_1's l2: 0.317478\n",
      "[37]\ttraining's l2: 0.330099\tvalid_1's l2: 0.31488\n",
      "[38]\ttraining's l2: 0.327574\tvalid_1's l2: 0.312562\n",
      "[39]\ttraining's l2: 0.325246\tvalid_1's l2: 0.310424\n",
      "[40]\ttraining's l2: 0.323154\tvalid_1's l2: 0.308486\n",
      "[41]\ttraining's l2: 0.321262\tvalid_1's l2: 0.306752\n",
      "[42]\ttraining's l2: 0.319484\tvalid_1's l2: 0.305138\n",
      "[43]\ttraining's l2: 0.317799\tvalid_1's l2: 0.30358\n",
      "[44]\ttraining's l2: 0.316262\tvalid_1's l2: 0.302206\n",
      "[45]\ttraining's l2: 0.315083\tvalid_1's l2: 0.301186\n",
      "[46]\ttraining's l2: 0.313762\tvalid_1's l2: 0.299956\n",
      "[47]\ttraining's l2: 0.312835\tvalid_1's l2: 0.299162\n",
      "[48]\ttraining's l2: 0.31191\tvalid_1's l2: 0.298378\n",
      "[49]\ttraining's l2: 0.310849\tvalid_1's l2: 0.297434\n",
      "[50]\ttraining's l2: 0.309863\tvalid_1's l2: 0.296562\n",
      "[51]\ttraining's l2: 0.309167\tvalid_1's l2: 0.295989\n",
      "[52]\ttraining's l2: 0.308496\tvalid_1's l2: 0.295445\n",
      "[53]\ttraining's l2: 0.307698\tvalid_1's l2: 0.294731\n",
      "[54]\ttraining's l2: 0.306922\tvalid_1's l2: 0.294027\n",
      "[55]\ttraining's l2: 0.30627\tvalid_1's l2: 0.293434\n",
      "[56]\ttraining's l2: 0.305575\tvalid_1's l2: 0.292811\n",
      "[57]\ttraining's l2: 0.304961\tvalid_1's l2: 0.292278\n",
      "[58]\ttraining's l2: 0.30437\tvalid_1's l2: 0.291761\n",
      "[59]\ttraining's l2: 0.303841\tvalid_1's l2: 0.291278\n",
      "[60]\ttraining's l2: 0.303376\tvalid_1's l2: 0.290866\n",
      "[61]\ttraining's l2: 0.302943\tvalid_1's l2: 0.290495\n",
      "[62]\ttraining's l2: 0.3026\tvalid_1's l2: 0.290224\n",
      "[63]\ttraining's l2: 0.302199\tvalid_1's l2: 0.289876\n",
      "[64]\ttraining's l2: 0.301813\tvalid_1's l2: 0.289534\n",
      "[65]\ttraining's l2: 0.301424\tvalid_1's l2: 0.289168\n",
      "[66]\ttraining's l2: 0.301086\tvalid_1's l2: 0.28888\n",
      "[67]\ttraining's l2: 0.300874\tvalid_1's l2: 0.288719\n",
      "[68]\ttraining's l2: 0.300555\tvalid_1's l2: 0.288458\n",
      "[69]\ttraining's l2: 0.300256\tvalid_1's l2: 0.288199\n",
      "[70]\ttraining's l2: 0.300046\tvalid_1's l2: 0.28803\n",
      "[71]\ttraining's l2: 0.299725\tvalid_1's l2: 0.287733\n",
      "[72]\ttraining's l2: 0.299478\tvalid_1's l2: 0.28754\n",
      "[73]\ttraining's l2: 0.299179\tvalid_1's l2: 0.287271\n",
      "[74]\ttraining's l2: 0.298918\tvalid_1's l2: 0.287033\n",
      "[75]\ttraining's l2: 0.298703\tvalid_1's l2: 0.286885\n",
      "[76]\ttraining's l2: 0.29853\tvalid_1's l2: 0.28675\n",
      "[77]\ttraining's l2: 0.298294\tvalid_1's l2: 0.286536\n",
      "[78]\ttraining's l2: 0.29808\tvalid_1's l2: 0.286335\n",
      "[79]\ttraining's l2: 0.297914\tvalid_1's l2: 0.286231\n",
      "[80]\ttraining's l2: 0.29774\tvalid_1's l2: 0.286096\n",
      "[81]\ttraining's l2: 0.297621\tvalid_1's l2: 0.286004\n",
      "[82]\ttraining's l2: 0.297432\tvalid_1's l2: 0.285849\n",
      "[83]\ttraining's l2: 0.297266\tvalid_1's l2: 0.285692\n",
      "[84]\ttraining's l2: 0.297084\tvalid_1's l2: 0.285531\n",
      "[85]\ttraining's l2: 0.296958\tvalid_1's l2: 0.285434\n",
      "[86]\ttraining's l2: 0.296824\tvalid_1's l2: 0.28533\n",
      "[87]\ttraining's l2: 0.296669\tvalid_1's l2: 0.285181\n",
      "[88]\ttraining's l2: 0.296529\tvalid_1's l2: 0.285052\n",
      "[89]\ttraining's l2: 0.296435\tvalid_1's l2: 0.28499\n",
      "[90]\ttraining's l2: 0.296292\tvalid_1's l2: 0.284854\n",
      "[91]\ttraining's l2: 0.296182\tvalid_1's l2: 0.284797\n",
      "[92]\ttraining's l2: 0.29607\tvalid_1's l2: 0.284752\n",
      "[93]\ttraining's l2: 0.295942\tvalid_1's l2: 0.284672\n",
      "[94]\ttraining's l2: 0.295759\tvalid_1's l2: 0.284523\n",
      "[95]\ttraining's l2: 0.295671\tvalid_1's l2: 0.28449\n",
      "[96]\ttraining's l2: 0.29551\tvalid_1's l2: 0.284336\n",
      "[97]\ttraining's l2: 0.29537\tvalid_1's l2: 0.284208\n",
      "[98]\ttraining's l2: 0.295253\tvalid_1's l2: 0.284111\n",
      "[99]\ttraining's l2: 0.295178\tvalid_1's l2: 0.284059\n",
      "[100]\ttraining's l2: 0.295105\tvalid_1's l2: 0.284003\n",
      "[101]\ttraining's l2: 0.294964\tvalid_1's l2: 0.283871\n",
      "[102]\ttraining's l2: 0.294868\tvalid_1's l2: 0.283806\n",
      "[103]\ttraining's l2: 0.294779\tvalid_1's l2: 0.283777\n",
      "[104]\ttraining's l2: 0.294701\tvalid_1's l2: 0.283726\n",
      "[105]\ttraining's l2: 0.294616\tvalid_1's l2: 0.283711\n",
      "[106]\ttraining's l2: 0.294534\tvalid_1's l2: 0.283661\n",
      "[107]\ttraining's l2: 0.29445\tvalid_1's l2: 0.283642\n",
      "[108]\ttraining's l2: 0.294379\tvalid_1's l2: 0.283611\n",
      "[109]\ttraining's l2: 0.29425\tvalid_1's l2: 0.283482\n",
      "[110]\ttraining's l2: 0.29417\tvalid_1's l2: 0.283421\n",
      "[111]\ttraining's l2: 0.29408\tvalid_1's l2: 0.283385\n",
      "[112]\ttraining's l2: 0.293979\tvalid_1's l2: 0.283319\n",
      "[113]\ttraining's l2: 0.293901\tvalid_1's l2: 0.283282\n",
      "[114]\ttraining's l2: 0.293791\tvalid_1's l2: 0.283214\n",
      "[115]\ttraining's l2: 0.293707\tvalid_1's l2: 0.28318\n",
      "[116]\ttraining's l2: 0.293642\tvalid_1's l2: 0.283128\n",
      "[117]\ttraining's l2: 0.293548\tvalid_1's l2: 0.283052\n",
      "[118]\ttraining's l2: 0.293458\tvalid_1's l2: 0.283009\n",
      "[119]\ttraining's l2: 0.293375\tvalid_1's l2: 0.282983\n",
      "[120]\ttraining's l2: 0.293314\tvalid_1's l2: 0.282939\n",
      "[121]\ttraining's l2: 0.293236\tvalid_1's l2: 0.282941\n",
      "[122]\ttraining's l2: 0.293168\tvalid_1's l2: 0.282899\n",
      "[123]\ttraining's l2: 0.293102\tvalid_1's l2: 0.282842\n",
      "[124]\ttraining's l2: 0.293048\tvalid_1's l2: 0.282822\n",
      "[125]\ttraining's l2: 0.292978\tvalid_1's l2: 0.282805\n",
      "[126]\ttraining's l2: 0.292907\tvalid_1's l2: 0.282747\n",
      "[127]\ttraining's l2: 0.292839\tvalid_1's l2: 0.282742\n",
      "[128]\ttraining's l2: 0.29277\tvalid_1's l2: 0.282718\n",
      "[129]\ttraining's l2: 0.29272\tvalid_1's l2: 0.282693\n",
      "[130]\ttraining's l2: 0.292668\tvalid_1's l2: 0.28267\n",
      "[131]\ttraining's l2: 0.292614\tvalid_1's l2: 0.282639\n",
      "[132]\ttraining's l2: 0.292547\tvalid_1's l2: 0.28259\n",
      "[133]\ttraining's l2: 0.292496\tvalid_1's l2: 0.282567\n",
      "[134]\ttraining's l2: 0.292451\tvalid_1's l2: 0.282524\n",
      "[135]\ttraining's l2: 0.292398\tvalid_1's l2: 0.282495\n",
      "[136]\ttraining's l2: 0.292339\tvalid_1's l2: 0.282453\n",
      "[137]\ttraining's l2: 0.292288\tvalid_1's l2: 0.282419\n",
      "[138]\ttraining's l2: 0.29224\tvalid_1's l2: 0.282375\n",
      "[139]\ttraining's l2: 0.292184\tvalid_1's l2: 0.282363\n",
      "[140]\ttraining's l2: 0.29212\tvalid_1's l2: 0.282362\n",
      "[141]\ttraining's l2: 0.292085\tvalid_1's l2: 0.282342\n",
      "[142]\ttraining's l2: 0.292031\tvalid_1's l2: 0.282322\n",
      "[143]\ttraining's l2: 0.291983\tvalid_1's l2: 0.282285\n",
      "[144]\ttraining's l2: 0.29192\tvalid_1's l2: 0.282242\n",
      "[145]\ttraining's l2: 0.291858\tvalid_1's l2: 0.282202\n",
      "[146]\ttraining's l2: 0.291807\tvalid_1's l2: 0.282166\n",
      "[147]\ttraining's l2: 0.291761\tvalid_1's l2: 0.282146\n",
      "[148]\ttraining's l2: 0.291713\tvalid_1's l2: 0.282116\n",
      "[149]\ttraining's l2: 0.291642\tvalid_1's l2: 0.282114\n",
      "[150]\ttraining's l2: 0.291596\tvalid_1's l2: 0.282103\n",
      "[151]\ttraining's l2: 0.291547\tvalid_1's l2: 0.282072\n",
      "[152]\ttraining's l2: 0.291504\tvalid_1's l2: 0.282059\n",
      "[153]\ttraining's l2: 0.291455\tvalid_1's l2: 0.282049\n",
      "[154]\ttraining's l2: 0.291405\tvalid_1's l2: 0.282018\n",
      "[155]\ttraining's l2: 0.291358\tvalid_1's l2: 0.281992\n",
      "[156]\ttraining's l2: 0.291314\tvalid_1's l2: 0.281975\n",
      "[157]\ttraining's l2: 0.291271\tvalid_1's l2: 0.281941\n",
      "[158]\ttraining's l2: 0.291221\tvalid_1's l2: 0.281916\n",
      "[159]\ttraining's l2: 0.291174\tvalid_1's l2: 0.281901\n",
      "[160]\ttraining's l2: 0.29113\tvalid_1's l2: 0.281875\n",
      "[161]\ttraining's l2: 0.291078\tvalid_1's l2: 0.281842\n",
      "[162]\ttraining's l2: 0.291025\tvalid_1's l2: 0.28183\n",
      "[163]\ttraining's l2: 0.29098\tvalid_1's l2: 0.281815\n",
      "[164]\ttraining's l2: 0.29095\tvalid_1's l2: 0.281789\n",
      "[165]\ttraining's l2: 0.29091\tvalid_1's l2: 0.281771\n",
      "[166]\ttraining's l2: 0.290864\tvalid_1's l2: 0.281749\n",
      "[167]\ttraining's l2: 0.290826\tvalid_1's l2: 0.281726\n",
      "[168]\ttraining's l2: 0.290797\tvalid_1's l2: 0.281724\n",
      "[169]\ttraining's l2: 0.290741\tvalid_1's l2: 0.281703\n",
      "[170]\ttraining's l2: 0.290695\tvalid_1's l2: 0.281706\n",
      "[171]\ttraining's l2: 0.290651\tvalid_1's l2: 0.281669\n",
      "[172]\ttraining's l2: 0.290614\tvalid_1's l2: 0.281669\n",
      "[173]\ttraining's l2: 0.290576\tvalid_1's l2: 0.281672\n",
      "[174]\ttraining's l2: 0.290544\tvalid_1's l2: 0.281643\n",
      "[175]\ttraining's l2: 0.290506\tvalid_1's l2: 0.28162\n",
      "[176]\ttraining's l2: 0.290477\tvalid_1's l2: 0.281606\n",
      "[177]\ttraining's l2: 0.29044\tvalid_1's l2: 0.281583\n",
      "[178]\ttraining's l2: 0.290401\tvalid_1's l2: 0.281553\n",
      "[179]\ttraining's l2: 0.29034\tvalid_1's l2: 0.281501\n",
      "[180]\ttraining's l2: 0.290303\tvalid_1's l2: 0.28147\n",
      "[181]\ttraining's l2: 0.290274\tvalid_1's l2: 0.281449\n",
      "[182]\ttraining's l2: 0.290236\tvalid_1's l2: 0.281458\n",
      "[183]\ttraining's l2: 0.290202\tvalid_1's l2: 0.281449\n",
      "[184]\ttraining's l2: 0.290167\tvalid_1's l2: 0.281424\n",
      "[185]\ttraining's l2: 0.290117\tvalid_1's l2: 0.281391\n",
      "[186]\ttraining's l2: 0.29009\tvalid_1's l2: 0.281392\n",
      "[187]\ttraining's l2: 0.29006\tvalid_1's l2: 0.281372\n",
      "[188]\ttraining's l2: 0.290024\tvalid_1's l2: 0.281357\n",
      "[189]\ttraining's l2: 0.289995\tvalid_1's l2: 0.281346\n",
      "[190]\ttraining's l2: 0.289961\tvalid_1's l2: 0.281337\n",
      "[191]\ttraining's l2: 0.289932\tvalid_1's l2: 0.281312\n",
      "[192]\ttraining's l2: 0.289897\tvalid_1's l2: 0.281291\n",
      "[193]\ttraining's l2: 0.289864\tvalid_1's l2: 0.281272\n",
      "[194]\ttraining's l2: 0.289837\tvalid_1's l2: 0.281248\n",
      "[195]\ttraining's l2: 0.289813\tvalid_1's l2: 0.281223\n",
      "[196]\ttraining's l2: 0.289773\tvalid_1's l2: 0.281194\n",
      "[197]\ttraining's l2: 0.289751\tvalid_1's l2: 0.281191\n",
      "[198]\ttraining's l2: 0.289715\tvalid_1's l2: 0.281159\n",
      "[199]\ttraining's l2: 0.289675\tvalid_1's l2: 0.281177\n",
      "[200]\ttraining's l2: 0.289629\tvalid_1's l2: 0.281152\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.289629\tvalid_1's l2: 0.281152\n",
      "mean_7_sales: 11228647.30\n",
      "mean_14_sales: 9163262.26\n",
      "mean_6_sales: 1745537.61\n",
      "mean_30_sales: 751251.61\n",
      "promo_0: 745101.98\n",
      "lag_1_sales: 736490.31\n",
      "mean_5_sales: 634216.80\n",
      "mean_20_dow0_2017: 605767.36\n",
      "mean_21_sales: 430031.01\n",
      "mean_4_dow0_2017: 377001.09\n",
      "mean_3_sales: 179423.90\n",
      "mean_63_sales: 161782.28\n",
      "item_class_features: 147625.11\n",
      "sum_7_promo: 144681.49\n",
      "std_14_sales: 124579.72\n",
      "item_family_features: 56024.62\n",
      "store_cluster_features: 55616.58\n",
      "promo_7: 51473.85\n",
      "sum_2_promo: 45063.82\n",
      "sum_4_promo: 43441.26\n",
      "lag_2_sales: 42388.88\n",
      "std_7_sales: 39510.49\n",
      "sum_14_promo: 39166.28\n",
      "mean_4_sales: 33757.62\n",
      "std_21_sales: 30662.73\n",
      "std_30_sales: 22706.61\n",
      "lag_28_sales: 16259.02\n",
      "mean_4_dow6_2017: 16104.46\n",
      "store_type_features: 15760.25\n",
      "lag_3_transactions: 15393.25\n",
      "lag_14_sales: 14714.05\n",
      "mean_60_sales: 13451.48\n",
      "std_6_sales: 13428.62\n",
      "sum_3_promo: 13119.13\n",
      "std_63_sales: 12446.03\n",
      "sum_21_promo: 12313.84\n",
      "lag_2_transactions: 11456.62\n",
      "lag_56_sales: 9900.93\n",
      "std_60_sales: 8971.52\n",
      "store_city_features: 8954.06\n",
      "lag_63_sales: 8639.09\n",
      "lag_35_sales: 8382.36\n",
      "lag_1_transactions: 7894.45\n",
      "lag_5_transactions: 7187.65\n",
      "lag_7_sales: 6868.13\n",
      "std_5_sales: 6379.79\n",
      "mean_20_dow2_2017: 6366.03\n",
      "lag_42_sales: 6011.86\n",
      "mean_4_dow5_2017: 5386.16\n",
      "promo_14: 4636.42\n",
      "lag_7_transactions: 4291.29\n",
      "std_3_sales: 4135.12\n",
      "lag_14_transactions: 3910.35\n",
      "lag_5_sales: 3817.77\n",
      "lag_3_sales: 3756.53\n",
      "std_4_sales: 3730.29\n",
      "mean_20_dow6_2017: 3636.47\n",
      "mean_20_dow4_2017: 3573.48\n",
      "lag_4_sales: 3406.28\n",
      "promo_3: 3319.64\n",
      "mean_20_dow3_2017: 3142.46\n",
      "mean_20_dow1_2017: 2730.36\n",
      "store_state_features: 2695.02\n",
      "lag_21_transactions: 2631.69\n",
      "promo_1: 2629.12\n",
      "sum_5_promo: 2419.32\n",
      "sum_6_promo: 2413.34\n",
      "mean_20_dow5_2017: 2303.71\n",
      "lag_6_transactions: 2247.87\n",
      "lag_6_sales: 2000.17\n",
      "lag_4_transactions: 1954.85\n",
      "promo_6: 1815.81\n",
      "promo_4: 1734.94\n",
      "promo_13: 1326.13\n",
      "promo_5: 1099.68\n",
      "promo_15: 1005.57\n",
      "promo_9: 988.46\n",
      "promo_2: 908.16\n",
      "mean_4_dow3_2017: 779.91\n",
      "mean_4_dow2_2017: 643.33\n",
      "mean_4_dow1_2017: 576.59\n",
      "mean_4_dow4_2017: 519.99\n",
      "promo_12: 335.86\n",
      "promo_11: 305.95\n",
      "promo_8: 300.32\n",
      "lag_21_sales: 275.13\n",
      "promo_10: 253.83\n",
      "lag_49_sales: 208.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [01:45<26:24, 105.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.94861\tvalid_1's l2: 0.92514\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.890743\tvalid_1's l2: 0.868577\n",
      "[3]\ttraining's l2: 0.838411\tvalid_1's l2: 0.817683\n",
      "[4]\ttraining's l2: 0.791094\tvalid_1's l2: 0.771371\n",
      "[5]\ttraining's l2: 0.748662\tvalid_1's l2: 0.730161\n",
      "[6]\ttraining's l2: 0.710467\tvalid_1's l2: 0.693095\n",
      "[7]\ttraining's l2: 0.675701\tvalid_1's l2: 0.659396\n",
      "[8]\ttraining's l2: 0.643618\tvalid_1's l2: 0.628102\n",
      "[9]\ttraining's l2: 0.614662\tvalid_1's l2: 0.599758\n",
      "[10]\ttraining's l2: 0.588515\tvalid_1's l2: 0.574308\n",
      "[11]\ttraining's l2: 0.564743\tvalid_1's l2: 0.551102\n",
      "[12]\ttraining's l2: 0.543097\tvalid_1's l2: 0.530072\n",
      "[13]\ttraining's l2: 0.523631\tvalid_1's l2: 0.511141\n",
      "[14]\ttraining's l2: 0.505973\tvalid_1's l2: 0.493935\n",
      "[15]\ttraining's l2: 0.489997\tvalid_1's l2: 0.47848\n",
      "[16]\ttraining's l2: 0.475799\tvalid_1's l2: 0.464806\n",
      "[17]\ttraining's l2: 0.462933\tvalid_1's l2: 0.452526\n",
      "[18]\ttraining's l2: 0.451015\tvalid_1's l2: 0.440911\n",
      "[19]\ttraining's l2: 0.440437\tvalid_1's l2: 0.430826\n",
      "[20]\ttraining's l2: 0.430862\tvalid_1's l2: 0.421682\n",
      "[21]\ttraining's l2: 0.421856\tvalid_1's l2: 0.412964\n",
      "[22]\ttraining's l2: 0.413733\tvalid_1's l2: 0.40503\n",
      "[23]\ttraining's l2: 0.406271\tvalid_1's l2: 0.397815\n",
      "[24]\ttraining's l2: 0.399543\tvalid_1's l2: 0.391279\n",
      "[25]\ttraining's l2: 0.393358\tvalid_1's l2: 0.385201\n",
      "[26]\ttraining's l2: 0.388047\tvalid_1's l2: 0.380169\n",
      "[27]\ttraining's l2: 0.38296\tvalid_1's l2: 0.375208\n",
      "[28]\ttraining's l2: 0.378309\tvalid_1's l2: 0.370601\n",
      "[29]\ttraining's l2: 0.374281\tvalid_1's l2: 0.366846\n",
      "[30]\ttraining's l2: 0.370433\tvalid_1's l2: 0.363108\n",
      "[31]\ttraining's l2: 0.366939\tvalid_1's l2: 0.359696\n",
      "[32]\ttraining's l2: 0.363721\tvalid_1's l2: 0.356594\n",
      "[33]\ttraining's l2: 0.360817\tvalid_1's l2: 0.353811\n",
      "[34]\ttraining's l2: 0.358214\tvalid_1's l2: 0.351282\n",
      "[35]\ttraining's l2: 0.355777\tvalid_1's l2: 0.348871\n",
      "[36]\ttraining's l2: 0.353586\tvalid_1's l2: 0.346769\n",
      "[37]\ttraining's l2: 0.351544\tvalid_1's l2: 0.344739\n",
      "[38]\ttraining's l2: 0.349635\tvalid_1's l2: 0.342911\n",
      "[39]\ttraining's l2: 0.347891\tvalid_1's l2: 0.341281\n",
      "[40]\ttraining's l2: 0.346286\tvalid_1's l2: 0.339773\n",
      "[41]\ttraining's l2: 0.34484\tvalid_1's l2: 0.338393\n",
      "[42]\ttraining's l2: 0.343504\tvalid_1's l2: 0.337132\n",
      "[43]\ttraining's l2: 0.342288\tvalid_1's l2: 0.335988\n",
      "[44]\ttraining's l2: 0.341172\tvalid_1's l2: 0.334938\n",
      "[45]\ttraining's l2: 0.340138\tvalid_1's l2: 0.333968\n",
      "[46]\ttraining's l2: 0.33924\tvalid_1's l2: 0.333155\n",
      "[47]\ttraining's l2: 0.338315\tvalid_1's l2: 0.332203\n",
      "[48]\ttraining's l2: 0.337452\tvalid_1's l2: 0.331348\n",
      "[49]\ttraining's l2: 0.336679\tvalid_1's l2: 0.330604\n",
      "[50]\ttraining's l2: 0.335944\tvalid_1's l2: 0.329926\n",
      "[51]\ttraining's l2: 0.33529\tvalid_1's l2: 0.329346\n",
      "[52]\ttraining's l2: 0.334693\tvalid_1's l2: 0.328863\n",
      "[53]\ttraining's l2: 0.334072\tvalid_1's l2: 0.328251\n",
      "[54]\ttraining's l2: 0.333487\tvalid_1's l2: 0.327699\n",
      "[55]\ttraining's l2: 0.332989\tvalid_1's l2: 0.327234\n",
      "[56]\ttraining's l2: 0.332484\tvalid_1's l2: 0.326752\n",
      "[57]\ttraining's l2: 0.332048\tvalid_1's l2: 0.326424\n",
      "[58]\ttraining's l2: 0.3316\tvalid_1's l2: 0.326044\n",
      "[59]\ttraining's l2: 0.331206\tvalid_1's l2: 0.325606\n",
      "[60]\ttraining's l2: 0.330812\tvalid_1's l2: 0.32524\n",
      "[61]\ttraining's l2: 0.330428\tvalid_1's l2: 0.324887\n",
      "[62]\ttraining's l2: 0.330079\tvalid_1's l2: 0.324531\n",
      "[63]\ttraining's l2: 0.329732\tvalid_1's l2: 0.324229\n",
      "[64]\ttraining's l2: 0.329433\tvalid_1's l2: 0.324006\n",
      "[65]\ttraining's l2: 0.329134\tvalid_1's l2: 0.323725\n",
      "[66]\ttraining's l2: 0.328874\tvalid_1's l2: 0.323481\n",
      "[67]\ttraining's l2: 0.328632\tvalid_1's l2: 0.323223\n",
      "[68]\ttraining's l2: 0.328342\tvalid_1's l2: 0.322969\n",
      "[69]\ttraining's l2: 0.328103\tvalid_1's l2: 0.322739\n",
      "[70]\ttraining's l2: 0.327884\tvalid_1's l2: 0.322577\n",
      "[71]\ttraining's l2: 0.327657\tvalid_1's l2: 0.322413\n",
      "[72]\ttraining's l2: 0.327463\tvalid_1's l2: 0.322279\n",
      "[73]\ttraining's l2: 0.327229\tvalid_1's l2: 0.32201\n",
      "[74]\ttraining's l2: 0.327004\tvalid_1's l2: 0.321767\n",
      "[75]\ttraining's l2: 0.326786\tvalid_1's l2: 0.321493\n",
      "[76]\ttraining's l2: 0.326579\tvalid_1's l2: 0.32125\n",
      "[77]\ttraining's l2: 0.326418\tvalid_1's l2: 0.321145\n",
      "[78]\ttraining's l2: 0.326268\tvalid_1's l2: 0.321042\n",
      "[79]\ttraining's l2: 0.326097\tvalid_1's l2: 0.320869\n",
      "[80]\ttraining's l2: 0.325902\tvalid_1's l2: 0.320643\n",
      "[81]\ttraining's l2: 0.325727\tvalid_1's l2: 0.320446\n",
      "[82]\ttraining's l2: 0.325561\tvalid_1's l2: 0.320295\n",
      "[83]\ttraining's l2: 0.325427\tvalid_1's l2: 0.32019\n",
      "[84]\ttraining's l2: 0.325294\tvalid_1's l2: 0.320074\n",
      "[85]\ttraining's l2: 0.32514\tvalid_1's l2: 0.319902\n",
      "[86]\ttraining's l2: 0.324995\tvalid_1's l2: 0.319762\n",
      "[87]\ttraining's l2: 0.32486\tvalid_1's l2: 0.319706\n",
      "[88]\ttraining's l2: 0.324737\tvalid_1's l2: 0.319629\n",
      "[89]\ttraining's l2: 0.324595\tvalid_1's l2: 0.31949\n",
      "[90]\ttraining's l2: 0.324483\tvalid_1's l2: 0.319329\n",
      "[91]\ttraining's l2: 0.324351\tvalid_1's l2: 0.319212\n",
      "[92]\ttraining's l2: 0.324241\tvalid_1's l2: 0.3191\n",
      "[93]\ttraining's l2: 0.324128\tvalid_1's l2: 0.319031\n",
      "[94]\ttraining's l2: 0.324029\tvalid_1's l2: 0.318975\n",
      "[95]\ttraining's l2: 0.323913\tvalid_1's l2: 0.31891\n",
      "[96]\ttraining's l2: 0.323791\tvalid_1's l2: 0.318823\n",
      "[97]\ttraining's l2: 0.323659\tvalid_1's l2: 0.318705\n",
      "[98]\ttraining's l2: 0.323525\tvalid_1's l2: 0.31867\n",
      "[99]\ttraining's l2: 0.323412\tvalid_1's l2: 0.318571\n",
      "[100]\ttraining's l2: 0.323328\tvalid_1's l2: 0.318483\n",
      "[101]\ttraining's l2: 0.323221\tvalid_1's l2: 0.31844\n",
      "[102]\ttraining's l2: 0.323123\tvalid_1's l2: 0.318388\n",
      "[103]\ttraining's l2: 0.323027\tvalid_1's l2: 0.31835\n",
      "[104]\ttraining's l2: 0.322938\tvalid_1's l2: 0.31829\n",
      "[105]\ttraining's l2: 0.322817\tvalid_1's l2: 0.318268\n",
      "[106]\ttraining's l2: 0.322736\tvalid_1's l2: 0.318239\n",
      "[107]\ttraining's l2: 0.322649\tvalid_1's l2: 0.318167\n",
      "[108]\ttraining's l2: 0.322535\tvalid_1's l2: 0.318033\n",
      "[109]\ttraining's l2: 0.322443\tvalid_1's l2: 0.31793\n",
      "[110]\ttraining's l2: 0.322349\tvalid_1's l2: 0.317879\n",
      "[111]\ttraining's l2: 0.322237\tvalid_1's l2: 0.317841\n",
      "[112]\ttraining's l2: 0.322147\tvalid_1's l2: 0.317747\n",
      "[113]\ttraining's l2: 0.322055\tvalid_1's l2: 0.317627\n",
      "[114]\ttraining's l2: 0.321939\tvalid_1's l2: 0.317513\n",
      "[115]\ttraining's l2: 0.321867\tvalid_1's l2: 0.317456\n",
      "[116]\ttraining's l2: 0.32179\tvalid_1's l2: 0.317427\n",
      "[117]\ttraining's l2: 0.321707\tvalid_1's l2: 0.317332\n",
      "[118]\ttraining's l2: 0.321613\tvalid_1's l2: 0.317292\n",
      "[119]\ttraining's l2: 0.321568\tvalid_1's l2: 0.317281\n",
      "[120]\ttraining's l2: 0.321506\tvalid_1's l2: 0.317237\n",
      "[121]\ttraining's l2: 0.321425\tvalid_1's l2: 0.317179\n",
      "[122]\ttraining's l2: 0.321351\tvalid_1's l2: 0.317161\n",
      "[123]\ttraining's l2: 0.321264\tvalid_1's l2: 0.317037\n",
      "[124]\ttraining's l2: 0.321188\tvalid_1's l2: 0.317005\n",
      "[125]\ttraining's l2: 0.321111\tvalid_1's l2: 0.316878\n",
      "[126]\ttraining's l2: 0.321041\tvalid_1's l2: 0.31685\n",
      "[127]\ttraining's l2: 0.320959\tvalid_1's l2: 0.316767\n",
      "[128]\ttraining's l2: 0.32087\tvalid_1's l2: 0.316699\n",
      "[129]\ttraining's l2: 0.320802\tvalid_1's l2: 0.316685\n",
      "[130]\ttraining's l2: 0.320712\tvalid_1's l2: 0.316627\n",
      "[131]\ttraining's l2: 0.320662\tvalid_1's l2: 0.316622\n",
      "[132]\ttraining's l2: 0.320595\tvalid_1's l2: 0.31658\n",
      "[133]\ttraining's l2: 0.320533\tvalid_1's l2: 0.316532\n",
      "[134]\ttraining's l2: 0.320461\tvalid_1's l2: 0.31648\n",
      "[135]\ttraining's l2: 0.320385\tvalid_1's l2: 0.316464\n",
      "[136]\ttraining's l2: 0.320325\tvalid_1's l2: 0.316395\n",
      "[137]\ttraining's l2: 0.320255\tvalid_1's l2: 0.316368\n",
      "[138]\ttraining's l2: 0.320201\tvalid_1's l2: 0.316337\n",
      "[139]\ttraining's l2: 0.320155\tvalid_1's l2: 0.316331\n",
      "[140]\ttraining's l2: 0.320112\tvalid_1's l2: 0.316339\n",
      "[141]\ttraining's l2: 0.320053\tvalid_1's l2: 0.316302\n",
      "[142]\ttraining's l2: 0.319991\tvalid_1's l2: 0.316264\n",
      "[143]\ttraining's l2: 0.319929\tvalid_1's l2: 0.316201\n",
      "[144]\ttraining's l2: 0.319873\tvalid_1's l2: 0.316188\n",
      "[145]\ttraining's l2: 0.319809\tvalid_1's l2: 0.31617\n",
      "[146]\ttraining's l2: 0.319735\tvalid_1's l2: 0.316096\n",
      "[147]\ttraining's l2: 0.31968\tvalid_1's l2: 0.316112\n",
      "[148]\ttraining's l2: 0.319624\tvalid_1's l2: 0.316054\n",
      "[149]\ttraining's l2: 0.319576\tvalid_1's l2: 0.316049\n",
      "[150]\ttraining's l2: 0.319517\tvalid_1's l2: 0.316049\n",
      "[151]\ttraining's l2: 0.31946\tvalid_1's l2: 0.315975\n",
      "[152]\ttraining's l2: 0.319411\tvalid_1's l2: 0.315935\n",
      "[153]\ttraining's l2: 0.319353\tvalid_1's l2: 0.315936\n",
      "[154]\ttraining's l2: 0.319308\tvalid_1's l2: 0.315885\n",
      "[155]\ttraining's l2: 0.319255\tvalid_1's l2: 0.315878\n",
      "[156]\ttraining's l2: 0.319208\tvalid_1's l2: 0.315851\n",
      "[157]\ttraining's l2: 0.319165\tvalid_1's l2: 0.315849\n",
      "[158]\ttraining's l2: 0.319099\tvalid_1's l2: 0.315785\n",
      "[159]\ttraining's l2: 0.319047\tvalid_1's l2: 0.315778\n",
      "[160]\ttraining's l2: 0.318998\tvalid_1's l2: 0.315785\n",
      "[161]\ttraining's l2: 0.318946\tvalid_1's l2: 0.315736\n",
      "[162]\ttraining's l2: 0.318898\tvalid_1's l2: 0.31574\n",
      "[163]\ttraining's l2: 0.318851\tvalid_1's l2: 0.315733\n",
      "[164]\ttraining's l2: 0.318819\tvalid_1's l2: 0.315715\n",
      "[165]\ttraining's l2: 0.318773\tvalid_1's l2: 0.315713\n",
      "[166]\ttraining's l2: 0.318742\tvalid_1's l2: 0.315701\n",
      "[167]\ttraining's l2: 0.318676\tvalid_1's l2: 0.315624\n",
      "[168]\ttraining's l2: 0.31864\tvalid_1's l2: 0.315593\n",
      "[169]\ttraining's l2: 0.318606\tvalid_1's l2: 0.31557\n",
      "[170]\ttraining's l2: 0.318565\tvalid_1's l2: 0.315522\n",
      "[171]\ttraining's l2: 0.31853\tvalid_1's l2: 0.315522\n",
      "[172]\ttraining's l2: 0.318481\tvalid_1's l2: 0.31551\n",
      "[173]\ttraining's l2: 0.318446\tvalid_1's l2: 0.315499\n",
      "[174]\ttraining's l2: 0.31841\tvalid_1's l2: 0.315462\n",
      "[175]\ttraining's l2: 0.318387\tvalid_1's l2: 0.315449\n",
      "[176]\ttraining's l2: 0.318354\tvalid_1's l2: 0.315451\n",
      "[177]\ttraining's l2: 0.318311\tvalid_1's l2: 0.315422\n",
      "[178]\ttraining's l2: 0.318256\tvalid_1's l2: 0.315366\n",
      "[179]\ttraining's l2: 0.318226\tvalid_1's l2: 0.315366\n",
      "[180]\ttraining's l2: 0.318182\tvalid_1's l2: 0.315348\n",
      "[181]\ttraining's l2: 0.318145\tvalid_1's l2: 0.315339\n",
      "[182]\ttraining's l2: 0.318106\tvalid_1's l2: 0.315326\n",
      "[183]\ttraining's l2: 0.318063\tvalid_1's l2: 0.315273\n",
      "[184]\ttraining's l2: 0.318034\tvalid_1's l2: 0.315267\n",
      "[185]\ttraining's l2: 0.317999\tvalid_1's l2: 0.315263\n",
      "[186]\ttraining's l2: 0.317966\tvalid_1's l2: 0.315257\n",
      "[187]\ttraining's l2: 0.317931\tvalid_1's l2: 0.315237\n",
      "[188]\ttraining's l2: 0.317899\tvalid_1's l2: 0.315232\n",
      "[189]\ttraining's l2: 0.317851\tvalid_1's l2: 0.315232\n",
      "[190]\ttraining's l2: 0.317819\tvalid_1's l2: 0.315234\n",
      "[191]\ttraining's l2: 0.317784\tvalid_1's l2: 0.315213\n",
      "[192]\ttraining's l2: 0.317742\tvalid_1's l2: 0.315183\n",
      "[193]\ttraining's l2: 0.317704\tvalid_1's l2: 0.31518\n",
      "[194]\ttraining's l2: 0.317666\tvalid_1's l2: 0.315156\n",
      "[195]\ttraining's l2: 0.317635\tvalid_1's l2: 0.315126\n",
      "[196]\ttraining's l2: 0.317604\tvalid_1's l2: 0.315108\n",
      "[197]\ttraining's l2: 0.317566\tvalid_1's l2: 0.315125\n",
      "[198]\ttraining's l2: 0.317534\tvalid_1's l2: 0.315125\n",
      "[199]\ttraining's l2: 0.317493\tvalid_1's l2: 0.31512\n",
      "[200]\ttraining's l2: 0.317462\tvalid_1's l2: 0.315096\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.317462\tvalid_1's l2: 0.315096\n",
      "mean_14_sales: 8736730.55\n",
      "mean_7_sales: 7085128.41\n",
      "mean_6_sales: 3371752.01\n",
      "mean_30_sales: 1075574.00\n",
      "mean_20_dow1_2017: 460206.79\n",
      "promo_1: 459732.96\n",
      "lag_1_sales: 324691.87\n",
      "mean_63_sales: 275490.40\n",
      "mean_21_sales: 250580.04\n",
      "item_class_features: 152669.23\n",
      "mean_4_dow1_2017: 132999.34\n",
      "mean_5_sales: 95664.57\n",
      "std_14_sales: 79844.28\n",
      "sum_4_promo: 67544.90\n",
      "sum_2_promo: 51758.43\n",
      "mean_3_sales: 46422.87\n",
      "sum_6_promo: 41440.87\n",
      "promo_0: 40121.66\n",
      "std_30_sales: 28182.34\n",
      "mean_20_dow2_2017: 27066.90\n",
      "mean_4_sales: 26189.32\n",
      "std_21_sales: 23805.65\n",
      "promo_3: 23375.39\n",
      "std_7_sales: 23163.93\n",
      "mean_4_dow2_2017: 17798.39\n",
      "lag_3_transactions: 17516.62\n",
      "lag_28_sales: 17094.40\n",
      "lag_1_transactions: 16780.40\n",
      "promo_2: 13654.20\n",
      "sum_7_promo: 13412.83\n",
      "promo_4: 11929.38\n",
      "sum_3_promo: 11810.65\n",
      "promo_5: 11268.33\n",
      "lag_5_sales: 10461.69\n",
      "mean_60_sales: 9830.13\n",
      "lag_5_transactions: 9072.94\n",
      "std_60_sales: 8875.03\n",
      "std_6_sales: 8326.22\n",
      "item_family_features: 8322.61\n",
      "std_5_sales: 8129.12\n",
      "std_63_sales: 7954.72\n",
      "store_city_features: 7849.72\n",
      "promo_7: 7557.03\n",
      "lag_2_transactions: 7366.33\n",
      "lag_2_sales: 7105.32\n",
      "lag_4_transactions: 6792.60\n",
      "sum_14_promo: 6617.24\n",
      "lag_14_transactions: 6443.18\n",
      "mean_20_dow0_2017: 6399.82\n",
      "lag_6_sales: 6018.23\n",
      "sum_5_promo: 5711.88\n",
      "lag_6_transactions: 5456.42\n",
      "store_cluster_features: 5045.85\n",
      "mean_4_dow6_2017: 4854.77\n",
      "lag_21_transactions: 4549.13\n",
      "lag_7_transactions: 4293.92\n",
      "lag_56_sales: 4285.10\n",
      "sum_21_promo: 4283.34\n",
      "mean_20_dow6_2017: 3776.67\n",
      "mean_20_dow4_2017: 3503.81\n",
      "promo_6: 3027.34\n",
      "mean_20_dow3_2017: 2947.41\n",
      "lag_4_sales: 2689.15\n",
      "lag_14_sales: 2200.99\n",
      "mean_4_dow5_2017: 2198.10\n",
      "lag_3_sales: 2190.76\n",
      "promo_14: 2160.02\n",
      "mean_4_dow0_2017: 1978.23\n",
      "std_4_sales: 1762.14\n",
      "promo_8: 1651.77\n",
      "lag_63_sales: 1545.61\n",
      "mean_4_dow3_2017: 1359.67\n",
      "lag_42_sales: 1255.68\n",
      "lag_7_sales: 1231.38\n",
      "store_state_features: 955.53\n",
      "std_3_sales: 921.82\n",
      "store_type_features: 829.90\n",
      "mean_20_dow5_2017: 618.57\n",
      "mean_4_dow4_2017: 432.24\n",
      "promo_15: 372.79\n",
      "lag_21_sales: 322.33\n",
      "lag_35_sales: 281.39\n",
      "promo_10: 196.50\n",
      "promo_13: 189.39\n",
      "promo_9: 163.23\n",
      "promo_12: 148.47\n",
      "lag_49_sales: 91.48\n",
      "promo_11: 32.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [03:26<24:17, 104.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05416\tvalid_1's l2: 1.0597\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.987435\tvalid_1's l2: 0.993141\n",
      "[3]\ttraining's l2: 0.927044\tvalid_1's l2: 0.932941\n",
      "[4]\ttraining's l2: 0.872288\tvalid_1's l2: 0.878221\n",
      "[5]\ttraining's l2: 0.822736\tvalid_1's l2: 0.828741\n",
      "[6]\ttraining's l2: 0.777793\tvalid_1's l2: 0.783905\n",
      "[7]\ttraining's l2: 0.737258\tvalid_1's l2: 0.743382\n",
      "[8]\ttraining's l2: 0.700401\tvalid_1's l2: 0.706458\n",
      "[9]\ttraining's l2: 0.666975\tvalid_1's l2: 0.672948\n",
      "[10]\ttraining's l2: 0.636805\tvalid_1's l2: 0.642687\n",
      "[11]\ttraining's l2: 0.609837\tvalid_1's l2: 0.615817\n",
      "[12]\ttraining's l2: 0.584994\tvalid_1's l2: 0.590912\n",
      "[13]\ttraining's l2: 0.562452\tvalid_1's l2: 0.568352\n",
      "[14]\ttraining's l2: 0.542018\tvalid_1's l2: 0.547933\n",
      "[15]\ttraining's l2: 0.524055\tvalid_1's l2: 0.529924\n",
      "[16]\ttraining's l2: 0.507191\tvalid_1's l2: 0.513021\n",
      "[17]\ttraining's l2: 0.492251\tvalid_1's l2: 0.498021\n",
      "[18]\ttraining's l2: 0.478304\tvalid_1's l2: 0.48402\n",
      "[19]\ttraining's l2: 0.465736\tvalid_1's l2: 0.471369\n",
      "[20]\ttraining's l2: 0.45458\tvalid_1's l2: 0.460166\n",
      "[21]\ttraining's l2: 0.444078\tvalid_1's l2: 0.449576\n",
      "[22]\ttraining's l2: 0.434493\tvalid_1's l2: 0.439891\n",
      "[23]\ttraining's l2: 0.425826\tvalid_1's l2: 0.431114\n",
      "[24]\ttraining's l2: 0.417945\tvalid_1's l2: 0.423141\n",
      "[25]\ttraining's l2: 0.410787\tvalid_1's l2: 0.41592\n",
      "[26]\ttraining's l2: 0.404257\tvalid_1's l2: 0.409293\n",
      "[27]\ttraining's l2: 0.398344\tvalid_1's l2: 0.403271\n",
      "[28]\ttraining's l2: 0.393153\tvalid_1's l2: 0.398045\n",
      "[29]\ttraining's l2: 0.388124\tvalid_1's l2: 0.392868\n",
      "[30]\ttraining's l2: 0.383558\tvalid_1's l2: 0.388209\n",
      "[31]\ttraining's l2: 0.379478\tvalid_1's l2: 0.384076\n",
      "[32]\ttraining's l2: 0.375779\tvalid_1's l2: 0.380358\n",
      "[33]\ttraining's l2: 0.372326\tvalid_1's l2: 0.376887\n",
      "[34]\ttraining's l2: 0.369163\tvalid_1's l2: 0.373734\n",
      "[35]\ttraining's l2: 0.366298\tvalid_1's l2: 0.3708\n",
      "[36]\ttraining's l2: 0.363625\tvalid_1's l2: 0.368037\n",
      "[37]\ttraining's l2: 0.361216\tvalid_1's l2: 0.365593\n",
      "[38]\ttraining's l2: 0.359041\tvalid_1's l2: 0.363373\n",
      "[39]\ttraining's l2: 0.357026\tvalid_1's l2: 0.3613\n",
      "[40]\ttraining's l2: 0.355153\tvalid_1's l2: 0.359393\n",
      "[41]\ttraining's l2: 0.353444\tvalid_1's l2: 0.357668\n",
      "[42]\ttraining's l2: 0.35186\tvalid_1's l2: 0.356032\n",
      "[43]\ttraining's l2: 0.35042\tvalid_1's l2: 0.354577\n",
      "[44]\ttraining's l2: 0.349109\tvalid_1's l2: 0.353279\n",
      "[45]\ttraining's l2: 0.347872\tvalid_1's l2: 0.35206\n",
      "[46]\ttraining's l2: 0.346649\tvalid_1's l2: 0.350825\n",
      "[47]\ttraining's l2: 0.345536\tvalid_1's l2: 0.34965\n",
      "[48]\ttraining's l2: 0.344558\tvalid_1's l2: 0.348671\n",
      "[49]\ttraining's l2: 0.343689\tvalid_1's l2: 0.34779\n",
      "[50]\ttraining's l2: 0.342874\tvalid_1's l2: 0.346991\n",
      "[51]\ttraining's l2: 0.342002\tvalid_1's l2: 0.34616\n",
      "[52]\ttraining's l2: 0.341203\tvalid_1's l2: 0.345397\n",
      "[53]\ttraining's l2: 0.340532\tvalid_1's l2: 0.344735\n",
      "[54]\ttraining's l2: 0.339908\tvalid_1's l2: 0.34413\n",
      "[55]\ttraining's l2: 0.339285\tvalid_1's l2: 0.343441\n",
      "[56]\ttraining's l2: 0.338758\tvalid_1's l2: 0.342958\n",
      "[57]\ttraining's l2: 0.338171\tvalid_1's l2: 0.342435\n",
      "[58]\ttraining's l2: 0.337578\tvalid_1's l2: 0.341845\n",
      "[59]\ttraining's l2: 0.337134\tvalid_1's l2: 0.341376\n",
      "[60]\ttraining's l2: 0.336612\tvalid_1's l2: 0.340865\n",
      "[61]\ttraining's l2: 0.336178\tvalid_1's l2: 0.340412\n",
      "[62]\ttraining's l2: 0.335766\tvalid_1's l2: 0.340028\n",
      "[63]\ttraining's l2: 0.335324\tvalid_1's l2: 0.339578\n",
      "[64]\ttraining's l2: 0.334837\tvalid_1's l2: 0.339111\n",
      "[65]\ttraining's l2: 0.334419\tvalid_1's l2: 0.338722\n",
      "[66]\ttraining's l2: 0.333938\tvalid_1's l2: 0.338318\n",
      "[67]\ttraining's l2: 0.333581\tvalid_1's l2: 0.338046\n",
      "[68]\ttraining's l2: 0.333196\tvalid_1's l2: 0.337643\n",
      "[69]\ttraining's l2: 0.332871\tvalid_1's l2: 0.337311\n",
      "[70]\ttraining's l2: 0.332531\tvalid_1's l2: 0.33696\n",
      "[71]\ttraining's l2: 0.332236\tvalid_1's l2: 0.336695\n",
      "[72]\ttraining's l2: 0.331918\tvalid_1's l2: 0.336416\n",
      "[73]\ttraining's l2: 0.331565\tvalid_1's l2: 0.336083\n",
      "[74]\ttraining's l2: 0.331343\tvalid_1's l2: 0.335902\n",
      "[75]\ttraining's l2: 0.331079\tvalid_1's l2: 0.335773\n",
      "[76]\ttraining's l2: 0.330768\tvalid_1's l2: 0.335488\n",
      "[77]\ttraining's l2: 0.330521\tvalid_1's l2: 0.335292\n",
      "[78]\ttraining's l2: 0.330295\tvalid_1's l2: 0.335172\n",
      "[79]\ttraining's l2: 0.330089\tvalid_1's l2: 0.335024\n",
      "[80]\ttraining's l2: 0.329848\tvalid_1's l2: 0.334862\n",
      "[81]\ttraining's l2: 0.329617\tvalid_1's l2: 0.334628\n",
      "[82]\ttraining's l2: 0.329432\tvalid_1's l2: 0.334522\n",
      "[83]\ttraining's l2: 0.329207\tvalid_1's l2: 0.334355\n",
      "[84]\ttraining's l2: 0.329004\tvalid_1's l2: 0.334101\n",
      "[85]\ttraining's l2: 0.328808\tvalid_1's l2: 0.333951\n",
      "[86]\ttraining's l2: 0.328602\tvalid_1's l2: 0.333772\n",
      "[87]\ttraining's l2: 0.328441\tvalid_1's l2: 0.333678\n",
      "[88]\ttraining's l2: 0.328295\tvalid_1's l2: 0.333612\n",
      "[89]\ttraining's l2: 0.328116\tvalid_1's l2: 0.333531\n",
      "[90]\ttraining's l2: 0.327932\tvalid_1's l2: 0.333362\n",
      "[91]\ttraining's l2: 0.327794\tvalid_1's l2: 0.333288\n",
      "[92]\ttraining's l2: 0.327638\tvalid_1's l2: 0.333132\n",
      "[93]\ttraining's l2: 0.327487\tvalid_1's l2: 0.333069\n",
      "[94]\ttraining's l2: 0.327324\tvalid_1's l2: 0.332931\n",
      "[95]\ttraining's l2: 0.327204\tvalid_1's l2: 0.332818\n",
      "[96]\ttraining's l2: 0.327048\tvalid_1's l2: 0.332725\n",
      "[97]\ttraining's l2: 0.326886\tvalid_1's l2: 0.332623\n",
      "[98]\ttraining's l2: 0.326695\tvalid_1's l2: 0.332482\n",
      "[99]\ttraining's l2: 0.326561\tvalid_1's l2: 0.332447\n",
      "[100]\ttraining's l2: 0.326373\tvalid_1's l2: 0.33227\n",
      "[101]\ttraining's l2: 0.32623\tvalid_1's l2: 0.332114\n",
      "[102]\ttraining's l2: 0.326087\tvalid_1's l2: 0.332059\n",
      "[103]\ttraining's l2: 0.325909\tvalid_1's l2: 0.331862\n",
      "[104]\ttraining's l2: 0.325809\tvalid_1's l2: 0.331834\n",
      "[105]\ttraining's l2: 0.325704\tvalid_1's l2: 0.331744\n",
      "[106]\ttraining's l2: 0.325585\tvalid_1's l2: 0.331689\n",
      "[107]\ttraining's l2: 0.325488\tvalid_1's l2: 0.331644\n",
      "[108]\ttraining's l2: 0.325358\tvalid_1's l2: 0.331613\n",
      "[109]\ttraining's l2: 0.325198\tvalid_1's l2: 0.331459\n",
      "[110]\ttraining's l2: 0.325086\tvalid_1's l2: 0.331391\n",
      "[111]\ttraining's l2: 0.324961\tvalid_1's l2: 0.33135\n",
      "[112]\ttraining's l2: 0.324861\tvalid_1's l2: 0.331313\n",
      "[113]\ttraining's l2: 0.324711\tvalid_1's l2: 0.331226\n",
      "[114]\ttraining's l2: 0.324601\tvalid_1's l2: 0.331164\n",
      "[115]\ttraining's l2: 0.324503\tvalid_1's l2: 0.331011\n",
      "[116]\ttraining's l2: 0.324395\tvalid_1's l2: 0.330935\n",
      "[117]\ttraining's l2: 0.324314\tvalid_1's l2: 0.330821\n",
      "[118]\ttraining's l2: 0.324217\tvalid_1's l2: 0.330778\n",
      "[119]\ttraining's l2: 0.324126\tvalid_1's l2: 0.330724\n",
      "[120]\ttraining's l2: 0.324038\tvalid_1's l2: 0.330693\n",
      "[121]\ttraining's l2: 0.323928\tvalid_1's l2: 0.330617\n",
      "[122]\ttraining's l2: 0.323817\tvalid_1's l2: 0.33056\n",
      "[123]\ttraining's l2: 0.323736\tvalid_1's l2: 0.33052\n",
      "[124]\ttraining's l2: 0.323626\tvalid_1's l2: 0.330354\n",
      "[125]\ttraining's l2: 0.323552\tvalid_1's l2: 0.330302\n",
      "[126]\ttraining's l2: 0.323472\tvalid_1's l2: 0.330268\n",
      "[127]\ttraining's l2: 0.323372\tvalid_1's l2: 0.330188\n",
      "[128]\ttraining's l2: 0.323283\tvalid_1's l2: 0.330108\n",
      "[129]\ttraining's l2: 0.32321\tvalid_1's l2: 0.329987\n",
      "[130]\ttraining's l2: 0.323105\tvalid_1's l2: 0.329957\n",
      "[131]\ttraining's l2: 0.323037\tvalid_1's l2: 0.329915\n",
      "[132]\ttraining's l2: 0.322923\tvalid_1's l2: 0.32988\n",
      "[133]\ttraining's l2: 0.322849\tvalid_1's l2: 0.329838\n",
      "[134]\ttraining's l2: 0.322756\tvalid_1's l2: 0.329779\n",
      "[135]\ttraining's l2: 0.322691\tvalid_1's l2: 0.32977\n",
      "[136]\ttraining's l2: 0.322592\tvalid_1's l2: 0.329685\n",
      "[137]\ttraining's l2: 0.322527\tvalid_1's l2: 0.32963\n",
      "[138]\ttraining's l2: 0.322465\tvalid_1's l2: 0.329513\n",
      "[139]\ttraining's l2: 0.322396\tvalid_1's l2: 0.329479\n",
      "[140]\ttraining's l2: 0.322316\tvalid_1's l2: 0.32945\n",
      "[141]\ttraining's l2: 0.322229\tvalid_1's l2: 0.329455\n",
      "[142]\ttraining's l2: 0.322145\tvalid_1's l2: 0.329426\n",
      "[143]\ttraining's l2: 0.322058\tvalid_1's l2: 0.329357\n",
      "[144]\ttraining's l2: 0.321982\tvalid_1's l2: 0.329337\n",
      "[145]\ttraining's l2: 0.321902\tvalid_1's l2: 0.329312\n",
      "[146]\ttraining's l2: 0.321832\tvalid_1's l2: 0.329263\n",
      "[147]\ttraining's l2: 0.321772\tvalid_1's l2: 0.32925\n",
      "[148]\ttraining's l2: 0.321716\tvalid_1's l2: 0.329245\n",
      "[149]\ttraining's l2: 0.321656\tvalid_1's l2: 0.329215\n",
      "[150]\ttraining's l2: 0.321581\tvalid_1's l2: 0.329228\n",
      "[151]\ttraining's l2: 0.321514\tvalid_1's l2: 0.329087\n",
      "[152]\ttraining's l2: 0.321452\tvalid_1's l2: 0.329028\n",
      "[153]\ttraining's l2: 0.321385\tvalid_1's l2: 0.329008\n",
      "[154]\ttraining's l2: 0.321328\tvalid_1's l2: 0.328932\n",
      "[155]\ttraining's l2: 0.321251\tvalid_1's l2: 0.328927\n",
      "[156]\ttraining's l2: 0.321194\tvalid_1's l2: 0.328915\n",
      "[157]\ttraining's l2: 0.321124\tvalid_1's l2: 0.328797\n",
      "[158]\ttraining's l2: 0.321067\tvalid_1's l2: 0.328791\n",
      "[159]\ttraining's l2: 0.320999\tvalid_1's l2: 0.328765\n",
      "[160]\ttraining's l2: 0.320941\tvalid_1's l2: 0.328761\n",
      "[161]\ttraining's l2: 0.320879\tvalid_1's l2: 0.328755\n",
      "[162]\ttraining's l2: 0.320826\tvalid_1's l2: 0.32869\n",
      "[163]\ttraining's l2: 0.32076\tvalid_1's l2: 0.328701\n",
      "[164]\ttraining's l2: 0.320716\tvalid_1's l2: 0.328677\n",
      "[165]\ttraining's l2: 0.320667\tvalid_1's l2: 0.328671\n",
      "[166]\ttraining's l2: 0.320611\tvalid_1's l2: 0.328602\n",
      "[167]\ttraining's l2: 0.320554\tvalid_1's l2: 0.328588\n",
      "[168]\ttraining's l2: 0.320505\tvalid_1's l2: 0.328587\n",
      "[169]\ttraining's l2: 0.320459\tvalid_1's l2: 0.328572\n",
      "[170]\ttraining's l2: 0.32041\tvalid_1's l2: 0.328551\n",
      "[171]\ttraining's l2: 0.320366\tvalid_1's l2: 0.328525\n",
      "[172]\ttraining's l2: 0.320304\tvalid_1's l2: 0.328527\n",
      "[173]\ttraining's l2: 0.320245\tvalid_1's l2: 0.328515\n",
      "[174]\ttraining's l2: 0.320197\tvalid_1's l2: 0.328488\n",
      "[175]\ttraining's l2: 0.320149\tvalid_1's l2: 0.328405\n",
      "[176]\ttraining's l2: 0.320089\tvalid_1's l2: 0.328409\n",
      "[177]\ttraining's l2: 0.32004\tvalid_1's l2: 0.32841\n",
      "[178]\ttraining's l2: 0.319991\tvalid_1's l2: 0.328408\n",
      "[179]\ttraining's l2: 0.319932\tvalid_1's l2: 0.328423\n",
      "[180]\ttraining's l2: 0.319878\tvalid_1's l2: 0.328365\n",
      "[181]\ttraining's l2: 0.319835\tvalid_1's l2: 0.328313\n",
      "[182]\ttraining's l2: 0.319794\tvalid_1's l2: 0.328314\n",
      "[183]\ttraining's l2: 0.319745\tvalid_1's l2: 0.328304\n",
      "[184]\ttraining's l2: 0.319703\tvalid_1's l2: 0.328286\n",
      "[185]\ttraining's l2: 0.319648\tvalid_1's l2: 0.328259\n",
      "[186]\ttraining's l2: 0.319593\tvalid_1's l2: 0.328256\n",
      "[187]\ttraining's l2: 0.319553\tvalid_1's l2: 0.328224\n",
      "[188]\ttraining's l2: 0.319511\tvalid_1's l2: 0.328198\n",
      "[189]\ttraining's l2: 0.319467\tvalid_1's l2: 0.328176\n",
      "[190]\ttraining's l2: 0.319437\tvalid_1's l2: 0.328156\n",
      "[191]\ttraining's l2: 0.319389\tvalid_1's l2: 0.328151\n",
      "[192]\ttraining's l2: 0.319344\tvalid_1's l2: 0.328117\n",
      "[193]\ttraining's l2: 0.319303\tvalid_1's l2: 0.328098\n",
      "[194]\ttraining's l2: 0.319246\tvalid_1's l2: 0.328072\n",
      "[195]\ttraining's l2: 0.319185\tvalid_1's l2: 0.328078\n",
      "[196]\ttraining's l2: 0.319134\tvalid_1's l2: 0.328072\n",
      "[197]\ttraining's l2: 0.319095\tvalid_1's l2: 0.328059\n",
      "[198]\ttraining's l2: 0.319049\tvalid_1's l2: 0.328023\n",
      "[199]\ttraining's l2: 0.319001\tvalid_1's l2: 0.327998\n",
      "[200]\ttraining's l2: 0.318959\tvalid_1's l2: 0.327994\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.318959\tvalid_1's l2: 0.327994\n",
      "mean_14_sales: 11308985.24\n",
      "mean_7_sales: 5918250.12\n",
      "mean_6_sales: 2389366.56\n",
      "mean_20_dow2_2017: 1455736.36\n",
      "mean_30_sales: 1230361.56\n",
      "mean_4_dow2_2017: 1158199.82\n",
      "mean_5_sales: 715562.37\n",
      "promo_2: 669076.95\n",
      "mean_21_sales: 627912.23\n",
      "item_class_features: 299743.16\n",
      "sum_5_promo: 152449.66\n",
      "std_14_sales: 87901.33\n",
      "lag_1_sales: 87448.80\n",
      "std_21_sales: 87401.06\n",
      "mean_63_sales: 73531.80\n",
      "std_30_sales: 48468.22\n",
      "item_family_features: 48372.11\n",
      "store_cluster_features: 46783.87\n",
      "lag_5_sales: 44072.68\n",
      "mean_3_sales: 39465.51\n",
      "promo_3: 34482.69\n",
      "sum_4_promo: 33839.45\n",
      "std_7_sales: 27297.72\n",
      "mean_60_sales: 26751.06\n",
      "promo_0: 23102.36\n",
      "std_6_sales: 22255.72\n",
      "promo_5: 20598.31\n",
      "mean_4_sales: 20053.01\n",
      "std_63_sales: 17342.70\n",
      "lag_28_sales: 17090.26\n",
      "lag_1_transactions: 16958.14\n",
      "promo_7: 16563.94\n",
      "sum_2_promo: 15529.69\n",
      "lag_21_transactions: 15234.98\n",
      "promo_4: 15152.71\n",
      "lag_3_transactions: 14173.24\n",
      "std_5_sales: 13502.34\n",
      "std_60_sales: 13032.53\n",
      "mean_20_dow0_2017: 11427.61\n",
      "lag_4_transactions: 9459.49\n",
      "lag_14_transactions: 9093.02\n",
      "lag_2_transactions: 9047.85\n",
      "sum_14_promo: 8716.52\n",
      "sum_7_promo: 8245.88\n",
      "lag_5_transactions: 8227.85\n",
      "store_city_features: 8038.63\n",
      "lag_7_transactions: 7829.06\n",
      "lag_56_sales: 7728.13\n",
      "store_type_features: 7662.21\n",
      "mean_4_dow1_2017: 7568.08\n",
      "mean_20_dow1_2017: 7304.79\n",
      "promo_9: 7254.93\n",
      "promo_1: 7230.87\n",
      "lag_6_transactions: 6448.39\n",
      "mean_20_dow4_2017: 6215.70\n",
      "mean_20_dow3_2017: 6083.05\n",
      "lag_4_sales: 5831.91\n",
      "promo_14: 5652.95\n",
      "sum_21_promo: 4769.12\n",
      "sum_3_promo: 4182.41\n",
      "promo_6: 3795.11\n",
      "store_state_features: 3738.75\n",
      "mean_4_dow3_2017: 3009.66\n",
      "mean_20_dow5_2017: 2521.83\n",
      "lag_6_sales: 2491.47\n",
      "promo_8: 2142.48\n",
      "mean_4_dow0_2017: 2080.11\n",
      "lag_2_sales: 2074.07\n",
      "mean_20_dow6_2017: 2067.73\n",
      "lag_21_sales: 1904.74\n",
      "promo_12: 1620.48\n",
      "std_4_sales: 1415.33\n",
      "lag_3_sales: 1335.13\n",
      "mean_4_dow4_2017: 1092.26\n",
      "mean_4_dow6_2017: 983.90\n",
      "promo_10: 908.79\n",
      "promo_13: 668.01\n",
      "lag_7_sales: 601.54\n",
      "sum_6_promo: 535.95\n",
      "lag_63_sales: 446.60\n",
      "lag_14_sales: 344.03\n",
      "lag_42_sales: 310.92\n",
      "promo_15: 221.31\n",
      "mean_4_dow5_2017: 186.73\n",
      "lag_35_sales: 96.66\n",
      "lag_49_sales: 56.46\n",
      "std_3_sales: 46.92\n",
      "promo_11: 44.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [05:06<22:16, 102.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.18942\tvalid_1's l2: 1.16019\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.11211\tvalid_1's l2: 1.0844\n",
      "[3]\ttraining's l2: 1.0416\tvalid_1's l2: 1.01506\n",
      "[4]\ttraining's l2: 0.977831\tvalid_1's l2: 0.952717\n",
      "[5]\ttraining's l2: 0.920271\tvalid_1's l2: 0.896289\n",
      "[6]\ttraining's l2: 0.868485\tvalid_1's l2: 0.84573\n",
      "[7]\ttraining's l2: 0.821942\tvalid_1's l2: 0.800252\n",
      "[8]\ttraining's l2: 0.778974\tvalid_1's l2: 0.758306\n",
      "[9]\ttraining's l2: 0.740597\tvalid_1's l2: 0.72085\n",
      "[10]\ttraining's l2: 0.705828\tvalid_1's l2: 0.687131\n",
      "[11]\ttraining's l2: 0.673961\tvalid_1's l2: 0.655981\n",
      "[12]\ttraining's l2: 0.644884\tvalid_1's l2: 0.62768\n",
      "[13]\ttraining's l2: 0.618828\tvalid_1's l2: 0.602315\n",
      "[14]\ttraining's l2: 0.595038\tvalid_1's l2: 0.579157\n",
      "[15]\ttraining's l2: 0.57387\tvalid_1's l2: 0.558669\n",
      "[16]\ttraining's l2: 0.554287\tvalid_1's l2: 0.539623\n",
      "[17]\ttraining's l2: 0.536813\tvalid_1's l2: 0.522705\n",
      "[18]\ttraining's l2: 0.520641\tvalid_1's l2: 0.506976\n",
      "[19]\ttraining's l2: 0.505984\tvalid_1's l2: 0.492739\n",
      "[20]\ttraining's l2: 0.4927\tvalid_1's l2: 0.479818\n",
      "[21]\ttraining's l2: 0.480923\tvalid_1's l2: 0.468505\n",
      "[22]\ttraining's l2: 0.470259\tvalid_1's l2: 0.458352\n",
      "[23]\ttraining's l2: 0.460321\tvalid_1's l2: 0.448732\n",
      "[24]\ttraining's l2: 0.451371\tvalid_1's l2: 0.440037\n",
      "[25]\ttraining's l2: 0.443418\tvalid_1's l2: 0.432465\n",
      "[26]\ttraining's l2: 0.435979\tvalid_1's l2: 0.425225\n",
      "[27]\ttraining's l2: 0.429201\tvalid_1's l2: 0.418598\n",
      "[28]\ttraining's l2: 0.423017\tvalid_1's l2: 0.412618\n",
      "[29]\ttraining's l2: 0.417361\tvalid_1's l2: 0.407024\n",
      "[30]\ttraining's l2: 0.412234\tvalid_1's l2: 0.402031\n",
      "[31]\ttraining's l2: 0.407657\tvalid_1's l2: 0.397546\n",
      "[32]\ttraining's l2: 0.403443\tvalid_1's l2: 0.393417\n",
      "[33]\ttraining's l2: 0.399609\tvalid_1's l2: 0.38968\n",
      "[34]\ttraining's l2: 0.396086\tvalid_1's l2: 0.386302\n",
      "[35]\ttraining's l2: 0.39291\tvalid_1's l2: 0.383278\n",
      "[36]\ttraining's l2: 0.389999\tvalid_1's l2: 0.380452\n",
      "[37]\ttraining's l2: 0.387314\tvalid_1's l2: 0.377843\n",
      "[38]\ttraining's l2: 0.384914\tvalid_1's l2: 0.375545\n",
      "[39]\ttraining's l2: 0.382717\tvalid_1's l2: 0.373419\n",
      "[40]\ttraining's l2: 0.380744\tvalid_1's l2: 0.371609\n",
      "[41]\ttraining's l2: 0.378834\tvalid_1's l2: 0.369799\n",
      "[42]\ttraining's l2: 0.37708\tvalid_1's l2: 0.368106\n",
      "[43]\ttraining's l2: 0.37553\tvalid_1's l2: 0.36666\n",
      "[44]\ttraining's l2: 0.374084\tvalid_1's l2: 0.365314\n",
      "[45]\ttraining's l2: 0.372802\tvalid_1's l2: 0.36416\n",
      "[46]\ttraining's l2: 0.371552\tvalid_1's l2: 0.362959\n",
      "[47]\ttraining's l2: 0.370403\tvalid_1's l2: 0.361853\n",
      "[48]\ttraining's l2: 0.369379\tvalid_1's l2: 0.360963\n",
      "[49]\ttraining's l2: 0.368359\tvalid_1's l2: 0.359969\n",
      "[50]\ttraining's l2: 0.367452\tvalid_1's l2: 0.359185\n",
      "[51]\ttraining's l2: 0.366593\tvalid_1's l2: 0.358383\n",
      "[52]\ttraining's l2: 0.365825\tvalid_1's l2: 0.357716\n",
      "[53]\ttraining's l2: 0.365113\tvalid_1's l2: 0.357057\n",
      "[54]\ttraining's l2: 0.364454\tvalid_1's l2: 0.356507\n",
      "[55]\ttraining's l2: 0.363774\tvalid_1's l2: 0.355933\n",
      "[56]\ttraining's l2: 0.363133\tvalid_1's l2: 0.355343\n",
      "[57]\ttraining's l2: 0.362553\tvalid_1's l2: 0.354834\n",
      "[58]\ttraining's l2: 0.362019\tvalid_1's l2: 0.354414\n",
      "[59]\ttraining's l2: 0.361515\tvalid_1's l2: 0.353964\n",
      "[60]\ttraining's l2: 0.361055\tvalid_1's l2: 0.35361\n",
      "[61]\ttraining's l2: 0.360584\tvalid_1's l2: 0.353168\n",
      "[62]\ttraining's l2: 0.360204\tvalid_1's l2: 0.352884\n",
      "[63]\ttraining's l2: 0.359821\tvalid_1's l2: 0.352584\n",
      "[64]\ttraining's l2: 0.359431\tvalid_1's l2: 0.352298\n",
      "[65]\ttraining's l2: 0.359084\tvalid_1's l2: 0.35206\n",
      "[66]\ttraining's l2: 0.358779\tvalid_1's l2: 0.351896\n",
      "[67]\ttraining's l2: 0.358428\tvalid_1's l2: 0.351493\n",
      "[68]\ttraining's l2: 0.358048\tvalid_1's l2: 0.351154\n",
      "[69]\ttraining's l2: 0.357762\tvalid_1's l2: 0.350922\n",
      "[70]\ttraining's l2: 0.357446\tvalid_1's l2: 0.35058\n",
      "[71]\ttraining's l2: 0.357166\tvalid_1's l2: 0.350366\n",
      "[72]\ttraining's l2: 0.356885\tvalid_1's l2: 0.350194\n",
      "[73]\ttraining's l2: 0.356615\tvalid_1's l2: 0.349999\n",
      "[74]\ttraining's l2: 0.3564\tvalid_1's l2: 0.349857\n",
      "[75]\ttraining's l2: 0.356116\tvalid_1's l2: 0.34963\n",
      "[76]\ttraining's l2: 0.355887\tvalid_1's l2: 0.349494\n",
      "[77]\ttraining's l2: 0.355638\tvalid_1's l2: 0.349314\n",
      "[78]\ttraining's l2: 0.355359\tvalid_1's l2: 0.349056\n",
      "[79]\ttraining's l2: 0.355099\tvalid_1's l2: 0.348897\n",
      "[80]\ttraining's l2: 0.354905\tvalid_1's l2: 0.348792\n",
      "[81]\ttraining's l2: 0.354718\tvalid_1's l2: 0.348644\n",
      "[82]\ttraining's l2: 0.354456\tvalid_1's l2: 0.348373\n",
      "[83]\ttraining's l2: 0.354284\tvalid_1's l2: 0.348202\n",
      "[84]\ttraining's l2: 0.354076\tvalid_1's l2: 0.348049\n",
      "[85]\ttraining's l2: 0.353888\tvalid_1's l2: 0.347976\n",
      "[86]\ttraining's l2: 0.353702\tvalid_1's l2: 0.347851\n",
      "[87]\ttraining's l2: 0.353541\tvalid_1's l2: 0.347741\n",
      "[88]\ttraining's l2: 0.353355\tvalid_1's l2: 0.347605\n",
      "[89]\ttraining's l2: 0.353193\tvalid_1's l2: 0.347485\n",
      "[90]\ttraining's l2: 0.35303\tvalid_1's l2: 0.347407\n",
      "[91]\ttraining's l2: 0.352757\tvalid_1's l2: 0.347138\n",
      "[92]\ttraining's l2: 0.352611\tvalid_1's l2: 0.347043\n",
      "[93]\ttraining's l2: 0.352429\tvalid_1's l2: 0.346853\n",
      "[94]\ttraining's l2: 0.352272\tvalid_1's l2: 0.346704\n",
      "[95]\ttraining's l2: 0.352115\tvalid_1's l2: 0.346598\n",
      "[96]\ttraining's l2: 0.351908\tvalid_1's l2: 0.346359\n",
      "[97]\ttraining's l2: 0.351763\tvalid_1's l2: 0.346374\n",
      "[98]\ttraining's l2: 0.351612\tvalid_1's l2: 0.346288\n",
      "[99]\ttraining's l2: 0.351472\tvalid_1's l2: 0.346164\n",
      "[100]\ttraining's l2: 0.351321\tvalid_1's l2: 0.346093\n",
      "[101]\ttraining's l2: 0.351151\tvalid_1's l2: 0.345948\n",
      "[102]\ttraining's l2: 0.35105\tvalid_1's l2: 0.345873\n",
      "[103]\ttraining's l2: 0.350895\tvalid_1's l2: 0.345848\n",
      "[104]\ttraining's l2: 0.350742\tvalid_1's l2: 0.345757\n",
      "[105]\ttraining's l2: 0.350612\tvalid_1's l2: 0.345673\n",
      "[106]\ttraining's l2: 0.350469\tvalid_1's l2: 0.345613\n",
      "[107]\ttraining's l2: 0.350337\tvalid_1's l2: 0.345542\n",
      "[108]\ttraining's l2: 0.35021\tvalid_1's l2: 0.345413\n",
      "[109]\ttraining's l2: 0.350006\tvalid_1's l2: 0.345171\n",
      "[110]\ttraining's l2: 0.349854\tvalid_1's l2: 0.345099\n",
      "[111]\ttraining's l2: 0.349746\tvalid_1's l2: 0.345081\n",
      "[112]\ttraining's l2: 0.349601\tvalid_1's l2: 0.344948\n",
      "[113]\ttraining's l2: 0.349482\tvalid_1's l2: 0.344803\n",
      "[114]\ttraining's l2: 0.349352\tvalid_1's l2: 0.34476\n",
      "[115]\ttraining's l2: 0.349246\tvalid_1's l2: 0.344754\n",
      "[116]\ttraining's l2: 0.349134\tvalid_1's l2: 0.344659\n",
      "[117]\ttraining's l2: 0.34901\tvalid_1's l2: 0.344622\n",
      "[118]\ttraining's l2: 0.348877\tvalid_1's l2: 0.344543\n",
      "[119]\ttraining's l2: 0.348779\tvalid_1's l2: 0.344497\n",
      "[120]\ttraining's l2: 0.348655\tvalid_1's l2: 0.344413\n",
      "[121]\ttraining's l2: 0.34853\tvalid_1's l2: 0.344331\n",
      "[122]\ttraining's l2: 0.348419\tvalid_1's l2: 0.344225\n",
      "[123]\ttraining's l2: 0.348319\tvalid_1's l2: 0.344147\n",
      "[124]\ttraining's l2: 0.348227\tvalid_1's l2: 0.344069\n",
      "[125]\ttraining's l2: 0.34811\tvalid_1's l2: 0.344067\n",
      "[126]\ttraining's l2: 0.348031\tvalid_1's l2: 0.343982\n",
      "[127]\ttraining's l2: 0.347936\tvalid_1's l2: 0.343917\n",
      "[128]\ttraining's l2: 0.347818\tvalid_1's l2: 0.34392\n",
      "[129]\ttraining's l2: 0.34769\tvalid_1's l2: 0.343759\n",
      "[130]\ttraining's l2: 0.347577\tvalid_1's l2: 0.343745\n",
      "[131]\ttraining's l2: 0.34751\tvalid_1's l2: 0.343696\n",
      "[132]\ttraining's l2: 0.347402\tvalid_1's l2: 0.343547\n",
      "[133]\ttraining's l2: 0.347308\tvalid_1's l2: 0.343445\n",
      "[134]\ttraining's l2: 0.347241\tvalid_1's l2: 0.343418\n",
      "[135]\ttraining's l2: 0.347163\tvalid_1's l2: 0.34343\n",
      "[136]\ttraining's l2: 0.347075\tvalid_1's l2: 0.343413\n",
      "[137]\ttraining's l2: 0.346989\tvalid_1's l2: 0.343367\n",
      "[138]\ttraining's l2: 0.346904\tvalid_1's l2: 0.343286\n",
      "[139]\ttraining's l2: 0.346822\tvalid_1's l2: 0.343272\n",
      "[140]\ttraining's l2: 0.346755\tvalid_1's l2: 0.343237\n",
      "[141]\ttraining's l2: 0.346681\tvalid_1's l2: 0.343214\n",
      "[142]\ttraining's l2: 0.346597\tvalid_1's l2: 0.343222\n",
      "[143]\ttraining's l2: 0.346504\tvalid_1's l2: 0.343182\n",
      "[144]\ttraining's l2: 0.346386\tvalid_1's l2: 0.343209\n",
      "[145]\ttraining's l2: 0.346268\tvalid_1's l2: 0.34318\n",
      "[146]\ttraining's l2: 0.346185\tvalid_1's l2: 0.343202\n",
      "[147]\ttraining's l2: 0.346102\tvalid_1's l2: 0.343132\n",
      "[148]\ttraining's l2: 0.346012\tvalid_1's l2: 0.343064\n",
      "[149]\ttraining's l2: 0.345935\tvalid_1's l2: 0.343078\n",
      "[150]\ttraining's l2: 0.34586\tvalid_1's l2: 0.343059\n",
      "[151]\ttraining's l2: 0.345768\tvalid_1's l2: 0.342975\n",
      "[152]\ttraining's l2: 0.345681\tvalid_1's l2: 0.34292\n",
      "[153]\ttraining's l2: 0.345569\tvalid_1's l2: 0.342918\n",
      "[154]\ttraining's l2: 0.345495\tvalid_1's l2: 0.342832\n",
      "[155]\ttraining's l2: 0.345427\tvalid_1's l2: 0.342784\n",
      "[156]\ttraining's l2: 0.345341\tvalid_1's l2: 0.34279\n",
      "[157]\ttraining's l2: 0.345267\tvalid_1's l2: 0.342734\n",
      "[158]\ttraining's l2: 0.345217\tvalid_1's l2: 0.342708\n",
      "[159]\ttraining's l2: 0.345148\tvalid_1's l2: 0.342721\n",
      "[160]\ttraining's l2: 0.345053\tvalid_1's l2: 0.342703\n",
      "[161]\ttraining's l2: 0.344985\tvalid_1's l2: 0.342674\n",
      "[162]\ttraining's l2: 0.344908\tvalid_1's l2: 0.342671\n",
      "[163]\ttraining's l2: 0.344856\tvalid_1's l2: 0.342651\n",
      "[164]\ttraining's l2: 0.344797\tvalid_1's l2: 0.342626\n",
      "[165]\ttraining's l2: 0.344716\tvalid_1's l2: 0.342554\n",
      "[166]\ttraining's l2: 0.34462\tvalid_1's l2: 0.342431\n",
      "[167]\ttraining's l2: 0.34453\tvalid_1's l2: 0.342474\n",
      "[168]\ttraining's l2: 0.344464\tvalid_1's l2: 0.342442\n",
      "[169]\ttraining's l2: 0.344406\tvalid_1's l2: 0.342432\n",
      "[170]\ttraining's l2: 0.34431\tvalid_1's l2: 0.342448\n",
      "[171]\ttraining's l2: 0.344266\tvalid_1's l2: 0.342418\n",
      "[172]\ttraining's l2: 0.344197\tvalid_1's l2: 0.342409\n",
      "[173]\ttraining's l2: 0.344139\tvalid_1's l2: 0.342405\n",
      "[174]\ttraining's l2: 0.344078\tvalid_1's l2: 0.342378\n",
      "[175]\ttraining's l2: 0.344015\tvalid_1's l2: 0.342359\n",
      "[176]\ttraining's l2: 0.343949\tvalid_1's l2: 0.342345\n",
      "[177]\ttraining's l2: 0.343868\tvalid_1's l2: 0.342284\n",
      "[178]\ttraining's l2: 0.343819\tvalid_1's l2: 0.342272\n",
      "[179]\ttraining's l2: 0.343774\tvalid_1's l2: 0.342261\n",
      "[180]\ttraining's l2: 0.343709\tvalid_1's l2: 0.342217\n",
      "[181]\ttraining's l2: 0.343631\tvalid_1's l2: 0.342226\n",
      "[182]\ttraining's l2: 0.343585\tvalid_1's l2: 0.342222\n",
      "[183]\ttraining's l2: 0.343549\tvalid_1's l2: 0.342209\n",
      "[184]\ttraining's l2: 0.343495\tvalid_1's l2: 0.342178\n",
      "[185]\ttraining's l2: 0.343455\tvalid_1's l2: 0.342167\n",
      "[186]\ttraining's l2: 0.343406\tvalid_1's l2: 0.342172\n",
      "[187]\ttraining's l2: 0.34338\tvalid_1's l2: 0.342154\n",
      "[188]\ttraining's l2: 0.343319\tvalid_1's l2: 0.342146\n",
      "[189]\ttraining's l2: 0.343283\tvalid_1's l2: 0.342141\n",
      "[190]\ttraining's l2: 0.343204\tvalid_1's l2: 0.342083\n",
      "[191]\ttraining's l2: 0.343159\tvalid_1's l2: 0.342071\n",
      "[192]\ttraining's l2: 0.343112\tvalid_1's l2: 0.342051\n",
      "[193]\ttraining's l2: 0.343064\tvalid_1's l2: 0.342038\n",
      "[194]\ttraining's l2: 0.343021\tvalid_1's l2: 0.342\n",
      "[195]\ttraining's l2: 0.342992\tvalid_1's l2: 0.341989\n",
      "[196]\ttraining's l2: 0.342965\tvalid_1's l2: 0.342005\n",
      "[197]\ttraining's l2: 0.342891\tvalid_1's l2: 0.341939\n",
      "[198]\ttraining's l2: 0.342829\tvalid_1's l2: 0.341959\n",
      "[199]\ttraining's l2: 0.342758\tvalid_1's l2: 0.341962\n",
      "[200]\ttraining's l2: 0.342713\tvalid_1's l2: 0.341936\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.342713\tvalid_1's l2: 0.341936\n",
      "mean_14_sales: 14907965.47\n",
      "mean_5_sales: 4296514.98\n",
      "mean_6_sales: 3477577.99\n",
      "mean_30_sales: 2578776.08\n",
      "mean_7_sales: 1246927.36\n",
      "mean_20_dow3_2017: 1078923.93\n",
      "mean_4_dow3_2017: 983926.40\n",
      "promo_3: 472173.84\n",
      "mean_60_sales: 364154.08\n",
      "mean_4_sales: 200665.79\n",
      "item_class_features: 179230.29\n",
      "mean_21_sales: 147975.76\n",
      "std_14_sales: 133990.29\n",
      "mean_63_sales: 119824.34\n",
      "mean_4_dow4_2017: 118998.75\n",
      "sum_4_promo: 101956.07\n",
      "mean_3_sales: 52071.84\n",
      "std_7_sales: 41393.06\n",
      "std_21_sales: 35486.06\n",
      "promo_7: 34817.47\n",
      "lag_1_sales: 30832.14\n",
      "promo_5: 29494.00\n",
      "store_cluster_features: 28711.37\n",
      "sum_2_promo: 25803.34\n",
      "lag_1_transactions: 25530.26\n",
      "promo_2: 23732.97\n",
      "std_30_sales: 22702.75\n",
      "promo_4: 22367.08\n",
      "store_city_features: 21067.14\n",
      "lag_21_transactions: 20099.68\n",
      "lag_3_transactions: 19876.00\n",
      "lag_14_transactions: 19115.04\n",
      "lag_3_sales: 19025.35\n",
      "std_6_sales: 18945.55\n",
      "item_family_features: 17377.76\n",
      "lag_4_sales: 14855.07\n",
      "lag_7_transactions: 14219.32\n",
      "promo_6: 13110.49\n",
      "sum_14_promo: 12599.06\n",
      "promo_0: 12007.02\n",
      "sum_3_promo: 11942.71\n",
      "lag_2_transactions: 11547.81\n",
      "std_63_sales: 11222.21\n",
      "lag_5_transactions: 10363.15\n",
      "lag_6_transactions: 10174.04\n",
      "lag_4_transactions: 10090.84\n",
      "promo_1: 9553.74\n",
      "mean_20_dow0_2017: 9033.55\n",
      "std_60_sales: 8505.40\n",
      "sum_7_promo: 8231.25\n",
      "std_5_sales: 8153.24\n",
      "sum_6_promo: 8028.53\n",
      "promo_14: 7769.15\n",
      "lag_56_sales: 7082.86\n",
      "sum_21_promo: 6963.25\n",
      "lag_28_sales: 6394.47\n",
      "sum_5_promo: 5953.87\n",
      "store_state_features: 4617.92\n",
      "std_4_sales: 3451.49\n",
      "promo_10: 3430.42\n",
      "mean_20_dow2_2017: 3337.82\n",
      "mean_4_dow1_2017: 3092.96\n",
      "mean_4_dow0_2017: 2782.02\n",
      "mean_20_dow1_2017: 2690.92\n",
      "promo_8: 2508.79\n",
      "store_type_features: 2402.71\n",
      "lag_5_sales: 1935.05\n",
      "std_3_sales: 1880.14\n",
      "mean_20_dow4_2017: 1772.47\n",
      "promo_9: 1510.20\n",
      "mean_4_dow2_2017: 1375.70\n",
      "lag_6_sales: 1269.99\n",
      "lag_2_sales: 1203.50\n",
      "mean_20_dow6_2017: 1178.76\n",
      "mean_20_dow5_2017: 1122.54\n",
      "mean_4_dow6_2017: 763.92\n",
      "mean_4_dow5_2017: 682.05\n",
      "lag_14_sales: 549.69\n",
      "promo_13: 530.11\n",
      "lag_7_sales: 447.98\n",
      "promo_11: 370.84\n",
      "lag_42_sales: 358.68\n",
      "lag_63_sales: 344.33\n",
      "lag_49_sales: 321.21\n",
      "lag_35_sales: 258.91\n",
      "lag_21_sales: 146.55\n",
      "promo_15: 97.57\n",
      "promo_12: 94.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [06:41<20:08, 100.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.23108\tvalid_1's l2: 1.22034\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.15102\tvalid_1's l2: 1.13901\n",
      "[3]\ttraining's l2: 1.07843\tvalid_1's l2: 1.06624\n",
      "[4]\ttraining's l2: 1.0124\tvalid_1's l2: 0.999177\n",
      "[5]\ttraining's l2: 0.952436\tvalid_1's l2: 0.938217\n",
      "[6]\ttraining's l2: 0.898157\tvalid_1's l2: 0.883183\n",
      "[7]\ttraining's l2: 0.849526\tvalid_1's l2: 0.83448\n",
      "[8]\ttraining's l2: 0.8053\tvalid_1's l2: 0.790291\n",
      "[9]\ttraining's l2: 0.765544\tvalid_1's l2: 0.750459\n",
      "[10]\ttraining's l2: 0.729349\tvalid_1's l2: 0.714391\n",
      "[11]\ttraining's l2: 0.696239\tvalid_1's l2: 0.68039\n",
      "[12]\ttraining's l2: 0.666009\tvalid_1's l2: 0.649513\n",
      "[13]\ttraining's l2: 0.638768\tvalid_1's l2: 0.622194\n",
      "[14]\ttraining's l2: 0.614089\tvalid_1's l2: 0.59752\n",
      "[15]\ttraining's l2: 0.591922\tvalid_1's l2: 0.575552\n",
      "[16]\ttraining's l2: 0.571809\tvalid_1's l2: 0.555264\n",
      "[17]\ttraining's l2: 0.553357\tvalid_1's l2: 0.536614\n",
      "[18]\ttraining's l2: 0.536585\tvalid_1's l2: 0.519816\n",
      "[19]\ttraining's l2: 0.521407\tvalid_1's l2: 0.504674\n",
      "[20]\ttraining's l2: 0.507609\tvalid_1's l2: 0.490913\n",
      "[21]\ttraining's l2: 0.495051\tvalid_1's l2: 0.478421\n",
      "[22]\ttraining's l2: 0.483851\tvalid_1's l2: 0.467334\n",
      "[23]\ttraining's l2: 0.47371\tvalid_1's l2: 0.457642\n",
      "[24]\ttraining's l2: 0.464351\tvalid_1's l2: 0.448314\n",
      "[25]\ttraining's l2: 0.455948\tvalid_1's l2: 0.440161\n",
      "[26]\ttraining's l2: 0.448147\tvalid_1's l2: 0.432442\n",
      "[27]\ttraining's l2: 0.441118\tvalid_1's l2: 0.425563\n",
      "[28]\ttraining's l2: 0.434734\tvalid_1's l2: 0.419453\n",
      "[29]\ttraining's l2: 0.428952\tvalid_1's l2: 0.413821\n",
      "[30]\ttraining's l2: 0.423676\tvalid_1's l2: 0.40867\n",
      "[31]\ttraining's l2: 0.418912\tvalid_1's l2: 0.40406\n",
      "[32]\ttraining's l2: 0.41452\tvalid_1's l2: 0.399884\n",
      "[33]\ttraining's l2: 0.410561\tvalid_1's l2: 0.396211\n",
      "[34]\ttraining's l2: 0.406876\tvalid_1's l2: 0.392613\n",
      "[35]\ttraining's l2: 0.403602\tvalid_1's l2: 0.389649\n",
      "[36]\ttraining's l2: 0.400643\tvalid_1's l2: 0.386954\n",
      "[37]\ttraining's l2: 0.397911\tvalid_1's l2: 0.384455\n",
      "[38]\ttraining's l2: 0.395291\tvalid_1's l2: 0.381979\n",
      "[39]\ttraining's l2: 0.393004\tvalid_1's l2: 0.379889\n",
      "[40]\ttraining's l2: 0.390721\tvalid_1's l2: 0.377693\n",
      "[41]\ttraining's l2: 0.388677\tvalid_1's l2: 0.375815\n",
      "[42]\ttraining's l2: 0.386842\tvalid_1's l2: 0.374033\n",
      "[43]\ttraining's l2: 0.385167\tvalid_1's l2: 0.372527\n",
      "[44]\ttraining's l2: 0.383575\tvalid_1's l2: 0.371029\n",
      "[45]\ttraining's l2: 0.382072\tvalid_1's l2: 0.369702\n",
      "[46]\ttraining's l2: 0.380667\tvalid_1's l2: 0.368329\n",
      "[47]\ttraining's l2: 0.379446\tvalid_1's l2: 0.367255\n",
      "[48]\ttraining's l2: 0.378327\tvalid_1's l2: 0.366357\n",
      "[49]\ttraining's l2: 0.377322\tvalid_1's l2: 0.365511\n",
      "[50]\ttraining's l2: 0.376321\tvalid_1's l2: 0.364567\n",
      "[51]\ttraining's l2: 0.375356\tvalid_1's l2: 0.36367\n",
      "[52]\ttraining's l2: 0.374531\tvalid_1's l2: 0.363016\n",
      "[53]\ttraining's l2: 0.373754\tvalid_1's l2: 0.362311\n",
      "[54]\ttraining's l2: 0.373006\tvalid_1's l2: 0.361675\n",
      "[55]\ttraining's l2: 0.37224\tvalid_1's l2: 0.36088\n",
      "[56]\ttraining's l2: 0.371549\tvalid_1's l2: 0.360242\n",
      "[57]\ttraining's l2: 0.370949\tvalid_1's l2: 0.359769\n",
      "[58]\ttraining's l2: 0.370344\tvalid_1's l2: 0.359204\n",
      "[59]\ttraining's l2: 0.369791\tvalid_1's l2: 0.358676\n",
      "[60]\ttraining's l2: 0.369289\tvalid_1's l2: 0.358288\n",
      "[61]\ttraining's l2: 0.368824\tvalid_1's l2: 0.357893\n",
      "[62]\ttraining's l2: 0.368335\tvalid_1's l2: 0.357482\n",
      "[63]\ttraining's l2: 0.367874\tvalid_1's l2: 0.357104\n",
      "[64]\ttraining's l2: 0.367419\tvalid_1's l2: 0.356773\n",
      "[65]\ttraining's l2: 0.367002\tvalid_1's l2: 0.356392\n",
      "[66]\ttraining's l2: 0.366628\tvalid_1's l2: 0.356146\n",
      "[67]\ttraining's l2: 0.366175\tvalid_1's l2: 0.355679\n",
      "[68]\ttraining's l2: 0.365795\tvalid_1's l2: 0.355382\n",
      "[69]\ttraining's l2: 0.365479\tvalid_1's l2: 0.355159\n",
      "[70]\ttraining's l2: 0.365111\tvalid_1's l2: 0.354869\n",
      "[71]\ttraining's l2: 0.36474\tvalid_1's l2: 0.354468\n",
      "[72]\ttraining's l2: 0.364368\tvalid_1's l2: 0.354126\n",
      "[73]\ttraining's l2: 0.364087\tvalid_1's l2: 0.353967\n",
      "[74]\ttraining's l2: 0.36378\tvalid_1's l2: 0.353716\n",
      "[75]\ttraining's l2: 0.363483\tvalid_1's l2: 0.353464\n",
      "[76]\ttraining's l2: 0.363192\tvalid_1's l2: 0.353247\n",
      "[77]\ttraining's l2: 0.362912\tvalid_1's l2: 0.353005\n",
      "[78]\ttraining's l2: 0.362697\tvalid_1's l2: 0.35285\n",
      "[79]\ttraining's l2: 0.362429\tvalid_1's l2: 0.352677\n",
      "[80]\ttraining's l2: 0.362196\tvalid_1's l2: 0.35248\n",
      "[81]\ttraining's l2: 0.361999\tvalid_1's l2: 0.352376\n",
      "[82]\ttraining's l2: 0.361756\tvalid_1's l2: 0.352256\n",
      "[83]\ttraining's l2: 0.361535\tvalid_1's l2: 0.351981\n",
      "[84]\ttraining's l2: 0.361311\tvalid_1's l2: 0.351824\n",
      "[85]\ttraining's l2: 0.361045\tvalid_1's l2: 0.351584\n",
      "[86]\ttraining's l2: 0.36084\tvalid_1's l2: 0.351468\n",
      "[87]\ttraining's l2: 0.360668\tvalid_1's l2: 0.35139\n",
      "[88]\ttraining's l2: 0.360416\tvalid_1's l2: 0.351232\n",
      "[89]\ttraining's l2: 0.360243\tvalid_1's l2: 0.35109\n",
      "[90]\ttraining's l2: 0.360066\tvalid_1's l2: 0.350994\n",
      "[91]\ttraining's l2: 0.359855\tvalid_1's l2: 0.350908\n",
      "[92]\ttraining's l2: 0.359664\tvalid_1's l2: 0.3508\n",
      "[93]\ttraining's l2: 0.359457\tvalid_1's l2: 0.350668\n",
      "[94]\ttraining's l2: 0.359268\tvalid_1's l2: 0.35044\n",
      "[95]\ttraining's l2: 0.359031\tvalid_1's l2: 0.350194\n",
      "[96]\ttraining's l2: 0.358851\tvalid_1's l2: 0.350094\n",
      "[97]\ttraining's l2: 0.358669\tvalid_1's l2: 0.349955\n",
      "[98]\ttraining's l2: 0.358484\tvalid_1's l2: 0.349757\n",
      "[99]\ttraining's l2: 0.358323\tvalid_1's l2: 0.349653\n",
      "[100]\ttraining's l2: 0.358162\tvalid_1's l2: 0.349564\n",
      "[101]\ttraining's l2: 0.357995\tvalid_1's l2: 0.349442\n",
      "[102]\ttraining's l2: 0.357821\tvalid_1's l2: 0.349295\n",
      "[103]\ttraining's l2: 0.357645\tvalid_1's l2: 0.349164\n",
      "[104]\ttraining's l2: 0.357507\tvalid_1's l2: 0.349124\n",
      "[105]\ttraining's l2: 0.357299\tvalid_1's l2: 0.348917\n",
      "[106]\ttraining's l2: 0.357147\tvalid_1's l2: 0.348876\n",
      "[107]\ttraining's l2: 0.356991\tvalid_1's l2: 0.348861\n",
      "[108]\ttraining's l2: 0.356886\tvalid_1's l2: 0.348789\n",
      "[109]\ttraining's l2: 0.356761\tvalid_1's l2: 0.348697\n",
      "[110]\ttraining's l2: 0.356622\tvalid_1's l2: 0.348632\n",
      "[111]\ttraining's l2: 0.356491\tvalid_1's l2: 0.34851\n",
      "[112]\ttraining's l2: 0.356352\tvalid_1's l2: 0.34839\n",
      "[113]\ttraining's l2: 0.356217\tvalid_1's l2: 0.348294\n",
      "[114]\ttraining's l2: 0.356106\tvalid_1's l2: 0.348189\n",
      "[115]\ttraining's l2: 0.355976\tvalid_1's l2: 0.348158\n",
      "[116]\ttraining's l2: 0.355793\tvalid_1's l2: 0.347983\n",
      "[117]\ttraining's l2: 0.355634\tvalid_1's l2: 0.347813\n",
      "[118]\ttraining's l2: 0.355486\tvalid_1's l2: 0.347782\n",
      "[119]\ttraining's l2: 0.355349\tvalid_1's l2: 0.347637\n",
      "[120]\ttraining's l2: 0.355165\tvalid_1's l2: 0.347436\n",
      "[121]\ttraining's l2: 0.355053\tvalid_1's l2: 0.347355\n",
      "[122]\ttraining's l2: 0.354909\tvalid_1's l2: 0.347263\n",
      "[123]\ttraining's l2: 0.354792\tvalid_1's l2: 0.347192\n",
      "[124]\ttraining's l2: 0.354662\tvalid_1's l2: 0.34718\n",
      "[125]\ttraining's l2: 0.354537\tvalid_1's l2: 0.347168\n",
      "[126]\ttraining's l2: 0.354427\tvalid_1's l2: 0.347106\n",
      "[127]\ttraining's l2: 0.354323\tvalid_1's l2: 0.346992\n",
      "[128]\ttraining's l2: 0.354227\tvalid_1's l2: 0.346959\n",
      "[129]\ttraining's l2: 0.354112\tvalid_1's l2: 0.346905\n",
      "[130]\ttraining's l2: 0.353961\tvalid_1's l2: 0.346786\n",
      "[131]\ttraining's l2: 0.353809\tvalid_1's l2: 0.346592\n",
      "[132]\ttraining's l2: 0.353728\tvalid_1's l2: 0.346553\n",
      "[133]\ttraining's l2: 0.353617\tvalid_1's l2: 0.346445\n",
      "[134]\ttraining's l2: 0.353525\tvalid_1's l2: 0.346376\n",
      "[135]\ttraining's l2: 0.353436\tvalid_1's l2: 0.346331\n",
      "[136]\ttraining's l2: 0.353338\tvalid_1's l2: 0.346323\n",
      "[137]\ttraining's l2: 0.353243\tvalid_1's l2: 0.346247\n",
      "[138]\ttraining's l2: 0.35315\tvalid_1's l2: 0.346167\n",
      "[139]\ttraining's l2: 0.353042\tvalid_1's l2: 0.346107\n",
      "[140]\ttraining's l2: 0.35294\tvalid_1's l2: 0.346046\n",
      "[141]\ttraining's l2: 0.352836\tvalid_1's l2: 0.346064\n",
      "[142]\ttraining's l2: 0.352745\tvalid_1's l2: 0.346067\n",
      "[143]\ttraining's l2: 0.352616\tvalid_1's l2: 0.345981\n",
      "[144]\ttraining's l2: 0.352522\tvalid_1's l2: 0.345901\n",
      "[145]\ttraining's l2: 0.352385\tvalid_1's l2: 0.345745\n",
      "[146]\ttraining's l2: 0.352261\tvalid_1's l2: 0.345696\n",
      "[147]\ttraining's l2: 0.35216\tvalid_1's l2: 0.345695\n",
      "[148]\ttraining's l2: 0.352063\tvalid_1's l2: 0.345651\n",
      "[149]\ttraining's l2: 0.35195\tvalid_1's l2: 0.345532\n",
      "[150]\ttraining's l2: 0.351841\tvalid_1's l2: 0.345417\n",
      "[151]\ttraining's l2: 0.351778\tvalid_1's l2: 0.345365\n",
      "[152]\ttraining's l2: 0.351692\tvalid_1's l2: 0.345307\n",
      "[153]\ttraining's l2: 0.351616\tvalid_1's l2: 0.345311\n",
      "[154]\ttraining's l2: 0.351544\tvalid_1's l2: 0.345276\n",
      "[155]\ttraining's l2: 0.351463\tvalid_1's l2: 0.345227\n",
      "[156]\ttraining's l2: 0.351389\tvalid_1's l2: 0.345184\n",
      "[157]\ttraining's l2: 0.351293\tvalid_1's l2: 0.345148\n",
      "[158]\ttraining's l2: 0.351206\tvalid_1's l2: 0.345175\n",
      "[159]\ttraining's l2: 0.351149\tvalid_1's l2: 0.34516\n",
      "[160]\ttraining's l2: 0.351087\tvalid_1's l2: 0.345111\n",
      "[161]\ttraining's l2: 0.350998\tvalid_1's l2: 0.345106\n",
      "[162]\ttraining's l2: 0.35095\tvalid_1's l2: 0.345105\n",
      "[163]\ttraining's l2: 0.350882\tvalid_1's l2: 0.345095\n",
      "[164]\ttraining's l2: 0.350805\tvalid_1's l2: 0.345068\n",
      "[165]\ttraining's l2: 0.350714\tvalid_1's l2: 0.34504\n",
      "[166]\ttraining's l2: 0.350619\tvalid_1's l2: 0.34496\n",
      "[167]\ttraining's l2: 0.350529\tvalid_1's l2: 0.344881\n",
      "[168]\ttraining's l2: 0.350456\tvalid_1's l2: 0.344822\n",
      "[169]\ttraining's l2: 0.3504\tvalid_1's l2: 0.344773\n",
      "[170]\ttraining's l2: 0.350308\tvalid_1's l2: 0.344784\n",
      "[171]\ttraining's l2: 0.350258\tvalid_1's l2: 0.344754\n",
      "[172]\ttraining's l2: 0.350194\tvalid_1's l2: 0.344715\n",
      "[173]\ttraining's l2: 0.350151\tvalid_1's l2: 0.344721\n",
      "[174]\ttraining's l2: 0.350089\tvalid_1's l2: 0.344674\n",
      "[175]\ttraining's l2: 0.350014\tvalid_1's l2: 0.344676\n",
      "[176]\ttraining's l2: 0.34997\tvalid_1's l2: 0.344669\n",
      "[177]\ttraining's l2: 0.349908\tvalid_1's l2: 0.344607\n",
      "[178]\ttraining's l2: 0.349852\tvalid_1's l2: 0.344584\n",
      "[179]\ttraining's l2: 0.349803\tvalid_1's l2: 0.344561\n",
      "[180]\ttraining's l2: 0.349721\tvalid_1's l2: 0.344572\n",
      "[181]\ttraining's l2: 0.349636\tvalid_1's l2: 0.344547\n",
      "[182]\ttraining's l2: 0.349568\tvalid_1's l2: 0.344502\n",
      "[183]\ttraining's l2: 0.349511\tvalid_1's l2: 0.344511\n",
      "[184]\ttraining's l2: 0.349459\tvalid_1's l2: 0.344483\n",
      "[185]\ttraining's l2: 0.3494\tvalid_1's l2: 0.344452\n",
      "[186]\ttraining's l2: 0.349329\tvalid_1's l2: 0.344432\n",
      "[187]\ttraining's l2: 0.349269\tvalid_1's l2: 0.344418\n",
      "[188]\ttraining's l2: 0.349209\tvalid_1's l2: 0.344409\n",
      "[189]\ttraining's l2: 0.349134\tvalid_1's l2: 0.34441\n",
      "[190]\ttraining's l2: 0.349087\tvalid_1's l2: 0.34438\n",
      "[191]\ttraining's l2: 0.349016\tvalid_1's l2: 0.344334\n",
      "[192]\ttraining's l2: 0.348955\tvalid_1's l2: 0.34433\n",
      "[193]\ttraining's l2: 0.348898\tvalid_1's l2: 0.344304\n",
      "[194]\ttraining's l2: 0.34882\tvalid_1's l2: 0.344244\n",
      "[195]\ttraining's l2: 0.348771\tvalid_1's l2: 0.344247\n",
      "[196]\ttraining's l2: 0.348725\tvalid_1's l2: 0.344249\n",
      "[197]\ttraining's l2: 0.348676\tvalid_1's l2: 0.344187\n",
      "[198]\ttraining's l2: 0.348622\tvalid_1's l2: 0.344141\n",
      "[199]\ttraining's l2: 0.348557\tvalid_1's l2: 0.34411\n",
      "[200]\ttraining's l2: 0.348486\tvalid_1's l2: 0.344056\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.348486\tvalid_1's l2: 0.344056\n",
      "mean_14_sales: 13517847.13\n",
      "mean_4_sales: 4215157.10\n",
      "mean_4_dow4_2017: 3772966.08\n",
      "mean_5_sales: 3496429.93\n",
      "mean_6_sales: 1879615.15\n",
      "mean_20_dow4_2017: 1579824.07\n",
      "mean_30_sales: 1175077.63\n",
      "promo_4: 499494.85\n",
      "mean_7_sales: 446236.09\n",
      "mean_60_sales: 197005.88\n",
      "item_class_features: 196859.96\n",
      "mean_21_sales: 189091.85\n",
      "mean_3_sales: 140504.50\n",
      "sum_3_promo: 122014.30\n",
      "std_14_sales: 105576.33\n",
      "lag_3_transactions: 86113.87\n",
      "std_21_sales: 82075.11\n",
      "lag_3_sales: 53707.68\n",
      "mean_4_dow3_2017: 53014.74\n",
      "store_cluster_features: 51406.20\n",
      "promo_7: 45705.02\n",
      "lag_1_sales: 29802.39\n",
      "promo_5: 27524.46\n",
      "lag_1_transactions: 27035.14\n",
      "store_city_features: 26786.17\n",
      "item_family_features: 25725.78\n",
      "promo_3: 24817.40\n",
      "mean_63_sales: 22695.63\n",
      "lag_21_transactions: 21893.02\n",
      "sum_2_promo: 20262.92\n",
      "std_30_sales: 18089.53\n",
      "promo_11: 18008.63\n",
      "sum_4_promo: 17386.05\n",
      "lag_5_transactions: 17178.59\n",
      "lag_14_transactions: 16954.99\n",
      "promo_6: 16572.80\n",
      "lag_7_transactions: 16263.20\n",
      "lag_2_transactions: 16172.06\n",
      "promo_1: 13352.53\n",
      "lag_4_transactions: 13173.40\n",
      "mean_20_dow3_2017: 11636.50\n",
      "sum_14_promo: 11608.95\n",
      "promo_2: 11601.15\n",
      "mean_20_dow0_2017: 11522.91\n",
      "std_5_sales: 10165.11\n",
      "std_60_sales: 9944.20\n",
      "lag_6_transactions: 9924.49\n",
      "promo_14: 9592.23\n",
      "sum_7_promo: 9155.60\n",
      "promo_0: 8398.50\n",
      "std_4_sales: 8312.71\n",
      "std_63_sales: 6995.58\n",
      "std_7_sales: 6946.09\n",
      "store_state_features: 5802.07\n",
      "mean_20_dow2_2017: 5634.31\n",
      "store_type_features: 5155.63\n",
      "lag_4_sales: 4317.16\n",
      "sum_21_promo: 3883.17\n",
      "mean_4_dow5_2017: 3546.15\n",
      "sum_6_promo: 3414.54\n",
      "std_6_sales: 3340.35\n",
      "mean_4_dow6_2017: 3207.73\n",
      "lag_28_sales: 3191.22\n",
      "mean_20_dow1_2017: 2659.32\n",
      "lag_6_sales: 2483.60\n",
      "lag_5_sales: 1800.69\n",
      "sum_5_promo: 1761.56\n",
      "lag_7_sales: 1554.00\n",
      "promo_13: 1498.82\n",
      "promo_12: 1390.11\n",
      "promo_8: 1347.02\n",
      "lag_2_sales: 1306.73\n",
      "std_3_sales: 1272.02\n",
      "mean_20_dow6_2017: 1150.28\n",
      "promo_10: 1060.76\n",
      "mean_4_dow1_2017: 1051.87\n",
      "mean_4_dow2_2017: 992.67\n",
      "promo_9: 980.45\n",
      "lag_14_sales: 575.21\n",
      "lag_56_sales: 514.54\n",
      "mean_4_dow0_2017: 467.42\n",
      "mean_20_dow5_2017: 377.03\n",
      "lag_49_sales: 186.43\n",
      "lag_63_sales: 173.16\n",
      "lag_42_sales: 135.95\n",
      "promo_15: 48.66\n",
      "lag_21_sales: 27.11\n",
      "lag_35_sales: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [08:19<18:18, 99.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.06252\tvalid_1's l2: 1.09768\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.99757\tvalid_1's l2: 1.03067\n",
      "[3]\ttraining's l2: 0.939783\tvalid_1's l2: 0.970921\n",
      "[4]\ttraining's l2: 0.886435\tvalid_1's l2: 0.915683\n",
      "[5]\ttraining's l2: 0.838477\tvalid_1's l2: 0.865634\n",
      "[6]\ttraining's l2: 0.79486\tvalid_1's l2: 0.820186\n",
      "[7]\ttraining's l2: 0.755842\tvalid_1's l2: 0.779704\n",
      "[8]\ttraining's l2: 0.720203\tvalid_1's l2: 0.74241\n",
      "[9]\ttraining's l2: 0.688381\tvalid_1's l2: 0.7091\n",
      "[10]\ttraining's l2: 0.659456\tvalid_1's l2: 0.679019\n",
      "[11]\ttraining's l2: 0.632693\tvalid_1's l2: 0.650931\n",
      "[12]\ttraining's l2: 0.608875\tvalid_1's l2: 0.62599\n",
      "[13]\ttraining's l2: 0.587539\tvalid_1's l2: 0.603495\n",
      "[14]\ttraining's l2: 0.568138\tvalid_1's l2: 0.583068\n",
      "[15]\ttraining's l2: 0.550016\tvalid_1's l2: 0.563854\n",
      "[16]\ttraining's l2: 0.533521\tvalid_1's l2: 0.546202\n",
      "[17]\ttraining's l2: 0.518684\tvalid_1's l2: 0.530363\n",
      "[18]\ttraining's l2: 0.505136\tvalid_1's l2: 0.515829\n",
      "[19]\ttraining's l2: 0.493207\tvalid_1's l2: 0.503055\n",
      "[20]\ttraining's l2: 0.481996\tvalid_1's l2: 0.490924\n",
      "[21]\ttraining's l2: 0.471893\tvalid_1's l2: 0.479947\n",
      "[22]\ttraining's l2: 0.462761\tvalid_1's l2: 0.469999\n",
      "[23]\ttraining's l2: 0.454442\tvalid_1's l2: 0.460857\n",
      "[24]\ttraining's l2: 0.447153\tvalid_1's l2: 0.452867\n",
      "[25]\ttraining's l2: 0.440478\tvalid_1's l2: 0.445581\n",
      "[26]\ttraining's l2: 0.434424\tvalid_1's l2: 0.439002\n",
      "[27]\ttraining's l2: 0.428647\tvalid_1's l2: 0.432493\n",
      "[28]\ttraining's l2: 0.423388\tvalid_1's l2: 0.426613\n",
      "[29]\ttraining's l2: 0.418597\tvalid_1's l2: 0.421222\n",
      "[30]\ttraining's l2: 0.414256\tvalid_1's l2: 0.416288\n",
      "[31]\ttraining's l2: 0.410264\tvalid_1's l2: 0.411739\n",
      "[32]\ttraining's l2: 0.406869\tvalid_1's l2: 0.407915\n",
      "[33]\ttraining's l2: 0.403572\tvalid_1's l2: 0.404124\n",
      "[34]\ttraining's l2: 0.400697\tvalid_1's l2: 0.400904\n",
      "[35]\ttraining's l2: 0.398089\tvalid_1's l2: 0.397915\n",
      "[36]\ttraining's l2: 0.395533\tvalid_1's l2: 0.394871\n",
      "[37]\ttraining's l2: 0.393231\tvalid_1's l2: 0.392151\n",
      "[38]\ttraining's l2: 0.391108\tvalid_1's l2: 0.389588\n",
      "[39]\ttraining's l2: 0.389169\tvalid_1's l2: 0.387278\n",
      "[40]\ttraining's l2: 0.387512\tvalid_1's l2: 0.385355\n",
      "[41]\ttraining's l2: 0.38598\tvalid_1's l2: 0.383537\n",
      "[42]\ttraining's l2: 0.384446\tvalid_1's l2: 0.381617\n",
      "[43]\ttraining's l2: 0.383023\tvalid_1's l2: 0.379917\n",
      "[44]\ttraining's l2: 0.381772\tvalid_1's l2: 0.378484\n",
      "[45]\ttraining's l2: 0.380544\tvalid_1's l2: 0.376896\n",
      "[46]\ttraining's l2: 0.379418\tvalid_1's l2: 0.375424\n",
      "[47]\ttraining's l2: 0.378464\tvalid_1's l2: 0.374299\n",
      "[48]\ttraining's l2: 0.377482\tvalid_1's l2: 0.373052\n",
      "[49]\ttraining's l2: 0.376597\tvalid_1's l2: 0.371894\n",
      "[50]\ttraining's l2: 0.375799\tvalid_1's l2: 0.370991\n",
      "[51]\ttraining's l2: 0.375034\tvalid_1's l2: 0.369989\n",
      "[52]\ttraining's l2: 0.37428\tvalid_1's l2: 0.368998\n",
      "[53]\ttraining's l2: 0.373616\tvalid_1's l2: 0.368116\n",
      "[54]\ttraining's l2: 0.373006\tvalid_1's l2: 0.367434\n",
      "[55]\ttraining's l2: 0.372402\tvalid_1's l2: 0.366794\n",
      "[56]\ttraining's l2: 0.371813\tvalid_1's l2: 0.366083\n",
      "[57]\ttraining's l2: 0.371306\tvalid_1's l2: 0.36541\n",
      "[58]\ttraining's l2: 0.370865\tvalid_1's l2: 0.364899\n",
      "[59]\ttraining's l2: 0.370383\tvalid_1's l2: 0.364299\n",
      "[60]\ttraining's l2: 0.369919\tvalid_1's l2: 0.363729\n",
      "[61]\ttraining's l2: 0.369516\tvalid_1's l2: 0.363212\n",
      "[62]\ttraining's l2: 0.369138\tvalid_1's l2: 0.362791\n",
      "[63]\ttraining's l2: 0.368769\tvalid_1's l2: 0.362294\n",
      "[64]\ttraining's l2: 0.368397\tvalid_1's l2: 0.361834\n",
      "[65]\ttraining's l2: 0.36811\tvalid_1's l2: 0.361487\n",
      "[66]\ttraining's l2: 0.367769\tvalid_1's l2: 0.361125\n",
      "[67]\ttraining's l2: 0.367418\tvalid_1's l2: 0.360757\n",
      "[68]\ttraining's l2: 0.367144\tvalid_1's l2: 0.360395\n",
      "[69]\ttraining's l2: 0.366821\tvalid_1's l2: 0.360074\n",
      "[70]\ttraining's l2: 0.36646\tvalid_1's l2: 0.359725\n",
      "[71]\ttraining's l2: 0.366144\tvalid_1's l2: 0.35941\n",
      "[72]\ttraining's l2: 0.365842\tvalid_1's l2: 0.359176\n",
      "[73]\ttraining's l2: 0.365537\tvalid_1's l2: 0.358814\n",
      "[74]\ttraining's l2: 0.365267\tvalid_1's l2: 0.358597\n",
      "[75]\ttraining's l2: 0.365041\tvalid_1's l2: 0.358331\n",
      "[76]\ttraining's l2: 0.364806\tvalid_1's l2: 0.358054\n",
      "[77]\ttraining's l2: 0.36457\tvalid_1's l2: 0.357807\n",
      "[78]\ttraining's l2: 0.364357\tvalid_1's l2: 0.35762\n",
      "[79]\ttraining's l2: 0.364128\tvalid_1's l2: 0.357374\n",
      "[80]\ttraining's l2: 0.363867\tvalid_1's l2: 0.357063\n",
      "[81]\ttraining's l2: 0.363699\tvalid_1's l2: 0.356931\n",
      "[82]\ttraining's l2: 0.363515\tvalid_1's l2: 0.356764\n",
      "[83]\ttraining's l2: 0.363348\tvalid_1's l2: 0.356584\n",
      "[84]\ttraining's l2: 0.363119\tvalid_1's l2: 0.356393\n",
      "[85]\ttraining's l2: 0.362933\tvalid_1's l2: 0.356176\n",
      "[86]\ttraining's l2: 0.362684\tvalid_1's l2: 0.356002\n",
      "[87]\ttraining's l2: 0.362523\tvalid_1's l2: 0.355816\n",
      "[88]\ttraining's l2: 0.362284\tvalid_1's l2: 0.355684\n",
      "[89]\ttraining's l2: 0.362137\tvalid_1's l2: 0.355537\n",
      "[90]\ttraining's l2: 0.361998\tvalid_1's l2: 0.355452\n",
      "[91]\ttraining's l2: 0.361859\tvalid_1's l2: 0.355335\n",
      "[92]\ttraining's l2: 0.361632\tvalid_1's l2: 0.355193\n",
      "[93]\ttraining's l2: 0.361392\tvalid_1's l2: 0.355079\n",
      "[94]\ttraining's l2: 0.36126\tvalid_1's l2: 0.355012\n",
      "[95]\ttraining's l2: 0.361093\tvalid_1's l2: 0.354945\n",
      "[96]\ttraining's l2: 0.360921\tvalid_1's l2: 0.35481\n",
      "[97]\ttraining's l2: 0.360751\tvalid_1's l2: 0.354691\n",
      "[98]\ttraining's l2: 0.360597\tvalid_1's l2: 0.354583\n",
      "[99]\ttraining's l2: 0.360466\tvalid_1's l2: 0.354493\n",
      "[100]\ttraining's l2: 0.360284\tvalid_1's l2: 0.354389\n",
      "[101]\ttraining's l2: 0.360047\tvalid_1's l2: 0.354291\n",
      "[102]\ttraining's l2: 0.359854\tvalid_1's l2: 0.354047\n",
      "[103]\ttraining's l2: 0.35971\tvalid_1's l2: 0.353928\n",
      "[104]\ttraining's l2: 0.359587\tvalid_1's l2: 0.353833\n",
      "[105]\ttraining's l2: 0.359361\tvalid_1's l2: 0.353836\n",
      "[106]\ttraining's l2: 0.359233\tvalid_1's l2: 0.353758\n",
      "[107]\ttraining's l2: 0.359022\tvalid_1's l2: 0.353699\n",
      "[108]\ttraining's l2: 0.358903\tvalid_1's l2: 0.353626\n",
      "[109]\ttraining's l2: 0.358763\tvalid_1's l2: 0.353555\n",
      "[110]\ttraining's l2: 0.358652\tvalid_1's l2: 0.353484\n",
      "[111]\ttraining's l2: 0.358526\tvalid_1's l2: 0.353438\n",
      "[112]\ttraining's l2: 0.358409\tvalid_1's l2: 0.35334\n",
      "[113]\ttraining's l2: 0.358286\tvalid_1's l2: 0.353171\n",
      "[114]\ttraining's l2: 0.358178\tvalid_1's l2: 0.353112\n",
      "[115]\ttraining's l2: 0.358037\tvalid_1's l2: 0.353038\n",
      "[116]\ttraining's l2: 0.357917\tvalid_1's l2: 0.352981\n",
      "[117]\ttraining's l2: 0.357717\tvalid_1's l2: 0.352941\n",
      "[118]\ttraining's l2: 0.357541\tvalid_1's l2: 0.352819\n",
      "[119]\ttraining's l2: 0.357354\tvalid_1's l2: 0.352824\n",
      "[120]\ttraining's l2: 0.357236\tvalid_1's l2: 0.352659\n",
      "[121]\ttraining's l2: 0.35716\tvalid_1's l2: 0.352597\n",
      "[122]\ttraining's l2: 0.357094\tvalid_1's l2: 0.352537\n",
      "[123]\ttraining's l2: 0.356907\tvalid_1's l2: 0.352521\n",
      "[124]\ttraining's l2: 0.356791\tvalid_1's l2: 0.352439\n",
      "[125]\ttraining's l2: 0.35669\tvalid_1's l2: 0.352303\n",
      "[126]\ttraining's l2: 0.356611\tvalid_1's l2: 0.352277\n",
      "[127]\ttraining's l2: 0.356527\tvalid_1's l2: 0.352236\n",
      "[128]\ttraining's l2: 0.356425\tvalid_1's l2: 0.352186\n",
      "[129]\ttraining's l2: 0.356293\tvalid_1's l2: 0.352077\n",
      "[130]\ttraining's l2: 0.356199\tvalid_1's l2: 0.352013\n",
      "[131]\ttraining's l2: 0.356039\tvalid_1's l2: 0.351967\n",
      "[132]\ttraining's l2: 0.355916\tvalid_1's l2: 0.35195\n",
      "[133]\ttraining's l2: 0.355822\tvalid_1's l2: 0.351916\n",
      "[134]\ttraining's l2: 0.355645\tvalid_1's l2: 0.351916\n",
      "[135]\ttraining's l2: 0.355548\tvalid_1's l2: 0.351846\n",
      "[136]\ttraining's l2: 0.355419\tvalid_1's l2: 0.351766\n",
      "[137]\ttraining's l2: 0.355286\tvalid_1's l2: 0.351634\n",
      "[138]\ttraining's l2: 0.3552\tvalid_1's l2: 0.351634\n",
      "[139]\ttraining's l2: 0.355144\tvalid_1's l2: 0.351595\n",
      "[140]\ttraining's l2: 0.355078\tvalid_1's l2: 0.351544\n",
      "[141]\ttraining's l2: 0.354975\tvalid_1's l2: 0.351475\n",
      "[142]\ttraining's l2: 0.354826\tvalid_1's l2: 0.351507\n",
      "[143]\ttraining's l2: 0.354725\tvalid_1's l2: 0.351467\n",
      "[144]\ttraining's l2: 0.35465\tvalid_1's l2: 0.351424\n",
      "[145]\ttraining's l2: 0.354546\tvalid_1's l2: 0.351405\n",
      "[146]\ttraining's l2: 0.354471\tvalid_1's l2: 0.35132\n",
      "[147]\ttraining's l2: 0.354371\tvalid_1's l2: 0.351209\n",
      "[148]\ttraining's l2: 0.354265\tvalid_1's l2: 0.351187\n",
      "[149]\ttraining's l2: 0.354154\tvalid_1's l2: 0.35121\n",
      "[150]\ttraining's l2: 0.354089\tvalid_1's l2: 0.351153\n",
      "[151]\ttraining's l2: 0.35397\tvalid_1's l2: 0.351155\n",
      "[152]\ttraining's l2: 0.353858\tvalid_1's l2: 0.351164\n",
      "[153]\ttraining's l2: 0.353767\tvalid_1's l2: 0.351141\n",
      "[154]\ttraining's l2: 0.353695\tvalid_1's l2: 0.351149\n",
      "[155]\ttraining's l2: 0.353606\tvalid_1's l2: 0.351114\n",
      "[156]\ttraining's l2: 0.353524\tvalid_1's l2: 0.351067\n",
      "[157]\ttraining's l2: 0.353466\tvalid_1's l2: 0.351059\n",
      "[158]\ttraining's l2: 0.353398\tvalid_1's l2: 0.35101\n",
      "[159]\ttraining's l2: 0.353335\tvalid_1's l2: 0.350969\n",
      "[160]\ttraining's l2: 0.353235\tvalid_1's l2: 0.350958\n",
      "[161]\ttraining's l2: 0.353159\tvalid_1's l2: 0.350962\n",
      "[162]\ttraining's l2: 0.353083\tvalid_1's l2: 0.350933\n",
      "[163]\ttraining's l2: 0.352994\tvalid_1's l2: 0.350853\n",
      "[164]\ttraining's l2: 0.352867\tvalid_1's l2: 0.35073\n",
      "[165]\ttraining's l2: 0.352754\tvalid_1's l2: 0.350651\n",
      "[166]\ttraining's l2: 0.352699\tvalid_1's l2: 0.350613\n",
      "[167]\ttraining's l2: 0.352605\tvalid_1's l2: 0.350436\n",
      "[168]\ttraining's l2: 0.352512\tvalid_1's l2: 0.350363\n",
      "[169]\ttraining's l2: 0.352426\tvalid_1's l2: 0.350411\n",
      "[170]\ttraining's l2: 0.352343\tvalid_1's l2: 0.350324\n",
      "[171]\ttraining's l2: 0.352234\tvalid_1's l2: 0.350327\n",
      "[172]\ttraining's l2: 0.352189\tvalid_1's l2: 0.3503\n",
      "[173]\ttraining's l2: 0.352126\tvalid_1's l2: 0.350293\n",
      "[174]\ttraining's l2: 0.352069\tvalid_1's l2: 0.350242\n",
      "[175]\ttraining's l2: 0.352001\tvalid_1's l2: 0.350281\n",
      "[176]\ttraining's l2: 0.351908\tvalid_1's l2: 0.350241\n",
      "[177]\ttraining's l2: 0.351843\tvalid_1's l2: 0.350245\n",
      "[178]\ttraining's l2: 0.351802\tvalid_1's l2: 0.350219\n",
      "[179]\ttraining's l2: 0.351713\tvalid_1's l2: 0.350163\n",
      "[180]\ttraining's l2: 0.351637\tvalid_1's l2: 0.350197\n",
      "[181]\ttraining's l2: 0.351558\tvalid_1's l2: 0.350208\n",
      "[182]\ttraining's l2: 0.351521\tvalid_1's l2: 0.3502\n",
      "[183]\ttraining's l2: 0.351438\tvalid_1's l2: 0.35015\n",
      "[184]\ttraining's l2: 0.35137\tvalid_1's l2: 0.35009\n",
      "[185]\ttraining's l2: 0.3513\tvalid_1's l2: 0.35005\n",
      "[186]\ttraining's l2: 0.351207\tvalid_1's l2: 0.349999\n",
      "[187]\ttraining's l2: 0.351174\tvalid_1's l2: 0.349971\n",
      "[188]\ttraining's l2: 0.35113\tvalid_1's l2: 0.349966\n",
      "[189]\ttraining's l2: 0.351093\tvalid_1's l2: 0.34994\n",
      "[190]\ttraining's l2: 0.350994\tvalid_1's l2: 0.34995\n",
      "[191]\ttraining's l2: 0.350909\tvalid_1's l2: 0.349935\n",
      "[192]\ttraining's l2: 0.350871\tvalid_1's l2: 0.349901\n",
      "[193]\ttraining's l2: 0.350834\tvalid_1's l2: 0.349893\n",
      "[194]\ttraining's l2: 0.350771\tvalid_1's l2: 0.349921\n",
      "[195]\ttraining's l2: 0.350717\tvalid_1's l2: 0.349914\n",
      "[196]\ttraining's l2: 0.350673\tvalid_1's l2: 0.349877\n",
      "[197]\ttraining's l2: 0.350635\tvalid_1's l2: 0.349838\n",
      "[198]\ttraining's l2: 0.35057\tvalid_1's l2: 0.349872\n",
      "[199]\ttraining's l2: 0.350521\tvalid_1's l2: 0.349838\n",
      "[200]\ttraining's l2: 0.350488\tvalid_1's l2: 0.349825\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.350488\tvalid_1's l2: 0.349825\n",
      "mean_14_sales: 12508946.06\n",
      "mean_30_sales: 3745735.28\n",
      "mean_7_sales: 3615712.54\n",
      "mean_3_sales: 1220397.15\n",
      "mean_60_sales: 659460.53\n",
      "mean_4_sales: 653029.81\n",
      "mean_20_dow5_2017: 533858.88\n",
      "promo_5: 530185.18\n",
      "mean_6_sales: 442299.91\n",
      "mean_21_sales: 354051.05\n",
      "mean_5_sales: 293143.10\n",
      "mean_4_dow5_2017: 264900.12\n",
      "item_class_features: 199452.94\n",
      "mean_63_sales: 174882.93\n",
      "promo_7: 75244.34\n",
      "std_14_sales: 74669.43\n",
      "sum_2_promo: 71914.51\n",
      "promo_3: 49772.25\n",
      "mean_4_dow6_2017: 47139.02\n",
      "sum_4_promo: 46833.75\n",
      "std_21_sales: 45447.26\n",
      "promo_6: 43711.69\n",
      "lag_1_transactions: 43488.80\n",
      "lag_4_transactions: 37725.89\n",
      "lag_7_transactions: 33249.00\n",
      "lag_3_transactions: 28074.47\n",
      "lag_21_transactions: 27722.79\n",
      "std_30_sales: 27009.76\n",
      "item_family_features: 23768.36\n",
      "mean_20_dow6_2017: 22281.39\n",
      "lag_2_transactions: 22071.54\n",
      "lag_1_sales: 21456.63\n",
      "lag_56_sales: 20988.45\n",
      "lag_5_transactions: 13985.04\n",
      "sum_7_promo: 13509.21\n",
      "lag_14_transactions: 12803.30\n",
      "mean_20_dow0_2017: 12367.14\n",
      "promo_14: 10126.46\n",
      "sum_14_promo: 10077.63\n",
      "promo_4: 9901.42\n",
      "std_60_sales: 9348.96\n",
      "lag_6_transactions: 9167.46\n",
      "sum_6_promo: 7887.33\n",
      "store_city_features: 7750.38\n",
      "lag_3_sales: 7732.90\n",
      "std_63_sales: 7397.49\n",
      "promo_1: 7278.63\n",
      "mean_20_dow3_2017: 6851.52\n",
      "store_cluster_features: 6736.94\n",
      "sum_21_promo: 6543.54\n",
      "promo_0: 6235.98\n",
      "promo_2: 6174.48\n",
      "promo_11: 5700.24\n",
      "sum_3_promo: 5350.75\n",
      "mean_4_dow4_2017: 4745.00\n",
      "std_7_sales: 4011.04\n",
      "lag_2_sales: 4008.86\n",
      "std_5_sales: 3813.30\n",
      "mean_4_dow1_2017: 3724.88\n",
      "promo_12: 3583.28\n",
      "std_4_sales: 2904.71\n",
      "lag_4_sales: 2706.91\n",
      "promo_10: 2639.21\n",
      "lag_7_sales: 2597.14\n",
      "mean_4_dow0_2017: 2458.73\n",
      "promo_8: 2239.43\n",
      "lag_28_sales: 2211.86\n",
      "store_type_features: 2047.99\n",
      "sum_5_promo: 1958.07\n",
      "mean_20_dow1_2017: 1818.84\n",
      "lag_21_sales: 1743.90\n",
      "std_3_sales: 1722.58\n",
      "promo_13: 1713.92\n",
      "mean_20_dow2_2017: 1588.90\n",
      "lag_42_sales: 1560.78\n",
      "mean_20_dow4_2017: 1467.72\n",
      "std_6_sales: 1366.69\n",
      "promo_9: 1269.50\n",
      "lag_6_sales: 1046.36\n",
      "mean_4_dow3_2017: 971.89\n",
      "store_state_features: 732.35\n",
      "lag_14_sales: 626.59\n",
      "lag_35_sales: 569.32\n",
      "mean_4_dow2_2017: 487.79\n",
      "lag_63_sales: 402.24\n",
      "lag_5_sales: 268.22\n",
      "lag_49_sales: 259.08\n",
      "promo_15: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [09:57<16:31, 99.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.02148\tvalid_1's l2: 1.185\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.960828\tvalid_1's l2: 1.11909\n",
      "[3]\ttraining's l2: 0.906141\tvalid_1's l2: 1.05975\n",
      "[4]\ttraining's l2: 0.854683\tvalid_1's l2: 1.00389\n",
      "[5]\ttraining's l2: 0.808444\tvalid_1's l2: 0.952798\n",
      "[6]\ttraining's l2: 0.766356\tvalid_1's l2: 0.906615\n",
      "[7]\ttraining's l2: 0.728239\tvalid_1's l2: 0.864389\n",
      "[8]\ttraining's l2: 0.693989\tvalid_1's l2: 0.826231\n",
      "[9]\ttraining's l2: 0.662794\tvalid_1's l2: 0.791438\n",
      "[10]\ttraining's l2: 0.634556\tvalid_1's l2: 0.759522\n",
      "[11]\ttraining's l2: 0.608893\tvalid_1's l2: 0.73077\n",
      "[12]\ttraining's l2: 0.585626\tvalid_1's l2: 0.704345\n",
      "[13]\ttraining's l2: 0.564674\tvalid_1's l2: 0.680316\n",
      "[14]\ttraining's l2: 0.545524\tvalid_1's l2: 0.658309\n",
      "[15]\ttraining's l2: 0.528314\tvalid_1's l2: 0.6385\n",
      "[16]\ttraining's l2: 0.513177\tvalid_1's l2: 0.620653\n",
      "[17]\ttraining's l2: 0.498939\tvalid_1's l2: 0.604094\n",
      "[18]\ttraining's l2: 0.486017\tvalid_1's l2: 0.588684\n",
      "[19]\ttraining's l2: 0.474321\tvalid_1's l2: 0.574773\n",
      "[20]\ttraining's l2: 0.463631\tvalid_1's l2: 0.562143\n",
      "[21]\ttraining's l2: 0.454019\tvalid_1's l2: 0.550377\n",
      "[22]\ttraining's l2: 0.445305\tvalid_1's l2: 0.539619\n",
      "[23]\ttraining's l2: 0.437364\tvalid_1's l2: 0.529885\n",
      "[24]\ttraining's l2: 0.430414\tvalid_1's l2: 0.521054\n",
      "[25]\ttraining's l2: 0.424083\tvalid_1's l2: 0.51292\n",
      "[26]\ttraining's l2: 0.418363\tvalid_1's l2: 0.505518\n",
      "[27]\ttraining's l2: 0.412891\tvalid_1's l2: 0.498604\n",
      "[28]\ttraining's l2: 0.408111\tvalid_1's l2: 0.492382\n",
      "[29]\ttraining's l2: 0.403495\tvalid_1's l2: 0.486515\n",
      "[30]\ttraining's l2: 0.399313\tvalid_1's l2: 0.481079\n",
      "[31]\ttraining's l2: 0.395521\tvalid_1's l2: 0.476128\n",
      "[32]\ttraining's l2: 0.39203\tvalid_1's l2: 0.471514\n",
      "[33]\ttraining's l2: 0.388878\tvalid_1's l2: 0.467247\n",
      "[34]\ttraining's l2: 0.385898\tvalid_1's l2: 0.463283\n",
      "[35]\ttraining's l2: 0.383235\tvalid_1's l2: 0.459654\n",
      "[36]\ttraining's l2: 0.380842\tvalid_1's l2: 0.456287\n",
      "[37]\ttraining's l2: 0.37867\tvalid_1's l2: 0.453278\n",
      "[38]\ttraining's l2: 0.37671\tvalid_1's l2: 0.450435\n",
      "[39]\ttraining's l2: 0.374853\tvalid_1's l2: 0.447819\n",
      "[40]\ttraining's l2: 0.373248\tvalid_1's l2: 0.445357\n",
      "[41]\ttraining's l2: 0.371607\tvalid_1's l2: 0.443008\n",
      "[42]\ttraining's l2: 0.37011\tvalid_1's l2: 0.440875\n",
      "[43]\ttraining's l2: 0.368921\tvalid_1's l2: 0.439014\n",
      "[44]\ttraining's l2: 0.367651\tvalid_1's l2: 0.43719\n",
      "[45]\ttraining's l2: 0.366452\tvalid_1's l2: 0.435396\n",
      "[46]\ttraining's l2: 0.365455\tvalid_1's l2: 0.433841\n",
      "[47]\ttraining's l2: 0.364394\tvalid_1's l2: 0.432286\n",
      "[48]\ttraining's l2: 0.363452\tvalid_1's l2: 0.430919\n",
      "[49]\ttraining's l2: 0.36258\tvalid_1's l2: 0.429667\n",
      "[50]\ttraining's l2: 0.361824\tvalid_1's l2: 0.428414\n",
      "[51]\ttraining's l2: 0.361186\tvalid_1's l2: 0.427388\n",
      "[52]\ttraining's l2: 0.36045\tvalid_1's l2: 0.42622\n",
      "[53]\ttraining's l2: 0.359846\tvalid_1's l2: 0.42522\n",
      "[54]\ttraining's l2: 0.359196\tvalid_1's l2: 0.424242\n",
      "[55]\ttraining's l2: 0.358574\tvalid_1's l2: 0.423373\n",
      "[56]\ttraining's l2: 0.357917\tvalid_1's l2: 0.422539\n",
      "[57]\ttraining's l2: 0.357331\tvalid_1's l2: 0.421735\n",
      "[58]\ttraining's l2: 0.356779\tvalid_1's l2: 0.420973\n",
      "[59]\ttraining's l2: 0.356336\tvalid_1's l2: 0.420237\n",
      "[60]\ttraining's l2: 0.355855\tvalid_1's l2: 0.419577\n",
      "[61]\ttraining's l2: 0.355434\tvalid_1's l2: 0.418863\n",
      "[62]\ttraining's l2: 0.355065\tvalid_1's l2: 0.418272\n",
      "[63]\ttraining's l2: 0.354709\tvalid_1's l2: 0.417686\n",
      "[64]\ttraining's l2: 0.354198\tvalid_1's l2: 0.417056\n",
      "[65]\ttraining's l2: 0.353823\tvalid_1's l2: 0.41647\n",
      "[66]\ttraining's l2: 0.353459\tvalid_1's l2: 0.415911\n",
      "[67]\ttraining's l2: 0.353089\tvalid_1's l2: 0.415395\n",
      "[68]\ttraining's l2: 0.352756\tvalid_1's l2: 0.415012\n",
      "[69]\ttraining's l2: 0.352435\tvalid_1's l2: 0.414516\n",
      "[70]\ttraining's l2: 0.352125\tvalid_1's l2: 0.41409\n",
      "[71]\ttraining's l2: 0.351881\tvalid_1's l2: 0.413585\n",
      "[72]\ttraining's l2: 0.351558\tvalid_1's l2: 0.413162\n",
      "[73]\ttraining's l2: 0.351303\tvalid_1's l2: 0.412988\n",
      "[74]\ttraining's l2: 0.35104\tvalid_1's l2: 0.412555\n",
      "[75]\ttraining's l2: 0.350765\tvalid_1's l2: 0.412216\n",
      "[76]\ttraining's l2: 0.350487\tvalid_1's l2: 0.411817\n",
      "[77]\ttraining's l2: 0.350238\tvalid_1's l2: 0.411498\n",
      "[78]\ttraining's l2: 0.350026\tvalid_1's l2: 0.411202\n",
      "[79]\ttraining's l2: 0.349778\tvalid_1's l2: 0.410813\n",
      "[80]\ttraining's l2: 0.349457\tvalid_1's l2: 0.410505\n",
      "[81]\ttraining's l2: 0.349255\tvalid_1's l2: 0.410186\n",
      "[82]\ttraining's l2: 0.349008\tvalid_1's l2: 0.409954\n",
      "[83]\ttraining's l2: 0.348801\tvalid_1's l2: 0.409774\n",
      "[84]\ttraining's l2: 0.34865\tvalid_1's l2: 0.409517\n",
      "[85]\ttraining's l2: 0.348386\tvalid_1's l2: 0.409361\n",
      "[86]\ttraining's l2: 0.348206\tvalid_1's l2: 0.409132\n",
      "[87]\ttraining's l2: 0.348044\tvalid_1's l2: 0.408914\n",
      "[88]\ttraining's l2: 0.347879\tvalid_1's l2: 0.408751\n",
      "[89]\ttraining's l2: 0.347712\tvalid_1's l2: 0.408601\n",
      "[90]\ttraining's l2: 0.34751\tvalid_1's l2: 0.4084\n",
      "[91]\ttraining's l2: 0.347311\tvalid_1's l2: 0.408198\n",
      "[92]\ttraining's l2: 0.347146\tvalid_1's l2: 0.408069\n",
      "[93]\ttraining's l2: 0.346997\tvalid_1's l2: 0.407889\n",
      "[94]\ttraining's l2: 0.34684\tvalid_1's l2: 0.407743\n",
      "[95]\ttraining's l2: 0.346723\tvalid_1's l2: 0.40752\n",
      "[96]\ttraining's l2: 0.346587\tvalid_1's l2: 0.407395\n",
      "[97]\ttraining's l2: 0.346463\tvalid_1's l2: 0.407265\n",
      "[98]\ttraining's l2: 0.346333\tvalid_1's l2: 0.407128\n",
      "[99]\ttraining's l2: 0.346137\tvalid_1's l2: 0.406935\n",
      "[100]\ttraining's l2: 0.345997\tvalid_1's l2: 0.406746\n",
      "[101]\ttraining's l2: 0.345845\tvalid_1's l2: 0.406616\n",
      "[102]\ttraining's l2: 0.345747\tvalid_1's l2: 0.406432\n",
      "[103]\ttraining's l2: 0.345608\tvalid_1's l2: 0.406317\n",
      "[104]\ttraining's l2: 0.345504\tvalid_1's l2: 0.406202\n",
      "[105]\ttraining's l2: 0.345342\tvalid_1's l2: 0.406228\n",
      "[106]\ttraining's l2: 0.345212\tvalid_1's l2: 0.406133\n",
      "[107]\ttraining's l2: 0.345045\tvalid_1's l2: 0.406093\n",
      "[108]\ttraining's l2: 0.344971\tvalid_1's l2: 0.406032\n",
      "[109]\ttraining's l2: 0.344874\tvalid_1's l2: 0.405961\n",
      "[110]\ttraining's l2: 0.344794\tvalid_1's l2: 0.405872\n",
      "[111]\ttraining's l2: 0.344699\tvalid_1's l2: 0.405824\n",
      "[112]\ttraining's l2: 0.344586\tvalid_1's l2: 0.405723\n",
      "[113]\ttraining's l2: 0.34449\tvalid_1's l2: 0.405735\n",
      "[114]\ttraining's l2: 0.344303\tvalid_1's l2: 0.405597\n",
      "[115]\ttraining's l2: 0.344205\tvalid_1's l2: 0.405601\n",
      "[116]\ttraining's l2: 0.344106\tvalid_1's l2: 0.405482\n",
      "[117]\ttraining's l2: 0.344024\tvalid_1's l2: 0.405412\n",
      "[118]\ttraining's l2: 0.343892\tvalid_1's l2: 0.405423\n",
      "[119]\ttraining's l2: 0.343759\tvalid_1's l2: 0.405453\n",
      "[120]\ttraining's l2: 0.343654\tvalid_1's l2: 0.405124\n",
      "[121]\ttraining's l2: 0.343547\tvalid_1's l2: 0.405031\n",
      "[122]\ttraining's l2: 0.343469\tvalid_1's l2: 0.404964\n",
      "[123]\ttraining's l2: 0.34338\tvalid_1's l2: 0.404876\n",
      "[124]\ttraining's l2: 0.343256\tvalid_1's l2: 0.404796\n",
      "[125]\ttraining's l2: 0.343159\tvalid_1's l2: 0.404749\n",
      "[126]\ttraining's l2: 0.343047\tvalid_1's l2: 0.40477\n",
      "[127]\ttraining's l2: 0.342957\tvalid_1's l2: 0.404724\n",
      "[128]\ttraining's l2: 0.34286\tvalid_1's l2: 0.404684\n",
      "[129]\ttraining's l2: 0.342759\tvalid_1's l2: 0.404509\n",
      "[130]\ttraining's l2: 0.342651\tvalid_1's l2: 0.404442\n",
      "[131]\ttraining's l2: 0.342563\tvalid_1's l2: 0.404313\n",
      "[132]\ttraining's l2: 0.342473\tvalid_1's l2: 0.404231\n",
      "[133]\ttraining's l2: 0.342372\tvalid_1's l2: 0.404187\n",
      "[134]\ttraining's l2: 0.342237\tvalid_1's l2: 0.404218\n",
      "[135]\ttraining's l2: 0.342173\tvalid_1's l2: 0.404185\n",
      "[136]\ttraining's l2: 0.342105\tvalid_1's l2: 0.404143\n",
      "[137]\ttraining's l2: 0.342027\tvalid_1's l2: 0.404115\n",
      "[138]\ttraining's l2: 0.341961\tvalid_1's l2: 0.404095\n",
      "[139]\ttraining's l2: 0.341842\tvalid_1's l2: 0.404063\n",
      "[140]\ttraining's l2: 0.341755\tvalid_1's l2: 0.40404\n",
      "[141]\ttraining's l2: 0.341699\tvalid_1's l2: 0.404023\n",
      "[142]\ttraining's l2: 0.341647\tvalid_1's l2: 0.403966\n",
      "[143]\ttraining's l2: 0.341556\tvalid_1's l2: 0.403899\n",
      "[144]\ttraining's l2: 0.341461\tvalid_1's l2: 0.403789\n",
      "[145]\ttraining's l2: 0.341344\tvalid_1's l2: 0.403754\n",
      "[146]\ttraining's l2: 0.341271\tvalid_1's l2: 0.403667\n",
      "[147]\ttraining's l2: 0.3412\tvalid_1's l2: 0.403644\n",
      "[148]\ttraining's l2: 0.34114\tvalid_1's l2: 0.403619\n",
      "[149]\ttraining's l2: 0.34107\tvalid_1's l2: 0.403611\n",
      "[150]\ttraining's l2: 0.341007\tvalid_1's l2: 0.403588\n",
      "[151]\ttraining's l2: 0.340945\tvalid_1's l2: 0.403588\n",
      "[152]\ttraining's l2: 0.340889\tvalid_1's l2: 0.403574\n",
      "[153]\ttraining's l2: 0.340799\tvalid_1's l2: 0.403523\n",
      "[154]\ttraining's l2: 0.340749\tvalid_1's l2: 0.403522\n",
      "[155]\ttraining's l2: 0.340633\tvalid_1's l2: 0.403535\n",
      "[156]\ttraining's l2: 0.340547\tvalid_1's l2: 0.403498\n",
      "[157]\ttraining's l2: 0.34047\tvalid_1's l2: 0.403468\n",
      "[158]\ttraining's l2: 0.34042\tvalid_1's l2: 0.403445\n",
      "[159]\ttraining's l2: 0.34034\tvalid_1's l2: 0.403355\n",
      "[160]\ttraining's l2: 0.340293\tvalid_1's l2: 0.403317\n",
      "[161]\ttraining's l2: 0.340232\tvalid_1's l2: 0.403316\n",
      "[162]\ttraining's l2: 0.340184\tvalid_1's l2: 0.403254\n",
      "[163]\ttraining's l2: 0.340139\tvalid_1's l2: 0.403235\n",
      "[164]\ttraining's l2: 0.340066\tvalid_1's l2: 0.40319\n",
      "[165]\ttraining's l2: 0.340009\tvalid_1's l2: 0.4031\n",
      "[166]\ttraining's l2: 0.339967\tvalid_1's l2: 0.402991\n",
      "[167]\ttraining's l2: 0.339911\tvalid_1's l2: 0.402942\n",
      "[168]\ttraining's l2: 0.339819\tvalid_1's l2: 0.402943\n",
      "[169]\ttraining's l2: 0.33975\tvalid_1's l2: 0.402883\n",
      "[170]\ttraining's l2: 0.339673\tvalid_1's l2: 0.402895\n",
      "[171]\ttraining's l2: 0.339626\tvalid_1's l2: 0.402895\n",
      "[172]\ttraining's l2: 0.339565\tvalid_1's l2: 0.402798\n",
      "[173]\ttraining's l2: 0.339513\tvalid_1's l2: 0.40276\n",
      "[174]\ttraining's l2: 0.33948\tvalid_1's l2: 0.402731\n",
      "[175]\ttraining's l2: 0.339421\tvalid_1's l2: 0.402827\n",
      "[176]\ttraining's l2: 0.339363\tvalid_1's l2: 0.402822\n",
      "[177]\ttraining's l2: 0.339297\tvalid_1's l2: 0.402746\n",
      "[178]\ttraining's l2: 0.339253\tvalid_1's l2: 0.402707\n",
      "[179]\ttraining's l2: 0.339189\tvalid_1's l2: 0.402662\n",
      "[180]\ttraining's l2: 0.339123\tvalid_1's l2: 0.402645\n",
      "[181]\ttraining's l2: 0.339054\tvalid_1's l2: 0.402665\n",
      "[182]\ttraining's l2: 0.33902\tvalid_1's l2: 0.40265\n",
      "[183]\ttraining's l2: 0.338955\tvalid_1's l2: 0.40269\n",
      "[184]\ttraining's l2: 0.338912\tvalid_1's l2: 0.402677\n",
      "[185]\ttraining's l2: 0.338861\tvalid_1's l2: 0.40259\n",
      "[186]\ttraining's l2: 0.338815\tvalid_1's l2: 0.402568\n",
      "[187]\ttraining's l2: 0.338721\tvalid_1's l2: 0.402523\n",
      "[188]\ttraining's l2: 0.338666\tvalid_1's l2: 0.402539\n",
      "[189]\ttraining's l2: 0.338621\tvalid_1's l2: 0.402526\n",
      "[190]\ttraining's l2: 0.338594\tvalid_1's l2: 0.402518\n",
      "[191]\ttraining's l2: 0.338557\tvalid_1's l2: 0.402515\n",
      "[192]\ttraining's l2: 0.338517\tvalid_1's l2: 0.402511\n",
      "[193]\ttraining's l2: 0.33848\tvalid_1's l2: 0.402515\n",
      "[194]\ttraining's l2: 0.338435\tvalid_1's l2: 0.40249\n",
      "[195]\ttraining's l2: 0.338388\tvalid_1's l2: 0.402497\n",
      "[196]\ttraining's l2: 0.338341\tvalid_1's l2: 0.402438\n",
      "[197]\ttraining's l2: 0.3383\tvalid_1's l2: 0.402413\n",
      "[198]\ttraining's l2: 0.338276\tvalid_1's l2: 0.402386\n",
      "[199]\ttraining's l2: 0.338245\tvalid_1's l2: 0.402374\n",
      "[200]\ttraining's l2: 0.338189\tvalid_1's l2: 0.402271\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.338189\tvalid_1's l2: 0.402271\n",
      "mean_14_sales: 10938771.06\n",
      "mean_30_sales: 3914288.41\n",
      "mean_7_sales: 3238777.04\n",
      "mean_20_dow6_2017: 1121304.22\n",
      "mean_4_dow6_2017: 907771.22\n",
      "mean_21_sales: 866106.62\n",
      "promo_6: 809817.56\n",
      "mean_6_sales: 693423.11\n",
      "mean_3_sales: 567897.83\n",
      "mean_4_sales: 245418.71\n",
      "item_class_features: 210023.50\n",
      "mean_5_sales: 187146.96\n",
      "mean_63_sales: 181768.42\n",
      "mean_60_sales: 123217.39\n",
      "lag_1_sales: 117006.04\n",
      "promo_7: 95928.42\n",
      "sum_4_promo: 67183.42\n",
      "std_30_sales: 62127.36\n",
      "promo_3: 51991.35\n",
      "std_21_sales: 48905.80\n",
      "item_family_features: 48677.94\n",
      "promo_5: 44066.51\n",
      "mean_20_dow5_2017: 37683.88\n",
      "promo_13: 34916.46\n",
      "sum_2_promo: 32426.10\n",
      "std_14_sales: 25768.98\n",
      "lag_21_transactions: 23012.24\n",
      "lag_56_sales: 22598.50\n",
      "mean_4_dow5_2017: 20765.85\n",
      "lag_3_transactions: 18159.89\n",
      "store_cluster_features: 16423.13\n",
      "std_60_sales: 15410.31\n",
      "lag_2_transactions: 14766.87\n",
      "std_63_sales: 13733.93\n",
      "mean_20_dow0_2017: 13632.31\n",
      "store_type_features: 13309.31\n",
      "lag_14_transactions: 13246.92\n",
      "sum_7_promo: 12799.66\n",
      "lag_1_transactions: 12085.07\n",
      "lag_4_transactions: 11294.77\n",
      "promo_0: 10773.64\n",
      "promo_14: 10636.13\n",
      "sum_14_promo: 10591.55\n",
      "promo_4: 9121.37\n",
      "mean_20_dow1_2017: 8315.65\n",
      "sum_6_promo: 8101.18\n",
      "promo_1: 7891.14\n",
      "sum_21_promo: 7660.35\n",
      "std_6_sales: 7610.99\n",
      "store_city_features: 7503.70\n",
      "mean_4_dow1_2017: 7445.70\n",
      "lag_7_transactions: 7428.30\n",
      "mean_20_dow3_2017: 7117.69\n",
      "sum_3_promo: 6330.25\n",
      "promo_2: 5840.58\n",
      "std_7_sales: 5270.39\n",
      "lag_28_sales: 5185.91\n",
      "lag_6_transactions: 5070.49\n",
      "lag_2_sales: 4742.28\n",
      "lag_5_transactions: 4494.64\n",
      "sum_5_promo: 3519.20\n",
      "std_4_sales: 2836.09\n",
      "promo_11: 2499.00\n",
      "lag_21_sales: 2466.72\n",
      "mean_4_dow4_2017: 2300.97\n",
      "lag_3_sales: 2258.68\n",
      "mean_20_dow4_2017: 2101.12\n",
      "promo_8: 2017.44\n",
      "mean_20_dow2_2017: 1986.11\n",
      "lag_5_sales: 1708.47\n",
      "lag_42_sales: 1693.91\n",
      "std_3_sales: 1690.51\n",
      "mean_4_dow0_2017: 1674.31\n",
      "std_5_sales: 1660.70\n",
      "lag_4_sales: 1557.02\n",
      "store_state_features: 1491.85\n",
      "promo_9: 1368.46\n",
      "promo_15: 1218.42\n",
      "lag_14_sales: 1142.72\n",
      "lag_35_sales: 1053.95\n",
      "lag_6_sales: 1047.30\n",
      "mean_4_dow3_2017: 993.72\n",
      "promo_10: 968.99\n",
      "lag_49_sales: 528.26\n",
      "mean_4_dow2_2017: 521.08\n",
      "lag_63_sales: 512.68\n",
      "lag_7_sales: 496.93\n",
      "promo_12: 184.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [11:35<14:49, 98.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05418\tvalid_1's l2: 1.1628\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.987906\tvalid_1's l2: 1.09358\n",
      "[3]\ttraining's l2: 0.930533\tvalid_1's l2: 1.03317\n",
      "[4]\ttraining's l2: 0.875885\tvalid_1's l2: 0.975577\n",
      "[5]\ttraining's l2: 0.826661\tvalid_1's l2: 0.923169\n",
      "[6]\ttraining's l2: 0.781863\tvalid_1's l2: 0.875715\n",
      "[7]\ttraining's l2: 0.741367\tvalid_1's l2: 0.832901\n",
      "[8]\ttraining's l2: 0.704755\tvalid_1's l2: 0.7937\n",
      "[9]\ttraining's l2: 0.672974\tvalid_1's l2: 0.759619\n",
      "[10]\ttraining's l2: 0.642774\tvalid_1's l2: 0.727391\n",
      "[11]\ttraining's l2: 0.615351\tvalid_1's l2: 0.698014\n",
      "[12]\ttraining's l2: 0.590372\tvalid_1's l2: 0.67123\n",
      "[13]\ttraining's l2: 0.567834\tvalid_1's l2: 0.646936\n",
      "[14]\ttraining's l2: 0.547472\tvalid_1's l2: 0.624753\n",
      "[15]\ttraining's l2: 0.528918\tvalid_1's l2: 0.604498\n",
      "[16]\ttraining's l2: 0.51217\tvalid_1's l2: 0.58597\n",
      "[17]\ttraining's l2: 0.496944\tvalid_1's l2: 0.569042\n",
      "[18]\ttraining's l2: 0.483151\tvalid_1's l2: 0.553675\n",
      "[19]\ttraining's l2: 0.47051\tvalid_1's l2: 0.53969\n",
      "[20]\ttraining's l2: 0.459678\tvalid_1's l2: 0.527366\n",
      "[21]\ttraining's l2: 0.449303\tvalid_1's l2: 0.515622\n",
      "[22]\ttraining's l2: 0.43986\tvalid_1's l2: 0.504895\n",
      "[23]\ttraining's l2: 0.431285\tvalid_1's l2: 0.494996\n",
      "[24]\ttraining's l2: 0.423402\tvalid_1's l2: 0.48595\n",
      "[25]\ttraining's l2: 0.416307\tvalid_1's l2: 0.47765\n",
      "[26]\ttraining's l2: 0.4098\tvalid_1's l2: 0.470049\n",
      "[27]\ttraining's l2: 0.403853\tvalid_1's l2: 0.463034\n",
      "[28]\ttraining's l2: 0.398431\tvalid_1's l2: 0.45682\n",
      "[29]\ttraining's l2: 0.393518\tvalid_1's l2: 0.450906\n",
      "[30]\ttraining's l2: 0.389394\tvalid_1's l2: 0.44585\n",
      "[31]\ttraining's l2: 0.385282\tvalid_1's l2: 0.441043\n",
      "[32]\ttraining's l2: 0.381867\tvalid_1's l2: 0.436775\n",
      "[33]\ttraining's l2: 0.378322\tvalid_1's l2: 0.432469\n",
      "[34]\ttraining's l2: 0.375156\tvalid_1's l2: 0.428572\n",
      "[35]\ttraining's l2: 0.372321\tvalid_1's l2: 0.425027\n",
      "[36]\ttraining's l2: 0.369715\tvalid_1's l2: 0.421702\n",
      "[37]\ttraining's l2: 0.367533\tvalid_1's l2: 0.418897\n",
      "[38]\ttraining's l2: 0.365294\tvalid_1's l2: 0.415996\n",
      "[39]\ttraining's l2: 0.363478\tvalid_1's l2: 0.413579\n",
      "[40]\ttraining's l2: 0.361606\tvalid_1's l2: 0.411111\n",
      "[41]\ttraining's l2: 0.359791\tvalid_1's l2: 0.408734\n",
      "[42]\ttraining's l2: 0.358135\tvalid_1's l2: 0.406577\n",
      "[43]\ttraining's l2: 0.356848\tvalid_1's l2: 0.404817\n",
      "[44]\ttraining's l2: 0.355452\tvalid_1's l2: 0.402998\n",
      "[45]\ttraining's l2: 0.35412\tvalid_1's l2: 0.401297\n",
      "[46]\ttraining's l2: 0.35291\tvalid_1's l2: 0.399737\n",
      "[47]\ttraining's l2: 0.351798\tvalid_1's l2: 0.39818\n",
      "[48]\ttraining's l2: 0.350762\tvalid_1's l2: 0.396779\n",
      "[49]\ttraining's l2: 0.34994\tvalid_1's l2: 0.395603\n",
      "[50]\ttraining's l2: 0.348984\tvalid_1's l2: 0.394303\n",
      "[51]\ttraining's l2: 0.348298\tvalid_1's l2: 0.393292\n",
      "[52]\ttraining's l2: 0.347481\tvalid_1's l2: 0.392249\n",
      "[53]\ttraining's l2: 0.346792\tvalid_1's l2: 0.391347\n",
      "[54]\ttraining's l2: 0.346217\tvalid_1's l2: 0.390527\n",
      "[55]\ttraining's l2: 0.345541\tvalid_1's l2: 0.389577\n",
      "[56]\ttraining's l2: 0.345053\tvalid_1's l2: 0.388842\n",
      "[57]\ttraining's l2: 0.34447\tvalid_1's l2: 0.388034\n",
      "[58]\ttraining's l2: 0.343825\tvalid_1's l2: 0.387234\n",
      "[59]\ttraining's l2: 0.343313\tvalid_1's l2: 0.386508\n",
      "[60]\ttraining's l2: 0.34279\tvalid_1's l2: 0.385876\n",
      "[61]\ttraining's l2: 0.342307\tvalid_1's l2: 0.385258\n",
      "[62]\ttraining's l2: 0.341873\tvalid_1's l2: 0.384715\n",
      "[63]\ttraining's l2: 0.341486\tvalid_1's l2: 0.384211\n",
      "[64]\ttraining's l2: 0.341106\tvalid_1's l2: 0.383646\n",
      "[65]\ttraining's l2: 0.340823\tvalid_1's l2: 0.38323\n",
      "[66]\ttraining's l2: 0.340484\tvalid_1's l2: 0.382745\n",
      "[67]\ttraining's l2: 0.340007\tvalid_1's l2: 0.38212\n",
      "[68]\ttraining's l2: 0.339635\tvalid_1's l2: 0.381674\n",
      "[69]\ttraining's l2: 0.339402\tvalid_1's l2: 0.381299\n",
      "[70]\ttraining's l2: 0.339022\tvalid_1's l2: 0.380791\n",
      "[71]\ttraining's l2: 0.338734\tvalid_1's l2: 0.38031\n",
      "[72]\ttraining's l2: 0.338388\tvalid_1's l2: 0.379897\n",
      "[73]\ttraining's l2: 0.338182\tvalid_1's l2: 0.379616\n",
      "[74]\ttraining's l2: 0.337971\tvalid_1's l2: 0.379278\n",
      "[75]\ttraining's l2: 0.337775\tvalid_1's l2: 0.378989\n",
      "[76]\ttraining's l2: 0.33747\tvalid_1's l2: 0.378606\n",
      "[77]\ttraining's l2: 0.337185\tvalid_1's l2: 0.378316\n",
      "[78]\ttraining's l2: 0.336915\tvalid_1's l2: 0.378093\n",
      "[79]\ttraining's l2: 0.3367\tvalid_1's l2: 0.377841\n",
      "[80]\ttraining's l2: 0.336526\tvalid_1's l2: 0.377616\n",
      "[81]\ttraining's l2: 0.336374\tvalid_1's l2: 0.377431\n",
      "[82]\ttraining's l2: 0.336138\tvalid_1's l2: 0.377191\n",
      "[83]\ttraining's l2: 0.335936\tvalid_1's l2: 0.376982\n",
      "[84]\ttraining's l2: 0.33577\tvalid_1's l2: 0.376714\n",
      "[85]\ttraining's l2: 0.33563\tvalid_1's l2: 0.376557\n",
      "[86]\ttraining's l2: 0.335464\tvalid_1's l2: 0.376383\n",
      "[87]\ttraining's l2: 0.335311\tvalid_1's l2: 0.376211\n",
      "[88]\ttraining's l2: 0.335146\tvalid_1's l2: 0.375992\n",
      "[89]\ttraining's l2: 0.334975\tvalid_1's l2: 0.375865\n",
      "[90]\ttraining's l2: 0.334814\tvalid_1's l2: 0.375687\n",
      "[91]\ttraining's l2: 0.334656\tvalid_1's l2: 0.375454\n",
      "[92]\ttraining's l2: 0.334528\tvalid_1's l2: 0.375299\n",
      "[93]\ttraining's l2: 0.334302\tvalid_1's l2: 0.375081\n",
      "[94]\ttraining's l2: 0.33416\tvalid_1's l2: 0.374901\n",
      "[95]\ttraining's l2: 0.334006\tvalid_1's l2: 0.374646\n",
      "[96]\ttraining's l2: 0.333888\tvalid_1's l2: 0.374482\n",
      "[97]\ttraining's l2: 0.333761\tvalid_1's l2: 0.37437\n",
      "[98]\ttraining's l2: 0.333633\tvalid_1's l2: 0.374209\n",
      "[99]\ttraining's l2: 0.333523\tvalid_1's l2: 0.374077\n",
      "[100]\ttraining's l2: 0.333372\tvalid_1's l2: 0.373956\n",
      "[101]\ttraining's l2: 0.333187\tvalid_1's l2: 0.373736\n",
      "[102]\ttraining's l2: 0.33305\tvalid_1's l2: 0.37354\n",
      "[103]\ttraining's l2: 0.332939\tvalid_1's l2: 0.373486\n",
      "[104]\ttraining's l2: 0.332746\tvalid_1's l2: 0.373272\n",
      "[105]\ttraining's l2: 0.332621\tvalid_1's l2: 0.373163\n",
      "[106]\ttraining's l2: 0.332505\tvalid_1's l2: 0.372928\n",
      "[107]\ttraining's l2: 0.332356\tvalid_1's l2: 0.372723\n",
      "[108]\ttraining's l2: 0.332255\tvalid_1's l2: 0.372656\n",
      "[109]\ttraining's l2: 0.33216\tvalid_1's l2: 0.372602\n",
      "[110]\ttraining's l2: 0.332036\tvalid_1's l2: 0.372405\n",
      "[111]\ttraining's l2: 0.331931\tvalid_1's l2: 0.372174\n",
      "[112]\ttraining's l2: 0.331764\tvalid_1's l2: 0.37199\n",
      "[113]\ttraining's l2: 0.331639\tvalid_1's l2: 0.371883\n",
      "[114]\ttraining's l2: 0.331503\tvalid_1's l2: 0.371787\n",
      "[115]\ttraining's l2: 0.331421\tvalid_1's l2: 0.371737\n",
      "[116]\ttraining's l2: 0.331306\tvalid_1's l2: 0.371706\n",
      "[117]\ttraining's l2: 0.331222\tvalid_1's l2: 0.371614\n",
      "[118]\ttraining's l2: 0.331125\tvalid_1's l2: 0.371479\n",
      "[119]\ttraining's l2: 0.331027\tvalid_1's l2: 0.371412\n",
      "[120]\ttraining's l2: 0.330926\tvalid_1's l2: 0.371185\n",
      "[121]\ttraining's l2: 0.330838\tvalid_1's l2: 0.371069\n",
      "[122]\ttraining's l2: 0.330767\tvalid_1's l2: 0.370997\n",
      "[123]\ttraining's l2: 0.330657\tvalid_1's l2: 0.370853\n",
      "[124]\ttraining's l2: 0.330584\tvalid_1's l2: 0.370746\n",
      "[125]\ttraining's l2: 0.330454\tvalid_1's l2: 0.370539\n",
      "[126]\ttraining's l2: 0.330379\tvalid_1's l2: 0.370487\n",
      "[127]\ttraining's l2: 0.33028\tvalid_1's l2: 0.370419\n",
      "[128]\ttraining's l2: 0.330199\tvalid_1's l2: 0.37034\n",
      "[129]\ttraining's l2: 0.330125\tvalid_1's l2: 0.370275\n",
      "[130]\ttraining's l2: 0.330039\tvalid_1's l2: 0.370125\n",
      "[131]\ttraining's l2: 0.329944\tvalid_1's l2: 0.370013\n",
      "[132]\ttraining's l2: 0.329865\tvalid_1's l2: 0.369967\n",
      "[133]\ttraining's l2: 0.329781\tvalid_1's l2: 0.369798\n",
      "[134]\ttraining's l2: 0.329703\tvalid_1's l2: 0.369692\n",
      "[135]\ttraining's l2: 0.329643\tvalid_1's l2: 0.369637\n",
      "[136]\ttraining's l2: 0.329581\tvalid_1's l2: 0.369579\n",
      "[137]\ttraining's l2: 0.329488\tvalid_1's l2: 0.369532\n",
      "[138]\ttraining's l2: 0.329437\tvalid_1's l2: 0.369496\n",
      "[139]\ttraining's l2: 0.32938\tvalid_1's l2: 0.369477\n",
      "[140]\ttraining's l2: 0.329308\tvalid_1's l2: 0.369484\n",
      "[141]\ttraining's l2: 0.329249\tvalid_1's l2: 0.369436\n",
      "[142]\ttraining's l2: 0.329168\tvalid_1's l2: 0.369366\n",
      "[143]\ttraining's l2: 0.329105\tvalid_1's l2: 0.369194\n",
      "[144]\ttraining's l2: 0.329045\tvalid_1's l2: 0.369207\n",
      "[145]\ttraining's l2: 0.328978\tvalid_1's l2: 0.369174\n",
      "[146]\ttraining's l2: 0.328907\tvalid_1's l2: 0.369106\n",
      "[147]\ttraining's l2: 0.32884\tvalid_1's l2: 0.369062\n",
      "[148]\ttraining's l2: 0.32877\tvalid_1's l2: 0.369023\n",
      "[149]\ttraining's l2: 0.328703\tvalid_1's l2: 0.369009\n",
      "[150]\ttraining's l2: 0.32865\tvalid_1's l2: 0.368938\n",
      "[151]\ttraining's l2: 0.328587\tvalid_1's l2: 0.368901\n",
      "[152]\ttraining's l2: 0.328521\tvalid_1's l2: 0.368864\n",
      "[153]\ttraining's l2: 0.328458\tvalid_1's l2: 0.368844\n",
      "[154]\ttraining's l2: 0.328412\tvalid_1's l2: 0.368791\n",
      "[155]\ttraining's l2: 0.328331\tvalid_1's l2: 0.368693\n",
      "[156]\ttraining's l2: 0.328279\tvalid_1's l2: 0.368668\n",
      "[157]\ttraining's l2: 0.328229\tvalid_1's l2: 0.368611\n",
      "[158]\ttraining's l2: 0.328178\tvalid_1's l2: 0.368576\n",
      "[159]\ttraining's l2: 0.328119\tvalid_1's l2: 0.368501\n",
      "[160]\ttraining's l2: 0.328034\tvalid_1's l2: 0.368399\n",
      "[161]\ttraining's l2: 0.327974\tvalid_1's l2: 0.368363\n",
      "[162]\ttraining's l2: 0.327921\tvalid_1's l2: 0.368318\n",
      "[163]\ttraining's l2: 0.32786\tvalid_1's l2: 0.368248\n",
      "[164]\ttraining's l2: 0.32778\tvalid_1's l2: 0.368151\n",
      "[165]\ttraining's l2: 0.32773\tvalid_1's l2: 0.368115\n",
      "[166]\ttraining's l2: 0.327676\tvalid_1's l2: 0.36809\n",
      "[167]\ttraining's l2: 0.327626\tvalid_1's l2: 0.368059\n",
      "[168]\ttraining's l2: 0.327569\tvalid_1's l2: 0.36804\n",
      "[169]\ttraining's l2: 0.327507\tvalid_1's l2: 0.367952\n",
      "[170]\ttraining's l2: 0.327463\tvalid_1's l2: 0.367927\n",
      "[171]\ttraining's l2: 0.327415\tvalid_1's l2: 0.367771\n",
      "[172]\ttraining's l2: 0.327372\tvalid_1's l2: 0.367759\n",
      "[173]\ttraining's l2: 0.327333\tvalid_1's l2: 0.367769\n",
      "[174]\ttraining's l2: 0.327291\tvalid_1's l2: 0.367756\n",
      "[175]\ttraining's l2: 0.327256\tvalid_1's l2: 0.367736\n",
      "[176]\ttraining's l2: 0.327218\tvalid_1's l2: 0.367728\n",
      "[177]\ttraining's l2: 0.327178\tvalid_1's l2: 0.36768\n",
      "[178]\ttraining's l2: 0.327123\tvalid_1's l2: 0.367656\n",
      "[179]\ttraining's l2: 0.32709\tvalid_1's l2: 0.367632\n",
      "[180]\ttraining's l2: 0.327054\tvalid_1's l2: 0.367602\n",
      "[181]\ttraining's l2: 0.327016\tvalid_1's l2: 0.367567\n",
      "[182]\ttraining's l2: 0.326948\tvalid_1's l2: 0.367491\n",
      "[183]\ttraining's l2: 0.326887\tvalid_1's l2: 0.367448\n",
      "[184]\ttraining's l2: 0.326848\tvalid_1's l2: 0.367428\n",
      "[185]\ttraining's l2: 0.326814\tvalid_1's l2: 0.3674\n",
      "[186]\ttraining's l2: 0.326765\tvalid_1's l2: 0.367339\n",
      "[187]\ttraining's l2: 0.326721\tvalid_1's l2: 0.367311\n",
      "[188]\ttraining's l2: 0.326675\tvalid_1's l2: 0.367282\n",
      "[189]\ttraining's l2: 0.326639\tvalid_1's l2: 0.367272\n",
      "[190]\ttraining's l2: 0.326591\tvalid_1's l2: 0.367242\n",
      "[191]\ttraining's l2: 0.326553\tvalid_1's l2: 0.367238\n",
      "[192]\ttraining's l2: 0.326521\tvalid_1's l2: 0.367204\n",
      "[193]\ttraining's l2: 0.326479\tvalid_1's l2: 0.367188\n",
      "[194]\ttraining's l2: 0.326408\tvalid_1's l2: 0.36716\n",
      "[195]\ttraining's l2: 0.326358\tvalid_1's l2: 0.367112\n",
      "[196]\ttraining's l2: 0.326315\tvalid_1's l2: 0.367092\n",
      "[197]\ttraining's l2: 0.326291\tvalid_1's l2: 0.367074\n",
      "[198]\ttraining's l2: 0.326245\tvalid_1's l2: 0.36703\n",
      "[199]\ttraining's l2: 0.326212\tvalid_1's l2: 0.36704\n",
      "[200]\ttraining's l2: 0.326187\tvalid_1's l2: 0.367008\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.326187\tvalid_1's l2: 0.367008\n",
      "mean_14_sales: 8404054.46\n",
      "mean_7_sales: 6087273.07\n",
      "mean_21_sales: 3747128.32\n",
      "mean_30_sales: 3411307.20\n",
      "mean_20_dow0_2017: 1391958.42\n",
      "promo_7: 1146610.29\n",
      "mean_63_sales: 352910.50\n",
      "mean_4_dow0_2017: 342000.85\n",
      "item_class_features: 241119.38\n",
      "promo_0: 139179.00\n",
      "sum_7_promo: 128782.42\n",
      "lag_1_sales: 113511.78\n",
      "mean_6_sales: 83645.65\n",
      "item_family_features: 81334.70\n",
      "mean_3_sales: 77512.17\n",
      "promo_14: 65144.66\n",
      "std_21_sales: 64730.48\n",
      "std_30_sales: 57332.71\n",
      "sum_14_promo: 54112.64\n",
      "store_cluster_features: 50500.90\n",
      "std_14_sales: 47591.57\n",
      "promo_6: 39710.31\n",
      "std_63_sales: 33028.94\n",
      "lag_56_sales: 29974.49\n",
      "lag_21_sales: 29843.48\n",
      "promo_3: 25659.37\n",
      "mean_4_dow6_2017: 24006.83\n",
      "sum_21_promo: 23586.99\n",
      "mean_5_sales: 22688.58\n",
      "promo_8: 21235.47\n",
      "mean_60_sales: 19303.69\n",
      "lag_21_transactions: 17795.34\n",
      "promo_5: 17726.42\n",
      "std_7_sales: 17615.70\n",
      "store_type_features: 13903.25\n",
      "lag_49_sales: 13575.05\n",
      "mean_4_dow5_2017: 13349.36\n",
      "lag_3_transactions: 12916.55\n",
      "std_60_sales: 12751.10\n",
      "mean_20_dow1_2017: 12046.14\n",
      "lag_2_sales: 11991.83\n",
      "mean_4_sales: 11506.15\n",
      "store_city_features: 9975.74\n",
      "mean_20_dow3_2017: 9370.30\n",
      "lag_1_transactions: 9133.52\n",
      "lag_2_transactions: 7685.12\n",
      "mean_20_dow2_2017: 7499.51\n",
      "sum_4_promo: 7253.94\n",
      "lag_7_transactions: 7115.07\n",
      "lag_7_sales: 6910.00\n",
      "lag_4_transactions: 6787.20\n",
      "promo_4: 6449.84\n",
      "lag_35_sales: 5828.24\n",
      "lag_6_transactions: 5490.29\n",
      "mean_20_dow6_2017: 5354.58\n",
      "lag_5_transactions: 4827.55\n",
      "std_6_sales: 4796.23\n",
      "promo_2: 4530.12\n",
      "promo_13: 4433.98\n",
      "lag_14_transactions: 3945.88\n",
      "promo_10: 3616.14\n",
      "promo_9: 3335.93\n",
      "mean_20_dow5_2017: 3078.29\n",
      "lag_42_sales: 3076.39\n",
      "mean_20_dow4_2017: 3009.72\n",
      "lag_5_sales: 2959.86\n",
      "sum_2_promo: 2913.72\n",
      "std_4_sales: 2805.70\n",
      "promo_12: 2795.28\n",
      "promo_11: 2714.96\n",
      "sum_5_promo: 2232.46\n",
      "std_5_sales: 2097.79\n",
      "store_state_features: 2094.18\n",
      "lag_6_sales: 1772.50\n",
      "lag_4_sales: 1754.23\n",
      "promo_1: 1650.38\n",
      "mean_4_dow4_2017: 1605.77\n",
      "sum_6_promo: 1575.72\n",
      "lag_28_sales: 1511.37\n",
      "promo_15: 1428.49\n",
      "mean_4_dow2_2017: 1376.11\n",
      "sum_3_promo: 1161.27\n",
      "lag_63_sales: 1082.69\n",
      "mean_4_dow1_2017: 797.17\n",
      "lag_3_sales: 606.38\n",
      "mean_4_dow3_2017: 471.17\n",
      "lag_14_sales: 383.97\n",
      "std_3_sales: 361.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [13:11<13:04, 98.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.951538\tvalid_1's l2: 0.99719\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.897497\tvalid_1's l2: 0.941246\n",
      "[3]\ttraining's l2: 0.84727\tvalid_1's l2: 0.889881\n",
      "[4]\ttraining's l2: 0.801941\tvalid_1's l2: 0.842925\n",
      "[5]\ttraining's l2: 0.760986\tvalid_1's l2: 0.800503\n",
      "[6]\ttraining's l2: 0.723665\tvalid_1's l2: 0.762145\n",
      "[7]\ttraining's l2: 0.689895\tvalid_1's l2: 0.727535\n",
      "[8]\ttraining's l2: 0.65956\tvalid_1's l2: 0.695971\n",
      "[9]\ttraining's l2: 0.631941\tvalid_1's l2: 0.667247\n",
      "[10]\ttraining's l2: 0.606831\tvalid_1's l2: 0.641266\n",
      "[11]\ttraining's l2: 0.584196\tvalid_1's l2: 0.617658\n",
      "[12]\ttraining's l2: 0.563933\tvalid_1's l2: 0.596614\n",
      "[13]\ttraining's l2: 0.545193\tvalid_1's l2: 0.577155\n",
      "[14]\ttraining's l2: 0.528215\tvalid_1's l2: 0.559223\n",
      "[15]\ttraining's l2: 0.512885\tvalid_1's l2: 0.543148\n",
      "[16]\ttraining's l2: 0.499443\tvalid_1's l2: 0.528913\n",
      "[17]\ttraining's l2: 0.486758\tvalid_1's l2: 0.515366\n",
      "[18]\ttraining's l2: 0.47529\tvalid_1's l2: 0.503155\n",
      "[19]\ttraining's l2: 0.464868\tvalid_1's l2: 0.492066\n",
      "[20]\ttraining's l2: 0.455667\tvalid_1's l2: 0.482196\n",
      "[21]\ttraining's l2: 0.44737\tvalid_1's l2: 0.473138\n",
      "[22]\ttraining's l2: 0.439521\tvalid_1's l2: 0.464707\n",
      "[23]\ttraining's l2: 0.432433\tvalid_1's l2: 0.457033\n",
      "[24]\ttraining's l2: 0.425933\tvalid_1's l2: 0.450033\n",
      "[25]\ttraining's l2: 0.420034\tvalid_1's l2: 0.443545\n",
      "[26]\ttraining's l2: 0.414887\tvalid_1's l2: 0.437809\n",
      "[27]\ttraining's l2: 0.41003\tvalid_1's l2: 0.432432\n",
      "[28]\ttraining's l2: 0.405583\tvalid_1's l2: 0.42743\n",
      "[29]\ttraining's l2: 0.401562\tvalid_1's l2: 0.42291\n",
      "[30]\ttraining's l2: 0.397865\tvalid_1's l2: 0.418791\n",
      "[31]\ttraining's l2: 0.394655\tvalid_1's l2: 0.415115\n",
      "[32]\ttraining's l2: 0.391586\tvalid_1's l2: 0.411604\n",
      "[33]\ttraining's l2: 0.388789\tvalid_1's l2: 0.408406\n",
      "[34]\ttraining's l2: 0.38622\tvalid_1's l2: 0.405404\n",
      "[35]\ttraining's l2: 0.383914\tvalid_1's l2: 0.402708\n",
      "[36]\ttraining's l2: 0.381875\tvalid_1's l2: 0.400288\n",
      "[37]\ttraining's l2: 0.380024\tvalid_1's l2: 0.398171\n",
      "[38]\ttraining's l2: 0.378337\tvalid_1's l2: 0.396173\n",
      "[39]\ttraining's l2: 0.376641\tvalid_1's l2: 0.394187\n",
      "[40]\ttraining's l2: 0.375141\tvalid_1's l2: 0.392502\n",
      "[41]\ttraining's l2: 0.3737\tvalid_1's l2: 0.390775\n",
      "[42]\ttraining's l2: 0.372378\tvalid_1's l2: 0.38918\n",
      "[43]\ttraining's l2: 0.371203\tvalid_1's l2: 0.387749\n",
      "[44]\ttraining's l2: 0.370158\tvalid_1's l2: 0.386481\n",
      "[45]\ttraining's l2: 0.369167\tvalid_1's l2: 0.385317\n",
      "[46]\ttraining's l2: 0.368253\tvalid_1's l2: 0.384215\n",
      "[47]\ttraining's l2: 0.367375\tvalid_1's l2: 0.383174\n",
      "[48]\ttraining's l2: 0.366519\tvalid_1's l2: 0.382124\n",
      "[49]\ttraining's l2: 0.365721\tvalid_1's l2: 0.381105\n",
      "[50]\ttraining's l2: 0.365007\tvalid_1's l2: 0.380215\n",
      "[51]\ttraining's l2: 0.364302\tvalid_1's l2: 0.379364\n",
      "[52]\ttraining's l2: 0.363647\tvalid_1's l2: 0.378533\n",
      "[53]\ttraining's l2: 0.363053\tvalid_1's l2: 0.377762\n",
      "[54]\ttraining's l2: 0.362475\tvalid_1's l2: 0.377112\n",
      "[55]\ttraining's l2: 0.361969\tvalid_1's l2: 0.376493\n",
      "[56]\ttraining's l2: 0.361465\tvalid_1's l2: 0.37584\n",
      "[57]\ttraining's l2: 0.360993\tvalid_1's l2: 0.375256\n",
      "[58]\ttraining's l2: 0.360508\tvalid_1's l2: 0.374706\n",
      "[59]\ttraining's l2: 0.360062\tvalid_1's l2: 0.374133\n",
      "[60]\ttraining's l2: 0.359635\tvalid_1's l2: 0.373595\n",
      "[61]\ttraining's l2: 0.359241\tvalid_1's l2: 0.373217\n",
      "[62]\ttraining's l2: 0.358893\tvalid_1's l2: 0.372839\n",
      "[63]\ttraining's l2: 0.35856\tvalid_1's l2: 0.372467\n",
      "[64]\ttraining's l2: 0.358211\tvalid_1's l2: 0.372076\n",
      "[65]\ttraining's l2: 0.35788\tvalid_1's l2: 0.371705\n",
      "[66]\ttraining's l2: 0.357583\tvalid_1's l2: 0.371376\n",
      "[67]\ttraining's l2: 0.357276\tvalid_1's l2: 0.371055\n",
      "[68]\ttraining's l2: 0.356959\tvalid_1's l2: 0.370705\n",
      "[69]\ttraining's l2: 0.356698\tvalid_1's l2: 0.37039\n",
      "[70]\ttraining's l2: 0.356415\tvalid_1's l2: 0.370078\n",
      "[71]\ttraining's l2: 0.35613\tvalid_1's l2: 0.369816\n",
      "[72]\ttraining's l2: 0.355884\tvalid_1's l2: 0.369588\n",
      "[73]\ttraining's l2: 0.355641\tvalid_1's l2: 0.369347\n",
      "[74]\ttraining's l2: 0.355411\tvalid_1's l2: 0.369111\n",
      "[75]\ttraining's l2: 0.355206\tvalid_1's l2: 0.368879\n",
      "[76]\ttraining's l2: 0.35497\tvalid_1's l2: 0.368655\n",
      "[77]\ttraining's l2: 0.354745\tvalid_1's l2: 0.368485\n",
      "[78]\ttraining's l2: 0.354511\tvalid_1's l2: 0.368325\n",
      "[79]\ttraining's l2: 0.354265\tvalid_1's l2: 0.368106\n",
      "[80]\ttraining's l2: 0.354023\tvalid_1's l2: 0.367932\n",
      "[81]\ttraining's l2: 0.353828\tvalid_1's l2: 0.367762\n",
      "[82]\ttraining's l2: 0.353654\tvalid_1's l2: 0.367588\n",
      "[83]\ttraining's l2: 0.35347\tvalid_1's l2: 0.367439\n",
      "[84]\ttraining's l2: 0.35327\tvalid_1's l2: 0.367226\n",
      "[85]\ttraining's l2: 0.353101\tvalid_1's l2: 0.36702\n",
      "[86]\ttraining's l2: 0.352936\tvalid_1's l2: 0.366894\n",
      "[87]\ttraining's l2: 0.352802\tvalid_1's l2: 0.366776\n",
      "[88]\ttraining's l2: 0.352662\tvalid_1's l2: 0.366641\n",
      "[89]\ttraining's l2: 0.352501\tvalid_1's l2: 0.366526\n",
      "[90]\ttraining's l2: 0.35238\tvalid_1's l2: 0.366437\n",
      "[91]\ttraining's l2: 0.352228\tvalid_1's l2: 0.366345\n",
      "[92]\ttraining's l2: 0.352089\tvalid_1's l2: 0.366215\n",
      "[93]\ttraining's l2: 0.351899\tvalid_1's l2: 0.36608\n",
      "[94]\ttraining's l2: 0.351737\tvalid_1's l2: 0.366009\n",
      "[95]\ttraining's l2: 0.351614\tvalid_1's l2: 0.365891\n",
      "[96]\ttraining's l2: 0.351493\tvalid_1's l2: 0.365859\n",
      "[97]\ttraining's l2: 0.351343\tvalid_1's l2: 0.365764\n",
      "[98]\ttraining's l2: 0.351211\tvalid_1's l2: 0.365702\n",
      "[99]\ttraining's l2: 0.351093\tvalid_1's l2: 0.365542\n",
      "[100]\ttraining's l2: 0.350964\tvalid_1's l2: 0.365428\n",
      "[101]\ttraining's l2: 0.350833\tvalid_1's l2: 0.365346\n",
      "[102]\ttraining's l2: 0.350737\tvalid_1's l2: 0.365307\n",
      "[103]\ttraining's l2: 0.3506\tvalid_1's l2: 0.365145\n",
      "[104]\ttraining's l2: 0.35042\tvalid_1's l2: 0.365024\n",
      "[105]\ttraining's l2: 0.350298\tvalid_1's l2: 0.364946\n",
      "[106]\ttraining's l2: 0.350165\tvalid_1's l2: 0.364862\n",
      "[107]\ttraining's l2: 0.350022\tvalid_1's l2: 0.364749\n",
      "[108]\ttraining's l2: 0.349916\tvalid_1's l2: 0.364691\n",
      "[109]\ttraining's l2: 0.349839\tvalid_1's l2: 0.36461\n",
      "[110]\ttraining's l2: 0.349679\tvalid_1's l2: 0.36441\n",
      "[111]\ttraining's l2: 0.349565\tvalid_1's l2: 0.364375\n",
      "[112]\ttraining's l2: 0.349457\tvalid_1's l2: 0.364287\n",
      "[113]\ttraining's l2: 0.349324\tvalid_1's l2: 0.364113\n",
      "[114]\ttraining's l2: 0.34926\tvalid_1's l2: 0.364099\n",
      "[115]\ttraining's l2: 0.349193\tvalid_1's l2: 0.364074\n",
      "[116]\ttraining's l2: 0.349087\tvalid_1's l2: 0.364\n",
      "[117]\ttraining's l2: 0.348986\tvalid_1's l2: 0.363898\n",
      "[118]\ttraining's l2: 0.348886\tvalid_1's l2: 0.363848\n",
      "[119]\ttraining's l2: 0.348814\tvalid_1's l2: 0.36378\n",
      "[120]\ttraining's l2: 0.348718\tvalid_1's l2: 0.363698\n",
      "[121]\ttraining's l2: 0.348636\tvalid_1's l2: 0.363651\n",
      "[122]\ttraining's l2: 0.348537\tvalid_1's l2: 0.363591\n",
      "[123]\ttraining's l2: 0.348455\tvalid_1's l2: 0.36353\n",
      "[124]\ttraining's l2: 0.348391\tvalid_1's l2: 0.363535\n",
      "[125]\ttraining's l2: 0.348269\tvalid_1's l2: 0.363436\n",
      "[126]\ttraining's l2: 0.348191\tvalid_1's l2: 0.363415\n",
      "[127]\ttraining's l2: 0.348108\tvalid_1's l2: 0.363365\n",
      "[128]\ttraining's l2: 0.348032\tvalid_1's l2: 0.363281\n",
      "[129]\ttraining's l2: 0.347939\tvalid_1's l2: 0.363161\n",
      "[130]\ttraining's l2: 0.347873\tvalid_1's l2: 0.363152\n",
      "[131]\ttraining's l2: 0.347799\tvalid_1's l2: 0.363121\n",
      "[132]\ttraining's l2: 0.347727\tvalid_1's l2: 0.363124\n",
      "[133]\ttraining's l2: 0.34766\tvalid_1's l2: 0.363058\n",
      "[134]\ttraining's l2: 0.347586\tvalid_1's l2: 0.362992\n",
      "[135]\ttraining's l2: 0.347507\tvalid_1's l2: 0.362962\n",
      "[136]\ttraining's l2: 0.347411\tvalid_1's l2: 0.362884\n",
      "[137]\ttraining's l2: 0.347308\tvalid_1's l2: 0.362839\n",
      "[138]\ttraining's l2: 0.347226\tvalid_1's l2: 0.362792\n",
      "[139]\ttraining's l2: 0.347158\tvalid_1's l2: 0.362754\n",
      "[140]\ttraining's l2: 0.347079\tvalid_1's l2: 0.362639\n",
      "[141]\ttraining's l2: 0.346985\tvalid_1's l2: 0.362591\n",
      "[142]\ttraining's l2: 0.346939\tvalid_1's l2: 0.362587\n",
      "[143]\ttraining's l2: 0.346855\tvalid_1's l2: 0.362571\n",
      "[144]\ttraining's l2: 0.346798\tvalid_1's l2: 0.362597\n",
      "[145]\ttraining's l2: 0.346746\tvalid_1's l2: 0.362573\n",
      "[146]\ttraining's l2: 0.346697\tvalid_1's l2: 0.362553\n",
      "[147]\ttraining's l2: 0.346645\tvalid_1's l2: 0.362527\n",
      "[148]\ttraining's l2: 0.346575\tvalid_1's l2: 0.362511\n",
      "[149]\ttraining's l2: 0.346521\tvalid_1's l2: 0.362502\n",
      "[150]\ttraining's l2: 0.346469\tvalid_1's l2: 0.362445\n",
      "[151]\ttraining's l2: 0.346415\tvalid_1's l2: 0.362408\n",
      "[152]\ttraining's l2: 0.346377\tvalid_1's l2: 0.362409\n",
      "[153]\ttraining's l2: 0.346328\tvalid_1's l2: 0.36238\n",
      "[154]\ttraining's l2: 0.346265\tvalid_1's l2: 0.362289\n",
      "[155]\ttraining's l2: 0.346193\tvalid_1's l2: 0.362209\n",
      "[156]\ttraining's l2: 0.346092\tvalid_1's l2: 0.362165\n",
      "[157]\ttraining's l2: 0.346057\tvalid_1's l2: 0.362155\n",
      "[158]\ttraining's l2: 0.345999\tvalid_1's l2: 0.362129\n",
      "[159]\ttraining's l2: 0.345939\tvalid_1's l2: 0.362055\n",
      "[160]\ttraining's l2: 0.34589\tvalid_1's l2: 0.362042\n",
      "[161]\ttraining's l2: 0.345772\tvalid_1's l2: 0.361925\n",
      "[162]\ttraining's l2: 0.345716\tvalid_1's l2: 0.361903\n",
      "[163]\ttraining's l2: 0.345667\tvalid_1's l2: 0.36185\n",
      "[164]\ttraining's l2: 0.34563\tvalid_1's l2: 0.361819\n",
      "[165]\ttraining's l2: 0.345558\tvalid_1's l2: 0.36177\n",
      "[166]\ttraining's l2: 0.345502\tvalid_1's l2: 0.36173\n",
      "[167]\ttraining's l2: 0.345453\tvalid_1's l2: 0.361697\n",
      "[168]\ttraining's l2: 0.345351\tvalid_1's l2: 0.361643\n",
      "[169]\ttraining's l2: 0.345307\tvalid_1's l2: 0.361627\n",
      "[170]\ttraining's l2: 0.345255\tvalid_1's l2: 0.361606\n",
      "[171]\ttraining's l2: 0.345207\tvalid_1's l2: 0.361595\n",
      "[172]\ttraining's l2: 0.345169\tvalid_1's l2: 0.361613\n",
      "[173]\ttraining's l2: 0.345103\tvalid_1's l2: 0.361568\n",
      "[174]\ttraining's l2: 0.345067\tvalid_1's l2: 0.361548\n",
      "[175]\ttraining's l2: 0.345029\tvalid_1's l2: 0.361521\n",
      "[176]\ttraining's l2: 0.344963\tvalid_1's l2: 0.361488\n",
      "[177]\ttraining's l2: 0.344896\tvalid_1's l2: 0.361431\n",
      "[178]\ttraining's l2: 0.34486\tvalid_1's l2: 0.36141\n",
      "[179]\ttraining's l2: 0.344825\tvalid_1's l2: 0.361395\n",
      "[180]\ttraining's l2: 0.344788\tvalid_1's l2: 0.361387\n",
      "[181]\ttraining's l2: 0.34475\tvalid_1's l2: 0.361343\n",
      "[182]\ttraining's l2: 0.344711\tvalid_1's l2: 0.361332\n",
      "[183]\ttraining's l2: 0.344669\tvalid_1's l2: 0.361329\n",
      "[184]\ttraining's l2: 0.344617\tvalid_1's l2: 0.361315\n",
      "[185]\ttraining's l2: 0.344586\tvalid_1's l2: 0.361303\n",
      "[186]\ttraining's l2: 0.344548\tvalid_1's l2: 0.361303\n",
      "[187]\ttraining's l2: 0.344511\tvalid_1's l2: 0.361281\n",
      "[188]\ttraining's l2: 0.344464\tvalid_1's l2: 0.361279\n",
      "[189]\ttraining's l2: 0.344421\tvalid_1's l2: 0.361288\n",
      "[190]\ttraining's l2: 0.344386\tvalid_1's l2: 0.361275\n",
      "[191]\ttraining's l2: 0.344352\tvalid_1's l2: 0.361256\n",
      "[192]\ttraining's l2: 0.34431\tvalid_1's l2: 0.361227\n",
      "[193]\ttraining's l2: 0.344281\tvalid_1's l2: 0.361227\n",
      "[194]\ttraining's l2: 0.344236\tvalid_1's l2: 0.361211\n",
      "[195]\ttraining's l2: 0.344161\tvalid_1's l2: 0.361121\n",
      "[196]\ttraining's l2: 0.344128\tvalid_1's l2: 0.361098\n",
      "[197]\ttraining's l2: 0.344075\tvalid_1's l2: 0.361025\n",
      "[198]\ttraining's l2: 0.344043\tvalid_1's l2: 0.36097\n",
      "[199]\ttraining's l2: 0.344001\tvalid_1's l2: 0.360953\n",
      "[200]\ttraining's l2: 0.343976\tvalid_1's l2: 0.36094\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.343976\tvalid_1's l2: 0.36094\n",
      "mean_30_sales: 4757781.83\n",
      "mean_7_sales: 4609700.31\n",
      "mean_14_sales: 4521931.55\n",
      "mean_21_sales: 4005957.54\n",
      "mean_20_dow1_2017: 856340.12\n",
      "mean_63_sales: 779580.94\n",
      "promo_8: 725915.94\n",
      "mean_6_sales: 509791.54\n",
      "mean_60_sales: 282561.08\n",
      "item_class_features: 238497.24\n",
      "lag_1_sales: 92653.54\n",
      "mean_4_dow1_2017: 75503.62\n",
      "promo_7: 68617.77\n",
      "sum_4_promo: 62790.14\n",
      "std_30_sales: 58658.59\n",
      "mean_20_dow2_2017: 46642.24\n",
      "promo_10: 45522.52\n",
      "std_21_sales: 36999.59\n",
      "mean_4_dow6_2017: 33289.74\n",
      "sum_6_promo: 28358.44\n",
      "sum_2_promo: 24621.49\n",
      "std_63_sales: 23658.26\n",
      "item_family_features: 23591.73\n",
      "promo_9: 21624.37\n",
      "promo_14: 21390.22\n",
      "std_14_sales: 20799.23\n",
      "mean_3_sales: 20242.72\n",
      "sum_7_promo: 18409.53\n",
      "lag_21_transactions: 18185.03\n",
      "mean_4_sales: 15125.54\n",
      "lag_1_transactions: 14836.79\n",
      "mean_5_sales: 14825.80\n",
      "lag_21_sales: 14608.61\n",
      "lag_3_transactions: 14602.98\n",
      "std_60_sales: 14481.68\n",
      "promo_12: 14344.40\n",
      "sum_14_promo: 11470.06\n",
      "sum_21_promo: 10578.29\n",
      "mean_20_dow0_2017: 9975.65\n",
      "promo_11: 9840.50\n",
      "sum_5_promo: 9554.31\n",
      "std_7_sales: 9371.15\n",
      "promo_3: 8712.92\n",
      "lag_56_sales: 8660.99\n",
      "promo_1: 8411.95\n",
      "promo_6: 8279.36\n",
      "lag_6_transactions: 7618.93\n",
      "lag_5_sales: 7586.35\n",
      "lag_6_sales: 7510.08\n",
      "lag_2_transactions: 7499.04\n",
      "mean_20_dow3_2017: 7135.28\n",
      "store_city_features: 6450.84\n",
      "store_cluster_features: 6443.49\n",
      "promo_13: 6407.12\n",
      "lag_14_transactions: 5746.96\n",
      "lag_7_transactions: 5691.03\n",
      "promo_4: 4579.64\n",
      "std_6_sales: 4504.95\n",
      "lag_4_sales: 4487.09\n",
      "sum_3_promo: 4322.08\n",
      "lag_5_transactions: 4320.94\n",
      "mean_20_dow6_2017: 3893.57\n",
      "mean_4_dow2_2017: 3540.25\n",
      "mean_20_dow4_2017: 3430.12\n",
      "promo_5: 3301.65\n",
      "lag_4_transactions: 3197.64\n",
      "promo_0: 3156.31\n",
      "lag_49_sales: 2880.31\n",
      "mean_4_dow0_2017: 2074.00\n",
      "lag_35_sales: 1833.44\n",
      "std_5_sales: 1790.45\n",
      "store_state_features: 1454.70\n",
      "mean_20_dow5_2017: 1412.28\n",
      "lag_3_sales: 1384.28\n",
      "promo_15: 1305.16\n",
      "lag_2_sales: 1269.18\n",
      "lag_7_sales: 1203.21\n",
      "lag_14_sales: 1073.80\n",
      "promo_2: 1069.36\n",
      "mean_4_dow3_2017: 1020.58\n",
      "mean_4_dow4_2017: 944.33\n",
      "mean_4_dow5_2017: 848.24\n",
      "store_type_features: 714.36\n",
      "lag_28_sales: 581.85\n",
      "std_4_sales: 414.35\n",
      "lag_63_sales: 349.10\n",
      "std_3_sales: 271.12\n",
      "lag_42_sales: 233.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [14:46<11:20, 97.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05838\tvalid_1's l2: 1.07115\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.994056\tvalid_1's l2: 1.0064\n",
      "[3]\ttraining's l2: 0.935763\tvalid_1's l2: 0.947768\n",
      "[4]\ttraining's l2: 0.883056\tvalid_1's l2: 0.894598\n",
      "[5]\ttraining's l2: 0.835649\tvalid_1's l2: 0.846472\n",
      "[6]\ttraining's l2: 0.792288\tvalid_1's l2: 0.802904\n",
      "[7]\ttraining's l2: 0.753073\tvalid_1's l2: 0.763542\n",
      "[8]\ttraining's l2: 0.717827\tvalid_1's l2: 0.727614\n",
      "[9]\ttraining's l2: 0.686424\tvalid_1's l2: 0.695756\n",
      "[10]\ttraining's l2: 0.65714\tvalid_1's l2: 0.666161\n",
      "[11]\ttraining's l2: 0.630496\tvalid_1's l2: 0.639094\n",
      "[12]\ttraining's l2: 0.606346\tvalid_1's l2: 0.614532\n",
      "[13]\ttraining's l2: 0.584496\tvalid_1's l2: 0.59235\n",
      "[14]\ttraining's l2: 0.565229\tvalid_1's l2: 0.57276\n",
      "[15]\ttraining's l2: 0.547201\tvalid_1's l2: 0.554533\n",
      "[16]\ttraining's l2: 0.531422\tvalid_1's l2: 0.538419\n",
      "[17]\ttraining's l2: 0.516562\tvalid_1's l2: 0.523085\n",
      "[18]\ttraining's l2: 0.503403\tvalid_1's l2: 0.509726\n",
      "[19]\ttraining's l2: 0.491074\tvalid_1's l2: 0.49703\n",
      "[20]\ttraining's l2: 0.479774\tvalid_1's l2: 0.48551\n",
      "[21]\ttraining's l2: 0.47003\tvalid_1's l2: 0.475517\n",
      "[22]\ttraining's l2: 0.461099\tvalid_1's l2: 0.466431\n",
      "[23]\ttraining's l2: 0.452629\tvalid_1's l2: 0.457673\n",
      "[24]\ttraining's l2: 0.444904\tvalid_1's l2: 0.449715\n",
      "[25]\ttraining's l2: 0.437822\tvalid_1's l2: 0.442463\n",
      "[26]\ttraining's l2: 0.431778\tvalid_1's l2: 0.436183\n",
      "[27]\ttraining's l2: 0.425905\tvalid_1's l2: 0.430092\n",
      "[28]\ttraining's l2: 0.42051\tvalid_1's l2: 0.424579\n",
      "[29]\ttraining's l2: 0.41562\tvalid_1's l2: 0.419583\n",
      "[30]\ttraining's l2: 0.411468\tvalid_1's l2: 0.41537\n",
      "[31]\ttraining's l2: 0.407311\tvalid_1's l2: 0.411105\n",
      "[32]\ttraining's l2: 0.403814\tvalid_1's l2: 0.407464\n",
      "[33]\ttraining's l2: 0.400617\tvalid_1's l2: 0.404099\n",
      "[34]\ttraining's l2: 0.397402\tvalid_1's l2: 0.400767\n",
      "[35]\ttraining's l2: 0.394468\tvalid_1's l2: 0.397684\n",
      "[36]\ttraining's l2: 0.391806\tvalid_1's l2: 0.394803\n",
      "[37]\ttraining's l2: 0.389512\tvalid_1's l2: 0.392474\n",
      "[38]\ttraining's l2: 0.387244\tvalid_1's l2: 0.39001\n",
      "[39]\ttraining's l2: 0.385069\tvalid_1's l2: 0.38767\n",
      "[40]\ttraining's l2: 0.38315\tvalid_1's l2: 0.385498\n",
      "[41]\ttraining's l2: 0.381356\tvalid_1's l2: 0.383549\n",
      "[42]\ttraining's l2: 0.379718\tvalid_1's l2: 0.38185\n",
      "[43]\ttraining's l2: 0.378201\tvalid_1's l2: 0.380212\n",
      "[44]\ttraining's l2: 0.376947\tvalid_1's l2: 0.378913\n",
      "[45]\ttraining's l2: 0.375723\tvalid_1's l2: 0.377735\n",
      "[46]\ttraining's l2: 0.374464\tvalid_1's l2: 0.376375\n",
      "[47]\ttraining's l2: 0.373331\tvalid_1's l2: 0.375121\n",
      "[48]\ttraining's l2: 0.37218\tvalid_1's l2: 0.37389\n",
      "[49]\ttraining's l2: 0.371227\tvalid_1's l2: 0.372883\n",
      "[50]\ttraining's l2: 0.370299\tvalid_1's l2: 0.37186\n",
      "[51]\ttraining's l2: 0.369506\tvalid_1's l2: 0.371057\n",
      "[52]\ttraining's l2: 0.368641\tvalid_1's l2: 0.370156\n",
      "[53]\ttraining's l2: 0.367887\tvalid_1's l2: 0.369324\n",
      "[54]\ttraining's l2: 0.367152\tvalid_1's l2: 0.368584\n",
      "[55]\ttraining's l2: 0.366467\tvalid_1's l2: 0.367877\n",
      "[56]\ttraining's l2: 0.365839\tvalid_1's l2: 0.367282\n",
      "[57]\ttraining's l2: 0.365233\tvalid_1's l2: 0.366714\n",
      "[58]\ttraining's l2: 0.364659\tvalid_1's l2: 0.366137\n",
      "[59]\ttraining's l2: 0.364164\tvalid_1's l2: 0.365625\n",
      "[60]\ttraining's l2: 0.36368\tvalid_1's l2: 0.365135\n",
      "[61]\ttraining's l2: 0.363198\tvalid_1's l2: 0.364649\n",
      "[62]\ttraining's l2: 0.362691\tvalid_1's l2: 0.364214\n",
      "[63]\ttraining's l2: 0.362212\tvalid_1's l2: 0.36381\n",
      "[64]\ttraining's l2: 0.361768\tvalid_1's l2: 0.363362\n",
      "[65]\ttraining's l2: 0.361412\tvalid_1's l2: 0.362978\n",
      "[66]\ttraining's l2: 0.361056\tvalid_1's l2: 0.362665\n",
      "[67]\ttraining's l2: 0.360698\tvalid_1's l2: 0.362279\n",
      "[68]\ttraining's l2: 0.360395\tvalid_1's l2: 0.362017\n",
      "[69]\ttraining's l2: 0.360044\tvalid_1's l2: 0.361639\n",
      "[70]\ttraining's l2: 0.359656\tvalid_1's l2: 0.361241\n",
      "[71]\ttraining's l2: 0.35934\tvalid_1's l2: 0.360955\n",
      "[72]\ttraining's l2: 0.35901\tvalid_1's l2: 0.360743\n",
      "[73]\ttraining's l2: 0.358738\tvalid_1's l2: 0.360582\n",
      "[74]\ttraining's l2: 0.358495\tvalid_1's l2: 0.360388\n",
      "[75]\ttraining's l2: 0.358197\tvalid_1's l2: 0.360126\n",
      "[76]\ttraining's l2: 0.357906\tvalid_1's l2: 0.359952\n",
      "[77]\ttraining's l2: 0.357639\tvalid_1's l2: 0.359689\n",
      "[78]\ttraining's l2: 0.357365\tvalid_1's l2: 0.359414\n",
      "[79]\ttraining's l2: 0.357135\tvalid_1's l2: 0.359284\n",
      "[80]\ttraining's l2: 0.356827\tvalid_1's l2: 0.359032\n",
      "[81]\ttraining's l2: 0.356576\tvalid_1's l2: 0.358855\n",
      "[82]\ttraining's l2: 0.356341\tvalid_1's l2: 0.358664\n",
      "[83]\ttraining's l2: 0.356119\tvalid_1's l2: 0.358505\n",
      "[84]\ttraining's l2: 0.355887\tvalid_1's l2: 0.358335\n",
      "[85]\ttraining's l2: 0.355695\tvalid_1's l2: 0.358209\n",
      "[86]\ttraining's l2: 0.355493\tvalid_1's l2: 0.358077\n",
      "[87]\ttraining's l2: 0.355279\tvalid_1's l2: 0.357865\n",
      "[88]\ttraining's l2: 0.35506\tvalid_1's l2: 0.35771\n",
      "[89]\ttraining's l2: 0.354809\tvalid_1's l2: 0.357534\n",
      "[90]\ttraining's l2: 0.354592\tvalid_1's l2: 0.357316\n",
      "[91]\ttraining's l2: 0.354442\tvalid_1's l2: 0.357261\n",
      "[92]\ttraining's l2: 0.354254\tvalid_1's l2: 0.357107\n",
      "[93]\ttraining's l2: 0.354009\tvalid_1's l2: 0.356941\n",
      "[94]\ttraining's l2: 0.353842\tvalid_1's l2: 0.356862\n",
      "[95]\ttraining's l2: 0.353628\tvalid_1's l2: 0.356673\n",
      "[96]\ttraining's l2: 0.353467\tvalid_1's l2: 0.356614\n",
      "[97]\ttraining's l2: 0.353303\tvalid_1's l2: 0.356587\n",
      "[98]\ttraining's l2: 0.353155\tvalid_1's l2: 0.35652\n",
      "[99]\ttraining's l2: 0.3529\tvalid_1's l2: 0.356294\n",
      "[100]\ttraining's l2: 0.352652\tvalid_1's l2: 0.356069\n",
      "[101]\ttraining's l2: 0.35252\tvalid_1's l2: 0.35597\n",
      "[102]\ttraining's l2: 0.352386\tvalid_1's l2: 0.355889\n",
      "[103]\ttraining's l2: 0.352275\tvalid_1's l2: 0.355837\n",
      "[104]\ttraining's l2: 0.352072\tvalid_1's l2: 0.355699\n",
      "[105]\ttraining's l2: 0.35193\tvalid_1's l2: 0.355653\n",
      "[106]\ttraining's l2: 0.351787\tvalid_1's l2: 0.355615\n",
      "[107]\ttraining's l2: 0.351656\tvalid_1's l2: 0.355615\n",
      "[108]\ttraining's l2: 0.351482\tvalid_1's l2: 0.355488\n",
      "[109]\ttraining's l2: 0.351377\tvalid_1's l2: 0.355408\n",
      "[110]\ttraining's l2: 0.351279\tvalid_1's l2: 0.355334\n",
      "[111]\ttraining's l2: 0.351141\tvalid_1's l2: 0.355323\n",
      "[112]\ttraining's l2: 0.351035\tvalid_1's l2: 0.355266\n",
      "[113]\ttraining's l2: 0.350906\tvalid_1's l2: 0.355192\n",
      "[114]\ttraining's l2: 0.350759\tvalid_1's l2: 0.355167\n",
      "[115]\ttraining's l2: 0.350576\tvalid_1's l2: 0.354995\n",
      "[116]\ttraining's l2: 0.35041\tvalid_1's l2: 0.354865\n",
      "[117]\ttraining's l2: 0.350295\tvalid_1's l2: 0.354799\n",
      "[118]\ttraining's l2: 0.350201\tvalid_1's l2: 0.354735\n",
      "[119]\ttraining's l2: 0.35012\tvalid_1's l2: 0.354703\n",
      "[120]\ttraining's l2: 0.350007\tvalid_1's l2: 0.354673\n",
      "[121]\ttraining's l2: 0.34986\tvalid_1's l2: 0.35452\n",
      "[122]\ttraining's l2: 0.349761\tvalid_1's l2: 0.354465\n",
      "[123]\ttraining's l2: 0.349608\tvalid_1's l2: 0.354331\n",
      "[124]\ttraining's l2: 0.349462\tvalid_1's l2: 0.354295\n",
      "[125]\ttraining's l2: 0.349345\tvalid_1's l2: 0.354141\n",
      "[126]\ttraining's l2: 0.349244\tvalid_1's l2: 0.354103\n",
      "[127]\ttraining's l2: 0.34917\tvalid_1's l2: 0.354071\n",
      "[128]\ttraining's l2: 0.349071\tvalid_1's l2: 0.354042\n",
      "[129]\ttraining's l2: 0.348998\tvalid_1's l2: 0.353999\n",
      "[130]\ttraining's l2: 0.348925\tvalid_1's l2: 0.353993\n",
      "[131]\ttraining's l2: 0.348812\tvalid_1's l2: 0.353849\n",
      "[132]\ttraining's l2: 0.348728\tvalid_1's l2: 0.353809\n",
      "[133]\ttraining's l2: 0.348638\tvalid_1's l2: 0.353766\n",
      "[134]\ttraining's l2: 0.348527\tvalid_1's l2: 0.353733\n",
      "[135]\ttraining's l2: 0.34843\tvalid_1's l2: 0.353661\n",
      "[136]\ttraining's l2: 0.348327\tvalid_1's l2: 0.35361\n",
      "[137]\ttraining's l2: 0.348262\tvalid_1's l2: 0.353577\n",
      "[138]\ttraining's l2: 0.348202\tvalid_1's l2: 0.353528\n",
      "[139]\ttraining's l2: 0.348148\tvalid_1's l2: 0.353496\n",
      "[140]\ttraining's l2: 0.348089\tvalid_1's l2: 0.353477\n",
      "[141]\ttraining's l2: 0.348019\tvalid_1's l2: 0.35347\n",
      "[142]\ttraining's l2: 0.347959\tvalid_1's l2: 0.353424\n",
      "[143]\ttraining's l2: 0.347881\tvalid_1's l2: 0.353404\n",
      "[144]\ttraining's l2: 0.347823\tvalid_1's l2: 0.353379\n",
      "[145]\ttraining's l2: 0.347779\tvalid_1's l2: 0.35336\n",
      "[146]\ttraining's l2: 0.34768\tvalid_1's l2: 0.353353\n",
      "[147]\ttraining's l2: 0.347621\tvalid_1's l2: 0.353319\n",
      "[148]\ttraining's l2: 0.347572\tvalid_1's l2: 0.353295\n",
      "[149]\ttraining's l2: 0.347488\tvalid_1's l2: 0.353226\n",
      "[150]\ttraining's l2: 0.347417\tvalid_1's l2: 0.353161\n",
      "[151]\ttraining's l2: 0.347353\tvalid_1's l2: 0.35311\n",
      "[152]\ttraining's l2: 0.347285\tvalid_1's l2: 0.353083\n",
      "[153]\ttraining's l2: 0.347226\tvalid_1's l2: 0.353091\n",
      "[154]\ttraining's l2: 0.347147\tvalid_1's l2: 0.353086\n",
      "[155]\ttraining's l2: 0.347104\tvalid_1's l2: 0.35306\n",
      "[156]\ttraining's l2: 0.347067\tvalid_1's l2: 0.353055\n",
      "[157]\ttraining's l2: 0.347022\tvalid_1's l2: 0.35304\n",
      "[158]\ttraining's l2: 0.346974\tvalid_1's l2: 0.353017\n",
      "[159]\ttraining's l2: 0.346909\tvalid_1's l2: 0.352969\n",
      "[160]\ttraining's l2: 0.346843\tvalid_1's l2: 0.352955\n",
      "[161]\ttraining's l2: 0.346778\tvalid_1's l2: 0.352938\n",
      "[162]\ttraining's l2: 0.346712\tvalid_1's l2: 0.3529\n",
      "[163]\ttraining's l2: 0.346662\tvalid_1's l2: 0.352883\n",
      "[164]\ttraining's l2: 0.346618\tvalid_1's l2: 0.352864\n",
      "[165]\ttraining's l2: 0.346509\tvalid_1's l2: 0.352801\n",
      "[166]\ttraining's l2: 0.346456\tvalid_1's l2: 0.352795\n",
      "[167]\ttraining's l2: 0.346396\tvalid_1's l2: 0.352736\n",
      "[168]\ttraining's l2: 0.34633\tvalid_1's l2: 0.352719\n",
      "[169]\ttraining's l2: 0.346271\tvalid_1's l2: 0.35266\n",
      "[170]\ttraining's l2: 0.346215\tvalid_1's l2: 0.352612\n",
      "[171]\ttraining's l2: 0.346178\tvalid_1's l2: 0.352643\n",
      "[172]\ttraining's l2: 0.346137\tvalid_1's l2: 0.352632\n",
      "[173]\ttraining's l2: 0.346069\tvalid_1's l2: 0.35261\n",
      "[174]\ttraining's l2: 0.346012\tvalid_1's l2: 0.352585\n",
      "[175]\ttraining's l2: 0.345965\tvalid_1's l2: 0.352557\n",
      "[176]\ttraining's l2: 0.345931\tvalid_1's l2: 0.352536\n",
      "[177]\ttraining's l2: 0.345894\tvalid_1's l2: 0.352515\n",
      "[178]\ttraining's l2: 0.345847\tvalid_1's l2: 0.352511\n",
      "[179]\ttraining's l2: 0.345799\tvalid_1's l2: 0.352491\n",
      "[180]\ttraining's l2: 0.345742\tvalid_1's l2: 0.352506\n",
      "[181]\ttraining's l2: 0.345687\tvalid_1's l2: 0.352478\n",
      "[182]\ttraining's l2: 0.345644\tvalid_1's l2: 0.352469\n",
      "[183]\ttraining's l2: 0.345566\tvalid_1's l2: 0.352415\n",
      "[184]\ttraining's l2: 0.345525\tvalid_1's l2: 0.352382\n",
      "[185]\ttraining's l2: 0.345489\tvalid_1's l2: 0.352368\n",
      "[186]\ttraining's l2: 0.345425\tvalid_1's l2: 0.352341\n",
      "[187]\ttraining's l2: 0.34538\tvalid_1's l2: 0.352318\n",
      "[188]\ttraining's l2: 0.345342\tvalid_1's l2: 0.352311\n",
      "[189]\ttraining's l2: 0.345305\tvalid_1's l2: 0.352304\n",
      "[190]\ttraining's l2: 0.345256\tvalid_1's l2: 0.35229\n",
      "[191]\ttraining's l2: 0.34521\tvalid_1's l2: 0.352291\n",
      "[192]\ttraining's l2: 0.345176\tvalid_1's l2: 0.352273\n",
      "[193]\ttraining's l2: 0.345134\tvalid_1's l2: 0.352271\n",
      "[194]\ttraining's l2: 0.345092\tvalid_1's l2: 0.352256\n",
      "[195]\ttraining's l2: 0.345044\tvalid_1's l2: 0.352238\n",
      "[196]\ttraining's l2: 0.344996\tvalid_1's l2: 0.352194\n",
      "[197]\ttraining's l2: 0.344956\tvalid_1's l2: 0.352181\n",
      "[198]\ttraining's l2: 0.344906\tvalid_1's l2: 0.352136\n",
      "[199]\ttraining's l2: 0.34487\tvalid_1's l2: 0.352122\n",
      "[200]\ttraining's l2: 0.344841\tvalid_1's l2: 0.352113\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.344841\tvalid_1's l2: 0.352113\n",
      "mean_21_sales: 8765808.00\n",
      "mean_7_sales: 3731896.60\n",
      "mean_14_sales: 2988590.48\n",
      "mean_20_dow2_2017: 2645692.10\n",
      "mean_30_sales: 2597501.44\n",
      "mean_6_sales: 1157250.93\n",
      "mean_4_dow2_2017: 1056572.89\n",
      "promo_9: 957957.29\n",
      "mean_63_sales: 430891.07\n",
      "item_class_features: 383302.43\n",
      "mean_60_sales: 160218.78\n",
      "mean_5_sales: 136916.39\n",
      "sum_5_promo: 120727.32\n",
      "item_family_features: 88482.07\n",
      "std_21_sales: 81911.58\n",
      "std_30_sales: 72515.53\n",
      "lag_1_sales: 58449.94\n",
      "promo_10: 50802.78\n",
      "promo_7: 49337.19\n",
      "store_cluster_features: 46940.68\n",
      "promo_14: 45013.81\n",
      "std_14_sales: 40686.08\n",
      "std_63_sales: 38436.86\n",
      "lag_5_sales: 35129.93\n",
      "promo_2: 30586.00\n",
      "std_60_sales: 28584.39\n",
      "promo_12: 27991.05\n",
      "sum_4_promo: 26298.56\n",
      "promo_8: 25314.21\n",
      "lag_1_transactions: 18422.42\n",
      "mean_20_dow1_2017: 17923.15\n",
      "promo_11: 16757.70\n",
      "lag_4_sales: 16308.96\n",
      "lag_14_transactions: 14854.84\n",
      "lag_4_transactions: 14408.96\n",
      "mean_20_dow0_2017: 13476.82\n",
      "sum_7_promo: 12886.04\n",
      "mean_20_dow3_2017: 12393.04\n",
      "lag_49_sales: 11579.92\n",
      "mean_4_sales: 11436.78\n",
      "mean_3_sales: 11353.55\n",
      "sum_14_promo: 11272.71\n",
      "sum_2_promo: 11222.02\n",
      "store_city_features: 10665.00\n",
      "lag_3_transactions: 10451.36\n",
      "lag_6_transactions: 9939.80\n",
      "std_7_sales: 9224.37\n",
      "lag_21_sales: 8862.87\n",
      "lag_21_transactions: 8501.98\n",
      "store_type_features: 8365.69\n",
      "lag_2_transactions: 8202.72\n",
      "std_6_sales: 7468.82\n",
      "std_5_sales: 6781.66\n",
      "sum_21_promo: 6548.15\n",
      "sum_3_promo: 6349.79\n",
      "store_state_features: 5333.94\n",
      "lag_5_transactions: 4502.27\n",
      "lag_7_transactions: 4421.64\n",
      "mean_20_dow4_2017: 4153.37\n",
      "promo_15: 4108.79\n",
      "promo_13: 3869.15\n",
      "mean_4_dow1_2017: 3712.25\n",
      "mean_4_dow0_2017: 3561.93\n",
      "promo_6: 2851.03\n",
      "mean_20_dow6_2017: 2538.81\n",
      "promo_0: 2313.07\n",
      "mean_4_dow3_2017: 2167.39\n",
      "lag_14_sales: 2065.60\n",
      "mean_4_dow6_2017: 1894.61\n",
      "lag_6_sales: 1695.47\n",
      "mean_4_dow4_2017: 1477.62\n",
      "sum_6_promo: 1385.02\n",
      "lag_35_sales: 1147.45\n",
      "lag_2_sales: 1089.99\n",
      "std_4_sales: 962.97\n",
      "mean_20_dow5_2017: 945.03\n",
      "promo_1: 839.45\n",
      "promo_3: 798.06\n",
      "lag_3_sales: 728.68\n",
      "lag_56_sales: 600.49\n",
      "lag_7_sales: 518.08\n",
      "lag_42_sales: 473.57\n",
      "lag_63_sales: 411.56\n",
      "mean_4_dow5_2017: 288.18\n",
      "lag_28_sales: 224.78\n",
      "std_3_sales: 158.76\n",
      "promo_4: 0.00\n",
      "promo_5: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [16:25<09:46, 97.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.19481\tvalid_1's l2: 1.14556\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.11989\tvalid_1's l2: 1.07225\n",
      "[3]\ttraining's l2: 1.05315\tvalid_1's l2: 1.00687\n",
      "[4]\ttraining's l2: 0.992752\tvalid_1's l2: 0.947856\n",
      "[5]\ttraining's l2: 0.93726\tvalid_1's l2: 0.893497\n",
      "[6]\ttraining's l2: 0.887814\tvalid_1's l2: 0.845271\n",
      "[7]\ttraining's l2: 0.84222\tvalid_1's l2: 0.800917\n",
      "[8]\ttraining's l2: 0.801017\tvalid_1's l2: 0.760819\n",
      "[9]\ttraining's l2: 0.764173\tvalid_1's l2: 0.725218\n",
      "[10]\ttraining's l2: 0.730859\tvalid_1's l2: 0.693006\n",
      "[11]\ttraining's l2: 0.699813\tvalid_1's l2: 0.662981\n",
      "[12]\ttraining's l2: 0.671617\tvalid_1's l2: 0.635702\n",
      "[13]\ttraining's l2: 0.646259\tvalid_1's l2: 0.611378\n",
      "[14]\ttraining's l2: 0.623826\tvalid_1's l2: 0.589962\n",
      "[15]\ttraining's l2: 0.60308\tvalid_1's l2: 0.570025\n",
      "[16]\ttraining's l2: 0.584739\tvalid_1's l2: 0.55245\n",
      "[17]\ttraining's l2: 0.567392\tvalid_1's l2: 0.535795\n",
      "[18]\ttraining's l2: 0.551682\tvalid_1's l2: 0.520791\n",
      "[19]\ttraining's l2: 0.537765\tvalid_1's l2: 0.507592\n",
      "[20]\ttraining's l2: 0.52472\tvalid_1's l2: 0.495101\n",
      "[21]\ttraining's l2: 0.513318\tvalid_1's l2: 0.484262\n",
      "[22]\ttraining's l2: 0.502539\tvalid_1's l2: 0.474052\n",
      "[23]\ttraining's l2: 0.493235\tvalid_1's l2: 0.465262\n",
      "[24]\ttraining's l2: 0.484368\tvalid_1's l2: 0.456855\n",
      "[25]\ttraining's l2: 0.476612\tvalid_1's l2: 0.449518\n",
      "[26]\ttraining's l2: 0.469215\tvalid_1's l2: 0.442527\n",
      "[27]\ttraining's l2: 0.462522\tvalid_1's l2: 0.43628\n",
      "[28]\ttraining's l2: 0.456414\tvalid_1's l2: 0.430541\n",
      "[29]\ttraining's l2: 0.450877\tvalid_1's l2: 0.425343\n",
      "[30]\ttraining's l2: 0.445779\tvalid_1's l2: 0.420569\n",
      "[31]\ttraining's l2: 0.441211\tvalid_1's l2: 0.416287\n",
      "[32]\ttraining's l2: 0.437023\tvalid_1's l2: 0.412371\n",
      "[33]\ttraining's l2: 0.433375\tvalid_1's l2: 0.409018\n",
      "[34]\ttraining's l2: 0.429902\tvalid_1's l2: 0.405686\n",
      "[35]\ttraining's l2: 0.426659\tvalid_1's l2: 0.402664\n",
      "[36]\ttraining's l2: 0.423719\tvalid_1's l2: 0.399861\n",
      "[37]\ttraining's l2: 0.421014\tvalid_1's l2: 0.397421\n",
      "[38]\ttraining's l2: 0.418647\tvalid_1's l2: 0.39534\n",
      "[39]\ttraining's l2: 0.41637\tvalid_1's l2: 0.393244\n",
      "[40]\ttraining's l2: 0.414373\tvalid_1's l2: 0.391484\n",
      "[41]\ttraining's l2: 0.412449\tvalid_1's l2: 0.389767\n",
      "[42]\ttraining's l2: 0.410688\tvalid_1's l2: 0.388138\n",
      "[43]\ttraining's l2: 0.40918\tvalid_1's l2: 0.38679\n",
      "[44]\ttraining's l2: 0.407749\tvalid_1's l2: 0.385487\n",
      "[45]\ttraining's l2: 0.406341\tvalid_1's l2: 0.384224\n",
      "[46]\ttraining's l2: 0.405016\tvalid_1's l2: 0.383012\n",
      "[47]\ttraining's l2: 0.403909\tvalid_1's l2: 0.382112\n",
      "[48]\ttraining's l2: 0.402793\tvalid_1's l2: 0.381131\n",
      "[49]\ttraining's l2: 0.401751\tvalid_1's l2: 0.380192\n",
      "[50]\ttraining's l2: 0.400873\tvalid_1's l2: 0.379428\n",
      "[51]\ttraining's l2: 0.400017\tvalid_1's l2: 0.378703\n",
      "[52]\ttraining's l2: 0.399186\tvalid_1's l2: 0.377974\n",
      "[53]\ttraining's l2: 0.398397\tvalid_1's l2: 0.377255\n",
      "[54]\ttraining's l2: 0.397628\tvalid_1's l2: 0.376675\n",
      "[55]\ttraining's l2: 0.396962\tvalid_1's l2: 0.376125\n",
      "[56]\ttraining's l2: 0.396326\tvalid_1's l2: 0.375556\n",
      "[57]\ttraining's l2: 0.395753\tvalid_1's l2: 0.375025\n",
      "[58]\ttraining's l2: 0.395176\tvalid_1's l2: 0.374494\n",
      "[59]\ttraining's l2: 0.394626\tvalid_1's l2: 0.374005\n",
      "[60]\ttraining's l2: 0.39409\tvalid_1's l2: 0.373559\n",
      "[61]\ttraining's l2: 0.393616\tvalid_1's l2: 0.373224\n",
      "[62]\ttraining's l2: 0.393174\tvalid_1's l2: 0.372872\n",
      "[63]\ttraining's l2: 0.392731\tvalid_1's l2: 0.372622\n",
      "[64]\ttraining's l2: 0.392312\tvalid_1's l2: 0.372268\n",
      "[65]\ttraining's l2: 0.391905\tvalid_1's l2: 0.371934\n",
      "[66]\ttraining's l2: 0.391557\tvalid_1's l2: 0.371669\n",
      "[67]\ttraining's l2: 0.391227\tvalid_1's l2: 0.371417\n",
      "[68]\ttraining's l2: 0.390879\tvalid_1's l2: 0.371186\n",
      "[69]\ttraining's l2: 0.39054\tvalid_1's l2: 0.370868\n",
      "[70]\ttraining's l2: 0.390225\tvalid_1's l2: 0.370641\n",
      "[71]\ttraining's l2: 0.389886\tvalid_1's l2: 0.370397\n",
      "[72]\ttraining's l2: 0.389593\tvalid_1's l2: 0.370197\n",
      "[73]\ttraining's l2: 0.389312\tvalid_1's l2: 0.370026\n",
      "[74]\ttraining's l2: 0.389016\tvalid_1's l2: 0.36988\n",
      "[75]\ttraining's l2: 0.38876\tvalid_1's l2: 0.36975\n",
      "[76]\ttraining's l2: 0.388476\tvalid_1's l2: 0.369619\n",
      "[77]\ttraining's l2: 0.388163\tvalid_1's l2: 0.369379\n",
      "[78]\ttraining's l2: 0.38788\tvalid_1's l2: 0.369177\n",
      "[79]\ttraining's l2: 0.387644\tvalid_1's l2: 0.369059\n",
      "[80]\ttraining's l2: 0.387405\tvalid_1's l2: 0.368891\n",
      "[81]\ttraining's l2: 0.387169\tvalid_1's l2: 0.368747\n",
      "[82]\ttraining's l2: 0.386943\tvalid_1's l2: 0.368629\n",
      "[83]\ttraining's l2: 0.38672\tvalid_1's l2: 0.368527\n",
      "[84]\ttraining's l2: 0.386491\tvalid_1's l2: 0.36838\n",
      "[85]\ttraining's l2: 0.386232\tvalid_1's l2: 0.368268\n",
      "[86]\ttraining's l2: 0.385942\tvalid_1's l2: 0.368125\n",
      "[87]\ttraining's l2: 0.385768\tvalid_1's l2: 0.368014\n",
      "[88]\ttraining's l2: 0.385554\tvalid_1's l2: 0.367911\n",
      "[89]\ttraining's l2: 0.385363\tvalid_1's l2: 0.367855\n",
      "[90]\ttraining's l2: 0.385159\tvalid_1's l2: 0.367705\n",
      "[91]\ttraining's l2: 0.384988\tvalid_1's l2: 0.367619\n",
      "[92]\ttraining's l2: 0.384781\tvalid_1's l2: 0.36753\n",
      "[93]\ttraining's l2: 0.384561\tvalid_1's l2: 0.367438\n",
      "[94]\ttraining's l2: 0.384402\tvalid_1's l2: 0.367372\n",
      "[95]\ttraining's l2: 0.384222\tvalid_1's l2: 0.367279\n",
      "[96]\ttraining's l2: 0.38405\tvalid_1's l2: 0.367225\n",
      "[97]\ttraining's l2: 0.383887\tvalid_1's l2: 0.367235\n",
      "[98]\ttraining's l2: 0.383675\tvalid_1's l2: 0.367132\n",
      "[99]\ttraining's l2: 0.383496\tvalid_1's l2: 0.367107\n",
      "[100]\ttraining's l2: 0.383319\tvalid_1's l2: 0.367019\n",
      "[101]\ttraining's l2: 0.383092\tvalid_1's l2: 0.366875\n",
      "[102]\ttraining's l2: 0.382906\tvalid_1's l2: 0.366828\n",
      "[103]\ttraining's l2: 0.382748\tvalid_1's l2: 0.366768\n",
      "[104]\ttraining's l2: 0.382552\tvalid_1's l2: 0.366809\n",
      "[105]\ttraining's l2: 0.382382\tvalid_1's l2: 0.366684\n",
      "[106]\ttraining's l2: 0.382213\tvalid_1's l2: 0.366675\n",
      "[107]\ttraining's l2: 0.382052\tvalid_1's l2: 0.366624\n",
      "[108]\ttraining's l2: 0.381875\tvalid_1's l2: 0.366436\n",
      "[109]\ttraining's l2: 0.38171\tvalid_1's l2: 0.366352\n",
      "[110]\ttraining's l2: 0.381494\tvalid_1's l2: 0.366129\n",
      "[111]\ttraining's l2: 0.381329\tvalid_1's l2: 0.366116\n",
      "[112]\ttraining's l2: 0.381096\tvalid_1's l2: 0.365997\n",
      "[113]\ttraining's l2: 0.38096\tvalid_1's l2: 0.365922\n",
      "[114]\ttraining's l2: 0.380839\tvalid_1's l2: 0.365859\n",
      "[115]\ttraining's l2: 0.380707\tvalid_1's l2: 0.3658\n",
      "[116]\ttraining's l2: 0.380549\tvalid_1's l2: 0.36573\n",
      "[117]\ttraining's l2: 0.380405\tvalid_1's l2: 0.365611\n",
      "[118]\ttraining's l2: 0.380254\tvalid_1's l2: 0.365557\n",
      "[119]\ttraining's l2: 0.380131\tvalid_1's l2: 0.365535\n",
      "[120]\ttraining's l2: 0.38003\tvalid_1's l2: 0.365483\n",
      "[121]\ttraining's l2: 0.379911\tvalid_1's l2: 0.365437\n",
      "[122]\ttraining's l2: 0.379816\tvalid_1's l2: 0.365403\n",
      "[123]\ttraining's l2: 0.379686\tvalid_1's l2: 0.365369\n",
      "[124]\ttraining's l2: 0.379599\tvalid_1's l2: 0.365317\n",
      "[125]\ttraining's l2: 0.3795\tvalid_1's l2: 0.365267\n",
      "[126]\ttraining's l2: 0.379373\tvalid_1's l2: 0.365231\n",
      "[127]\ttraining's l2: 0.379194\tvalid_1's l2: 0.365133\n",
      "[128]\ttraining's l2: 0.379095\tvalid_1's l2: 0.365109\n",
      "[129]\ttraining's l2: 0.378986\tvalid_1's l2: 0.365121\n",
      "[130]\ttraining's l2: 0.378849\tvalid_1's l2: 0.365096\n",
      "[131]\ttraining's l2: 0.378702\tvalid_1's l2: 0.365059\n",
      "[132]\ttraining's l2: 0.378616\tvalid_1's l2: 0.365031\n",
      "[133]\ttraining's l2: 0.378503\tvalid_1's l2: 0.36496\n",
      "[134]\ttraining's l2: 0.378334\tvalid_1's l2: 0.364833\n",
      "[135]\ttraining's l2: 0.378256\tvalid_1's l2: 0.36485\n",
      "[136]\ttraining's l2: 0.378158\tvalid_1's l2: 0.364834\n",
      "[137]\ttraining's l2: 0.37804\tvalid_1's l2: 0.36483\n",
      "[138]\ttraining's l2: 0.377962\tvalid_1's l2: 0.364763\n",
      "[139]\ttraining's l2: 0.377776\tvalid_1's l2: 0.364662\n",
      "[140]\ttraining's l2: 0.377686\tvalid_1's l2: 0.364654\n",
      "[141]\ttraining's l2: 0.377619\tvalid_1's l2: 0.36463\n",
      "[142]\ttraining's l2: 0.377468\tvalid_1's l2: 0.364578\n",
      "[143]\ttraining's l2: 0.377356\tvalid_1's l2: 0.364592\n",
      "[144]\ttraining's l2: 0.377235\tvalid_1's l2: 0.36456\n",
      "[145]\ttraining's l2: 0.377162\tvalid_1's l2: 0.36453\n",
      "[146]\ttraining's l2: 0.377088\tvalid_1's l2: 0.364512\n",
      "[147]\ttraining's l2: 0.376925\tvalid_1's l2: 0.364407\n",
      "[148]\ttraining's l2: 0.376837\tvalid_1's l2: 0.364395\n",
      "[149]\ttraining's l2: 0.376714\tvalid_1's l2: 0.364389\n",
      "[150]\ttraining's l2: 0.376649\tvalid_1's l2: 0.364346\n",
      "[151]\ttraining's l2: 0.376584\tvalid_1's l2: 0.36432\n",
      "[152]\ttraining's l2: 0.376538\tvalid_1's l2: 0.364298\n",
      "[153]\ttraining's l2: 0.376465\tvalid_1's l2: 0.364333\n",
      "[154]\ttraining's l2: 0.376341\tvalid_1's l2: 0.36422\n",
      "[155]\ttraining's l2: 0.376217\tvalid_1's l2: 0.364143\n",
      "[156]\ttraining's l2: 0.376115\tvalid_1's l2: 0.364132\n",
      "[157]\ttraining's l2: 0.376054\tvalid_1's l2: 0.364153\n",
      "[158]\ttraining's l2: 0.375948\tvalid_1's l2: 0.364151\n",
      "[159]\ttraining's l2: 0.37586\tvalid_1's l2: 0.364141\n",
      "[160]\ttraining's l2: 0.37576\tvalid_1's l2: 0.364122\n",
      "[161]\ttraining's l2: 0.375705\tvalid_1's l2: 0.364154\n",
      "[162]\ttraining's l2: 0.375593\tvalid_1's l2: 0.364067\n",
      "[163]\ttraining's l2: 0.375509\tvalid_1's l2: 0.363989\n",
      "[164]\ttraining's l2: 0.375423\tvalid_1's l2: 0.363961\n",
      "[165]\ttraining's l2: 0.375373\tvalid_1's l2: 0.363956\n",
      "[166]\ttraining's l2: 0.375281\tvalid_1's l2: 0.3639\n",
      "[167]\ttraining's l2: 0.375216\tvalid_1's l2: 0.363885\n",
      "[168]\ttraining's l2: 0.375082\tvalid_1's l2: 0.363827\n",
      "[169]\ttraining's l2: 0.37503\tvalid_1's l2: 0.363776\n",
      "[170]\ttraining's l2: 0.374968\tvalid_1's l2: 0.36376\n",
      "[171]\ttraining's l2: 0.374896\tvalid_1's l2: 0.363758\n",
      "[172]\ttraining's l2: 0.374842\tvalid_1's l2: 0.363757\n",
      "[173]\ttraining's l2: 0.374788\tvalid_1's l2: 0.363746\n",
      "[174]\ttraining's l2: 0.37471\tvalid_1's l2: 0.363679\n",
      "[175]\ttraining's l2: 0.374668\tvalid_1's l2: 0.363647\n",
      "[176]\ttraining's l2: 0.374589\tvalid_1's l2: 0.363679\n",
      "[177]\ttraining's l2: 0.374529\tvalid_1's l2: 0.363702\n",
      "[178]\ttraining's l2: 0.374467\tvalid_1's l2: 0.363655\n",
      "[179]\ttraining's l2: 0.374426\tvalid_1's l2: 0.36364\n",
      "[180]\ttraining's l2: 0.374359\tvalid_1's l2: 0.363624\n",
      "[181]\ttraining's l2: 0.374286\tvalid_1's l2: 0.363559\n",
      "[182]\ttraining's l2: 0.374232\tvalid_1's l2: 0.363528\n",
      "[183]\ttraining's l2: 0.374174\tvalid_1's l2: 0.363538\n",
      "[184]\ttraining's l2: 0.374106\tvalid_1's l2: 0.363521\n",
      "[185]\ttraining's l2: 0.374015\tvalid_1's l2: 0.363451\n",
      "[186]\ttraining's l2: 0.37395\tvalid_1's l2: 0.36344\n",
      "[187]\ttraining's l2: 0.373899\tvalid_1's l2: 0.363436\n",
      "[188]\ttraining's l2: 0.373829\tvalid_1's l2: 0.363424\n",
      "[189]\ttraining's l2: 0.373755\tvalid_1's l2: 0.363487\n",
      "[190]\ttraining's l2: 0.373705\tvalid_1's l2: 0.3635\n",
      "[191]\ttraining's l2: 0.37364\tvalid_1's l2: 0.363476\n",
      "[192]\ttraining's l2: 0.373572\tvalid_1's l2: 0.363458\n",
      "[193]\ttraining's l2: 0.373529\tvalid_1's l2: 0.363443\n",
      "[194]\ttraining's l2: 0.373429\tvalid_1's l2: 0.363388\n",
      "[195]\ttraining's l2: 0.373379\tvalid_1's l2: 0.363375\n",
      "[196]\ttraining's l2: 0.373338\tvalid_1's l2: 0.363365\n",
      "[197]\ttraining's l2: 0.373279\tvalid_1's l2: 0.363358\n",
      "[198]\ttraining's l2: 0.373179\tvalid_1's l2: 0.363298\n",
      "[199]\ttraining's l2: 0.373133\tvalid_1's l2: 0.363288\n",
      "[200]\ttraining's l2: 0.373089\tvalid_1's l2: 0.36327\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.373089\tvalid_1's l2: 0.36327\n",
      "mean_21_sales: 11948592.08\n",
      "mean_30_sales: 3318785.75\n",
      "mean_6_sales: 2675382.61\n",
      "mean_14_sales: 2558925.01\n",
      "mean_5_sales: 1682053.98\n",
      "mean_7_sales: 1580223.96\n",
      "mean_20_dow3_2017: 1369280.33\n",
      "mean_4_dow3_2017: 1227589.56\n",
      "mean_60_sales: 1203494.44\n",
      "promo_10: 650514.91\n",
      "mean_4_sales: 323910.02\n",
      "item_class_features: 290771.31\n",
      "mean_63_sales: 166429.15\n",
      "std_21_sales: 94670.80\n",
      "promo_14: 76624.72\n",
      "std_30_sales: 74349.62\n",
      "sum_4_promo: 69110.27\n",
      "promo_12: 57799.89\n",
      "lag_3_sales: 56718.63\n",
      "promo_11: 53333.99\n",
      "lag_21_transactions: 50780.04\n",
      "promo_9: 48730.73\n",
      "promo_7: 47190.64\n",
      "mean_4_dow4_2017: 40592.67\n",
      "item_family_features: 35458.48\n",
      "store_cluster_features: 30604.30\n",
      "lag_1_transactions: 25599.16\n",
      "std_14_sales: 22709.58\n",
      "store_city_features: 22398.84\n",
      "sum_2_promo: 21187.23\n",
      "promo_13: 21098.83\n",
      "std_63_sales: 20715.83\n",
      "lag_3_transactions: 16606.09\n",
      "sum_14_promo: 16557.34\n",
      "sum_3_promo: 16089.34\n",
      "promo_8: 15842.75\n",
      "promo_3: 15496.19\n",
      "lag_4_sales: 15351.24\n",
      "mean_20_dow0_2017: 15193.50\n",
      "std_60_sales: 14495.34\n",
      "mean_3_sales: 12739.15\n",
      "sum_7_promo: 11779.88\n",
      "lag_2_transactions: 11704.85\n",
      "lag_4_transactions: 11250.27\n",
      "sum_6_promo: 10800.73\n",
      "std_5_sales: 9788.07\n",
      "lag_1_sales: 9643.25\n",
      "lag_49_sales: 9061.77\n",
      "lag_14_transactions: 8357.03\n",
      "lag_7_transactions: 8142.89\n",
      "lag_5_transactions: 7851.01\n",
      "sum_21_promo: 7518.39\n",
      "store_state_features: 7176.54\n",
      "std_7_sales: 6512.77\n",
      "store_type_features: 6163.90\n",
      "lag_6_transactions: 6044.21\n",
      "sum_5_promo: 5822.01\n",
      "mean_20_dow4_2017: 5057.69\n",
      "promo_6: 5042.91\n",
      "mean_20_dow2_2017: 4873.69\n",
      "std_6_sales: 4431.53\n",
      "std_4_sales: 4169.78\n",
      "lag_21_sales: 3501.92\n",
      "mean_20_dow1_2017: 3444.72\n",
      "promo_15: 3341.19\n",
      "mean_4_dow2_2017: 2987.09\n",
      "mean_4_dow1_2017: 2981.44\n",
      "mean_4_dow0_2017: 2857.00\n",
      "mean_4_dow6_2017: 2521.05\n",
      "lag_5_sales: 1645.96\n",
      "mean_20_dow6_2017: 1350.22\n",
      "mean_20_dow5_2017: 1055.16\n",
      "promo_0: 1052.14\n",
      "promo_4: 915.91\n",
      "lag_2_sales: 831.46\n",
      "lag_63_sales: 820.69\n",
      "lag_14_sales: 803.53\n",
      "lag_35_sales: 798.56\n",
      "std_3_sales: 675.44\n",
      "lag_56_sales: 606.19\n",
      "lag_42_sales: 480.32\n",
      "promo_2: 455.88\n",
      "mean_4_dow5_2017: 389.98\n",
      "lag_6_sales: 371.16\n",
      "promo_5: 292.21\n",
      "lag_28_sales: 271.98\n",
      "lag_7_sales: 202.51\n",
      "promo_1: 153.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [18:15<08:26, 101.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.23424\tvalid_1's l2: 1.20859\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.15681\tvalid_1's l2: 1.12917\n",
      "[3]\ttraining's l2: 1.08717\tvalid_1's l2: 1.05928\n",
      "[4]\ttraining's l2: 1.02376\tvalid_1's l2: 0.995097\n",
      "[5]\ttraining's l2: 0.967\tvalid_1's l2: 0.937385\n",
      "[6]\ttraining's l2: 0.914723\tvalid_1's l2: 0.884906\n",
      "[7]\ttraining's l2: 0.867625\tvalid_1's l2: 0.837235\n",
      "[8]\ttraining's l2: 0.825207\tvalid_1's l2: 0.794979\n",
      "[9]\ttraining's l2: 0.78645\tvalid_1's l2: 0.755954\n",
      "[10]\ttraining's l2: 0.751749\tvalid_1's l2: 0.721576\n",
      "[11]\ttraining's l2: 0.720226\tvalid_1's l2: 0.689727\n",
      "[12]\ttraining's l2: 0.69136\tvalid_1's l2: 0.6608\n",
      "[13]\ttraining's l2: 0.665028\tvalid_1's l2: 0.634654\n",
      "[14]\ttraining's l2: 0.641226\tvalid_1's l2: 0.610829\n",
      "[15]\ttraining's l2: 0.620047\tvalid_1's l2: 0.59035\n",
      "[16]\ttraining's l2: 0.600459\tvalid_1's l2: 0.571171\n",
      "[17]\ttraining's l2: 0.58273\tvalid_1's l2: 0.553864\n",
      "[18]\ttraining's l2: 0.566554\tvalid_1's l2: 0.537998\n",
      "[19]\ttraining's l2: 0.551832\tvalid_1's l2: 0.523573\n",
      "[20]\ttraining's l2: 0.538528\tvalid_1's l2: 0.510729\n",
      "[21]\ttraining's l2: 0.526448\tvalid_1's l2: 0.499065\n",
      "[22]\ttraining's l2: 0.515456\tvalid_1's l2: 0.48854\n",
      "[23]\ttraining's l2: 0.505546\tvalid_1's l2: 0.479405\n",
      "[24]\ttraining's l2: 0.496565\tvalid_1's l2: 0.470962\n",
      "[25]\ttraining's l2: 0.488502\tvalid_1's l2: 0.463446\n",
      "[26]\ttraining's l2: 0.480942\tvalid_1's l2: 0.456216\n",
      "[27]\ttraining's l2: 0.474007\tvalid_1's l2: 0.449601\n",
      "[28]\ttraining's l2: 0.4678\tvalid_1's l2: 0.443776\n",
      "[29]\ttraining's l2: 0.462096\tvalid_1's l2: 0.438416\n",
      "[30]\ttraining's l2: 0.456879\tvalid_1's l2: 0.433496\n",
      "[31]\ttraining's l2: 0.452185\tvalid_1's l2: 0.429159\n",
      "[32]\ttraining's l2: 0.447785\tvalid_1's l2: 0.425101\n",
      "[33]\ttraining's l2: 0.443891\tvalid_1's l2: 0.421552\n",
      "[34]\ttraining's l2: 0.440188\tvalid_1's l2: 0.418073\n",
      "[35]\ttraining's l2: 0.436867\tvalid_1's l2: 0.41515\n",
      "[36]\ttraining's l2: 0.433856\tvalid_1's l2: 0.412529\n",
      "[37]\ttraining's l2: 0.431116\tvalid_1's l2: 0.410227\n",
      "[38]\ttraining's l2: 0.428545\tvalid_1's l2: 0.407888\n",
      "[39]\ttraining's l2: 0.426165\tvalid_1's l2: 0.40582\n",
      "[40]\ttraining's l2: 0.423977\tvalid_1's l2: 0.403875\n",
      "[41]\ttraining's l2: 0.42194\tvalid_1's l2: 0.40213\n",
      "[42]\ttraining's l2: 0.420092\tvalid_1's l2: 0.400513\n",
      "[43]\ttraining's l2: 0.41848\tvalid_1's l2: 0.399225\n",
      "[44]\ttraining's l2: 0.416925\tvalid_1's l2: 0.397906\n",
      "[45]\ttraining's l2: 0.415401\tvalid_1's l2: 0.396639\n",
      "[46]\ttraining's l2: 0.414044\tvalid_1's l2: 0.395569\n",
      "[47]\ttraining's l2: 0.412716\tvalid_1's l2: 0.394499\n",
      "[48]\ttraining's l2: 0.411433\tvalid_1's l2: 0.393363\n",
      "[49]\ttraining's l2: 0.41036\tvalid_1's l2: 0.39248\n",
      "[50]\ttraining's l2: 0.409343\tvalid_1's l2: 0.39161\n",
      "[51]\ttraining's l2: 0.408307\tvalid_1's l2: 0.390742\n",
      "[52]\ttraining's l2: 0.407417\tvalid_1's l2: 0.390108\n",
      "[53]\ttraining's l2: 0.406604\tvalid_1's l2: 0.389406\n",
      "[54]\ttraining's l2: 0.405808\tvalid_1's l2: 0.388774\n",
      "[55]\ttraining's l2: 0.405066\tvalid_1's l2: 0.38824\n",
      "[56]\ttraining's l2: 0.404278\tvalid_1's l2: 0.387528\n",
      "[57]\ttraining's l2: 0.403634\tvalid_1's l2: 0.387066\n",
      "[58]\ttraining's l2: 0.403014\tvalid_1's l2: 0.386576\n",
      "[59]\ttraining's l2: 0.402459\tvalid_1's l2: 0.386124\n",
      "[60]\ttraining's l2: 0.401804\tvalid_1's l2: 0.385533\n",
      "[61]\ttraining's l2: 0.401279\tvalid_1's l2: 0.385258\n",
      "[62]\ttraining's l2: 0.40075\tvalid_1's l2: 0.384871\n",
      "[63]\ttraining's l2: 0.400224\tvalid_1's l2: 0.384492\n",
      "[64]\ttraining's l2: 0.399721\tvalid_1's l2: 0.384185\n",
      "[65]\ttraining's l2: 0.399308\tvalid_1's l2: 0.383909\n",
      "[66]\ttraining's l2: 0.398843\tvalid_1's l2: 0.383595\n",
      "[67]\ttraining's l2: 0.398395\tvalid_1's l2: 0.383315\n",
      "[68]\ttraining's l2: 0.397985\tvalid_1's l2: 0.383038\n",
      "[69]\ttraining's l2: 0.397571\tvalid_1's l2: 0.382789\n",
      "[70]\ttraining's l2: 0.397086\tvalid_1's l2: 0.38247\n",
      "[71]\ttraining's l2: 0.396729\tvalid_1's l2: 0.382245\n",
      "[72]\ttraining's l2: 0.396389\tvalid_1's l2: 0.382058\n",
      "[73]\ttraining's l2: 0.396036\tvalid_1's l2: 0.381899\n",
      "[74]\ttraining's l2: 0.395653\tvalid_1's l2: 0.381703\n",
      "[75]\ttraining's l2: 0.395337\tvalid_1's l2: 0.381569\n",
      "[76]\ttraining's l2: 0.394948\tvalid_1's l2: 0.38131\n",
      "[77]\ttraining's l2: 0.394624\tvalid_1's l2: 0.38104\n",
      "[78]\ttraining's l2: 0.394351\tvalid_1's l2: 0.380922\n",
      "[79]\ttraining's l2: 0.394057\tvalid_1's l2: 0.380695\n",
      "[80]\ttraining's l2: 0.393669\tvalid_1's l2: 0.380413\n",
      "[81]\ttraining's l2: 0.393293\tvalid_1's l2: 0.380167\n",
      "[82]\ttraining's l2: 0.393043\tvalid_1's l2: 0.380046\n",
      "[83]\ttraining's l2: 0.392776\tvalid_1's l2: 0.379915\n",
      "[84]\ttraining's l2: 0.392473\tvalid_1's l2: 0.379833\n",
      "[85]\ttraining's l2: 0.39224\tvalid_1's l2: 0.379735\n",
      "[86]\ttraining's l2: 0.391987\tvalid_1's l2: 0.37959\n",
      "[87]\ttraining's l2: 0.391693\tvalid_1's l2: 0.379609\n",
      "[88]\ttraining's l2: 0.391497\tvalid_1's l2: 0.379509\n",
      "[89]\ttraining's l2: 0.391192\tvalid_1's l2: 0.379348\n",
      "[90]\ttraining's l2: 0.390874\tvalid_1's l2: 0.379033\n",
      "[91]\ttraining's l2: 0.390533\tvalid_1's l2: 0.378737\n",
      "[92]\ttraining's l2: 0.390293\tvalid_1's l2: 0.378773\n",
      "[93]\ttraining's l2: 0.389938\tvalid_1's l2: 0.378463\n",
      "[94]\ttraining's l2: 0.389596\tvalid_1's l2: 0.378213\n",
      "[95]\ttraining's l2: 0.389338\tvalid_1's l2: 0.378047\n",
      "[96]\ttraining's l2: 0.389148\tvalid_1's l2: 0.37798\n",
      "[97]\ttraining's l2: 0.388957\tvalid_1's l2: 0.377957\n",
      "[98]\ttraining's l2: 0.388674\tvalid_1's l2: 0.377779\n",
      "[99]\ttraining's l2: 0.388462\tvalid_1's l2: 0.377817\n",
      "[100]\ttraining's l2: 0.388302\tvalid_1's l2: 0.37771\n",
      "[101]\ttraining's l2: 0.388136\tvalid_1's l2: 0.377653\n",
      "[102]\ttraining's l2: 0.387904\tvalid_1's l2: 0.377494\n",
      "[103]\ttraining's l2: 0.387704\tvalid_1's l2: 0.377392\n",
      "[104]\ttraining's l2: 0.387535\tvalid_1's l2: 0.377366\n",
      "[105]\ttraining's l2: 0.387366\tvalid_1's l2: 0.37736\n",
      "[106]\ttraining's l2: 0.387209\tvalid_1's l2: 0.377294\n",
      "[107]\ttraining's l2: 0.386938\tvalid_1's l2: 0.377065\n",
      "[108]\ttraining's l2: 0.386733\tvalid_1's l2: 0.376874\n",
      "[109]\ttraining's l2: 0.386577\tvalid_1's l2: 0.376837\n",
      "[110]\ttraining's l2: 0.386443\tvalid_1's l2: 0.376801\n",
      "[111]\ttraining's l2: 0.386256\tvalid_1's l2: 0.376698\n",
      "[112]\ttraining's l2: 0.386064\tvalid_1's l2: 0.376603\n",
      "[113]\ttraining's l2: 0.385919\tvalid_1's l2: 0.376497\n",
      "[114]\ttraining's l2: 0.385778\tvalid_1's l2: 0.376444\n",
      "[115]\ttraining's l2: 0.385608\tvalid_1's l2: 0.376342\n",
      "[116]\ttraining's l2: 0.385436\tvalid_1's l2: 0.376248\n",
      "[117]\ttraining's l2: 0.385245\tvalid_1's l2: 0.376307\n",
      "[118]\ttraining's l2: 0.385109\tvalid_1's l2: 0.376265\n",
      "[119]\ttraining's l2: 0.384923\tvalid_1's l2: 0.376156\n",
      "[120]\ttraining's l2: 0.384769\tvalid_1's l2: 0.376071\n",
      "[121]\ttraining's l2: 0.384624\tvalid_1's l2: 0.37612\n",
      "[122]\ttraining's l2: 0.384448\tvalid_1's l2: 0.375997\n",
      "[123]\ttraining's l2: 0.384314\tvalid_1's l2: 0.37595\n",
      "[124]\ttraining's l2: 0.384165\tvalid_1's l2: 0.375893\n",
      "[125]\ttraining's l2: 0.384025\tvalid_1's l2: 0.375793\n",
      "[126]\ttraining's l2: 0.383855\tvalid_1's l2: 0.375704\n",
      "[127]\ttraining's l2: 0.383733\tvalid_1's l2: 0.375608\n",
      "[128]\ttraining's l2: 0.383602\tvalid_1's l2: 0.37569\n",
      "[129]\ttraining's l2: 0.383481\tvalid_1's l2: 0.375731\n",
      "[130]\ttraining's l2: 0.383343\tvalid_1's l2: 0.375717\n",
      "[131]\ttraining's l2: 0.383209\tvalid_1's l2: 0.375614\n",
      "[132]\ttraining's l2: 0.383115\tvalid_1's l2: 0.375616\n",
      "[133]\ttraining's l2: 0.382977\tvalid_1's l2: 0.375567\n",
      "[134]\ttraining's l2: 0.382874\tvalid_1's l2: 0.375575\n",
      "[135]\ttraining's l2: 0.38276\tvalid_1's l2: 0.375551\n",
      "[136]\ttraining's l2: 0.382639\tvalid_1's l2: 0.375525\n",
      "[137]\ttraining's l2: 0.382436\tvalid_1's l2: 0.375422\n",
      "[138]\ttraining's l2: 0.382345\tvalid_1's l2: 0.375343\n",
      "[139]\ttraining's l2: 0.382217\tvalid_1's l2: 0.375302\n",
      "[140]\ttraining's l2: 0.3821\tvalid_1's l2: 0.375307\n",
      "[141]\ttraining's l2: 0.382021\tvalid_1's l2: 0.375285\n",
      "[142]\ttraining's l2: 0.381912\tvalid_1's l2: 0.375369\n",
      "[143]\ttraining's l2: 0.381777\tvalid_1's l2: 0.375267\n",
      "[144]\ttraining's l2: 0.381648\tvalid_1's l2: 0.3753\n",
      "[145]\ttraining's l2: 0.381534\tvalid_1's l2: 0.375299\n",
      "[146]\ttraining's l2: 0.381456\tvalid_1's l2: 0.375279\n",
      "[147]\ttraining's l2: 0.381317\tvalid_1's l2: 0.375182\n",
      "[148]\ttraining's l2: 0.381217\tvalid_1's l2: 0.375156\n",
      "[149]\ttraining's l2: 0.381145\tvalid_1's l2: 0.375125\n",
      "[150]\ttraining's l2: 0.381051\tvalid_1's l2: 0.37522\n",
      "[151]\ttraining's l2: 0.380961\tvalid_1's l2: 0.375171\n",
      "[152]\ttraining's l2: 0.380852\tvalid_1's l2: 0.375161\n",
      "[153]\ttraining's l2: 0.380761\tvalid_1's l2: 0.375167\n",
      "[154]\ttraining's l2: 0.380703\tvalid_1's l2: 0.375213\n",
      "[155]\ttraining's l2: 0.380618\tvalid_1's l2: 0.375181\n",
      "[156]\ttraining's l2: 0.380527\tvalid_1's l2: 0.375178\n",
      "[157]\ttraining's l2: 0.380428\tvalid_1's l2: 0.375193\n",
      "[158]\ttraining's l2: 0.380291\tvalid_1's l2: 0.375131\n",
      "[159]\ttraining's l2: 0.380233\tvalid_1's l2: 0.375083\n",
      "[160]\ttraining's l2: 0.380136\tvalid_1's l2: 0.375069\n",
      "[161]\ttraining's l2: 0.380058\tvalid_1's l2: 0.375035\n",
      "[162]\ttraining's l2: 0.379971\tvalid_1's l2: 0.374975\n",
      "[163]\ttraining's l2: 0.379901\tvalid_1's l2: 0.374933\n",
      "[164]\ttraining's l2: 0.37983\tvalid_1's l2: 0.375009\n",
      "[165]\ttraining's l2: 0.379733\tvalid_1's l2: 0.374952\n",
      "[166]\ttraining's l2: 0.379654\tvalid_1's l2: 0.374883\n",
      "[167]\ttraining's l2: 0.379582\tvalid_1's l2: 0.374856\n",
      "[168]\ttraining's l2: 0.37952\tvalid_1's l2: 0.374873\n",
      "[169]\ttraining's l2: 0.379457\tvalid_1's l2: 0.37495\n",
      "[170]\ttraining's l2: 0.379377\tvalid_1's l2: 0.374939\n",
      "[171]\ttraining's l2: 0.379286\tvalid_1's l2: 0.374932\n",
      "[172]\ttraining's l2: 0.379182\tvalid_1's l2: 0.374889\n",
      "[173]\ttraining's l2: 0.379059\tvalid_1's l2: 0.374816\n",
      "[174]\ttraining's l2: 0.378982\tvalid_1's l2: 0.374814\n",
      "[175]\ttraining's l2: 0.378884\tvalid_1's l2: 0.374714\n",
      "[176]\ttraining's l2: 0.378815\tvalid_1's l2: 0.374803\n",
      "[177]\ttraining's l2: 0.378718\tvalid_1's l2: 0.374801\n",
      "[178]\ttraining's l2: 0.378634\tvalid_1's l2: 0.374792\n",
      "[179]\ttraining's l2: 0.378549\tvalid_1's l2: 0.374782\n",
      "[180]\ttraining's l2: 0.37845\tvalid_1's l2: 0.374739\n",
      "[181]\ttraining's l2: 0.378386\tvalid_1's l2: 0.374717\n",
      "[182]\ttraining's l2: 0.378266\tvalid_1's l2: 0.374634\n",
      "[183]\ttraining's l2: 0.37821\tvalid_1's l2: 0.374669\n",
      "[184]\ttraining's l2: 0.378157\tvalid_1's l2: 0.374655\n",
      "[185]\ttraining's l2: 0.378079\tvalid_1's l2: 0.374659\n",
      "[186]\ttraining's l2: 0.377998\tvalid_1's l2: 0.37473\n",
      "[187]\ttraining's l2: 0.37793\tvalid_1's l2: 0.37473\n",
      "[188]\ttraining's l2: 0.377854\tvalid_1's l2: 0.374701\n",
      "[189]\ttraining's l2: 0.377791\tvalid_1's l2: 0.3747\n",
      "[190]\ttraining's l2: 0.377711\tvalid_1's l2: 0.374681\n",
      "[191]\ttraining's l2: 0.377642\tvalid_1's l2: 0.374678\n",
      "[192]\ttraining's l2: 0.37758\tvalid_1's l2: 0.37468\n",
      "[193]\ttraining's l2: 0.377497\tvalid_1's l2: 0.374662\n",
      "[194]\ttraining's l2: 0.37742\tvalid_1's l2: 0.374669\n",
      "[195]\ttraining's l2: 0.377341\tvalid_1's l2: 0.374693\n",
      "[196]\ttraining's l2: 0.377298\tvalid_1's l2: 0.374662\n",
      "[197]\ttraining's l2: 0.377227\tvalid_1's l2: 0.374603\n",
      "[198]\ttraining's l2: 0.377156\tvalid_1's l2: 0.374576\n",
      "[199]\ttraining's l2: 0.377111\tvalid_1's l2: 0.374595\n",
      "[200]\ttraining's l2: 0.377063\tvalid_1's l2: 0.374578\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.377063\tvalid_1's l2: 0.374578\n",
      "mean_21_sales: 8989135.38\n",
      "mean_4_dow4_2017: 5580850.67\n",
      "mean_14_sales: 3893202.13\n",
      "mean_4_sales: 2740850.41\n",
      "mean_20_dow4_2017: 2602556.96\n",
      "mean_30_sales: 2069334.94\n",
      "mean_5_sales: 1588888.10\n",
      "promo_11: 732441.82\n",
      "mean_60_sales: 680938.99\n",
      "mean_6_sales: 643161.64\n",
      "item_class_features: 319042.64\n",
      "mean_7_sales: 204677.30\n",
      "mean_63_sales: 112521.33\n",
      "sum_3_promo: 85567.01\n",
      "promo_14: 84412.29\n",
      "lag_3_transactions: 82106.07\n",
      "mean_4_dow3_2017: 80859.96\n",
      "lag_3_sales: 74537.97\n",
      "std_21_sales: 62618.20\n",
      "store_cluster_features: 61979.86\n",
      "lag_2_transactions: 61743.87\n",
      "std_30_sales: 60442.40\n",
      "promo_12: 56185.13\n",
      "std_14_sales: 48022.93\n",
      "item_family_features: 42847.49\n",
      "lag_21_transactions: 37014.45\n",
      "lag_1_transactions: 36840.33\n",
      "promo_7: 31191.26\n",
      "promo_13: 29711.29\n",
      "mean_3_sales: 28826.88\n",
      "promo_10: 28621.32\n",
      "store_city_features: 26119.85\n",
      "promo_9: 23302.02\n",
      "lag_1_sales: 22846.87\n",
      "mean_20_dow0_2017: 19293.07\n",
      "sum_2_promo: 16862.67\n",
      "promo_4: 16559.27\n",
      "std_60_sales: 14881.60\n",
      "lag_4_transactions: 14835.54\n",
      "lag_14_transactions: 14651.96\n",
      "sum_7_promo: 13973.76\n",
      "lag_7_transactions: 13741.62\n",
      "promo_8: 12624.12\n",
      "lag_6_transactions: 12227.70\n",
      "std_63_sales: 11858.09\n",
      "mean_20_dow3_2017: 11663.58\n",
      "mean_20_dow2_2017: 9390.25\n",
      "sum_14_promo: 9210.70\n",
      "sum_4_promo: 9155.30\n",
      "sum_21_promo: 9082.03\n",
      "store_type_features: 8197.49\n",
      "lag_5_transactions: 7199.77\n",
      "store_state_features: 7104.10\n",
      "mean_4_dow5_2017: 4872.97\n",
      "sum_6_promo: 4827.20\n",
      "lag_4_sales: 4627.52\n",
      "std_7_sales: 4182.20\n",
      "std_4_sales: 4068.63\n",
      "std_6_sales: 3486.93\n",
      "mean_20_dow1_2017: 3198.67\n",
      "mean_4_dow6_2017: 3198.56\n",
      "promo_15: 2776.20\n",
      "mean_20_dow5_2017: 2440.84\n",
      "sum_5_promo: 2434.54\n",
      "lag_7_sales: 2262.01\n",
      "std_5_sales: 1970.93\n",
      "promo_0: 1960.50\n",
      "lag_63_sales: 1874.22\n",
      "promo_6: 1711.21\n",
      "lag_21_sales: 1460.26\n",
      "lag_6_sales: 1341.84\n",
      "lag_14_sales: 1139.68\n",
      "mean_20_dow6_2017: 1075.10\n",
      "mean_4_dow1_2017: 910.28\n",
      "lag_5_sales: 712.16\n",
      "mean_4_dow0_2017: 697.93\n",
      "promo_3: 676.23\n",
      "mean_4_dow2_2017: 647.02\n",
      "lag_28_sales: 573.48\n",
      "std_3_sales: 491.53\n",
      "lag_49_sales: 486.58\n",
      "promo_2: 456.33\n",
      "lag_2_sales: 422.58\n",
      "lag_42_sales: 362.63\n",
      "lag_35_sales: 352.83\n",
      "lag_56_sales: 300.18\n",
      "promo_1: 110.09\n",
      "promo_5: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [20:07<06:58, 104.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.06641\tvalid_1's l2: 1.04936\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.00338\tvalid_1's l2: 0.986248\n",
      "[3]\ttraining's l2: 0.947456\tvalid_1's l2: 0.930002\n",
      "[4]\ttraining's l2: 0.89578\tvalid_1's l2: 0.878239\n",
      "[5]\ttraining's l2: 0.849161\tvalid_1's l2: 0.831409\n",
      "[6]\ttraining's l2: 0.806901\tvalid_1's l2: 0.789069\n",
      "[7]\ttraining's l2: 0.768647\tvalid_1's l2: 0.750737\n",
      "[8]\ttraining's l2: 0.734122\tvalid_1's l2: 0.716055\n",
      "[9]\ttraining's l2: 0.702671\tvalid_1's l2: 0.684668\n",
      "[10]\ttraining's l2: 0.674161\tvalid_1's l2: 0.656195\n",
      "[11]\ttraining's l2: 0.64851\tvalid_1's l2: 0.630623\n",
      "[12]\ttraining's l2: 0.6251\tvalid_1's l2: 0.60716\n",
      "[13]\ttraining's l2: 0.604144\tvalid_1's l2: 0.586079\n",
      "[14]\ttraining's l2: 0.585306\tvalid_1's l2: 0.567144\n",
      "[15]\ttraining's l2: 0.567859\tvalid_1's l2: 0.549784\n",
      "[16]\ttraining's l2: 0.552163\tvalid_1's l2: 0.53408\n",
      "[17]\ttraining's l2: 0.537881\tvalid_1's l2: 0.519804\n",
      "[18]\ttraining's l2: 0.525129\tvalid_1's l2: 0.506968\n",
      "[19]\ttraining's l2: 0.513354\tvalid_1's l2: 0.495067\n",
      "[20]\ttraining's l2: 0.502584\tvalid_1's l2: 0.484169\n",
      "[21]\ttraining's l2: 0.492833\tvalid_1's l2: 0.47444\n",
      "[22]\ttraining's l2: 0.484178\tvalid_1's l2: 0.46579\n",
      "[23]\ttraining's l2: 0.476177\tvalid_1's l2: 0.457743\n",
      "[24]\ttraining's l2: 0.468842\tvalid_1's l2: 0.450475\n",
      "[25]\ttraining's l2: 0.462335\tvalid_1's l2: 0.443888\n",
      "[26]\ttraining's l2: 0.456261\tvalid_1's l2: 0.437873\n",
      "[27]\ttraining's l2: 0.450735\tvalid_1's l2: 0.432352\n",
      "[28]\ttraining's l2: 0.445665\tvalid_1's l2: 0.427265\n",
      "[29]\ttraining's l2: 0.441042\tvalid_1's l2: 0.422653\n",
      "[30]\ttraining's l2: 0.4369\tvalid_1's l2: 0.418493\n",
      "[31]\ttraining's l2: 0.433095\tvalid_1's l2: 0.414668\n",
      "[32]\ttraining's l2: 0.429637\tvalid_1's l2: 0.411169\n",
      "[33]\ttraining's l2: 0.426454\tvalid_1's l2: 0.407959\n",
      "[34]\ttraining's l2: 0.423557\tvalid_1's l2: 0.404968\n",
      "[35]\ttraining's l2: 0.420903\tvalid_1's l2: 0.402336\n",
      "[36]\ttraining's l2: 0.418471\tvalid_1's l2: 0.399845\n",
      "[37]\ttraining's l2: 0.416219\tvalid_1's l2: 0.397653\n",
      "[38]\ttraining's l2: 0.414225\tvalid_1's l2: 0.395752\n",
      "[39]\ttraining's l2: 0.412287\tvalid_1's l2: 0.393874\n",
      "[40]\ttraining's l2: 0.410571\tvalid_1's l2: 0.392222\n",
      "[41]\ttraining's l2: 0.408975\tvalid_1's l2: 0.390657\n",
      "[42]\ttraining's l2: 0.4075\tvalid_1's l2: 0.389183\n",
      "[43]\ttraining's l2: 0.406181\tvalid_1's l2: 0.387809\n",
      "[44]\ttraining's l2: 0.404944\tvalid_1's l2: 0.386559\n",
      "[45]\ttraining's l2: 0.403723\tvalid_1's l2: 0.385375\n",
      "[46]\ttraining's l2: 0.402631\tvalid_1's l2: 0.384441\n",
      "[47]\ttraining's l2: 0.401655\tvalid_1's l2: 0.383523\n",
      "[48]\ttraining's l2: 0.40073\tvalid_1's l2: 0.382654\n",
      "[49]\ttraining's l2: 0.399833\tvalid_1's l2: 0.381778\n",
      "[50]\ttraining's l2: 0.39902\tvalid_1's l2: 0.380987\n",
      "[51]\ttraining's l2: 0.398185\tvalid_1's l2: 0.380245\n",
      "[52]\ttraining's l2: 0.397485\tvalid_1's l2: 0.379615\n",
      "[53]\ttraining's l2: 0.396799\tvalid_1's l2: 0.379014\n",
      "[54]\ttraining's l2: 0.396165\tvalid_1's l2: 0.378438\n",
      "[55]\ttraining's l2: 0.395542\tvalid_1's l2: 0.377869\n",
      "[56]\ttraining's l2: 0.39496\tvalid_1's l2: 0.377385\n",
      "[57]\ttraining's l2: 0.394406\tvalid_1's l2: 0.376835\n",
      "[58]\ttraining's l2: 0.393871\tvalid_1's l2: 0.376461\n",
      "[59]\ttraining's l2: 0.393319\tvalid_1's l2: 0.376001\n",
      "[60]\ttraining's l2: 0.392836\tvalid_1's l2: 0.375472\n",
      "[61]\ttraining's l2: 0.392388\tvalid_1's l2: 0.375165\n",
      "[62]\ttraining's l2: 0.391974\tvalid_1's l2: 0.374847\n",
      "[63]\ttraining's l2: 0.391621\tvalid_1's l2: 0.374571\n",
      "[64]\ttraining's l2: 0.391206\tvalid_1's l2: 0.37429\n",
      "[65]\ttraining's l2: 0.390761\tvalid_1's l2: 0.37398\n",
      "[66]\ttraining's l2: 0.390337\tvalid_1's l2: 0.373608\n",
      "[67]\ttraining's l2: 0.389984\tvalid_1's l2: 0.373375\n",
      "[68]\ttraining's l2: 0.389696\tvalid_1's l2: 0.37316\n",
      "[69]\ttraining's l2: 0.389385\tvalid_1's l2: 0.372843\n",
      "[70]\ttraining's l2: 0.38906\tvalid_1's l2: 0.372612\n",
      "[71]\ttraining's l2: 0.388673\tvalid_1's l2: 0.372291\n",
      "[72]\ttraining's l2: 0.388397\tvalid_1's l2: 0.372059\n",
      "[73]\ttraining's l2: 0.387939\tvalid_1's l2: 0.371834\n",
      "[74]\ttraining's l2: 0.387607\tvalid_1's l2: 0.371673\n",
      "[75]\ttraining's l2: 0.387278\tvalid_1's l2: 0.371403\n",
      "[76]\ttraining's l2: 0.387002\tvalid_1's l2: 0.371212\n",
      "[77]\ttraining's l2: 0.38674\tvalid_1's l2: 0.371075\n",
      "[78]\ttraining's l2: 0.386488\tvalid_1's l2: 0.370867\n",
      "[79]\ttraining's l2: 0.386195\tvalid_1's l2: 0.370681\n",
      "[80]\ttraining's l2: 0.385906\tvalid_1's l2: 0.370457\n",
      "[81]\ttraining's l2: 0.385688\tvalid_1's l2: 0.370316\n",
      "[82]\ttraining's l2: 0.385533\tvalid_1's l2: 0.370232\n",
      "[83]\ttraining's l2: 0.385295\tvalid_1's l2: 0.370033\n",
      "[84]\ttraining's l2: 0.385058\tvalid_1's l2: 0.369948\n",
      "[85]\ttraining's l2: 0.384808\tvalid_1's l2: 0.369853\n",
      "[86]\ttraining's l2: 0.384594\tvalid_1's l2: 0.369778\n",
      "[87]\ttraining's l2: 0.384351\tvalid_1's l2: 0.369656\n",
      "[88]\ttraining's l2: 0.384165\tvalid_1's l2: 0.36957\n",
      "[89]\ttraining's l2: 0.383953\tvalid_1's l2: 0.369457\n",
      "[90]\ttraining's l2: 0.383775\tvalid_1's l2: 0.369365\n",
      "[91]\ttraining's l2: 0.383613\tvalid_1's l2: 0.369277\n",
      "[92]\ttraining's l2: 0.383449\tvalid_1's l2: 0.369181\n",
      "[93]\ttraining's l2: 0.383226\tvalid_1's l2: 0.369042\n",
      "[94]\ttraining's l2: 0.382995\tvalid_1's l2: 0.368911\n",
      "[95]\ttraining's l2: 0.382788\tvalid_1's l2: 0.368842\n",
      "[96]\ttraining's l2: 0.382639\tvalid_1's l2: 0.36875\n",
      "[97]\ttraining's l2: 0.3824\tvalid_1's l2: 0.368602\n",
      "[98]\ttraining's l2: 0.382205\tvalid_1's l2: 0.368508\n",
      "[99]\ttraining's l2: 0.382053\tvalid_1's l2: 0.368411\n",
      "[100]\ttraining's l2: 0.381864\tvalid_1's l2: 0.368328\n",
      "[101]\ttraining's l2: 0.381629\tvalid_1's l2: 0.368288\n",
      "[102]\ttraining's l2: 0.381417\tvalid_1's l2: 0.368183\n",
      "[103]\ttraining's l2: 0.3813\tvalid_1's l2: 0.368131\n",
      "[104]\ttraining's l2: 0.381117\tvalid_1's l2: 0.367967\n",
      "[105]\ttraining's l2: 0.380987\tvalid_1's l2: 0.367914\n",
      "[106]\ttraining's l2: 0.380788\tvalid_1's l2: 0.367975\n",
      "[107]\ttraining's l2: 0.380559\tvalid_1's l2: 0.367947\n",
      "[108]\ttraining's l2: 0.380397\tvalid_1's l2: 0.367893\n",
      "[109]\ttraining's l2: 0.380148\tvalid_1's l2: 0.367717\n",
      "[110]\ttraining's l2: 0.37999\tvalid_1's l2: 0.367622\n",
      "[111]\ttraining's l2: 0.379824\tvalid_1's l2: 0.367589\n",
      "[112]\ttraining's l2: 0.379681\tvalid_1's l2: 0.36753\n",
      "[113]\ttraining's l2: 0.379584\tvalid_1's l2: 0.367438\n",
      "[114]\ttraining's l2: 0.379411\tvalid_1's l2: 0.367328\n",
      "[115]\ttraining's l2: 0.379294\tvalid_1's l2: 0.367281\n",
      "[116]\ttraining's l2: 0.379153\tvalid_1's l2: 0.367223\n",
      "[117]\ttraining's l2: 0.378943\tvalid_1's l2: 0.367215\n",
      "[118]\ttraining's l2: 0.378832\tvalid_1's l2: 0.367174\n",
      "[119]\ttraining's l2: 0.378674\tvalid_1's l2: 0.367142\n",
      "[120]\ttraining's l2: 0.378512\tvalid_1's l2: 0.367044\n",
      "[121]\ttraining's l2: 0.378403\tvalid_1's l2: 0.366997\n",
      "[122]\ttraining's l2: 0.378285\tvalid_1's l2: 0.366974\n",
      "[123]\ttraining's l2: 0.378174\tvalid_1's l2: 0.366948\n",
      "[124]\ttraining's l2: 0.377941\tvalid_1's l2: 0.366875\n",
      "[125]\ttraining's l2: 0.377785\tvalid_1's l2: 0.366786\n",
      "[126]\ttraining's l2: 0.377664\tvalid_1's l2: 0.366755\n",
      "[127]\ttraining's l2: 0.377542\tvalid_1's l2: 0.366757\n",
      "[128]\ttraining's l2: 0.377463\tvalid_1's l2: 0.366712\n",
      "[129]\ttraining's l2: 0.37734\tvalid_1's l2: 0.366651\n",
      "[130]\ttraining's l2: 0.377269\tvalid_1's l2: 0.36662\n",
      "[131]\ttraining's l2: 0.377126\tvalid_1's l2: 0.366622\n",
      "[132]\ttraining's l2: 0.377014\tvalid_1's l2: 0.366609\n",
      "[133]\ttraining's l2: 0.37691\tvalid_1's l2: 0.366609\n",
      "[134]\ttraining's l2: 0.376815\tvalid_1's l2: 0.366589\n",
      "[135]\ttraining's l2: 0.376755\tvalid_1's l2: 0.366568\n",
      "[136]\ttraining's l2: 0.37669\tvalid_1's l2: 0.366537\n",
      "[137]\ttraining's l2: 0.376592\tvalid_1's l2: 0.366506\n",
      "[138]\ttraining's l2: 0.376527\tvalid_1's l2: 0.366484\n",
      "[139]\ttraining's l2: 0.376388\tvalid_1's l2: 0.366408\n",
      "[140]\ttraining's l2: 0.376244\tvalid_1's l2: 0.3664\n",
      "[141]\ttraining's l2: 0.376111\tvalid_1's l2: 0.366402\n",
      "[142]\ttraining's l2: 0.376\tvalid_1's l2: 0.366402\n",
      "[143]\ttraining's l2: 0.375868\tvalid_1's l2: 0.366366\n",
      "[144]\ttraining's l2: 0.375792\tvalid_1's l2: 0.366351\n",
      "[145]\ttraining's l2: 0.375699\tvalid_1's l2: 0.366359\n",
      "[146]\ttraining's l2: 0.375621\tvalid_1's l2: 0.366361\n",
      "[147]\ttraining's l2: 0.37557\tvalid_1's l2: 0.366342\n",
      "[148]\ttraining's l2: 0.375467\tvalid_1's l2: 0.366327\n",
      "[149]\ttraining's l2: 0.375352\tvalid_1's l2: 0.366324\n",
      "[150]\ttraining's l2: 0.375293\tvalid_1's l2: 0.366281\n",
      "[151]\ttraining's l2: 0.375175\tvalid_1's l2: 0.366277\n",
      "[152]\ttraining's l2: 0.375128\tvalid_1's l2: 0.366255\n",
      "[153]\ttraining's l2: 0.375038\tvalid_1's l2: 0.366241\n",
      "[154]\ttraining's l2: 0.374934\tvalid_1's l2: 0.36626\n",
      "[155]\ttraining's l2: 0.37485\tvalid_1's l2: 0.366193\n",
      "[156]\ttraining's l2: 0.374802\tvalid_1's l2: 0.366172\n",
      "[157]\ttraining's l2: 0.374747\tvalid_1's l2: 0.366158\n",
      "[158]\ttraining's l2: 0.374673\tvalid_1's l2: 0.366173\n",
      "[159]\ttraining's l2: 0.374565\tvalid_1's l2: 0.36618\n",
      "[160]\ttraining's l2: 0.374515\tvalid_1's l2: 0.366157\n",
      "[161]\ttraining's l2: 0.374414\tvalid_1's l2: 0.366147\n",
      "[162]\ttraining's l2: 0.374314\tvalid_1's l2: 0.366139\n",
      "[163]\ttraining's l2: 0.374175\tvalid_1's l2: 0.366045\n",
      "[164]\ttraining's l2: 0.374109\tvalid_1's l2: 0.366034\n",
      "[165]\ttraining's l2: 0.37399\tvalid_1's l2: 0.365959\n",
      "[166]\ttraining's l2: 0.373947\tvalid_1's l2: 0.365945\n",
      "[167]\ttraining's l2: 0.373895\tvalid_1's l2: 0.365917\n",
      "[168]\ttraining's l2: 0.373827\tvalid_1's l2: 0.365924\n",
      "[169]\ttraining's l2: 0.373745\tvalid_1's l2: 0.365922\n",
      "[170]\ttraining's l2: 0.373686\tvalid_1's l2: 0.365897\n",
      "[171]\ttraining's l2: 0.373621\tvalid_1's l2: 0.365868\n",
      "[172]\ttraining's l2: 0.373539\tvalid_1's l2: 0.365889\n",
      "[173]\ttraining's l2: 0.373481\tvalid_1's l2: 0.365861\n",
      "[174]\ttraining's l2: 0.373361\tvalid_1's l2: 0.365795\n",
      "[175]\ttraining's l2: 0.373327\tvalid_1's l2: 0.365785\n",
      "[176]\ttraining's l2: 0.373246\tvalid_1's l2: 0.365727\n",
      "[177]\ttraining's l2: 0.373201\tvalid_1's l2: 0.365713\n",
      "[178]\ttraining's l2: 0.373118\tvalid_1's l2: 0.365717\n",
      "[179]\ttraining's l2: 0.373077\tvalid_1's l2: 0.365696\n",
      "[180]\ttraining's l2: 0.373034\tvalid_1's l2: 0.365678\n",
      "[181]\ttraining's l2: 0.372966\tvalid_1's l2: 0.365705\n",
      "[182]\ttraining's l2: 0.372918\tvalid_1's l2: 0.365692\n",
      "[183]\ttraining's l2: 0.372847\tvalid_1's l2: 0.365644\n",
      "[184]\ttraining's l2: 0.372777\tvalid_1's l2: 0.365624\n",
      "[185]\ttraining's l2: 0.372727\tvalid_1's l2: 0.365613\n",
      "[186]\ttraining's l2: 0.372689\tvalid_1's l2: 0.365589\n",
      "[187]\ttraining's l2: 0.372656\tvalid_1's l2: 0.365587\n",
      "[188]\ttraining's l2: 0.372589\tvalid_1's l2: 0.365584\n",
      "[189]\ttraining's l2: 0.37255\tvalid_1's l2: 0.365575\n",
      "[190]\ttraining's l2: 0.372493\tvalid_1's l2: 0.365587\n",
      "[191]\ttraining's l2: 0.3724\tvalid_1's l2: 0.365584\n",
      "[192]\ttraining's l2: 0.372341\tvalid_1's l2: 0.365568\n",
      "[193]\ttraining's l2: 0.372289\tvalid_1's l2: 0.365598\n",
      "[194]\ttraining's l2: 0.372249\tvalid_1's l2: 0.365592\n",
      "[195]\ttraining's l2: 0.372205\tvalid_1's l2: 0.365568\n",
      "[196]\ttraining's l2: 0.372156\tvalid_1's l2: 0.365556\n",
      "[197]\ttraining's l2: 0.37208\tvalid_1's l2: 0.365557\n",
      "[198]\ttraining's l2: 0.37204\tvalid_1's l2: 0.365527\n",
      "[199]\ttraining's l2: 0.371977\tvalid_1's l2: 0.365477\n",
      "[200]\ttraining's l2: 0.371939\tvalid_1's l2: 0.365446\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.371939\tvalid_1's l2: 0.365446\n",
      "mean_21_sales: 8472714.85\n",
      "mean_30_sales: 4833273.71\n",
      "mean_7_sales: 2831640.43\n",
      "mean_14_sales: 2465704.39\n",
      "mean_60_sales: 1523745.60\n",
      "mean_20_dow5_2017: 822958.03\n",
      "promo_12: 784761.17\n",
      "mean_3_sales: 763329.81\n",
      "mean_4_sales: 649974.99\n",
      "mean_6_sales: 481417.79\n",
      "item_class_features: 295658.64\n",
      "mean_63_sales: 233712.86\n",
      "mean_4_dow5_2017: 218485.67\n",
      "mean_5_sales: 191624.89\n",
      "promo_14: 94982.42\n",
      "promo_13: 58874.89\n",
      "lag_1_transactions: 49676.20\n",
      "sum_2_promo: 47644.64\n",
      "promo_10: 44233.13\n",
      "sum_4_promo: 41527.96\n",
      "std_21_sales: 40004.96\n",
      "std_30_sales: 38041.56\n",
      "item_family_features: 36699.91\n",
      "mean_20_dow6_2017: 35980.83\n",
      "lag_6_transactions: 35573.46\n",
      "lag_3_transactions: 31796.07\n",
      "lag_1_sales: 31538.04\n",
      "lag_21_transactions: 27096.48\n",
      "lag_4_transactions: 25691.84\n",
      "lag_49_sales: 21222.37\n",
      "std_63_sales: 17484.51\n",
      "promo_9: 16789.15\n",
      "store_cluster_features: 16257.09\n",
      "lag_5_transactions: 15734.09\n",
      "mean_20_dow0_2017: 15722.45\n",
      "std_60_sales: 15713.06\n",
      "sum_14_promo: 13165.33\n",
      "lag_2_transactions: 12891.77\n",
      "promo_7: 12218.68\n",
      "lag_7_transactions: 12167.24\n",
      "promo_11: 11928.02\n",
      "mean_4_dow6_2017: 10026.76\n",
      "sum_7_promo: 9145.98\n",
      "lag_2_sales: 8953.48\n",
      "std_14_sales: 8865.39\n",
      "mean_20_dow3_2017: 8852.44\n",
      "sum_21_promo: 8187.55\n",
      "lag_14_transactions: 7793.47\n",
      "store_city_features: 7740.58\n",
      "promo_8: 7044.31\n",
      "sum_3_promo: 6918.95\n",
      "sum_6_promo: 5687.03\n",
      "promo_15: 5426.25\n",
      "promo_5: 4408.90\n",
      "mean_4_dow3_2017: 3826.34\n",
      "std_7_sales: 3658.76\n",
      "mean_20_dow1_2017: 3591.53\n",
      "mean_4_dow1_2017: 3491.64\n",
      "promo_0: 3475.04\n",
      "lag_6_sales: 3279.07\n",
      "mean_4_dow4_2017: 3056.63\n",
      "promo_6: 2936.20\n",
      "mean_20_dow2_2017: 2832.35\n",
      "mean_4_dow0_2017: 2794.16\n",
      "lag_3_sales: 2235.58\n",
      "std_4_sales: 2174.78\n",
      "promo_2: 2030.70\n",
      "lag_7_sales: 1954.03\n",
      "std_5_sales: 1917.73\n",
      "sum_5_promo: 1827.43\n",
      "lag_21_sales: 1689.91\n",
      "lag_4_sales: 1679.64\n",
      "mean_20_dow4_2017: 1497.05\n",
      "lag_56_sales: 1449.12\n",
      "std_6_sales: 1404.19\n",
      "store_state_features: 1360.84\n",
      "lag_14_sales: 1225.13\n",
      "std_3_sales: 1213.41\n",
      "lag_28_sales: 1180.67\n",
      "store_type_features: 893.04\n",
      "lag_63_sales: 788.65\n",
      "mean_4_dow2_2017: 645.70\n",
      "promo_3: 615.56\n",
      "lag_42_sales: 533.91\n",
      "lag_5_sales: 485.37\n",
      "promo_4: 243.71\n",
      "lag_35_sales: 235.42\n",
      "promo_1: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [21:47<05:09, 103.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.03104\tvalid_1's l2: 0.994067\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.969991\tvalid_1's l2: 0.934006\n",
      "[3]\ttraining's l2: 0.914781\tvalid_1's l2: 0.879791\n",
      "[4]\ttraining's l2: 0.864926\tvalid_1's l2: 0.830806\n",
      "[5]\ttraining's l2: 0.819832\tvalid_1's l2: 0.786291\n",
      "[6]\ttraining's l2: 0.779017\tvalid_1's l2: 0.746213\n",
      "[7]\ttraining's l2: 0.742009\tvalid_1's l2: 0.71003\n",
      "[8]\ttraining's l2: 0.708654\tvalid_1's l2: 0.677298\n",
      "[9]\ttraining's l2: 0.678305\tvalid_1's l2: 0.647625\n",
      "[10]\ttraining's l2: 0.650789\tvalid_1's l2: 0.620707\n",
      "[11]\ttraining's l2: 0.625858\tvalid_1's l2: 0.596634\n",
      "[12]\ttraining's l2: 0.603796\tvalid_1's l2: 0.575183\n",
      "[13]\ttraining's l2: 0.583312\tvalid_1's l2: 0.555103\n",
      "[14]\ttraining's l2: 0.56468\tvalid_1's l2: 0.537056\n",
      "[15]\ttraining's l2: 0.547842\tvalid_1's l2: 0.520773\n",
      "[16]\ttraining's l2: 0.532569\tvalid_1's l2: 0.505957\n",
      "[17]\ttraining's l2: 0.518697\tvalid_1's l2: 0.492553\n",
      "[18]\ttraining's l2: 0.506534\tvalid_1's l2: 0.480697\n",
      "[19]\ttraining's l2: 0.495405\tvalid_1's l2: 0.469977\n",
      "[20]\ttraining's l2: 0.48496\tvalid_1's l2: 0.459843\n",
      "[21]\ttraining's l2: 0.475486\tvalid_1's l2: 0.450636\n",
      "[22]\ttraining's l2: 0.466833\tvalid_1's l2: 0.442345\n",
      "[23]\ttraining's l2: 0.458989\tvalid_1's l2: 0.434788\n",
      "[24]\ttraining's l2: 0.451863\tvalid_1's l2: 0.427972\n",
      "[25]\ttraining's l2: 0.44532\tvalid_1's l2: 0.421759\n",
      "[26]\ttraining's l2: 0.439393\tvalid_1's l2: 0.416093\n",
      "[27]\ttraining's l2: 0.434032\tvalid_1's l2: 0.410971\n",
      "[28]\ttraining's l2: 0.429132\tvalid_1's l2: 0.406329\n",
      "[29]\ttraining's l2: 0.42469\tvalid_1's l2: 0.402197\n",
      "[30]\ttraining's l2: 0.420651\tvalid_1's l2: 0.398474\n",
      "[31]\ttraining's l2: 0.416974\tvalid_1's l2: 0.395004\n",
      "[32]\ttraining's l2: 0.413492\tvalid_1's l2: 0.391854\n",
      "[33]\ttraining's l2: 0.410364\tvalid_1's l2: 0.388929\n",
      "[34]\ttraining's l2: 0.407517\tvalid_1's l2: 0.386238\n",
      "[35]\ttraining's l2: 0.404872\tvalid_1's l2: 0.38383\n",
      "[36]\ttraining's l2: 0.402507\tvalid_1's l2: 0.381596\n",
      "[37]\ttraining's l2: 0.400303\tvalid_1's l2: 0.379629\n",
      "[38]\ttraining's l2: 0.398248\tvalid_1's l2: 0.377758\n",
      "[39]\ttraining's l2: 0.396387\tvalid_1's l2: 0.376093\n",
      "[40]\ttraining's l2: 0.394719\tvalid_1's l2: 0.37465\n",
      "[41]\ttraining's l2: 0.393197\tvalid_1's l2: 0.373364\n",
      "[42]\ttraining's l2: 0.391691\tvalid_1's l2: 0.372007\n",
      "[43]\ttraining's l2: 0.39031\tvalid_1's l2: 0.37073\n",
      "[44]\ttraining's l2: 0.388909\tvalid_1's l2: 0.369555\n",
      "[45]\ttraining's l2: 0.387739\tvalid_1's l2: 0.36853\n",
      "[46]\ttraining's l2: 0.386612\tvalid_1's l2: 0.367586\n",
      "[47]\ttraining's l2: 0.385608\tvalid_1's l2: 0.366757\n",
      "[48]\ttraining's l2: 0.384565\tvalid_1's l2: 0.365872\n",
      "[49]\ttraining's l2: 0.38372\tvalid_1's l2: 0.365168\n",
      "[50]\ttraining's l2: 0.38286\tvalid_1's l2: 0.364484\n",
      "[51]\ttraining's l2: 0.381995\tvalid_1's l2: 0.363806\n",
      "[52]\ttraining's l2: 0.381207\tvalid_1's l2: 0.363148\n",
      "[53]\ttraining's l2: 0.380594\tvalid_1's l2: 0.362619\n",
      "[54]\ttraining's l2: 0.379895\tvalid_1's l2: 0.362104\n",
      "[55]\ttraining's l2: 0.379304\tvalid_1's l2: 0.361621\n",
      "[56]\ttraining's l2: 0.37868\tvalid_1's l2: 0.361144\n",
      "[57]\ttraining's l2: 0.378173\tvalid_1's l2: 0.360763\n",
      "[58]\ttraining's l2: 0.377563\tvalid_1's l2: 0.36032\n",
      "[59]\ttraining's l2: 0.377136\tvalid_1's l2: 0.359985\n",
      "[60]\ttraining's l2: 0.376634\tvalid_1's l2: 0.359611\n",
      "[61]\ttraining's l2: 0.37616\tvalid_1's l2: 0.359251\n",
      "[62]\ttraining's l2: 0.375655\tvalid_1's l2: 0.358897\n",
      "[63]\ttraining's l2: 0.375299\tvalid_1's l2: 0.35866\n",
      "[64]\ttraining's l2: 0.374952\tvalid_1's l2: 0.358426\n",
      "[65]\ttraining's l2: 0.374592\tvalid_1's l2: 0.358123\n",
      "[66]\ttraining's l2: 0.374189\tvalid_1's l2: 0.3578\n",
      "[67]\ttraining's l2: 0.37386\tvalid_1's l2: 0.357539\n",
      "[68]\ttraining's l2: 0.373519\tvalid_1's l2: 0.357312\n",
      "[69]\ttraining's l2: 0.373237\tvalid_1's l2: 0.357047\n",
      "[70]\ttraining's l2: 0.372936\tvalid_1's l2: 0.356861\n",
      "[71]\ttraining's l2: 0.372707\tvalid_1's l2: 0.3567\n",
      "[72]\ttraining's l2: 0.372305\tvalid_1's l2: 0.356418\n",
      "[73]\ttraining's l2: 0.371851\tvalid_1's l2: 0.356148\n",
      "[74]\ttraining's l2: 0.371607\tvalid_1's l2: 0.35601\n",
      "[75]\ttraining's l2: 0.371344\tvalid_1's l2: 0.355829\n",
      "[76]\ttraining's l2: 0.371093\tvalid_1's l2: 0.355704\n",
      "[77]\ttraining's l2: 0.370851\tvalid_1's l2: 0.355513\n",
      "[78]\ttraining's l2: 0.370662\tvalid_1's l2: 0.355431\n",
      "[79]\ttraining's l2: 0.370486\tvalid_1's l2: 0.355319\n",
      "[80]\ttraining's l2: 0.37023\tvalid_1's l2: 0.355162\n",
      "[81]\ttraining's l2: 0.369922\tvalid_1's l2: 0.35499\n",
      "[82]\ttraining's l2: 0.369744\tvalid_1's l2: 0.35488\n",
      "[83]\ttraining's l2: 0.369518\tvalid_1's l2: 0.354735\n",
      "[84]\ttraining's l2: 0.369328\tvalid_1's l2: 0.35463\n",
      "[85]\ttraining's l2: 0.369067\tvalid_1's l2: 0.354455\n",
      "[86]\ttraining's l2: 0.36891\tvalid_1's l2: 0.354378\n",
      "[87]\ttraining's l2: 0.368689\tvalid_1's l2: 0.354257\n",
      "[88]\ttraining's l2: 0.368547\tvalid_1's l2: 0.35422\n",
      "[89]\ttraining's l2: 0.368357\tvalid_1's l2: 0.354098\n",
      "[90]\ttraining's l2: 0.368199\tvalid_1's l2: 0.354019\n",
      "[91]\ttraining's l2: 0.368084\tvalid_1's l2: 0.353975\n",
      "[92]\ttraining's l2: 0.367913\tvalid_1's l2: 0.353896\n",
      "[93]\ttraining's l2: 0.367799\tvalid_1's l2: 0.353849\n",
      "[94]\ttraining's l2: 0.367544\tvalid_1's l2: 0.353649\n",
      "[95]\ttraining's l2: 0.367359\tvalid_1's l2: 0.353539\n",
      "[96]\ttraining's l2: 0.367219\tvalid_1's l2: 0.353492\n",
      "[97]\ttraining's l2: 0.36699\tvalid_1's l2: 0.353318\n",
      "[98]\ttraining's l2: 0.366836\tvalid_1's l2: 0.353243\n",
      "[99]\ttraining's l2: 0.366668\tvalid_1's l2: 0.35323\n",
      "[100]\ttraining's l2: 0.366562\tvalid_1's l2: 0.353171\n",
      "[101]\ttraining's l2: 0.366473\tvalid_1's l2: 0.353122\n",
      "[102]\ttraining's l2: 0.366162\tvalid_1's l2: 0.352931\n",
      "[103]\ttraining's l2: 0.366026\tvalid_1's l2: 0.352872\n",
      "[104]\ttraining's l2: 0.365886\tvalid_1's l2: 0.352894\n",
      "[105]\ttraining's l2: 0.365732\tvalid_1's l2: 0.352802\n",
      "[106]\ttraining's l2: 0.365628\tvalid_1's l2: 0.352764\n",
      "[107]\ttraining's l2: 0.365451\tvalid_1's l2: 0.352646\n",
      "[108]\ttraining's l2: 0.365345\tvalid_1's l2: 0.352586\n",
      "[109]\ttraining's l2: 0.365222\tvalid_1's l2: 0.352568\n",
      "[110]\ttraining's l2: 0.365043\tvalid_1's l2: 0.352462\n",
      "[111]\ttraining's l2: 0.364948\tvalid_1's l2: 0.352451\n",
      "[112]\ttraining's l2: 0.364838\tvalid_1's l2: 0.352426\n",
      "[113]\ttraining's l2: 0.364745\tvalid_1's l2: 0.352373\n",
      "[114]\ttraining's l2: 0.364632\tvalid_1's l2: 0.35238\n",
      "[115]\ttraining's l2: 0.364552\tvalid_1's l2: 0.352379\n",
      "[116]\ttraining's l2: 0.36438\tvalid_1's l2: 0.352283\n",
      "[117]\ttraining's l2: 0.364265\tvalid_1's l2: 0.35231\n",
      "[118]\ttraining's l2: 0.364149\tvalid_1's l2: 0.352244\n",
      "[119]\ttraining's l2: 0.36403\tvalid_1's l2: 0.35223\n",
      "[120]\ttraining's l2: 0.363928\tvalid_1's l2: 0.352181\n",
      "[121]\ttraining's l2: 0.363844\tvalid_1's l2: 0.352139\n",
      "[122]\ttraining's l2: 0.363773\tvalid_1's l2: 0.352103\n",
      "[123]\ttraining's l2: 0.363641\tvalid_1's l2: 0.352052\n",
      "[124]\ttraining's l2: 0.363532\tvalid_1's l2: 0.352008\n",
      "[125]\ttraining's l2: 0.363374\tvalid_1's l2: 0.3519\n",
      "[126]\ttraining's l2: 0.363267\tvalid_1's l2: 0.351862\n",
      "[127]\ttraining's l2: 0.363108\tvalid_1's l2: 0.351746\n",
      "[128]\ttraining's l2: 0.363041\tvalid_1's l2: 0.351753\n",
      "[129]\ttraining's l2: 0.362958\tvalid_1's l2: 0.351745\n",
      "[130]\ttraining's l2: 0.36286\tvalid_1's l2: 0.351715\n",
      "[131]\ttraining's l2: 0.362725\tvalid_1's l2: 0.351626\n",
      "[132]\ttraining's l2: 0.362657\tvalid_1's l2: 0.351625\n",
      "[133]\ttraining's l2: 0.362584\tvalid_1's l2: 0.351623\n",
      "[134]\ttraining's l2: 0.362426\tvalid_1's l2: 0.351535\n",
      "[135]\ttraining's l2: 0.362322\tvalid_1's l2: 0.351491\n",
      "[136]\ttraining's l2: 0.362258\tvalid_1's l2: 0.351514\n",
      "[137]\ttraining's l2: 0.362205\tvalid_1's l2: 0.351512\n",
      "[138]\ttraining's l2: 0.362133\tvalid_1's l2: 0.351491\n",
      "[139]\ttraining's l2: 0.362062\tvalid_1's l2: 0.351498\n",
      "[140]\ttraining's l2: 0.361891\tvalid_1's l2: 0.351381\n",
      "[141]\ttraining's l2: 0.361829\tvalid_1's l2: 0.351372\n",
      "[142]\ttraining's l2: 0.36175\tvalid_1's l2: 0.35134\n",
      "[143]\ttraining's l2: 0.361668\tvalid_1's l2: 0.35131\n",
      "[144]\ttraining's l2: 0.361588\tvalid_1's l2: 0.351324\n",
      "[145]\ttraining's l2: 0.36152\tvalid_1's l2: 0.351316\n",
      "[146]\ttraining's l2: 0.361448\tvalid_1's l2: 0.351315\n",
      "[147]\ttraining's l2: 0.361383\tvalid_1's l2: 0.351313\n",
      "[148]\ttraining's l2: 0.36129\tvalid_1's l2: 0.351253\n",
      "[149]\ttraining's l2: 0.361185\tvalid_1's l2: 0.351213\n",
      "[150]\ttraining's l2: 0.361132\tvalid_1's l2: 0.351212\n",
      "[151]\ttraining's l2: 0.361081\tvalid_1's l2: 0.351234\n",
      "[152]\ttraining's l2: 0.361028\tvalid_1's l2: 0.351242\n",
      "[153]\ttraining's l2: 0.360957\tvalid_1's l2: 0.351239\n",
      "[154]\ttraining's l2: 0.360894\tvalid_1's l2: 0.35122\n",
      "[155]\ttraining's l2: 0.360803\tvalid_1's l2: 0.351145\n",
      "[156]\ttraining's l2: 0.360751\tvalid_1's l2: 0.351122\n",
      "[157]\ttraining's l2: 0.360707\tvalid_1's l2: 0.351118\n",
      "[158]\ttraining's l2: 0.360569\tvalid_1's l2: 0.351041\n",
      "[159]\ttraining's l2: 0.360481\tvalid_1's l2: 0.351005\n",
      "[160]\ttraining's l2: 0.360401\tvalid_1's l2: 0.350994\n",
      "[161]\ttraining's l2: 0.360346\tvalid_1's l2: 0.350967\n",
      "[162]\ttraining's l2: 0.36028\tvalid_1's l2: 0.350948\n",
      "[163]\ttraining's l2: 0.36024\tvalid_1's l2: 0.350947\n",
      "[164]\ttraining's l2: 0.360193\tvalid_1's l2: 0.350939\n",
      "[165]\ttraining's l2: 0.360127\tvalid_1's l2: 0.350889\n",
      "[166]\ttraining's l2: 0.360058\tvalid_1's l2: 0.350878\n",
      "[167]\ttraining's l2: 0.360019\tvalid_1's l2: 0.350875\n",
      "[168]\ttraining's l2: 0.359962\tvalid_1's l2: 0.350881\n",
      "[169]\ttraining's l2: 0.359913\tvalid_1's l2: 0.350912\n",
      "[170]\ttraining's l2: 0.359872\tvalid_1's l2: 0.35091\n",
      "[171]\ttraining's l2: 0.359825\tvalid_1's l2: 0.35089\n",
      "[172]\ttraining's l2: 0.359782\tvalid_1's l2: 0.350876\n",
      "[173]\ttraining's l2: 0.359745\tvalid_1's l2: 0.350861\n",
      "[174]\ttraining's l2: 0.359695\tvalid_1's l2: 0.350832\n",
      "[175]\ttraining's l2: 0.359643\tvalid_1's l2: 0.350833\n",
      "[176]\ttraining's l2: 0.359571\tvalid_1's l2: 0.350768\n",
      "[177]\ttraining's l2: 0.359512\tvalid_1's l2: 0.350757\n",
      "[178]\ttraining's l2: 0.359464\tvalid_1's l2: 0.350746\n",
      "[179]\ttraining's l2: 0.35942\tvalid_1's l2: 0.350751\n",
      "[180]\ttraining's l2: 0.359375\tvalid_1's l2: 0.350756\n",
      "[181]\ttraining's l2: 0.359311\tvalid_1's l2: 0.35077\n",
      "[182]\ttraining's l2: 0.359279\tvalid_1's l2: 0.35075\n",
      "[183]\ttraining's l2: 0.35921\tvalid_1's l2: 0.350749\n",
      "[184]\ttraining's l2: 0.359165\tvalid_1's l2: 0.350757\n",
      "[185]\ttraining's l2: 0.359133\tvalid_1's l2: 0.350752\n",
      "[186]\ttraining's l2: 0.359079\tvalid_1's l2: 0.350751\n",
      "[187]\ttraining's l2: 0.359034\tvalid_1's l2: 0.35074\n",
      "[188]\ttraining's l2: 0.35899\tvalid_1's l2: 0.350747\n",
      "[189]\ttraining's l2: 0.358955\tvalid_1's l2: 0.350742\n",
      "[190]\ttraining's l2: 0.358909\tvalid_1's l2: 0.350741\n",
      "[191]\ttraining's l2: 0.358866\tvalid_1's l2: 0.350744\n",
      "[192]\ttraining's l2: 0.358835\tvalid_1's l2: 0.350741\n",
      "[193]\ttraining's l2: 0.358771\tvalid_1's l2: 0.350734\n",
      "[194]\ttraining's l2: 0.358723\tvalid_1's l2: 0.350694\n",
      "[195]\ttraining's l2: 0.358691\tvalid_1's l2: 0.350683\n",
      "[196]\ttraining's l2: 0.358643\tvalid_1's l2: 0.350677\n",
      "[197]\ttraining's l2: 0.358542\tvalid_1's l2: 0.350627\n",
      "[198]\ttraining's l2: 0.358454\tvalid_1's l2: 0.350557\n",
      "[199]\ttraining's l2: 0.358415\tvalid_1's l2: 0.350538\n",
      "[200]\ttraining's l2: 0.358387\tvalid_1's l2: 0.350528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.358387\tvalid_1's l2: 0.350528\n",
      "mean_21_sales: 6497437.34\n",
      "mean_30_sales: 6278107.69\n",
      "mean_14_sales: 2604887.31\n",
      "mean_7_sales: 2042335.68\n",
      "mean_20_dow6_2017: 1712320.89\n",
      "promo_13: 1111854.60\n",
      "mean_3_sales: 864621.52\n",
      "mean_6_sales: 698497.02\n",
      "mean_4_dow6_2017: 551648.75\n",
      "mean_60_sales: 535874.93\n",
      "item_class_features: 309497.52\n",
      "mean_63_sales: 303466.26\n",
      "mean_4_sales: 184586.61\n",
      "promo_14: 122036.89\n",
      "mean_20_dow5_2017: 79879.48\n",
      "lag_1_sales: 72873.10\n",
      "item_family_features: 67881.51\n",
      "std_30_sales: 54288.21\n",
      "std_21_sales: 45387.12\n",
      "sum_4_promo: 44472.17\n",
      "promo_10: 40085.09\n",
      "std_63_sales: 31256.84\n",
      "mean_5_sales: 28981.76\n",
      "promo_6: 26759.74\n",
      "sum_2_promo: 26211.50\n",
      "lag_2_sales: 25457.57\n",
      "promo_12: 23755.98\n",
      "lag_1_transactions: 23146.15\n",
      "lag_49_sales: 21041.46\n",
      "std_60_sales: 19999.74\n",
      "lag_3_transactions: 17819.61\n",
      "store_cluster_features: 14470.73\n",
      "lag_14_transactions: 14344.80\n",
      "sum_14_promo: 13644.18\n",
      "lag_2_transactions: 13490.05\n",
      "sum_7_promo: 12354.41\n",
      "mean_20_dow1_2017: 11880.77\n",
      "sum_21_promo: 11370.29\n",
      "mean_20_dow0_2017: 11118.31\n",
      "promo_9: 10421.12\n",
      "store_type_features: 9851.26\n",
      "mean_20_dow3_2017: 9412.01\n",
      "std_14_sales: 9321.45\n",
      "lag_4_transactions: 9066.97\n",
      "promo_0: 8953.56\n",
      "lag_21_transactions: 8025.48\n",
      "promo_7: 7743.02\n",
      "lag_7_transactions: 7175.81\n",
      "std_7_sales: 6372.25\n",
      "lag_6_transactions: 6314.65\n",
      "promo_11: 6279.57\n",
      "store_city_features: 6176.10\n",
      "lag_5_transactions: 6063.36\n",
      "sum_6_promo: 6019.69\n",
      "sum_5_promo: 5802.10\n",
      "promo_15: 5003.27\n",
      "promo_8: 4436.64\n",
      "lag_6_sales: 4192.06\n",
      "sum_3_promo: 3917.50\n",
      "lag_14_sales: 3891.84\n",
      "mean_4_dow5_2017: 2586.53\n",
      "lag_7_sales: 2491.82\n",
      "lag_21_sales: 2449.30\n",
      "mean_4_dow0_2017: 2295.17\n",
      "lag_3_sales: 2241.23\n",
      "mean_4_dow4_2017: 2167.52\n",
      "mean_20_dow4_2017: 2102.09\n",
      "std_5_sales: 2083.22\n",
      "store_state_features: 1924.51\n",
      "mean_4_dow1_2017: 1892.55\n",
      "mean_20_dow2_2017: 1795.10\n",
      "lag_4_sales: 1788.71\n",
      "std_4_sales: 1778.02\n",
      "lag_28_sales: 1657.06\n",
      "mean_4_dow3_2017: 1502.05\n",
      "std_6_sales: 1359.48\n",
      "lag_42_sales: 1277.26\n",
      "lag_35_sales: 1144.09\n",
      "mean_4_dow2_2017: 992.31\n",
      "lag_63_sales: 950.54\n",
      "lag_56_sales: 720.70\n",
      "lag_5_sales: 661.10\n",
      "std_3_sales: 514.35\n",
      "promo_2: 487.85\n",
      "promo_1: 220.41\n",
      "promo_4: 52.62\n",
      "promo_3: 0.00\n",
      "promo_5: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [23:23<03:22, 101.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05906\tvalid_1's l2: 1.0086\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.994618\tvalid_1's l2: 0.946203\n",
      "[3]\ttraining's l2: 0.936245\tvalid_1's l2: 0.889772\n",
      "[4]\ttraining's l2: 0.885967\tvalid_1's l2: 0.840585\n",
      "[5]\ttraining's l2: 0.838041\tvalid_1's l2: 0.79409\n",
      "[6]\ttraining's l2: 0.796889\tvalid_1's l2: 0.753991\n",
      "[7]\ttraining's l2: 0.757313\tvalid_1's l2: 0.716043\n",
      "[8]\ttraining's l2: 0.721568\tvalid_1's l2: 0.681508\n",
      "[9]\ttraining's l2: 0.689113\tvalid_1's l2: 0.650425\n",
      "[10]\ttraining's l2: 0.659591\tvalid_1's l2: 0.622307\n",
      "[11]\ttraining's l2: 0.632947\tvalid_1's l2: 0.596708\n",
      "[12]\ttraining's l2: 0.608767\tvalid_1's l2: 0.573589\n",
      "[13]\ttraining's l2: 0.586652\tvalid_1's l2: 0.552765\n",
      "[14]\ttraining's l2: 0.566668\tvalid_1's l2: 0.533752\n",
      "[15]\ttraining's l2: 0.549637\tvalid_1's l2: 0.517416\n",
      "[16]\ttraining's l2: 0.533038\tvalid_1's l2: 0.501738\n",
      "[17]\ttraining's l2: 0.518933\tvalid_1's l2: 0.48826\n",
      "[18]\ttraining's l2: 0.505185\tvalid_1's l2: 0.475219\n",
      "[19]\ttraining's l2: 0.492766\tvalid_1's l2: 0.463609\n",
      "[20]\ttraining's l2: 0.482197\tvalid_1's l2: 0.453617\n",
      "[21]\ttraining's l2: 0.471745\tvalid_1's l2: 0.443876\n",
      "[22]\ttraining's l2: 0.462361\tvalid_1's l2: 0.435184\n",
      "[23]\ttraining's l2: 0.453735\tvalid_1's l2: 0.427138\n",
      "[24]\ttraining's l2: 0.445905\tvalid_1's l2: 0.419902\n",
      "[25]\ttraining's l2: 0.438705\tvalid_1's l2: 0.413211\n",
      "[26]\ttraining's l2: 0.432142\tvalid_1's l2: 0.407212\n",
      "[27]\ttraining's l2: 0.426748\tvalid_1's l2: 0.402166\n",
      "[28]\ttraining's l2: 0.421282\tvalid_1's l2: 0.397199\n",
      "[29]\ttraining's l2: 0.416278\tvalid_1's l2: 0.392643\n",
      "[30]\ttraining's l2: 0.41174\tvalid_1's l2: 0.388472\n",
      "[31]\ttraining's l2: 0.40755\tvalid_1's l2: 0.38469\n",
      "[32]\ttraining's l2: 0.403788\tvalid_1's l2: 0.381302\n",
      "[33]\ttraining's l2: 0.400654\tvalid_1's l2: 0.378391\n",
      "[34]\ttraining's l2: 0.397431\tvalid_1's l2: 0.375493\n",
      "[35]\ttraining's l2: 0.394494\tvalid_1's l2: 0.372853\n",
      "[36]\ttraining's l2: 0.391873\tvalid_1's l2: 0.370492\n",
      "[37]\ttraining's l2: 0.389337\tvalid_1's l2: 0.368285\n",
      "[38]\ttraining's l2: 0.386937\tvalid_1's l2: 0.366177\n",
      "[39]\ttraining's l2: 0.384811\tvalid_1's l2: 0.364329\n",
      "[40]\ttraining's l2: 0.382872\tvalid_1's l2: 0.362607\n",
      "[41]\ttraining's l2: 0.381109\tvalid_1's l2: 0.361052\n",
      "[42]\ttraining's l2: 0.379401\tvalid_1's l2: 0.359608\n",
      "[43]\ttraining's l2: 0.378071\tvalid_1's l2: 0.358442\n",
      "[44]\ttraining's l2: 0.376687\tvalid_1's l2: 0.357232\n",
      "[45]\ttraining's l2: 0.375267\tvalid_1's l2: 0.356073\n",
      "[46]\ttraining's l2: 0.374002\tvalid_1's l2: 0.354993\n",
      "[47]\ttraining's l2: 0.372866\tvalid_1's l2: 0.354017\n",
      "[48]\ttraining's l2: 0.371914\tvalid_1's l2: 0.353238\n",
      "[49]\ttraining's l2: 0.371058\tvalid_1's l2: 0.352509\n",
      "[50]\ttraining's l2: 0.369985\tvalid_1's l2: 0.351614\n",
      "[51]\ttraining's l2: 0.369108\tvalid_1's l2: 0.350876\n",
      "[52]\ttraining's l2: 0.368283\tvalid_1's l2: 0.350222\n",
      "[53]\ttraining's l2: 0.367676\tvalid_1's l2: 0.349737\n",
      "[54]\ttraining's l2: 0.366929\tvalid_1's l2: 0.349176\n",
      "[55]\ttraining's l2: 0.366235\tvalid_1's l2: 0.348592\n",
      "[56]\ttraining's l2: 0.365595\tvalid_1's l2: 0.348093\n",
      "[57]\ttraining's l2: 0.36501\tvalid_1's l2: 0.347593\n",
      "[58]\ttraining's l2: 0.364404\tvalid_1's l2: 0.347176\n",
      "[59]\ttraining's l2: 0.36389\tvalid_1's l2: 0.346731\n",
      "[60]\ttraining's l2: 0.363358\tvalid_1's l2: 0.34634\n",
      "[61]\ttraining's l2: 0.362915\tvalid_1's l2: 0.346064\n",
      "[62]\ttraining's l2: 0.362467\tvalid_1's l2: 0.345726\n",
      "[63]\ttraining's l2: 0.362002\tvalid_1's l2: 0.345415\n",
      "[64]\ttraining's l2: 0.361578\tvalid_1's l2: 0.345085\n",
      "[65]\ttraining's l2: 0.36115\tvalid_1's l2: 0.344808\n",
      "[66]\ttraining's l2: 0.360743\tvalid_1's l2: 0.344467\n",
      "[67]\ttraining's l2: 0.360319\tvalid_1's l2: 0.344137\n",
      "[68]\ttraining's l2: 0.360027\tvalid_1's l2: 0.343924\n",
      "[69]\ttraining's l2: 0.359676\tvalid_1's l2: 0.34362\n",
      "[70]\ttraining's l2: 0.359324\tvalid_1's l2: 0.343361\n",
      "[71]\ttraining's l2: 0.359007\tvalid_1's l2: 0.343106\n",
      "[72]\ttraining's l2: 0.358694\tvalid_1's l2: 0.342883\n",
      "[73]\ttraining's l2: 0.358282\tvalid_1's l2: 0.34257\n",
      "[74]\ttraining's l2: 0.357943\tvalid_1's l2: 0.342364\n",
      "[75]\ttraining's l2: 0.357685\tvalid_1's l2: 0.342213\n",
      "[76]\ttraining's l2: 0.357429\tvalid_1's l2: 0.342054\n",
      "[77]\ttraining's l2: 0.357158\tvalid_1's l2: 0.341934\n",
      "[78]\ttraining's l2: 0.35697\tvalid_1's l2: 0.341849\n",
      "[79]\ttraining's l2: 0.356795\tvalid_1's l2: 0.341729\n",
      "[80]\ttraining's l2: 0.356536\tvalid_1's l2: 0.341559\n",
      "[81]\ttraining's l2: 0.356306\tvalid_1's l2: 0.341436\n",
      "[82]\ttraining's l2: 0.35613\tvalid_1's l2: 0.341337\n",
      "[83]\ttraining's l2: 0.355943\tvalid_1's l2: 0.341203\n",
      "[84]\ttraining's l2: 0.355776\tvalid_1's l2: 0.341099\n",
      "[85]\ttraining's l2: 0.355579\tvalid_1's l2: 0.340956\n",
      "[86]\ttraining's l2: 0.355384\tvalid_1's l2: 0.34085\n",
      "[87]\ttraining's l2: 0.355181\tvalid_1's l2: 0.340668\n",
      "[88]\ttraining's l2: 0.354973\tvalid_1's l2: 0.340476\n",
      "[89]\ttraining's l2: 0.354793\tvalid_1's l2: 0.340378\n",
      "[90]\ttraining's l2: 0.354656\tvalid_1's l2: 0.340325\n",
      "[91]\ttraining's l2: 0.354531\tvalid_1's l2: 0.340251\n",
      "[92]\ttraining's l2: 0.354365\tvalid_1's l2: 0.340177\n",
      "[93]\ttraining's l2: 0.354231\tvalid_1's l2: 0.340117\n",
      "[94]\ttraining's l2: 0.353994\tvalid_1's l2: 0.339961\n",
      "[95]\ttraining's l2: 0.353725\tvalid_1's l2: 0.339766\n",
      "[96]\ttraining's l2: 0.353572\tvalid_1's l2: 0.339682\n",
      "[97]\ttraining's l2: 0.353425\tvalid_1's l2: 0.339591\n",
      "[98]\ttraining's l2: 0.353299\tvalid_1's l2: 0.339537\n",
      "[99]\ttraining's l2: 0.353197\tvalid_1's l2: 0.339459\n",
      "[100]\ttraining's l2: 0.353101\tvalid_1's l2: 0.339396\n",
      "[101]\ttraining's l2: 0.35289\tvalid_1's l2: 0.339254\n",
      "[102]\ttraining's l2: 0.352764\tvalid_1's l2: 0.339143\n",
      "[103]\ttraining's l2: 0.352566\tvalid_1's l2: 0.339016\n",
      "[104]\ttraining's l2: 0.352447\tvalid_1's l2: 0.338992\n",
      "[105]\ttraining's l2: 0.352334\tvalid_1's l2: 0.338955\n",
      "[106]\ttraining's l2: 0.352232\tvalid_1's l2: 0.338915\n",
      "[107]\ttraining's l2: 0.352054\tvalid_1's l2: 0.338778\n",
      "[108]\ttraining's l2: 0.351954\tvalid_1's l2: 0.338688\n",
      "[109]\ttraining's l2: 0.351809\tvalid_1's l2: 0.338632\n",
      "[110]\ttraining's l2: 0.351709\tvalid_1's l2: 0.338599\n",
      "[111]\ttraining's l2: 0.35162\tvalid_1's l2: 0.338585\n",
      "[112]\ttraining's l2: 0.351519\tvalid_1's l2: 0.338573\n",
      "[113]\ttraining's l2: 0.351411\tvalid_1's l2: 0.338522\n",
      "[114]\ttraining's l2: 0.351311\tvalid_1's l2: 0.338494\n",
      "[115]\ttraining's l2: 0.351178\tvalid_1's l2: 0.338397\n",
      "[116]\ttraining's l2: 0.351053\tvalid_1's l2: 0.338288\n",
      "[117]\ttraining's l2: 0.350957\tvalid_1's l2: 0.338243\n",
      "[118]\ttraining's l2: 0.350831\tvalid_1's l2: 0.338154\n",
      "[119]\ttraining's l2: 0.350681\tvalid_1's l2: 0.338044\n",
      "[120]\ttraining's l2: 0.350584\tvalid_1's l2: 0.338064\n",
      "[121]\ttraining's l2: 0.350496\tvalid_1's l2: 0.338023\n",
      "[122]\ttraining's l2: 0.350392\tvalid_1's l2: 0.337944\n",
      "[123]\ttraining's l2: 0.350311\tvalid_1's l2: 0.337909\n",
      "[124]\ttraining's l2: 0.350232\tvalid_1's l2: 0.337911\n",
      "[125]\ttraining's l2: 0.350171\tvalid_1's l2: 0.337884\n",
      "[126]\ttraining's l2: 0.350076\tvalid_1's l2: 0.337823\n",
      "[127]\ttraining's l2: 0.350001\tvalid_1's l2: 0.33781\n",
      "[128]\ttraining's l2: 0.349927\tvalid_1's l2: 0.337788\n",
      "[129]\ttraining's l2: 0.349812\tvalid_1's l2: 0.337681\n",
      "[130]\ttraining's l2: 0.349731\tvalid_1's l2: 0.337665\n",
      "[131]\ttraining's l2: 0.349642\tvalid_1's l2: 0.337595\n",
      "[132]\ttraining's l2: 0.349516\tvalid_1's l2: 0.337494\n",
      "[133]\ttraining's l2: 0.349435\tvalid_1's l2: 0.337454\n",
      "[134]\ttraining's l2: 0.349361\tvalid_1's l2: 0.337438\n",
      "[135]\ttraining's l2: 0.349286\tvalid_1's l2: 0.337404\n",
      "[136]\ttraining's l2: 0.34921\tvalid_1's l2: 0.337377\n",
      "[137]\ttraining's l2: 0.349088\tvalid_1's l2: 0.337269\n",
      "[138]\ttraining's l2: 0.349017\tvalid_1's l2: 0.337229\n",
      "[139]\ttraining's l2: 0.348961\tvalid_1's l2: 0.33721\n",
      "[140]\ttraining's l2: 0.348873\tvalid_1's l2: 0.337182\n",
      "[141]\ttraining's l2: 0.348821\tvalid_1's l2: 0.337174\n",
      "[142]\ttraining's l2: 0.348745\tvalid_1's l2: 0.337171\n",
      "[143]\ttraining's l2: 0.348682\tvalid_1's l2: 0.337151\n",
      "[144]\ttraining's l2: 0.348584\tvalid_1's l2: 0.337097\n",
      "[145]\ttraining's l2: 0.348525\tvalid_1's l2: 0.33707\n",
      "[146]\ttraining's l2: 0.348428\tvalid_1's l2: 0.33703\n",
      "[147]\ttraining's l2: 0.348348\tvalid_1's l2: 0.337018\n",
      "[148]\ttraining's l2: 0.348266\tvalid_1's l2: 0.336994\n",
      "[149]\ttraining's l2: 0.348161\tvalid_1's l2: 0.336947\n",
      "[150]\ttraining's l2: 0.348085\tvalid_1's l2: 0.336891\n",
      "[151]\ttraining's l2: 0.348034\tvalid_1's l2: 0.336869\n",
      "[152]\ttraining's l2: 0.347976\tvalid_1's l2: 0.336826\n",
      "[153]\ttraining's l2: 0.34791\tvalid_1's l2: 0.336833\n",
      "[154]\ttraining's l2: 0.347841\tvalid_1's l2: 0.336799\n",
      "[155]\ttraining's l2: 0.347773\tvalid_1's l2: 0.336793\n",
      "[156]\ttraining's l2: 0.347696\tvalid_1's l2: 0.336768\n",
      "[157]\ttraining's l2: 0.347643\tvalid_1's l2: 0.336781\n",
      "[158]\ttraining's l2: 0.347582\tvalid_1's l2: 0.336757\n",
      "[159]\ttraining's l2: 0.347523\tvalid_1's l2: 0.336753\n",
      "[160]\ttraining's l2: 0.347481\tvalid_1's l2: 0.336748\n",
      "[161]\ttraining's l2: 0.347416\tvalid_1's l2: 0.336711\n",
      "[162]\ttraining's l2: 0.347374\tvalid_1's l2: 0.336684\n",
      "[163]\ttraining's l2: 0.347331\tvalid_1's l2: 0.336682\n",
      "[164]\ttraining's l2: 0.347239\tvalid_1's l2: 0.336623\n",
      "[165]\ttraining's l2: 0.347177\tvalid_1's l2: 0.336596\n",
      "[166]\ttraining's l2: 0.34712\tvalid_1's l2: 0.336629\n",
      "[167]\ttraining's l2: 0.347073\tvalid_1's l2: 0.336617\n",
      "[168]\ttraining's l2: 0.347034\tvalid_1's l2: 0.336624\n",
      "[169]\ttraining's l2: 0.346972\tvalid_1's l2: 0.336609\n",
      "[170]\ttraining's l2: 0.346914\tvalid_1's l2: 0.336585\n",
      "[171]\ttraining's l2: 0.346866\tvalid_1's l2: 0.336566\n",
      "[172]\ttraining's l2: 0.346813\tvalid_1's l2: 0.336555\n",
      "[173]\ttraining's l2: 0.346771\tvalid_1's l2: 0.336552\n",
      "[174]\ttraining's l2: 0.346717\tvalid_1's l2: 0.336517\n",
      "[175]\ttraining's l2: 0.346681\tvalid_1's l2: 0.336496\n",
      "[176]\ttraining's l2: 0.346631\tvalid_1's l2: 0.336502\n",
      "[177]\ttraining's l2: 0.34658\tvalid_1's l2: 0.336508\n",
      "[178]\ttraining's l2: 0.346542\tvalid_1's l2: 0.336508\n",
      "[179]\ttraining's l2: 0.3465\tvalid_1's l2: 0.336481\n",
      "[180]\ttraining's l2: 0.346448\tvalid_1's l2: 0.336485\n",
      "[181]\ttraining's l2: 0.346412\tvalid_1's l2: 0.336468\n",
      "[182]\ttraining's l2: 0.346376\tvalid_1's l2: 0.336457\n",
      "[183]\ttraining's l2: 0.34629\tvalid_1's l2: 0.33638\n",
      "[184]\ttraining's l2: 0.346232\tvalid_1's l2: 0.33638\n",
      "[185]\ttraining's l2: 0.346182\tvalid_1's l2: 0.336387\n",
      "[186]\ttraining's l2: 0.346141\tvalid_1's l2: 0.336394\n",
      "[187]\ttraining's l2: 0.346085\tvalid_1's l2: 0.336383\n",
      "[188]\ttraining's l2: 0.346028\tvalid_1's l2: 0.336359\n",
      "[189]\ttraining's l2: 0.34599\tvalid_1's l2: 0.33636\n",
      "[190]\ttraining's l2: 0.345936\tvalid_1's l2: 0.336342\n",
      "[191]\ttraining's l2: 0.345888\tvalid_1's l2: 0.336309\n",
      "[192]\ttraining's l2: 0.345848\tvalid_1's l2: 0.336327\n",
      "[193]\ttraining's l2: 0.345799\tvalid_1's l2: 0.336305\n",
      "[194]\ttraining's l2: 0.345745\tvalid_1's l2: 0.336278\n",
      "[195]\ttraining's l2: 0.345708\tvalid_1's l2: 0.336278\n",
      "[196]\ttraining's l2: 0.345661\tvalid_1's l2: 0.336266\n",
      "[197]\ttraining's l2: 0.345626\tvalid_1's l2: 0.336256\n",
      "[198]\ttraining's l2: 0.345565\tvalid_1's l2: 0.336207\n",
      "[199]\ttraining's l2: 0.345519\tvalid_1's l2: 0.336189\n",
      "[200]\ttraining's l2: 0.345483\tvalid_1's l2: 0.336186\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.345483\tvalid_1's l2: 0.336186\n",
      "mean_21_sales: 8679828.53\n",
      "mean_14_sales: 4579836.04\n",
      "mean_30_sales: 3608879.41\n",
      "mean_7_sales: 2523479.11\n",
      "mean_20_dow0_2017: 2005386.00\n",
      "promo_14: 1368968.66\n",
      "mean_63_sales: 970313.20\n",
      "item_class_features: 346400.80\n",
      "mean_4_dow0_2017: 288215.58\n",
      "mean_60_sales: 210374.22\n",
      "mean_3_sales: 147774.53\n",
      "item_family_features: 112166.15\n",
      "promo_13: 111065.32\n",
      "sum_7_promo: 91675.40\n",
      "std_30_sales: 81397.10\n",
      "lag_1_sales: 78427.43\n",
      "promo_7: 75703.59\n",
      "promo_0: 70174.95\n",
      "mean_6_sales: 63079.27\n",
      "store_cluster_features: 60658.32\n",
      "sum_14_promo: 58726.41\n",
      "mean_5_sales: 55734.06\n",
      "std_21_sales: 53997.08\n",
      "std_63_sales: 44969.03\n",
      "lag_2_sales: 43727.78\n",
      "sum_21_promo: 34519.43\n",
      "lag_14_sales: 29391.57\n",
      "promo_12: 28706.04\n",
      "std_60_sales: 26856.25\n",
      "lag_49_sales: 24915.82\n",
      "promo_10: 23310.65\n",
      "lag_42_sales: 21158.08\n",
      "promo_15: 19920.23\n",
      "mean_4_sales: 19055.98\n",
      "mean_20_dow2_2017: 17519.89\n",
      "mean_20_dow1_2017: 17440.12\n",
      "std_14_sales: 16833.63\n",
      "lag_14_transactions: 16437.36\n",
      "store_type_features: 15781.14\n",
      "lag_1_transactions: 14898.12\n",
      "mean_20_dow3_2017: 14791.99\n",
      "lag_3_transactions: 13215.36\n",
      "lag_21_transactions: 11883.77\n",
      "std_7_sales: 11369.79\n",
      "store_city_features: 10818.09\n",
      "promo_9: 10463.49\n",
      "sum_2_promo: 8796.44\n",
      "sum_5_promo: 8220.77\n",
      "promo_11: 7928.73\n",
      "mean_20_dow6_2017: 7586.20\n",
      "lag_2_transactions: 6380.47\n",
      "mean_20_dow5_2017: 5426.29\n",
      "sum_4_promo: 5319.02\n",
      "lag_4_transactions: 4977.24\n",
      "lag_7_transactions: 4961.04\n",
      "mean_4_dow6_2017: 3852.45\n",
      "lag_5_transactions: 3558.19\n",
      "promo_6: 3178.85\n",
      "store_state_features: 2987.78\n",
      "lag_6_transactions: 2912.25\n",
      "lag_7_sales: 2897.60\n",
      "mean_20_dow4_2017: 2616.58\n",
      "lag_21_sales: 2476.76\n",
      "lag_28_sales: 2441.81\n",
      "promo_8: 2280.05\n",
      "lag_35_sales: 2160.88\n",
      "sum_6_promo: 1794.19\n",
      "lag_56_sales: 1779.12\n",
      "sum_3_promo: 1732.43\n",
      "mean_4_dow4_2017: 1556.98\n",
      "mean_4_dow5_2017: 1542.35\n",
      "mean_4_dow2_2017: 1295.70\n",
      "lag_63_sales: 1237.32\n",
      "promo_2: 1218.38\n",
      "lag_4_sales: 812.58\n",
      "mean_4_dow3_2017: 793.14\n",
      "std_4_sales: 735.64\n",
      "lag_5_sales: 712.48\n",
      "mean_4_dow1_2017: 576.40\n",
      "lag_3_sales: 418.94\n",
      "lag_6_sales: 410.94\n",
      "promo_5: 275.06\n",
      "promo_3: 254.81\n",
      "std_3_sales: 212.29\n",
      "std_6_sales: 185.58\n",
      "promo_1: 145.04\n",
      "std_5_sales: 133.78\n",
      "promo_4: 97.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [25:01<01:40, 100.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.955334\tvalid_1's l2: 0.937427\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.901319\tvalid_1's l2: 0.883671\n",
      "[3]\ttraining's l2: 0.852431\tvalid_1's l2: 0.835249\n",
      "[4]\ttraining's l2: 0.808292\tvalid_1's l2: 0.791357\n",
      "[5]\ttraining's l2: 0.768349\tvalid_1's l2: 0.751722\n",
      "[6]\ttraining's l2: 0.733286\tvalid_1's l2: 0.716865\n",
      "[7]\ttraining's l2: 0.7004\tvalid_1's l2: 0.684522\n",
      "[8]\ttraining's l2: 0.67073\tvalid_1's l2: 0.655358\n",
      "[9]\ttraining's l2: 0.643739\tvalid_1's l2: 0.628642\n",
      "[10]\ttraining's l2: 0.619304\tvalid_1's l2: 0.604571\n",
      "[11]\ttraining's l2: 0.597249\tvalid_1's l2: 0.582756\n",
      "[12]\ttraining's l2: 0.57731\tvalid_1's l2: 0.563142\n",
      "[13]\ttraining's l2: 0.55916\tvalid_1's l2: 0.545354\n",
      "[14]\ttraining's l2: 0.542764\tvalid_1's l2: 0.52915\n",
      "[15]\ttraining's l2: 0.527899\tvalid_1's l2: 0.514536\n",
      "[16]\ttraining's l2: 0.51437\tvalid_1's l2: 0.501214\n",
      "[17]\ttraining's l2: 0.502513\tvalid_1's l2: 0.489462\n",
      "[18]\ttraining's l2: 0.491401\tvalid_1's l2: 0.478553\n",
      "[19]\ttraining's l2: 0.481524\tvalid_1's l2: 0.468851\n",
      "[20]\ttraining's l2: 0.472249\tvalid_1's l2: 0.459838\n",
      "[21]\ttraining's l2: 0.463886\tvalid_1's l2: 0.451672\n",
      "[22]\ttraining's l2: 0.45632\tvalid_1's l2: 0.444217\n",
      "[23]\ttraining's l2: 0.449614\tvalid_1's l2: 0.437644\n",
      "[24]\ttraining's l2: 0.443446\tvalid_1's l2: 0.431611\n",
      "[25]\ttraining's l2: 0.437691\tvalid_1's l2: 0.426075\n",
      "[26]\ttraining's l2: 0.432586\tvalid_1's l2: 0.421116\n",
      "[27]\ttraining's l2: 0.428051\tvalid_1's l2: 0.416661\n",
      "[28]\ttraining's l2: 0.42363\tvalid_1's l2: 0.412392\n",
      "[29]\ttraining's l2: 0.419751\tvalid_1's l2: 0.408623\n",
      "[30]\ttraining's l2: 0.416059\tvalid_1's l2: 0.405066\n",
      "[31]\ttraining's l2: 0.412788\tvalid_1's l2: 0.401935\n",
      "[32]\ttraining's l2: 0.409702\tvalid_1's l2: 0.398995\n",
      "[33]\ttraining's l2: 0.406916\tvalid_1's l2: 0.396294\n",
      "[34]\ttraining's l2: 0.404356\tvalid_1's l2: 0.393864\n",
      "[35]\ttraining's l2: 0.402008\tvalid_1's l2: 0.391672\n",
      "[36]\ttraining's l2: 0.399866\tvalid_1's l2: 0.389566\n",
      "[37]\ttraining's l2: 0.397883\tvalid_1's l2: 0.387733\n",
      "[38]\ttraining's l2: 0.396093\tvalid_1's l2: 0.386037\n",
      "[39]\ttraining's l2: 0.394428\tvalid_1's l2: 0.384477\n",
      "[40]\ttraining's l2: 0.392921\tvalid_1's l2: 0.383028\n",
      "[41]\ttraining's l2: 0.391528\tvalid_1's l2: 0.38169\n",
      "[42]\ttraining's l2: 0.390238\tvalid_1's l2: 0.380519\n",
      "[43]\ttraining's l2: 0.389049\tvalid_1's l2: 0.379375\n",
      "[44]\ttraining's l2: 0.387985\tvalid_1's l2: 0.378373\n",
      "[45]\ttraining's l2: 0.386935\tvalid_1's l2: 0.377403\n",
      "[46]\ttraining's l2: 0.385965\tvalid_1's l2: 0.376523\n",
      "[47]\ttraining's l2: 0.385048\tvalid_1's l2: 0.37574\n",
      "[48]\ttraining's l2: 0.384203\tvalid_1's l2: 0.375006\n",
      "[49]\ttraining's l2: 0.383442\tvalid_1's l2: 0.3743\n",
      "[50]\ttraining's l2: 0.382735\tvalid_1's l2: 0.373659\n",
      "[51]\ttraining's l2: 0.382006\tvalid_1's l2: 0.373005\n",
      "[52]\ttraining's l2: 0.38135\tvalid_1's l2: 0.372496\n",
      "[53]\ttraining's l2: 0.380785\tvalid_1's l2: 0.371956\n",
      "[54]\ttraining's l2: 0.380222\tvalid_1's l2: 0.371478\n",
      "[55]\ttraining's l2: 0.379712\tvalid_1's l2: 0.371014\n",
      "[56]\ttraining's l2: 0.379192\tvalid_1's l2: 0.370595\n",
      "[57]\ttraining's l2: 0.378753\tvalid_1's l2: 0.370212\n",
      "[58]\ttraining's l2: 0.378322\tvalid_1's l2: 0.369836\n",
      "[59]\ttraining's l2: 0.377918\tvalid_1's l2: 0.369495\n",
      "[60]\ttraining's l2: 0.377452\tvalid_1's l2: 0.369105\n",
      "[61]\ttraining's l2: 0.377066\tvalid_1's l2: 0.368792\n",
      "[62]\ttraining's l2: 0.376679\tvalid_1's l2: 0.368494\n",
      "[63]\ttraining's l2: 0.376347\tvalid_1's l2: 0.368229\n",
      "[64]\ttraining's l2: 0.376024\tvalid_1's l2: 0.36798\n",
      "[65]\ttraining's l2: 0.375733\tvalid_1's l2: 0.367746\n",
      "[66]\ttraining's l2: 0.375451\tvalid_1's l2: 0.367525\n",
      "[67]\ttraining's l2: 0.375121\tvalid_1's l2: 0.36728\n",
      "[68]\ttraining's l2: 0.37485\tvalid_1's l2: 0.367035\n",
      "[69]\ttraining's l2: 0.374577\tvalid_1's l2: 0.366808\n",
      "[70]\ttraining's l2: 0.374334\tvalid_1's l2: 0.36664\n",
      "[71]\ttraining's l2: 0.374074\tvalid_1's l2: 0.366438\n",
      "[72]\ttraining's l2: 0.373841\tvalid_1's l2: 0.366237\n",
      "[73]\ttraining's l2: 0.373567\tvalid_1's l2: 0.366049\n",
      "[74]\ttraining's l2: 0.37329\tvalid_1's l2: 0.36583\n",
      "[75]\ttraining's l2: 0.37305\tvalid_1's l2: 0.365659\n",
      "[76]\ttraining's l2: 0.372779\tvalid_1's l2: 0.365472\n",
      "[77]\ttraining's l2: 0.372565\tvalid_1's l2: 0.365352\n",
      "[78]\ttraining's l2: 0.372367\tvalid_1's l2: 0.365225\n",
      "[79]\ttraining's l2: 0.37221\tvalid_1's l2: 0.365078\n",
      "[80]\ttraining's l2: 0.372025\tvalid_1's l2: 0.364932\n",
      "[81]\ttraining's l2: 0.371795\tvalid_1's l2: 0.364773\n",
      "[82]\ttraining's l2: 0.371653\tvalid_1's l2: 0.364672\n",
      "[83]\ttraining's l2: 0.371468\tvalid_1's l2: 0.364506\n",
      "[84]\ttraining's l2: 0.371294\tvalid_1's l2: 0.364366\n",
      "[85]\ttraining's l2: 0.371136\tvalid_1's l2: 0.364285\n",
      "[86]\ttraining's l2: 0.370946\tvalid_1's l2: 0.364156\n",
      "[87]\ttraining's l2: 0.370772\tvalid_1's l2: 0.364008\n",
      "[88]\ttraining's l2: 0.370644\tvalid_1's l2: 0.363909\n",
      "[89]\ttraining's l2: 0.370485\tvalid_1's l2: 0.363805\n",
      "[90]\ttraining's l2: 0.370355\tvalid_1's l2: 0.363739\n",
      "[91]\ttraining's l2: 0.370218\tvalid_1's l2: 0.363622\n",
      "[92]\ttraining's l2: 0.370069\tvalid_1's l2: 0.363515\n",
      "[93]\ttraining's l2: 0.369934\tvalid_1's l2: 0.363393\n",
      "[94]\ttraining's l2: 0.369787\tvalid_1's l2: 0.36331\n",
      "[95]\ttraining's l2: 0.369668\tvalid_1's l2: 0.363217\n",
      "[96]\ttraining's l2: 0.369543\tvalid_1's l2: 0.363135\n",
      "[97]\ttraining's l2: 0.369378\tvalid_1's l2: 0.363029\n",
      "[98]\ttraining's l2: 0.369258\tvalid_1's l2: 0.36298\n",
      "[99]\ttraining's l2: 0.369121\tvalid_1's l2: 0.362902\n",
      "[100]\ttraining's l2: 0.36899\tvalid_1's l2: 0.362923\n",
      "[101]\ttraining's l2: 0.368857\tvalid_1's l2: 0.362841\n",
      "[102]\ttraining's l2: 0.368727\tvalid_1's l2: 0.362776\n",
      "[103]\ttraining's l2: 0.368596\tvalid_1's l2: 0.362692\n",
      "[104]\ttraining's l2: 0.368477\tvalid_1's l2: 0.362618\n",
      "[105]\ttraining's l2: 0.368271\tvalid_1's l2: 0.362473\n",
      "[106]\ttraining's l2: 0.368163\tvalid_1's l2: 0.362417\n",
      "[107]\ttraining's l2: 0.368063\tvalid_1's l2: 0.362305\n",
      "[108]\ttraining's l2: 0.367953\tvalid_1's l2: 0.362244\n",
      "[109]\ttraining's l2: 0.36784\tvalid_1's l2: 0.362208\n",
      "[110]\ttraining's l2: 0.367715\tvalid_1's l2: 0.362145\n",
      "[111]\ttraining's l2: 0.367594\tvalid_1's l2: 0.362064\n",
      "[112]\ttraining's l2: 0.367506\tvalid_1's l2: 0.36203\n",
      "[113]\ttraining's l2: 0.367416\tvalid_1's l2: 0.361962\n",
      "[114]\ttraining's l2: 0.367319\tvalid_1's l2: 0.361906\n",
      "[115]\ttraining's l2: 0.367164\tvalid_1's l2: 0.361803\n",
      "[116]\ttraining's l2: 0.36708\tvalid_1's l2: 0.361756\n",
      "[117]\ttraining's l2: 0.367\tvalid_1's l2: 0.3617\n",
      "[118]\ttraining's l2: 0.366924\tvalid_1's l2: 0.361656\n",
      "[119]\ttraining's l2: 0.366826\tvalid_1's l2: 0.361634\n",
      "[120]\ttraining's l2: 0.366747\tvalid_1's l2: 0.361667\n",
      "[121]\ttraining's l2: 0.366687\tvalid_1's l2: 0.361635\n",
      "[122]\ttraining's l2: 0.366566\tvalid_1's l2: 0.361554\n",
      "[123]\ttraining's l2: 0.366487\tvalid_1's l2: 0.361539\n",
      "[124]\ttraining's l2: 0.366394\tvalid_1's l2: 0.3615\n",
      "[125]\ttraining's l2: 0.366325\tvalid_1's l2: 0.361474\n",
      "[126]\ttraining's l2: 0.366183\tvalid_1's l2: 0.361364\n",
      "[127]\ttraining's l2: 0.36612\tvalid_1's l2: 0.361344\n",
      "[128]\ttraining's l2: 0.366052\tvalid_1's l2: 0.361324\n",
      "[129]\ttraining's l2: 0.365984\tvalid_1's l2: 0.361291\n",
      "[130]\ttraining's l2: 0.365896\tvalid_1's l2: 0.361282\n",
      "[131]\ttraining's l2: 0.365844\tvalid_1's l2: 0.361266\n",
      "[132]\ttraining's l2: 0.365763\tvalid_1's l2: 0.361271\n",
      "[133]\ttraining's l2: 0.365634\tvalid_1's l2: 0.361192\n",
      "[134]\ttraining's l2: 0.365505\tvalid_1's l2: 0.361098\n",
      "[135]\ttraining's l2: 0.365451\tvalid_1's l2: 0.361073\n",
      "[136]\ttraining's l2: 0.365321\tvalid_1's l2: 0.360993\n",
      "[137]\ttraining's l2: 0.365229\tvalid_1's l2: 0.360955\n",
      "[138]\ttraining's l2: 0.36516\tvalid_1's l2: 0.360935\n",
      "[139]\ttraining's l2: 0.365112\tvalid_1's l2: 0.360935\n",
      "[140]\ttraining's l2: 0.365061\tvalid_1's l2: 0.360914\n",
      "[141]\ttraining's l2: 0.36498\tvalid_1's l2: 0.360874\n",
      "[142]\ttraining's l2: 0.364909\tvalid_1's l2: 0.360867\n",
      "[143]\ttraining's l2: 0.364839\tvalid_1's l2: 0.360856\n",
      "[144]\ttraining's l2: 0.364788\tvalid_1's l2: 0.360845\n",
      "[145]\ttraining's l2: 0.364723\tvalid_1's l2: 0.360922\n",
      "[146]\ttraining's l2: 0.364612\tvalid_1's l2: 0.360825\n",
      "[147]\ttraining's l2: 0.364562\tvalid_1's l2: 0.360824\n",
      "[148]\ttraining's l2: 0.364452\tvalid_1's l2: 0.360769\n",
      "[149]\ttraining's l2: 0.3644\tvalid_1's l2: 0.360811\n",
      "[150]\ttraining's l2: 0.364358\tvalid_1's l2: 0.360807\n",
      "[151]\ttraining's l2: 0.364303\tvalid_1's l2: 0.360872\n",
      "[152]\ttraining's l2: 0.364256\tvalid_1's l2: 0.360847\n",
      "[153]\ttraining's l2: 0.364188\tvalid_1's l2: 0.360816\n",
      "[154]\ttraining's l2: 0.364097\tvalid_1's l2: 0.360755\n",
      "[155]\ttraining's l2: 0.364022\tvalid_1's l2: 0.360749\n",
      "[156]\ttraining's l2: 0.363939\tvalid_1's l2: 0.360693\n",
      "[157]\ttraining's l2: 0.363861\tvalid_1's l2: 0.360682\n",
      "[158]\ttraining's l2: 0.363777\tvalid_1's l2: 0.360634\n",
      "[159]\ttraining's l2: 0.363723\tvalid_1's l2: 0.360667\n",
      "[160]\ttraining's l2: 0.363675\tvalid_1's l2: 0.360663\n",
      "[161]\ttraining's l2: 0.363613\tvalid_1's l2: 0.360647\n",
      "[162]\ttraining's l2: 0.363569\tvalid_1's l2: 0.360649\n",
      "[163]\ttraining's l2: 0.363535\tvalid_1's l2: 0.360634\n",
      "[164]\ttraining's l2: 0.363492\tvalid_1's l2: 0.360628\n",
      "[165]\ttraining's l2: 0.363428\tvalid_1's l2: 0.360594\n",
      "[166]\ttraining's l2: 0.363366\tvalid_1's l2: 0.360595\n",
      "[167]\ttraining's l2: 0.363321\tvalid_1's l2: 0.360596\n",
      "[168]\ttraining's l2: 0.363266\tvalid_1's l2: 0.360696\n",
      "[169]\ttraining's l2: 0.363225\tvalid_1's l2: 0.360664\n",
      "[170]\ttraining's l2: 0.363135\tvalid_1's l2: 0.360628\n",
      "[171]\ttraining's l2: 0.363073\tvalid_1's l2: 0.360642\n",
      "[172]\ttraining's l2: 0.36302\tvalid_1's l2: 0.360625\n",
      "[173]\ttraining's l2: 0.36299\tvalid_1's l2: 0.360622\n",
      "[174]\ttraining's l2: 0.362874\tvalid_1's l2: 0.360562\n",
      "[175]\ttraining's l2: 0.362844\tvalid_1's l2: 0.360542\n",
      "[176]\ttraining's l2: 0.362818\tvalid_1's l2: 0.360533\n",
      "[177]\ttraining's l2: 0.362771\tvalid_1's l2: 0.360531\n",
      "[178]\ttraining's l2: 0.362723\tvalid_1's l2: 0.360546\n",
      "[179]\ttraining's l2: 0.36269\tvalid_1's l2: 0.360557\n",
      "[180]\ttraining's l2: 0.362622\tvalid_1's l2: 0.360535\n",
      "[181]\ttraining's l2: 0.362577\tvalid_1's l2: 0.360465\n",
      "[182]\ttraining's l2: 0.362544\tvalid_1's l2: 0.360497\n",
      "[183]\ttraining's l2: 0.362514\tvalid_1's l2: 0.360488\n",
      "[184]\ttraining's l2: 0.36244\tvalid_1's l2: 0.360457\n",
      "[185]\ttraining's l2: 0.362407\tvalid_1's l2: 0.36046\n",
      "[186]\ttraining's l2: 0.362372\tvalid_1's l2: 0.360442\n",
      "[187]\ttraining's l2: 0.362337\tvalid_1's l2: 0.360428\n",
      "[188]\ttraining's l2: 0.362302\tvalid_1's l2: 0.360415\n",
      "[189]\ttraining's l2: 0.362259\tvalid_1's l2: 0.360406\n",
      "[190]\ttraining's l2: 0.362221\tvalid_1's l2: 0.360407\n",
      "[191]\ttraining's l2: 0.36219\tvalid_1's l2: 0.360414\n",
      "[192]\ttraining's l2: 0.362153\tvalid_1's l2: 0.360477\n",
      "[193]\ttraining's l2: 0.362113\tvalid_1's l2: 0.360463\n",
      "[194]\ttraining's l2: 0.362085\tvalid_1's l2: 0.360456\n",
      "[195]\ttraining's l2: 0.362041\tvalid_1's l2: 0.360405\n",
      "[196]\ttraining's l2: 0.362018\tvalid_1's l2: 0.360407\n",
      "[197]\ttraining's l2: 0.361971\tvalid_1's l2: 0.360387\n",
      "[198]\ttraining's l2: 0.361857\tvalid_1's l2: 0.360319\n",
      "[199]\ttraining's l2: 0.361811\tvalid_1's l2: 0.360301\n",
      "[200]\ttraining's l2: 0.361759\tvalid_1's l2: 0.360269\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.361759\tvalid_1's l2: 0.360269\n",
      "mean_21_sales: 6494509.60\n",
      "mean_30_sales: 5407912.86\n",
      "mean_14_sales: 3120048.46\n",
      "mean_63_sales: 1297528.98\n",
      "mean_20_dow1_2017: 1030411.61\n",
      "mean_7_sales: 947886.66\n",
      "mean_60_sales: 925051.06\n",
      "promo_15: 866821.09\n",
      "mean_6_sales: 425762.43\n",
      "item_class_features: 321484.22\n",
      "lag_1_sales: 105388.54\n",
      "promo_14: 90127.68\n",
      "mean_20_dow2_2017: 59189.65\n",
      "std_30_sales: 53572.87\n",
      "mean_4_dow1_2017: 51842.20\n",
      "std_21_sales: 44259.00\n",
      "std_63_sales: 39451.11\n",
      "sum_4_promo: 38004.01\n",
      "item_family_features: 35524.56\n",
      "mean_5_sales: 28852.36\n",
      "mean_3_sales: 24657.48\n",
      "lag_1_transactions: 21549.49\n",
      "std_14_sales: 20352.71\n",
      "promo_13: 19975.18\n",
      "std_60_sales: 19547.94\n",
      "sum_2_promo: 19220.81\n",
      "sum_14_promo: 18010.79\n",
      "lag_14_transactions: 17498.49\n",
      "mean_20_dow6_2017: 16700.93\n",
      "sum_6_promo: 16138.67\n",
      "promo_10: 15255.53\n",
      "sum_21_promo: 13013.02\n",
      "lag_3_transactions: 12376.66\n",
      "mean_4_sales: 12277.08\n",
      "sum_7_promo: 10924.87\n",
      "mean_20_dow0_2017: 10828.43\n",
      "promo_12: 10641.37\n",
      "promo_8: 10169.51\n",
      "lag_14_sales: 10131.62\n",
      "lag_2_sales: 9992.81\n",
      "lag_21_transactions: 9930.28\n",
      "store_city_features: 9424.39\n",
      "lag_42_sales: 7971.96\n",
      "lag_7_transactions: 7570.30\n",
      "lag_49_sales: 7370.59\n",
      "mean_4_dow6_2017: 6586.29\n",
      "store_cluster_features: 6238.51\n",
      "promo_9: 6185.44\n",
      "sum_3_promo: 5977.53\n",
      "std_6_sales: 5685.05\n",
      "lag_4_transactions: 5502.97\n",
      "std_7_sales: 4959.36\n",
      "mean_20_dow3_2017: 4951.27\n",
      "promo_7: 4410.88\n",
      "lag_2_transactions: 4030.96\n",
      "sum_5_promo: 3718.75\n",
      "lag_6_transactions: 3540.72\n",
      "promo_0: 3315.29\n",
      "mean_20_dow4_2017: 3308.37\n",
      "lag_5_transactions: 3226.97\n",
      "lag_5_sales: 3209.48\n",
      "mean_4_dow0_2017: 2839.52\n",
      "store_state_features: 2832.29\n",
      "lag_6_sales: 2504.17\n",
      "mean_4_dow3_2017: 2237.31\n",
      "promo_11: 2189.61\n",
      "std_5_sales: 2094.94\n",
      "lag_4_sales: 2047.35\n",
      "mean_4_dow2_2017: 2004.18\n",
      "mean_20_dow5_2017: 1884.89\n",
      "mean_4_dow4_2017: 1718.24\n",
      "lag_28_sales: 1556.39\n",
      "std_4_sales: 1435.67\n",
      "mean_4_dow5_2017: 1303.15\n",
      "lag_63_sales: 1110.21\n",
      "lag_21_sales: 1109.95\n",
      "lag_7_sales: 1108.27\n",
      "promo_6: 1052.72\n",
      "store_type_features: 876.09\n",
      "lag_3_sales: 871.76\n",
      "lag_56_sales: 861.50\n",
      "lag_35_sales: 536.69\n",
      "promo_1: 447.33\n",
      "promo_3: 335.75\n",
      "promo_5: 198.28\n",
      "promo_4: 115.75\n",
      "promo_2: 56.91\n",
      "std_3_sales: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [26:37<00:00, 98.86s/it] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(16)):\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * nbr_weeks) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "\n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=MAX_ROUNDS,\n",
    "#         verbose_eval = False,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50)\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34995690601359186"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_train.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0913978494623656"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "153/1674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 0.34995690601359186\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "\n",
    "mlflow.set_experiment('grocery forecasting')\n",
    "with mlflow.start_run(run_name='lgbm'):\n",
    "    mlflow.log_param('model', 'lgbm')\n",
    "    mlflow.log_param('train starts', train_start)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param('lagging', LAG_DICT.values())\n",
    "    mlflow.log_param('slidingWindows', SLIDING_DICT.values())\n",
    "    mlflow.log_param('item_info', 'Yes')\n",
    "    mlflow.log_param('store_info', 'Yes')\n",
    "    mlflow.log_param('transactions', 'Yes')\n",
    "    mlflow.log_param('private score', 0.52153)\n",
    "    mlflow.log_param('private rank', '12%')\n",
    "    mlflow.log_param('public score', 0.51516)\n",
    "\n",
    "    mlflow.log_metric('mse', mse)\n",
    "    \n",
    "print(\"Validation mse:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
