{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from config import (\n",
    "    RAW_DATA_DIR,\n",
    "    FEATURE_DIR,\n",
    "    LAG_DICT,\n",
    "    SLIDING_DICT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve lightgbm error on MAC\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv(\n",
    "    RAW_DATA_DIR+'train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    RAW_DATA_DIR+'test.csv', usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    RAW_DATA_DIR+'items.csv',\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    RAW_DATA_DIR+'stores.csv',\n",
    ").set_index(\"store_nbr\")\n",
    "\n",
    "transactions_df = pd.read_csv(\n",
    "    RAW_DATA_DIR+'transactions.csv'\n",
    ")\n",
    "\n",
    "transactions_df = pd.read_csv(\n",
    "    RAW_DATA_DIR+'transactions.csv'\n",
    ")\n",
    "\n",
    "oil_df = pd.read_csv(\n",
    "    RAW_DATA_DIR+'oil.csv',\n",
    "    parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Period\n",
    "\n",
    "2017-08-16 to 2017-08-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = date(2017, 8, 16)\n",
    "test_end = date(2017,8, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid starts from 2017-07-26 to 2017-08-10\n"
     ]
    }
   ],
   "source": [
    "valid_start = test_start - timedelta(16)\n",
    "while(1):\n",
    "    if valid_start.weekday() == test_start.weekday():\n",
    "        break\n",
    "    valid_start = valid_start-timedelta(days=1)\n",
    "valid_end = valid_start + timedelta(15)\n",
    "print('valid starts from {} to {}'.format(valid_start, valid_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Period\n",
    "\n",
    "Considering the more nearer peiods of sales data may have more in common, it would be better to find the nearest period as valid period.\n",
    "\n",
    "Based on the analysis before, we assume the sales data is periodically with the frequency of 7 days, so we want to keep that feature same\n",
    "in the train, valid and test period.\n",
    "\n",
    "So finally, we choose valid period:\n",
    "\n",
    "2017-07-26 to 2017-08-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_start = date(2017, 7, 26)\n",
    "valid_end = date(2017, 8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Period\n",
    "\n",
    "#### Earthquake happended on April 16, 2016. It may affect for the next several weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train datasets starts from 2016-10-05\n"
     ]
    }
   ],
   "source": [
    "# filter the period which is affected by earthquake.\n",
    "filter_date = date(2016,4,16) + timedelta(7*4)\n",
    "lag_max = 140\n",
    "train_start=  filter_date+timedelta(days=lag_max)\n",
    "\n",
    "while(1):\n",
    "    train_start = train_start + timedelta(1)\n",
    "    if train_start.weekday() == valid_start.weekday():\n",
    "        break\n",
    "print('train datasets starts from {}'.format(train_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = date(2017,2,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train[df_train['date']>=filter_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_train = df_train.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]]\n",
    "\n",
    "# missing onpromotions filling\n",
    "promo_train = promo_train.unstack(level=-1).fillna(False)\n",
    "promo_train.columns = promo_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing test onpromotions filling\n",
    "promo_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_test.columns = promo_test.columns.get_level_values(1)\n",
    "# filter those items/stores in promo_test but not in promo_train\n",
    "promo_test = promo_test.reindex(promo_train.index).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_features = pd.concat([promo_train, promo_test], axis=1)\n",
    "del promo_test, promo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\n",
    "    RAW_DATA_DIR+'transactions.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "df_train = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
    "# tmp = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
    "transactions_df = transactions_df.set_index([\"store_nbr\", \"date\"])[[\"transactions\"]].unstack(level=-1).fillna(0)\n",
    "transactions_df = transactions_df.reindex(df_train.index.get_level_values(0))\n",
    "transactions_df.columns = transactions_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = pd.read_csv(\n",
    "    RAW_DATA_DIR+'oil.csv',\n",
    "    parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = oil_df.fillna(oil_df.dcoilwtico.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            date      \n",
       "dcoilwtico  2013-01-01    67.714366\n",
       "            2013-01-02    93.140000\n",
       "            2013-01-03    92.970000\n",
       "            2013-01-04    93.120000\n",
       "            2013-01-07    93.200000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = oil_df.set_index([\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = oil_df.unstack(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = oil_df.set_index([\"date\"])[[\"dcoilwtico\"]].unstack(level=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            date      \n",
       "dcoilwtico  2013-01-01    67.714366\n",
       "            2013-01-02    93.140000\n",
       "            2013-01-03    92.970000\n",
       "            2013-01-04    93.120000\n",
       "            2013-01-07    93.200000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7a2d92935135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moil_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moil_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5061\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "oil_df.columns = oil_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # oil_df\n",
    "# oil_df = oil_df.reindex(df_train.index.get_level_values(0))\n",
    "# oil_df.columns = oil_df.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_train.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['family'] = items['family'].astype('category')\n",
    "item_family_features = items.family.cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['class'] = items['class'].astype('category')\n",
    "item_class_features = items['class'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = stores.reindex(df_train.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['city'] = stores['city'].astype('category')\n",
    "store_city_features = stores['city'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['state'] = stores['state'].astype('category')\n",
    "store_state_features = stores['state'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['type'] = stores['type'].astype('category')\n",
    "store_type_features = stores['type'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['cluster'] = stores['cluster'].astype('category')\n",
    "store_cluster_features = stores['cluster'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = df_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = df_train.columns\n",
    "obj_list = pd.date_range(filter_date, test_start-timedelta(1))\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    df_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = promo_features.columns\n",
    "obj_list = pd.date_range(filter_date, test_end)\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    promo_features[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagging and sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG_DICT = {'unit_sales': [1,2,3,4,5,6,7,14,21,28,35,42,49,56,63],\n",
    "            'onpromotion': [2, 3,4,5,6, 7, 14, 21],\n",
    "            'transactions': [1, 2, 3, 4, 5, 6, 7, 14, 21]}\n",
    "\n",
    "SLIDING_DICT = {'unit_sales': [3, 4, 5, 6, 7, 14, 21, 30, 60, 63]}\n",
    "\n",
    "\n",
    "\n",
    "# initialise dirs\n",
    "RAW_DATA_DIR = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, \n",
    "                 start_time,\n",
    "                 minus,\n",
    "                 periods,\n",
    "                 freq='D'):\n",
    "    return df[pd.date_range(start_time - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def gen_dataset(df,\n",
    "                promo_features,\n",
    "                item_family_features,\n",
    "                item_class_features,\n",
    "                store_city_features,\n",
    "                store_state_features,\n",
    "                store_type_features,\n",
    "                store_cluster_features,\n",
    "                transactions_df,\n",
    "                start_time,\n",
    "                is_train=True):\n",
    "    # init\n",
    "    X = pd.DataFrame()\n",
    "\n",
    "    for i in LAG_DICT['unit_sales']:\n",
    "        X['lag_{}_sales'.format(i)] = get_timespan(df, start_time, i, 1).values.ravel()\n",
    "    \n",
    "    for i in LAG_DICT['onpromotion']:\n",
    "        X['sum_{}_promo'.format(i)] = get_timespan(promo_features, start_time, i, 1).sum(axis=1).ravel()\n",
    "\n",
    "    for i in SLIDING_DICT['unit_sales']:\n",
    "        X[\"mean_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).mean(axis=1).values\n",
    "        X[\"std_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).std(axis=1).values\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, start_time, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, start_time, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "\n",
    "    for i in LAG_DICT['transactions']:\n",
    "        X['lag_{}_transactions'.format(i)] = get_timespan(transactions_df, start_time, i, 1).values.ravel()\n",
    "\n",
    "    # for the next to-predict 16 days \n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_features[start_time + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X['item_family_features'] = item_family_features\n",
    "\n",
    "    X['item_class_features'] = item_class_features\n",
    "\n",
    "    X['store_city_features'] = store_city_features\n",
    "\n",
    "    X['store_state_features'] = store_state_features\n",
    "\n",
    "    X['store_type_features'] = store_type_features\n",
    "\n",
    "    X['store_cluster_features'] = store_cluster_features\n",
    "        \n",
    "    if is_train:\n",
    "        y = df[pd.date_range(start_time, periods=16)].values\n",
    "        return X, y\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train, valid and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No. of week:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No. of week: 100%|██████████| 24/24 [00:21<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "\n",
    "nbr_weeks = int((valid_start - train_start).days/7)\n",
    "\n",
    "X_l, y_l = [], []\n",
    "\n",
    "for i in tqdm(range(nbr_weeks), desc = 'No. of week'):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = gen_dataset(\n",
    "        df_train,\n",
    "        promo_features,\n",
    "        item_family_features,\n",
    "        item_class_features,\n",
    "        store_city_features,\n",
    "        store_state_features,\n",
    "        store_type_features,\n",
    "        store_cluster_features,\n",
    "        transactions_df,\n",
    "        train_start + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gen_dataset() missing 1 required positional argument: 'start_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-ef6653d5ecd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                            \u001b[0mstore_type_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                            \u001b[0mstore_cluster_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                            valid_start)\n\u001b[0m\u001b[1;32m     10\u001b[0m X_test = gen_dataset(df_train, \n\u001b[1;32m     11\u001b[0m                     \u001b[0mpromo_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: gen_dataset() missing 1 required positional argument: 'start_time'"
     ]
    }
   ],
   "source": [
    "X_val, y_val = gen_dataset(df_train,\n",
    "                           promo_features,\n",
    "                           item_family_features,\n",
    "                           item_class_features,\n",
    "                           store_city_features,\n",
    "                           store_state_features,\n",
    "                           store_type_features,\n",
    "                           store_cluster_features,\n",
    "                           transactions_df,\n",
    "                           valid_start)\n",
    "X_test = gen_dataset(df_train, \n",
    "                    promo_features,\n",
    "                    item_family_features,\n",
    "                    item_class_features,\n",
    "                    store_city_features,\n",
    "                    store_state_features,\n",
    "                    store_type_features,\n",
    "                    store_cluster_features,\n",
    "                     transactions_df\n",
    "                    test_start, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 200\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = ['item_family_features',\n",
    "            'item_class_features',\n",
    "            'store_city_features',\n",
    "            'store_state_features',\n",
    "            'store_type_features',\n",
    "            'store_cluster_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.04938\tvalid_1's l2: 1.00423\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.981164\tvalid_1's l2: 0.938377\n",
      "[3]\ttraining's l2: 0.918131\tvalid_1's l2: 0.877528\n",
      "[4]\ttraining's l2: 0.862105\tvalid_1's l2: 0.823612\n",
      "[5]\ttraining's l2: 0.810182\tvalid_1's l2: 0.773513\n",
      "[6]\ttraining's l2: 0.763315\tvalid_1's l2: 0.728307\n",
      "[7]\ttraining's l2: 0.720817\tvalid_1's l2: 0.687407\n",
      "[8]\ttraining's l2: 0.68249\tvalid_1's l2: 0.650288\n",
      "[9]\ttraining's l2: 0.647824\tvalid_1's l2: 0.617082\n",
      "[10]\ttraining's l2: 0.616322\tvalid_1's l2: 0.586896\n",
      "[11]\ttraining's l2: 0.587809\tvalid_1's l2: 0.55955\n",
      "[12]\ttraining's l2: 0.562755\tvalid_1's l2: 0.535611\n",
      "[13]\ttraining's l2: 0.539936\tvalid_1's l2: 0.513771\n",
      "[14]\ttraining's l2: 0.518578\tvalid_1's l2: 0.49327\n",
      "[15]\ttraining's l2: 0.499246\tvalid_1's l2: 0.474779\n",
      "[16]\ttraining's l2: 0.481693\tvalid_1's l2: 0.458007\n",
      "[17]\ttraining's l2: 0.465802\tvalid_1's l2: 0.442843\n",
      "[18]\ttraining's l2: 0.451247\tvalid_1's l2: 0.428881\n",
      "[19]\ttraining's l2: 0.438209\tvalid_1's l2: 0.416379\n",
      "[20]\ttraining's l2: 0.426271\tvalid_1's l2: 0.405019\n",
      "[21]\ttraining's l2: 0.41544\tvalid_1's l2: 0.394747\n",
      "[22]\ttraining's l2: 0.405608\tvalid_1's l2: 0.385429\n",
      "[23]\ttraining's l2: 0.397022\tvalid_1's l2: 0.377365\n",
      "[24]\ttraining's l2: 0.388795\tvalid_1's l2: 0.36948\n",
      "[25]\ttraining's l2: 0.381454\tvalid_1's l2: 0.362609\n",
      "[26]\ttraining's l2: 0.374726\tvalid_1's l2: 0.356286\n",
      "[27]\ttraining's l2: 0.368838\tvalid_1's l2: 0.350805\n",
      "[28]\ttraining's l2: 0.363471\tvalid_1's l2: 0.345813\n",
      "[29]\ttraining's l2: 0.358226\tvalid_1's l2: 0.340882\n",
      "[30]\ttraining's l2: 0.353414\tvalid_1's l2: 0.336402\n",
      "[31]\ttraining's l2: 0.349023\tvalid_1's l2: 0.33231\n",
      "[32]\ttraining's l2: 0.344974\tvalid_1's l2: 0.328594\n",
      "[33]\ttraining's l2: 0.34162\tvalid_1's l2: 0.325533\n",
      "[34]\ttraining's l2: 0.3385\tvalid_1's l2: 0.322712\n",
      "[35]\ttraining's l2: 0.335431\tvalid_1's l2: 0.319805\n",
      "[36]\ttraining's l2: 0.332557\tvalid_1's l2: 0.317162\n",
      "[37]\ttraining's l2: 0.32991\tvalid_1's l2: 0.314717\n",
      "[38]\ttraining's l2: 0.327538\tvalid_1's l2: 0.312485\n",
      "[39]\ttraining's l2: 0.325327\tvalid_1's l2: 0.310475\n",
      "[40]\ttraining's l2: 0.323292\tvalid_1's l2: 0.308643\n",
      "[41]\ttraining's l2: 0.321603\tvalid_1's l2: 0.307169\n",
      "[42]\ttraining's l2: 0.319861\tvalid_1's l2: 0.305587\n",
      "[43]\ttraining's l2: 0.31846\tvalid_1's l2: 0.304334\n",
      "[44]\ttraining's l2: 0.317186\tvalid_1's l2: 0.303225\n",
      "[45]\ttraining's l2: 0.315827\tvalid_1's l2: 0.302015\n",
      "[46]\ttraining's l2: 0.314508\tvalid_1's l2: 0.300781\n",
      "[47]\ttraining's l2: 0.31332\tvalid_1's l2: 0.299666\n",
      "[48]\ttraining's l2: 0.312221\tvalid_1's l2: 0.298686\n",
      "[49]\ttraining's l2: 0.311204\tvalid_1's l2: 0.297793\n",
      "[50]\ttraining's l2: 0.310464\tvalid_1's l2: 0.297164\n",
      "[51]\ttraining's l2: 0.309702\tvalid_1's l2: 0.296519\n",
      "[52]\ttraining's l2: 0.308843\tvalid_1's l2: 0.295772\n",
      "[53]\ttraining's l2: 0.308087\tvalid_1's l2: 0.29513\n",
      "[54]\ttraining's l2: 0.307542\tvalid_1's l2: 0.294677\n",
      "[55]\ttraining's l2: 0.306804\tvalid_1's l2: 0.293977\n",
      "[56]\ttraining's l2: 0.30621\tvalid_1's l2: 0.293488\n",
      "[57]\ttraining's l2: 0.305586\tvalid_1's l2: 0.292904\n",
      "[58]\ttraining's l2: 0.305038\tvalid_1's l2: 0.292405\n",
      "[59]\ttraining's l2: 0.30462\tvalid_1's l2: 0.292058\n",
      "[60]\ttraining's l2: 0.304126\tvalid_1's l2: 0.291614\n",
      "[61]\ttraining's l2: 0.303752\tvalid_1's l2: 0.291331\n",
      "[62]\ttraining's l2: 0.303276\tvalid_1's l2: 0.290898\n",
      "[63]\ttraining's l2: 0.302868\tvalid_1's l2: 0.290546\n",
      "[64]\ttraining's l2: 0.302403\tvalid_1's l2: 0.290112\n",
      "[65]\ttraining's l2: 0.302031\tvalid_1's l2: 0.28976\n",
      "[66]\ttraining's l2: 0.301673\tvalid_1's l2: 0.28945\n",
      "[67]\ttraining's l2: 0.301362\tvalid_1's l2: 0.289216\n",
      "[68]\ttraining's l2: 0.301094\tvalid_1's l2: 0.289015\n",
      "[69]\ttraining's l2: 0.300798\tvalid_1's l2: 0.288768\n",
      "[70]\ttraining's l2: 0.300567\tvalid_1's l2: 0.288573\n",
      "[71]\ttraining's l2: 0.300369\tvalid_1's l2: 0.288411\n",
      "[72]\ttraining's l2: 0.300056\tvalid_1's l2: 0.288126\n",
      "[73]\ttraining's l2: 0.299761\tvalid_1's l2: 0.287849\n",
      "[74]\ttraining's l2: 0.299569\tvalid_1's l2: 0.287715\n",
      "[75]\ttraining's l2: 0.2994\tvalid_1's l2: 0.287611\n",
      "[76]\ttraining's l2: 0.299117\tvalid_1's l2: 0.287361\n",
      "[77]\ttraining's l2: 0.298865\tvalid_1's l2: 0.287117\n",
      "[78]\ttraining's l2: 0.298627\tvalid_1's l2: 0.286888\n",
      "[79]\ttraining's l2: 0.298451\tvalid_1's l2: 0.286733\n",
      "[80]\ttraining's l2: 0.298213\tvalid_1's l2: 0.286512\n",
      "[81]\ttraining's l2: 0.298002\tvalid_1's l2: 0.286337\n",
      "[82]\ttraining's l2: 0.297826\tvalid_1's l2: 0.286181\n",
      "[83]\ttraining's l2: 0.297668\tvalid_1's l2: 0.286035\n",
      "[84]\ttraining's l2: 0.297542\tvalid_1's l2: 0.285928\n",
      "[85]\ttraining's l2: 0.29743\tvalid_1's l2: 0.285836\n",
      "[86]\ttraining's l2: 0.297263\tvalid_1's l2: 0.285685\n",
      "[87]\ttraining's l2: 0.297097\tvalid_1's l2: 0.285517\n",
      "[88]\ttraining's l2: 0.297006\tvalid_1's l2: 0.285447\n",
      "[89]\ttraining's l2: 0.29686\tvalid_1's l2: 0.285312\n",
      "[90]\ttraining's l2: 0.296758\tvalid_1's l2: 0.285236\n",
      "[91]\ttraining's l2: 0.296634\tvalid_1's l2: 0.285129\n",
      "[92]\ttraining's l2: 0.296519\tvalid_1's l2: 0.285009\n",
      "[93]\ttraining's l2: 0.296385\tvalid_1's l2: 0.284881\n",
      "[94]\ttraining's l2: 0.296307\tvalid_1's l2: 0.284824\n",
      "[95]\ttraining's l2: 0.296205\tvalid_1's l2: 0.284737\n",
      "[96]\ttraining's l2: 0.296087\tvalid_1's l2: 0.284635\n",
      "[97]\ttraining's l2: 0.296022\tvalid_1's l2: 0.284592\n",
      "[98]\ttraining's l2: 0.295886\tvalid_1's l2: 0.284455\n",
      "[99]\ttraining's l2: 0.295809\tvalid_1's l2: 0.284396\n",
      "[100]\ttraining's l2: 0.295677\tvalid_1's l2: 0.2843\n",
      "[101]\ttraining's l2: 0.295595\tvalid_1's l2: 0.284232\n",
      "[102]\ttraining's l2: 0.295531\tvalid_1's l2: 0.284188\n",
      "[103]\ttraining's l2: 0.295477\tvalid_1's l2: 0.284143\n",
      "[104]\ttraining's l2: 0.295411\tvalid_1's l2: 0.284093\n",
      "[105]\ttraining's l2: 0.295287\tvalid_1's l2: 0.28398\n",
      "[106]\ttraining's l2: 0.295205\tvalid_1's l2: 0.28392\n",
      "[107]\ttraining's l2: 0.295146\tvalid_1's l2: 0.283868\n",
      "[108]\ttraining's l2: 0.295077\tvalid_1's l2: 0.283824\n",
      "[109]\ttraining's l2: 0.295033\tvalid_1's l2: 0.283791\n",
      "[110]\ttraining's l2: 0.294972\tvalid_1's l2: 0.283763\n",
      "[111]\ttraining's l2: 0.294861\tvalid_1's l2: 0.283661\n",
      "[112]\ttraining's l2: 0.294809\tvalid_1's l2: 0.283628\n",
      "[113]\ttraining's l2: 0.294703\tvalid_1's l2: 0.283545\n",
      "[114]\ttraining's l2: 0.294639\tvalid_1's l2: 0.283491\n",
      "[115]\ttraining's l2: 0.294589\tvalid_1's l2: 0.283453\n",
      "[116]\ttraining's l2: 0.294524\tvalid_1's l2: 0.283404\n",
      "[117]\ttraining's l2: 0.294473\tvalid_1's l2: 0.283363\n",
      "[118]\ttraining's l2: 0.294377\tvalid_1's l2: 0.283318\n",
      "[119]\ttraining's l2: 0.294272\tvalid_1's l2: 0.283233\n",
      "[120]\ttraining's l2: 0.29418\tvalid_1's l2: 0.283163\n",
      "[121]\ttraining's l2: 0.294139\tvalid_1's l2: 0.283135\n",
      "[122]\ttraining's l2: 0.294088\tvalid_1's l2: 0.283096\n",
      "[123]\ttraining's l2: 0.294\tvalid_1's l2: 0.283044\n",
      "[124]\ttraining's l2: 0.293947\tvalid_1's l2: 0.282991\n",
      "[125]\ttraining's l2: 0.293908\tvalid_1's l2: 0.282959\n",
      "[126]\ttraining's l2: 0.293855\tvalid_1's l2: 0.28292\n",
      "[127]\ttraining's l2: 0.293769\tvalid_1's l2: 0.282843\n",
      "[128]\ttraining's l2: 0.293698\tvalid_1's l2: 0.2828\n",
      "[129]\ttraining's l2: 0.293594\tvalid_1's l2: 0.282708\n",
      "[130]\ttraining's l2: 0.293552\tvalid_1's l2: 0.282682\n",
      "[131]\ttraining's l2: 0.293499\tvalid_1's l2: 0.282646\n",
      "[132]\ttraining's l2: 0.293451\tvalid_1's l2: 0.282617\n",
      "[133]\ttraining's l2: 0.293415\tvalid_1's l2: 0.282584\n",
      "[134]\ttraining's l2: 0.293378\tvalid_1's l2: 0.282565\n",
      "[135]\ttraining's l2: 0.293308\tvalid_1's l2: 0.282504\n",
      "[136]\ttraining's l2: 0.293257\tvalid_1's l2: 0.282469\n",
      "[137]\ttraining's l2: 0.293197\tvalid_1's l2: 0.282436\n",
      "[138]\ttraining's l2: 0.293152\tvalid_1's l2: 0.282414\n",
      "[139]\ttraining's l2: 0.293085\tvalid_1's l2: 0.282381\n",
      "[140]\ttraining's l2: 0.293044\tvalid_1's l2: 0.282349\n",
      "[141]\ttraining's l2: 0.292974\tvalid_1's l2: 0.282311\n",
      "[142]\ttraining's l2: 0.292935\tvalid_1's l2: 0.28228\n",
      "[143]\ttraining's l2: 0.292885\tvalid_1's l2: 0.282276\n",
      "[144]\ttraining's l2: 0.292846\tvalid_1's l2: 0.282253\n",
      "[145]\ttraining's l2: 0.292798\tvalid_1's l2: 0.282211\n",
      "[146]\ttraining's l2: 0.292763\tvalid_1's l2: 0.282179\n",
      "[147]\ttraining's l2: 0.292698\tvalid_1's l2: 0.28213\n",
      "[148]\ttraining's l2: 0.292642\tvalid_1's l2: 0.282091\n",
      "[149]\ttraining's l2: 0.292601\tvalid_1's l2: 0.282071\n",
      "[150]\ttraining's l2: 0.29256\tvalid_1's l2: 0.282049\n",
      "[151]\ttraining's l2: 0.29251\tvalid_1's l2: 0.282006\n",
      "[152]\ttraining's l2: 0.29247\tvalid_1's l2: 0.281984\n",
      "[153]\ttraining's l2: 0.292422\tvalid_1's l2: 0.281956\n",
      "[154]\ttraining's l2: 0.292384\tvalid_1's l2: 0.281916\n",
      "[155]\ttraining's l2: 0.292348\tvalid_1's l2: 0.281897\n",
      "[156]\ttraining's l2: 0.292319\tvalid_1's l2: 0.281874\n",
      "[157]\ttraining's l2: 0.29228\tvalid_1's l2: 0.28185\n",
      "[158]\ttraining's l2: 0.292234\tvalid_1's l2: 0.281839\n",
      "[159]\ttraining's l2: 0.29221\tvalid_1's l2: 0.281815\n",
      "[160]\ttraining's l2: 0.29217\tvalid_1's l2: 0.281795\n",
      "[161]\ttraining's l2: 0.292135\tvalid_1's l2: 0.281773\n",
      "[162]\ttraining's l2: 0.2921\tvalid_1's l2: 0.281745\n",
      "[163]\ttraining's l2: 0.292057\tvalid_1's l2: 0.281735\n",
      "[164]\ttraining's l2: 0.292034\tvalid_1's l2: 0.281719\n",
      "[165]\ttraining's l2: 0.291994\tvalid_1's l2: 0.2817\n",
      "[166]\ttraining's l2: 0.291963\tvalid_1's l2: 0.281684\n",
      "[167]\ttraining's l2: 0.291926\tvalid_1's l2: 0.281657\n",
      "[168]\ttraining's l2: 0.291889\tvalid_1's l2: 0.281635\n",
      "[169]\ttraining's l2: 0.291861\tvalid_1's l2: 0.281612\n",
      "[170]\ttraining's l2: 0.291818\tvalid_1's l2: 0.281583\n",
      "[171]\ttraining's l2: 0.291772\tvalid_1's l2: 0.281552\n",
      "[172]\ttraining's l2: 0.291741\tvalid_1's l2: 0.281522\n",
      "[173]\ttraining's l2: 0.291697\tvalid_1's l2: 0.281484\n",
      "[174]\ttraining's l2: 0.29166\tvalid_1's l2: 0.281464\n",
      "[175]\ttraining's l2: 0.291629\tvalid_1's l2: 0.281437\n",
      "[176]\ttraining's l2: 0.291598\tvalid_1's l2: 0.281423\n",
      "[177]\ttraining's l2: 0.291567\tvalid_1's l2: 0.281394\n",
      "[178]\ttraining's l2: 0.291535\tvalid_1's l2: 0.281372\n",
      "[179]\ttraining's l2: 0.291503\tvalid_1's l2: 0.281352\n",
      "[180]\ttraining's l2: 0.291449\tvalid_1's l2: 0.28131\n",
      "[181]\ttraining's l2: 0.291421\tvalid_1's l2: 0.281301\n",
      "[182]\ttraining's l2: 0.291382\tvalid_1's l2: 0.281267\n",
      "[183]\ttraining's l2: 0.291352\tvalid_1's l2: 0.281259\n",
      "[184]\ttraining's l2: 0.291322\tvalid_1's l2: 0.281241\n",
      "[185]\ttraining's l2: 0.291297\tvalid_1's l2: 0.281213\n",
      "[186]\ttraining's l2: 0.291268\tvalid_1's l2: 0.281189\n",
      "[187]\ttraining's l2: 0.29123\tvalid_1's l2: 0.281156\n",
      "[188]\ttraining's l2: 0.291193\tvalid_1's l2: 0.281129\n",
      "[189]\ttraining's l2: 0.291168\tvalid_1's l2: 0.28112\n",
      "[190]\ttraining's l2: 0.291133\tvalid_1's l2: 0.281092\n",
      "[191]\ttraining's l2: 0.291101\tvalid_1's l2: 0.281079\n",
      "[192]\ttraining's l2: 0.291078\tvalid_1's l2: 0.281061\n",
      "[193]\ttraining's l2: 0.291044\tvalid_1's l2: 0.281027\n",
      "[194]\ttraining's l2: 0.291015\tvalid_1's l2: 0.280998\n",
      "[195]\ttraining's l2: 0.290992\tvalid_1's l2: 0.280985\n",
      "[196]\ttraining's l2: 0.29095\tvalid_1's l2: 0.280958\n",
      "[197]\ttraining's l2: 0.290931\tvalid_1's l2: 0.280943\n",
      "[198]\ttraining's l2: 0.290905\tvalid_1's l2: 0.280926\n",
      "[199]\ttraining's l2: 0.290884\tvalid_1's l2: 0.280913\n",
      "[200]\ttraining's l2: 0.290857\tvalid_1's l2: 0.2809\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.290857\tvalid_1's l2: 0.2809\n",
      "mean_7_sales: 13295805.17\n",
      "mean_14_sales: 8951598.75\n",
      "lag_1_sales: 838358.27\n",
      "promo_0: 724414.00\n",
      "mean_5_sales: 688795.52\n",
      "mean_20_dow0_2017: 597184.69\n",
      "mean_30_sales: 519742.23\n",
      "mean_3_sales: 430011.92\n",
      "mean_4_dow0_2017: 385808.06\n",
      "item_class_features: 156454.71\n",
      "sum_7_promo: 148271.50\n",
      "mean_63_sales: 146890.62\n",
      "mean_21_sales: 125166.69\n",
      "std_14_sales: 99912.04\n",
      "mean_6_sales: 92609.11\n",
      "store_cluster_features: 58306.82\n",
      "sum_2_promo: 47840.97\n",
      "sum_4_promo: 45197.41\n",
      "item_family_features: 45041.65\n",
      "promo_7: 40984.38\n",
      "mean_4_sales: 38705.34\n",
      "sum_14_promo: 36826.73\n",
      "std_21_sales: 33800.91\n",
      "std_7_sales: 31085.07\n",
      "mean_4_dow6_2017: 29536.95\n",
      "lag_2_sales: 28719.14\n",
      "lag_28_sales: 27116.57\n",
      "lag_14_sales: 25575.53\n",
      "std_30_sales: 22609.65\n",
      "std_63_sales: 13424.53\n",
      "sum_3_promo: 12120.24\n",
      "store_type_features: 11484.44\n",
      "mean_60_sales: 10238.60\n",
      "sum_21_promo: 10072.51\n",
      "lag_56_sales: 8999.62\n",
      "mean_4_dow5_2017: 8652.35\n",
      "std_3_sales: 8510.09\n",
      "std_60_sales: 7708.01\n",
      "std_5_sales: 7290.89\n",
      "lag_3_sales: 6995.24\n",
      "mean_20_dow2_2017: 6877.39\n",
      "lag_63_sales: 6678.26\n",
      "lag_35_sales: 6566.02\n",
      "mean_20_dow4_2017: 6459.77\n",
      "store_city_features: 6232.43\n",
      "promo_14: 5623.77\n",
      "lag_7_sales: 5587.45\n",
      "std_6_sales: 5167.64\n",
      "lag_42_sales: 5078.28\n",
      "mean_20_dow6_2017: 4207.70\n",
      "mean_20_dow1_2017: 4196.36\n",
      "lag_4_sales: 4004.84\n",
      "promo_3: 3837.14\n",
      "mean_20_dow3_2017: 3652.87\n",
      "promo_6: 2993.50\n",
      "std_4_sales: 2901.23\n",
      "promo_1: 2553.64\n",
      "sum_5_promo: 2448.75\n",
      "lag_5_sales: 2405.15\n",
      "sum_6_promo: 2232.69\n",
      "promo_13: 2020.69\n",
      "mean_4_dow2_2017: 1686.20\n",
      "lag_6_sales: 1577.01\n",
      "promo_9: 1343.71\n",
      "mean_4_dow3_2017: 1318.57\n",
      "promo_4: 1260.09\n",
      "mean_20_dow5_2017: 1121.73\n",
      "promo_5: 1074.73\n",
      "promo_2: 932.46\n",
      "mean_4_dow1_2017: 881.85\n",
      "lag_21_sales: 663.26\n",
      "promo_15: 631.86\n",
      "mean_4_dow4_2017: 527.48\n",
      "store_state_features: 469.68\n",
      "lag_49_sales: 383.17\n",
      "promo_10: 244.49\n",
      "promo_8: 204.35\n",
      "promo_11: 172.16\n",
      "promo_12: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [01:33<23:22, 93.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.94861\tvalid_1's l2: 0.92514\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.890793\tvalid_1's l2: 0.868809\n",
      "[3]\ttraining's l2: 0.838363\tvalid_1's l2: 0.817604\n",
      "[4]\ttraining's l2: 0.790858\tvalid_1's l2: 0.771317\n",
      "[5]\ttraining's l2: 0.747899\tvalid_1's l2: 0.729328\n",
      "[6]\ttraining's l2: 0.709689\tvalid_1's l2: 0.692348\n",
      "[7]\ttraining's l2: 0.67449\tvalid_1's l2: 0.657869\n",
      "[8]\ttraining's l2: 0.643348\tvalid_1's l2: 0.627508\n",
      "[9]\ttraining's l2: 0.614606\tvalid_1's l2: 0.599446\n",
      "[10]\ttraining's l2: 0.588337\tvalid_1's l2: 0.573912\n",
      "[11]\ttraining's l2: 0.565035\tvalid_1's l2: 0.551382\n",
      "[12]\ttraining's l2: 0.543475\tvalid_1's l2: 0.530368\n",
      "[13]\ttraining's l2: 0.523972\tvalid_1's l2: 0.511355\n",
      "[14]\ttraining's l2: 0.506729\tvalid_1's l2: 0.494654\n",
      "[15]\ttraining's l2: 0.490593\tvalid_1's l2: 0.479024\n",
      "[16]\ttraining's l2: 0.476019\tvalid_1's l2: 0.464926\n",
      "[17]\ttraining's l2: 0.462839\tvalid_1's l2: 0.4522\n",
      "[18]\ttraining's l2: 0.450837\tvalid_1's l2: 0.440511\n",
      "[19]\ttraining's l2: 0.440053\tvalid_1's l2: 0.430087\n",
      "[20]\ttraining's l2: 0.430473\tvalid_1's l2: 0.420912\n",
      "[21]\ttraining's l2: 0.421511\tvalid_1's l2: 0.412219\n",
      "[22]\ttraining's l2: 0.413383\tvalid_1's l2: 0.404316\n",
      "[23]\ttraining's l2: 0.406295\tvalid_1's l2: 0.397576\n",
      "[24]\ttraining's l2: 0.39954\tvalid_1's l2: 0.390978\n",
      "[25]\ttraining's l2: 0.39346\tvalid_1's l2: 0.385093\n",
      "[26]\ttraining's l2: 0.387949\tvalid_1's l2: 0.379713\n",
      "[27]\ttraining's l2: 0.382898\tvalid_1's l2: 0.374828\n",
      "[28]\ttraining's l2: 0.378287\tvalid_1's l2: 0.370337\n",
      "[29]\ttraining's l2: 0.374178\tvalid_1's l2: 0.366375\n",
      "[30]\ttraining's l2: 0.370387\tvalid_1's l2: 0.362755\n",
      "[31]\ttraining's l2: 0.366908\tvalid_1's l2: 0.359378\n",
      "[32]\ttraining's l2: 0.363731\tvalid_1's l2: 0.35632\n",
      "[33]\ttraining's l2: 0.360911\tvalid_1's l2: 0.353623\n",
      "[34]\ttraining's l2: 0.358388\tvalid_1's l2: 0.351302\n",
      "[35]\ttraining's l2: 0.355981\tvalid_1's l2: 0.348968\n",
      "[36]\ttraining's l2: 0.353707\tvalid_1's l2: 0.346792\n",
      "[37]\ttraining's l2: 0.351654\tvalid_1's l2: 0.344836\n",
      "[38]\ttraining's l2: 0.349922\tvalid_1's l2: 0.343228\n",
      "[39]\ttraining's l2: 0.348191\tvalid_1's l2: 0.341606\n",
      "[40]\ttraining's l2: 0.346597\tvalid_1's l2: 0.340104\n",
      "[41]\ttraining's l2: 0.345112\tvalid_1's l2: 0.338679\n",
      "[42]\ttraining's l2: 0.343742\tvalid_1's l2: 0.337359\n",
      "[43]\ttraining's l2: 0.342553\tvalid_1's l2: 0.336235\n",
      "[44]\ttraining's l2: 0.34144\tvalid_1's l2: 0.335181\n",
      "[45]\ttraining's l2: 0.340416\tvalid_1's l2: 0.334213\n",
      "[46]\ttraining's l2: 0.339531\tvalid_1's l2: 0.333427\n",
      "[47]\ttraining's l2: 0.338715\tvalid_1's l2: 0.332699\n",
      "[48]\ttraining's l2: 0.337836\tvalid_1's l2: 0.331845\n",
      "[49]\ttraining's l2: 0.336976\tvalid_1's l2: 0.330992\n",
      "[50]\ttraining's l2: 0.336231\tvalid_1's l2: 0.330227\n",
      "[51]\ttraining's l2: 0.335596\tvalid_1's l2: 0.329695\n",
      "[52]\ttraining's l2: 0.334898\tvalid_1's l2: 0.329036\n",
      "[53]\ttraining's l2: 0.334275\tvalid_1's l2: 0.328485\n",
      "[54]\ttraining's l2: 0.333725\tvalid_1's l2: 0.32791\n",
      "[55]\ttraining's l2: 0.333184\tvalid_1's l2: 0.327365\n",
      "[56]\ttraining's l2: 0.332669\tvalid_1's l2: 0.32689\n",
      "[57]\ttraining's l2: 0.332198\tvalid_1's l2: 0.326431\n",
      "[58]\ttraining's l2: 0.331745\tvalid_1's l2: 0.325942\n",
      "[59]\ttraining's l2: 0.331345\tvalid_1's l2: 0.32557\n",
      "[60]\ttraining's l2: 0.330953\tvalid_1's l2: 0.325203\n",
      "[61]\ttraining's l2: 0.330607\tvalid_1's l2: 0.32489\n",
      "[62]\ttraining's l2: 0.330253\tvalid_1's l2: 0.324585\n",
      "[63]\ttraining's l2: 0.329926\tvalid_1's l2: 0.324255\n",
      "[64]\ttraining's l2: 0.329622\tvalid_1's l2: 0.323958\n",
      "[65]\ttraining's l2: 0.329332\tvalid_1's l2: 0.323662\n",
      "[66]\ttraining's l2: 0.329031\tvalid_1's l2: 0.323425\n",
      "[67]\ttraining's l2: 0.328736\tvalid_1's l2: 0.323118\n",
      "[68]\ttraining's l2: 0.328472\tvalid_1's l2: 0.322884\n",
      "[69]\ttraining's l2: 0.328235\tvalid_1's l2: 0.322711\n",
      "[70]\ttraining's l2: 0.32801\tvalid_1's l2: 0.32253\n",
      "[71]\ttraining's l2: 0.3278\tvalid_1's l2: 0.322309\n",
      "[72]\ttraining's l2: 0.32758\tvalid_1's l2: 0.322071\n",
      "[73]\ttraining's l2: 0.327356\tvalid_1's l2: 0.321867\n",
      "[74]\ttraining's l2: 0.327186\tvalid_1's l2: 0.32174\n",
      "[75]\ttraining's l2: 0.326968\tvalid_1's l2: 0.321498\n",
      "[76]\ttraining's l2: 0.326794\tvalid_1's l2: 0.321383\n",
      "[77]\ttraining's l2: 0.326603\tvalid_1's l2: 0.321208\n",
      "[78]\ttraining's l2: 0.32642\tvalid_1's l2: 0.321029\n",
      "[79]\ttraining's l2: 0.326228\tvalid_1's l2: 0.320793\n",
      "[80]\ttraining's l2: 0.326075\tvalid_1's l2: 0.320675\n",
      "[81]\ttraining's l2: 0.325901\tvalid_1's l2: 0.320454\n",
      "[82]\ttraining's l2: 0.325755\tvalid_1's l2: 0.320312\n",
      "[83]\ttraining's l2: 0.325588\tvalid_1's l2: 0.320152\n",
      "[84]\ttraining's l2: 0.325454\tvalid_1's l2: 0.320045\n",
      "[85]\ttraining's l2: 0.325314\tvalid_1's l2: 0.319923\n",
      "[86]\ttraining's l2: 0.325172\tvalid_1's l2: 0.319769\n",
      "[87]\ttraining's l2: 0.325033\tvalid_1's l2: 0.319612\n",
      "[88]\ttraining's l2: 0.324919\tvalid_1's l2: 0.319474\n",
      "[89]\ttraining's l2: 0.324798\tvalid_1's l2: 0.319389\n",
      "[90]\ttraining's l2: 0.324675\tvalid_1's l2: 0.319274\n",
      "[91]\ttraining's l2: 0.324563\tvalid_1's l2: 0.319175\n",
      "[92]\ttraining's l2: 0.324443\tvalid_1's l2: 0.319077\n",
      "[93]\ttraining's l2: 0.324336\tvalid_1's l2: 0.319001\n",
      "[94]\ttraining's l2: 0.324251\tvalid_1's l2: 0.318951\n",
      "[95]\ttraining's l2: 0.324133\tvalid_1's l2: 0.318827\n",
      "[96]\ttraining's l2: 0.324036\tvalid_1's l2: 0.31868\n",
      "[97]\ttraining's l2: 0.323934\tvalid_1's l2: 0.318578\n",
      "[98]\ttraining's l2: 0.323852\tvalid_1's l2: 0.31851\n",
      "[99]\ttraining's l2: 0.323755\tvalid_1's l2: 0.318428\n",
      "[100]\ttraining's l2: 0.323653\tvalid_1's l2: 0.318339\n",
      "[101]\ttraining's l2: 0.323554\tvalid_1's l2: 0.31823\n",
      "[102]\ttraining's l2: 0.323491\tvalid_1's l2: 0.318201\n",
      "[103]\ttraining's l2: 0.323422\tvalid_1's l2: 0.318161\n",
      "[104]\ttraining's l2: 0.323363\tvalid_1's l2: 0.318121\n",
      "[105]\ttraining's l2: 0.323286\tvalid_1's l2: 0.318086\n",
      "[106]\ttraining's l2: 0.323214\tvalid_1's l2: 0.318048\n",
      "[107]\ttraining's l2: 0.323102\tvalid_1's l2: 0.317891\n",
      "[108]\ttraining's l2: 0.32302\tvalid_1's l2: 0.317822\n",
      "[109]\ttraining's l2: 0.322966\tvalid_1's l2: 0.317791\n",
      "[110]\ttraining's l2: 0.322871\tvalid_1's l2: 0.317691\n",
      "[111]\ttraining's l2: 0.322809\tvalid_1's l2: 0.317649\n",
      "[112]\ttraining's l2: 0.322732\tvalid_1's l2: 0.317603\n",
      "[113]\ttraining's l2: 0.322654\tvalid_1's l2: 0.31756\n",
      "[114]\ttraining's l2: 0.322597\tvalid_1's l2: 0.317525\n",
      "[115]\ttraining's l2: 0.322543\tvalid_1's l2: 0.317493\n",
      "[116]\ttraining's l2: 0.322497\tvalid_1's l2: 0.317466\n",
      "[117]\ttraining's l2: 0.322449\tvalid_1's l2: 0.317421\n",
      "[118]\ttraining's l2: 0.322385\tvalid_1's l2: 0.317345\n",
      "[119]\ttraining's l2: 0.322282\tvalid_1's l2: 0.317221\n",
      "[120]\ttraining's l2: 0.322223\tvalid_1's l2: 0.317171\n",
      "[121]\ttraining's l2: 0.322175\tvalid_1's l2: 0.317168\n",
      "[122]\ttraining's l2: 0.322099\tvalid_1's l2: 0.317075\n",
      "[123]\ttraining's l2: 0.322028\tvalid_1's l2: 0.317025\n",
      "[124]\ttraining's l2: 0.321956\tvalid_1's l2: 0.316988\n",
      "[125]\ttraining's l2: 0.321894\tvalid_1's l2: 0.316956\n",
      "[126]\ttraining's l2: 0.321823\tvalid_1's l2: 0.316884\n",
      "[127]\ttraining's l2: 0.321778\tvalid_1's l2: 0.316845\n",
      "[128]\ttraining's l2: 0.321675\tvalid_1's l2: 0.31675\n",
      "[129]\ttraining's l2: 0.321633\tvalid_1's l2: 0.316717\n",
      "[130]\ttraining's l2: 0.321595\tvalid_1's l2: 0.316694\n",
      "[131]\ttraining's l2: 0.321552\tvalid_1's l2: 0.316677\n",
      "[132]\ttraining's l2: 0.321495\tvalid_1's l2: 0.316637\n",
      "[133]\ttraining's l2: 0.321458\tvalid_1's l2: 0.316609\n",
      "[134]\ttraining's l2: 0.321407\tvalid_1's l2: 0.316582\n",
      "[135]\ttraining's l2: 0.321371\tvalid_1's l2: 0.316571\n",
      "[136]\ttraining's l2: 0.321322\tvalid_1's l2: 0.316526\n",
      "[137]\ttraining's l2: 0.321219\tvalid_1's l2: 0.316447\n",
      "[138]\ttraining's l2: 0.321167\tvalid_1's l2: 0.316407\n",
      "[139]\ttraining's l2: 0.321113\tvalid_1's l2: 0.316366\n",
      "[140]\ttraining's l2: 0.321082\tvalid_1's l2: 0.316352\n",
      "[141]\ttraining's l2: 0.32103\tvalid_1's l2: 0.316331\n",
      "[142]\ttraining's l2: 0.320974\tvalid_1's l2: 0.316293\n",
      "[143]\ttraining's l2: 0.320919\tvalid_1's l2: 0.316243\n",
      "[144]\ttraining's l2: 0.320854\tvalid_1's l2: 0.316177\n",
      "[145]\ttraining's l2: 0.320818\tvalid_1's l2: 0.316148\n",
      "[146]\ttraining's l2: 0.320757\tvalid_1's l2: 0.316071\n",
      "[147]\ttraining's l2: 0.320691\tvalid_1's l2: 0.316013\n",
      "[148]\ttraining's l2: 0.320615\tvalid_1's l2: 0.315901\n",
      "[149]\ttraining's l2: 0.320591\tvalid_1's l2: 0.315896\n",
      "[150]\ttraining's l2: 0.320557\tvalid_1's l2: 0.315887\n",
      "[151]\ttraining's l2: 0.320518\tvalid_1's l2: 0.315849\n",
      "[152]\ttraining's l2: 0.320483\tvalid_1's l2: 0.315818\n",
      "[153]\ttraining's l2: 0.320447\tvalid_1's l2: 0.315801\n",
      "[154]\ttraining's l2: 0.32041\tvalid_1's l2: 0.315756\n",
      "[155]\ttraining's l2: 0.320361\tvalid_1's l2: 0.31573\n",
      "[156]\ttraining's l2: 0.320338\tvalid_1's l2: 0.315722\n",
      "[157]\ttraining's l2: 0.320305\tvalid_1's l2: 0.315707\n",
      "[158]\ttraining's l2: 0.320258\tvalid_1's l2: 0.315632\n",
      "[159]\ttraining's l2: 0.320234\tvalid_1's l2: 0.315626\n",
      "[160]\ttraining's l2: 0.320188\tvalid_1's l2: 0.315549\n",
      "[161]\ttraining's l2: 0.320153\tvalid_1's l2: 0.31554\n",
      "[162]\ttraining's l2: 0.320127\tvalid_1's l2: 0.315527\n",
      "[163]\ttraining's l2: 0.320088\tvalid_1's l2: 0.315504\n",
      "[164]\ttraining's l2: 0.320066\tvalid_1's l2: 0.315493\n",
      "[165]\ttraining's l2: 0.320017\tvalid_1's l2: 0.315473\n",
      "[166]\ttraining's l2: 0.319962\tvalid_1's l2: 0.315407\n",
      "[167]\ttraining's l2: 0.319926\tvalid_1's l2: 0.315388\n",
      "[168]\ttraining's l2: 0.319889\tvalid_1's l2: 0.315351\n",
      "[169]\ttraining's l2: 0.319851\tvalid_1's l2: 0.31534\n",
      "[170]\ttraining's l2: 0.319805\tvalid_1's l2: 0.315301\n",
      "[171]\ttraining's l2: 0.319772\tvalid_1's l2: 0.315277\n",
      "[172]\ttraining's l2: 0.319726\tvalid_1's l2: 0.31524\n",
      "[173]\ttraining's l2: 0.319689\tvalid_1's l2: 0.315217\n",
      "[174]\ttraining's l2: 0.319643\tvalid_1's l2: 0.315183\n",
      "[175]\ttraining's l2: 0.319623\tvalid_1's l2: 0.315169\n",
      "[176]\ttraining's l2: 0.31959\tvalid_1's l2: 0.315155\n",
      "[177]\ttraining's l2: 0.319556\tvalid_1's l2: 0.315141\n",
      "[178]\ttraining's l2: 0.319522\tvalid_1's l2: 0.315131\n",
      "[179]\ttraining's l2: 0.319494\tvalid_1's l2: 0.315117\n",
      "[180]\ttraining's l2: 0.319474\tvalid_1's l2: 0.315102\n",
      "[181]\ttraining's l2: 0.319446\tvalid_1's l2: 0.315097\n",
      "[182]\ttraining's l2: 0.319406\tvalid_1's l2: 0.315042\n",
      "[183]\ttraining's l2: 0.319366\tvalid_1's l2: 0.315011\n",
      "[184]\ttraining's l2: 0.319334\tvalid_1's l2: 0.315007\n",
      "[185]\ttraining's l2: 0.319308\tvalid_1's l2: 0.314991\n",
      "[186]\ttraining's l2: 0.319273\tvalid_1's l2: 0.314976\n",
      "[187]\ttraining's l2: 0.319243\tvalid_1's l2: 0.314968\n",
      "[188]\ttraining's l2: 0.319222\tvalid_1's l2: 0.314958\n",
      "[189]\ttraining's l2: 0.319183\tvalid_1's l2: 0.314935\n",
      "[190]\ttraining's l2: 0.319153\tvalid_1's l2: 0.314898\n",
      "[191]\ttraining's l2: 0.319119\tvalid_1's l2: 0.314838\n",
      "[192]\ttraining's l2: 0.319093\tvalid_1's l2: 0.314834\n",
      "[193]\ttraining's l2: 0.319052\tvalid_1's l2: 0.314804\n",
      "[194]\ttraining's l2: 0.319024\tvalid_1's l2: 0.314783\n",
      "[195]\ttraining's l2: 0.318985\tvalid_1's l2: 0.314724\n",
      "[196]\ttraining's l2: 0.318957\tvalid_1's l2: 0.314707\n",
      "[197]\ttraining's l2: 0.318925\tvalid_1's l2: 0.314665\n",
      "[198]\ttraining's l2: 0.318903\tvalid_1's l2: 0.314654\n",
      "[199]\ttraining's l2: 0.318874\tvalid_1's l2: 0.314644\n",
      "[200]\ttraining's l2: 0.318839\tvalid_1's l2: 0.314632\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.318839\tvalid_1's l2: 0.314632\n",
      "mean_14_sales: 8959154.87\n",
      "mean_7_sales: 7268420.98\n",
      "mean_6_sales: 2933030.84\n",
      "mean_30_sales: 955941.83\n",
      "mean_20_dow1_2017: 482901.66\n",
      "promo_1: 461581.64\n",
      "lag_1_sales: 363847.21\n",
      "mean_21_sales: 321778.84\n",
      "mean_63_sales: 235847.52\n",
      "item_class_features: 158161.21\n",
      "mean_5_sales: 130612.45\n",
      "mean_4_dow1_2017: 125164.61\n",
      "std_14_sales: 103643.02\n",
      "sum_4_promo: 61212.32\n",
      "sum_2_promo: 54778.80\n",
      "mean_3_sales: 44471.02\n",
      "sum_6_promo: 42347.48\n",
      "promo_0: 41567.71\n",
      "std_7_sales: 39690.79\n",
      "mean_4_sales: 29993.25\n",
      "mean_60_sales: 29369.46\n",
      "mean_20_dow2_2017: 28930.89\n",
      "std_21_sales: 23619.92\n",
      "promo_3: 22070.96\n",
      "std_30_sales: 21133.61\n",
      "lag_28_sales: 19314.84\n",
      "sum_7_promo: 15025.52\n",
      "sum_3_promo: 12352.23\n",
      "promo_2: 11452.86\n",
      "std_63_sales: 10756.59\n",
      "store_cluster_features: 10561.38\n",
      "store_city_features: 10468.65\n",
      "promo_5: 10332.96\n",
      "mean_4_dow2_2017: 9747.58\n",
      "item_family_features: 9702.91\n",
      "promo_4: 9627.19\n",
      "std_6_sales: 9393.04\n",
      "lag_5_sales: 8778.28\n",
      "mean_20_dow0_2017: 8054.61\n",
      "promo_7: 7685.18\n",
      "sum_14_promo: 7370.42\n",
      "mean_20_dow4_2017: 6930.89\n",
      "std_60_sales: 6751.57\n",
      "sum_5_promo: 5994.63\n",
      "mean_4_dow6_2017: 5807.30\n",
      "lag_2_sales: 5702.58\n",
      "lag_6_sales: 5573.97\n",
      "lag_56_sales: 3983.47\n",
      "std_5_sales: 3979.52\n",
      "lag_3_sales: 3943.36\n",
      "mean_20_dow6_2017: 3856.87\n",
      "sum_21_promo: 3754.21\n",
      "promo_6: 3182.42\n",
      "lag_4_sales: 3115.96\n",
      "mean_20_dow3_2017: 3026.19\n",
      "lag_14_sales: 2979.88\n",
      "promo_14: 2939.90\n",
      "std_3_sales: 1922.88\n",
      "mean_4_dow5_2017: 1795.51\n",
      "lag_63_sales: 1607.88\n",
      "mean_4_dow0_2017: 1539.14\n",
      "lag_7_sales: 1347.27\n",
      "lag_42_sales: 1295.62\n",
      "mean_4_dow4_2017: 1275.11\n",
      "std_4_sales: 1260.94\n",
      "promo_8: 1193.64\n",
      "store_type_features: 993.98\n",
      "mean_4_dow3_2017: 788.48\n",
      "store_state_features: 599.94\n",
      "mean_20_dow5_2017: 551.54\n",
      "promo_9: 512.56\n",
      "lag_35_sales: 447.25\n",
      "promo_13: 274.03\n",
      "promo_10: 259.75\n",
      "promo_12: 255.24\n",
      "lag_21_sales: 193.55\n",
      "promo_15: 188.23\n",
      "lag_49_sales: 75.45\n",
      "promo_11: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [03:04<21:38, 92.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05416\tvalid_1's l2: 1.0597\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.987876\tvalid_1's l2: 0.993571\n",
      "[3]\ttraining's l2: 0.928453\tvalid_1's l2: 0.934357\n",
      "[4]\ttraining's l2: 0.873394\tvalid_1's l2: 0.879396\n",
      "[5]\ttraining's l2: 0.823862\tvalid_1's l2: 0.82985\n",
      "[6]\ttraining's l2: 0.779723\tvalid_1's l2: 0.785783\n",
      "[7]\ttraining's l2: 0.738901\tvalid_1's l2: 0.744934\n",
      "[8]\ttraining's l2: 0.701865\tvalid_1's l2: 0.70795\n",
      "[9]\ttraining's l2: 0.668383\tvalid_1's l2: 0.674601\n",
      "[10]\ttraining's l2: 0.638558\tvalid_1's l2: 0.644748\n",
      "[11]\ttraining's l2: 0.61099\tvalid_1's l2: 0.617162\n",
      "[12]\ttraining's l2: 0.586153\tvalid_1's l2: 0.592313\n",
      "[13]\ttraining's l2: 0.563435\tvalid_1's l2: 0.569467\n",
      "[14]\ttraining's l2: 0.542843\tvalid_1's l2: 0.548825\n",
      "[15]\ttraining's l2: 0.524738\tvalid_1's l2: 0.530657\n",
      "[16]\ttraining's l2: 0.508291\tvalid_1's l2: 0.514152\n",
      "[17]\ttraining's l2: 0.492908\tvalid_1's l2: 0.49861\n",
      "[18]\ttraining's l2: 0.478786\tvalid_1's l2: 0.484409\n",
      "[19]\ttraining's l2: 0.466006\tvalid_1's l2: 0.471566\n",
      "[20]\ttraining's l2: 0.45443\tvalid_1's l2: 0.459909\n",
      "[21]\ttraining's l2: 0.444424\tvalid_1's l2: 0.449826\n",
      "[22]\ttraining's l2: 0.434985\tvalid_1's l2: 0.440222\n",
      "[23]\ttraining's l2: 0.426281\tvalid_1's l2: 0.431429\n",
      "[24]\ttraining's l2: 0.418285\tvalid_1's l2: 0.42331\n",
      "[25]\ttraining's l2: 0.411419\tvalid_1's l2: 0.416357\n",
      "[26]\ttraining's l2: 0.404765\tvalid_1's l2: 0.409627\n",
      "[27]\ttraining's l2: 0.399046\tvalid_1's l2: 0.40382\n",
      "[28]\ttraining's l2: 0.393486\tvalid_1's l2: 0.398129\n",
      "[29]\ttraining's l2: 0.388808\tvalid_1's l2: 0.39342\n",
      "[30]\ttraining's l2: 0.38447\tvalid_1's l2: 0.389009\n",
      "[31]\ttraining's l2: 0.380207\tvalid_1's l2: 0.38465\n",
      "[32]\ttraining's l2: 0.376272\tvalid_1's l2: 0.380655\n",
      "[33]\ttraining's l2: 0.372758\tvalid_1's l2: 0.377066\n",
      "[34]\ttraining's l2: 0.369481\tvalid_1's l2: 0.373773\n",
      "[35]\ttraining's l2: 0.366533\tvalid_1's l2: 0.37077\n",
      "[36]\ttraining's l2: 0.363829\tvalid_1's l2: 0.367987\n",
      "[37]\ttraining's l2: 0.361377\tvalid_1's l2: 0.36549\n",
      "[38]\ttraining's l2: 0.359096\tvalid_1's l2: 0.363142\n",
      "[39]\ttraining's l2: 0.35703\tvalid_1's l2: 0.36102\n",
      "[40]\ttraining's l2: 0.355161\tvalid_1's l2: 0.359123\n",
      "[41]\ttraining's l2: 0.353367\tvalid_1's l2: 0.3573\n",
      "[42]\ttraining's l2: 0.351762\tvalid_1's l2: 0.355674\n",
      "[43]\ttraining's l2: 0.350376\tvalid_1's l2: 0.354277\n",
      "[44]\ttraining's l2: 0.348994\tvalid_1's l2: 0.352884\n",
      "[45]\ttraining's l2: 0.347746\tvalid_1's l2: 0.351615\n",
      "[46]\ttraining's l2: 0.34653\tvalid_1's l2: 0.350405\n",
      "[47]\ttraining's l2: 0.345525\tvalid_1's l2: 0.349338\n",
      "[48]\ttraining's l2: 0.344566\tvalid_1's l2: 0.348376\n",
      "[49]\ttraining's l2: 0.343547\tvalid_1's l2: 0.347398\n",
      "[50]\ttraining's l2: 0.342661\tvalid_1's l2: 0.346527\n",
      "[51]\ttraining's l2: 0.34176\tvalid_1's l2: 0.34564\n",
      "[52]\ttraining's l2: 0.340938\tvalid_1's l2: 0.344817\n",
      "[53]\ttraining's l2: 0.340174\tvalid_1's l2: 0.344025\n",
      "[54]\ttraining's l2: 0.339553\tvalid_1's l2: 0.343376\n",
      "[55]\ttraining's l2: 0.338865\tvalid_1's l2: 0.342667\n",
      "[56]\ttraining's l2: 0.338303\tvalid_1's l2: 0.3421\n",
      "[57]\ttraining's l2: 0.3377\tvalid_1's l2: 0.341504\n",
      "[58]\ttraining's l2: 0.337139\tvalid_1's l2: 0.340893\n",
      "[59]\ttraining's l2: 0.336611\tvalid_1's l2: 0.340381\n",
      "[60]\ttraining's l2: 0.336179\tvalid_1's l2: 0.339996\n",
      "[61]\ttraining's l2: 0.335726\tvalid_1's l2: 0.33962\n",
      "[62]\ttraining's l2: 0.335227\tvalid_1's l2: 0.339131\n",
      "[63]\ttraining's l2: 0.334878\tvalid_1's l2: 0.338809\n",
      "[64]\ttraining's l2: 0.334554\tvalid_1's l2: 0.338504\n",
      "[65]\ttraining's l2: 0.334096\tvalid_1's l2: 0.338037\n",
      "[66]\ttraining's l2: 0.333698\tvalid_1's l2: 0.337658\n",
      "[67]\ttraining's l2: 0.333399\tvalid_1's l2: 0.337396\n",
      "[68]\ttraining's l2: 0.333102\tvalid_1's l2: 0.337125\n",
      "[69]\ttraining's l2: 0.332777\tvalid_1's l2: 0.336853\n",
      "[70]\ttraining's l2: 0.332428\tvalid_1's l2: 0.336511\n",
      "[71]\ttraining's l2: 0.332063\tvalid_1's l2: 0.336192\n",
      "[72]\ttraining's l2: 0.331756\tvalid_1's l2: 0.335884\n",
      "[73]\ttraining's l2: 0.331548\tvalid_1's l2: 0.335704\n",
      "[74]\ttraining's l2: 0.331265\tvalid_1's l2: 0.33552\n",
      "[75]\ttraining's l2: 0.33104\tvalid_1's l2: 0.335359\n",
      "[76]\ttraining's l2: 0.330733\tvalid_1's l2: 0.335079\n",
      "[77]\ttraining's l2: 0.330501\tvalid_1's l2: 0.334861\n",
      "[78]\ttraining's l2: 0.330213\tvalid_1's l2: 0.334602\n",
      "[79]\ttraining's l2: 0.32998\tvalid_1's l2: 0.33442\n",
      "[80]\ttraining's l2: 0.329736\tvalid_1's l2: 0.334202\n",
      "[81]\ttraining's l2: 0.329531\tvalid_1's l2: 0.334008\n",
      "[82]\ttraining's l2: 0.329343\tvalid_1's l2: 0.333867\n",
      "[83]\ttraining's l2: 0.329152\tvalid_1's l2: 0.333726\n",
      "[84]\ttraining's l2: 0.32901\tvalid_1's l2: 0.333626\n",
      "[85]\ttraining's l2: 0.328833\tvalid_1's l2: 0.33346\n",
      "[86]\ttraining's l2: 0.328661\tvalid_1's l2: 0.333339\n",
      "[87]\ttraining's l2: 0.328522\tvalid_1's l2: 0.333222\n",
      "[88]\ttraining's l2: 0.328396\tvalid_1's l2: 0.333098\n",
      "[89]\ttraining's l2: 0.328223\tvalid_1's l2: 0.333006\n",
      "[90]\ttraining's l2: 0.328004\tvalid_1's l2: 0.332813\n",
      "[91]\ttraining's l2: 0.327876\tvalid_1's l2: 0.332755\n",
      "[92]\ttraining's l2: 0.327698\tvalid_1's l2: 0.332486\n",
      "[93]\ttraining's l2: 0.327535\tvalid_1's l2: 0.332398\n",
      "[94]\ttraining's l2: 0.327359\tvalid_1's l2: 0.332266\n",
      "[95]\ttraining's l2: 0.327211\tvalid_1's l2: 0.332135\n",
      "[96]\ttraining's l2: 0.327074\tvalid_1's l2: 0.332014\n",
      "[97]\ttraining's l2: 0.326963\tvalid_1's l2: 0.331895\n",
      "[98]\ttraining's l2: 0.326829\tvalid_1's l2: 0.331809\n",
      "[99]\ttraining's l2: 0.326737\tvalid_1's l2: 0.33173\n",
      "[100]\ttraining's l2: 0.326599\tvalid_1's l2: 0.331684\n",
      "[101]\ttraining's l2: 0.326479\tvalid_1's l2: 0.331623\n",
      "[102]\ttraining's l2: 0.326372\tvalid_1's l2: 0.331552\n",
      "[103]\ttraining's l2: 0.326264\tvalid_1's l2: 0.331503\n",
      "[104]\ttraining's l2: 0.326166\tvalid_1's l2: 0.331398\n",
      "[105]\ttraining's l2: 0.326055\tvalid_1's l2: 0.331328\n",
      "[106]\ttraining's l2: 0.325884\tvalid_1's l2: 0.331175\n",
      "[107]\ttraining's l2: 0.325767\tvalid_1's l2: 0.331017\n",
      "[108]\ttraining's l2: 0.325652\tvalid_1's l2: 0.330956\n",
      "[109]\ttraining's l2: 0.32554\tvalid_1's l2: 0.330892\n",
      "[110]\ttraining's l2: 0.325427\tvalid_1's l2: 0.330851\n",
      "[111]\ttraining's l2: 0.325357\tvalid_1's l2: 0.330792\n",
      "[112]\ttraining's l2: 0.325287\tvalid_1's l2: 0.330749\n",
      "[113]\ttraining's l2: 0.325195\tvalid_1's l2: 0.330679\n",
      "[114]\ttraining's l2: 0.325134\tvalid_1's l2: 0.330618\n",
      "[115]\ttraining's l2: 0.325009\tvalid_1's l2: 0.330554\n",
      "[116]\ttraining's l2: 0.324924\tvalid_1's l2: 0.330518\n",
      "[117]\ttraining's l2: 0.324816\tvalid_1's l2: 0.330454\n",
      "[118]\ttraining's l2: 0.32474\tvalid_1's l2: 0.330382\n",
      "[119]\ttraining's l2: 0.324682\tvalid_1's l2: 0.330343\n",
      "[120]\ttraining's l2: 0.324609\tvalid_1's l2: 0.330288\n",
      "[121]\ttraining's l2: 0.324494\tvalid_1's l2: 0.330223\n",
      "[122]\ttraining's l2: 0.324439\tvalid_1's l2: 0.330169\n",
      "[123]\ttraining's l2: 0.324366\tvalid_1's l2: 0.330131\n",
      "[124]\ttraining's l2: 0.324271\tvalid_1's l2: 0.330066\n",
      "[125]\ttraining's l2: 0.324182\tvalid_1's l2: 0.330022\n",
      "[126]\ttraining's l2: 0.324108\tvalid_1's l2: 0.329963\n",
      "[127]\ttraining's l2: 0.324051\tvalid_1's l2: 0.32989\n",
      "[128]\ttraining's l2: 0.323998\tvalid_1's l2: 0.329869\n",
      "[129]\ttraining's l2: 0.323905\tvalid_1's l2: 0.329746\n",
      "[130]\ttraining's l2: 0.323866\tvalid_1's l2: 0.329724\n",
      "[131]\ttraining's l2: 0.323796\tvalid_1's l2: 0.3297\n",
      "[132]\ttraining's l2: 0.323743\tvalid_1's l2: 0.329647\n",
      "[133]\ttraining's l2: 0.323661\tvalid_1's l2: 0.329607\n",
      "[134]\ttraining's l2: 0.323611\tvalid_1's l2: 0.32959\n",
      "[135]\ttraining's l2: 0.323549\tvalid_1's l2: 0.329578\n",
      "[136]\ttraining's l2: 0.323483\tvalid_1's l2: 0.329539\n",
      "[137]\ttraining's l2: 0.323396\tvalid_1's l2: 0.329462\n",
      "[138]\ttraining's l2: 0.323335\tvalid_1's l2: 0.329423\n",
      "[139]\ttraining's l2: 0.32326\tvalid_1's l2: 0.329347\n",
      "[140]\ttraining's l2: 0.323205\tvalid_1's l2: 0.32931\n",
      "[141]\ttraining's l2: 0.323166\tvalid_1's l2: 0.329303\n",
      "[142]\ttraining's l2: 0.323094\tvalid_1's l2: 0.329269\n",
      "[143]\ttraining's l2: 0.323023\tvalid_1's l2: 0.329208\n",
      "[144]\ttraining's l2: 0.322944\tvalid_1's l2: 0.329118\n",
      "[145]\ttraining's l2: 0.322899\tvalid_1's l2: 0.329088\n",
      "[146]\ttraining's l2: 0.32284\tvalid_1's l2: 0.329009\n",
      "[147]\ttraining's l2: 0.322766\tvalid_1's l2: 0.328911\n",
      "[148]\ttraining's l2: 0.322708\tvalid_1's l2: 0.328903\n",
      "[149]\ttraining's l2: 0.322659\tvalid_1's l2: 0.328898\n",
      "[150]\ttraining's l2: 0.322624\tvalid_1's l2: 0.328871\n",
      "[151]\ttraining's l2: 0.322564\tvalid_1's l2: 0.328763\n",
      "[152]\ttraining's l2: 0.322515\tvalid_1's l2: 0.328745\n",
      "[153]\ttraining's l2: 0.322475\tvalid_1's l2: 0.328703\n",
      "[154]\ttraining's l2: 0.322409\tvalid_1's l2: 0.328608\n",
      "[155]\ttraining's l2: 0.322377\tvalid_1's l2: 0.328581\n",
      "[156]\ttraining's l2: 0.322333\tvalid_1's l2: 0.328565\n",
      "[157]\ttraining's l2: 0.322274\tvalid_1's l2: 0.328497\n",
      "[158]\ttraining's l2: 0.322206\tvalid_1's l2: 0.328462\n",
      "[159]\ttraining's l2: 0.322172\tvalid_1's l2: 0.328438\n",
      "[160]\ttraining's l2: 0.322137\tvalid_1's l2: 0.328423\n",
      "[161]\ttraining's l2: 0.322109\tvalid_1's l2: 0.3284\n",
      "[162]\ttraining's l2: 0.322056\tvalid_1's l2: 0.328324\n",
      "[163]\ttraining's l2: 0.321993\tvalid_1's l2: 0.328303\n",
      "[164]\ttraining's l2: 0.32196\tvalid_1's l2: 0.328265\n",
      "[165]\ttraining's l2: 0.321902\tvalid_1's l2: 0.328258\n",
      "[166]\ttraining's l2: 0.321858\tvalid_1's l2: 0.328239\n",
      "[167]\ttraining's l2: 0.321804\tvalid_1's l2: 0.328205\n",
      "[168]\ttraining's l2: 0.321771\tvalid_1's l2: 0.32818\n",
      "[169]\ttraining's l2: 0.321725\tvalid_1's l2: 0.328156\n",
      "[170]\ttraining's l2: 0.321687\tvalid_1's l2: 0.328136\n",
      "[171]\ttraining's l2: 0.321646\tvalid_1's l2: 0.328131\n",
      "[172]\ttraining's l2: 0.321594\tvalid_1's l2: 0.328092\n",
      "[173]\ttraining's l2: 0.321555\tvalid_1's l2: 0.328064\n",
      "[174]\ttraining's l2: 0.321513\tvalid_1's l2: 0.328037\n",
      "[175]\ttraining's l2: 0.321472\tvalid_1's l2: 0.327995\n",
      "[176]\ttraining's l2: 0.32144\tvalid_1's l2: 0.327988\n",
      "[177]\ttraining's l2: 0.3214\tvalid_1's l2: 0.327953\n",
      "[178]\ttraining's l2: 0.321346\tvalid_1's l2: 0.327955\n",
      "[179]\ttraining's l2: 0.321302\tvalid_1's l2: 0.327927\n",
      "[180]\ttraining's l2: 0.321264\tvalid_1's l2: 0.327909\n",
      "[181]\ttraining's l2: 0.321226\tvalid_1's l2: 0.327887\n",
      "[182]\ttraining's l2: 0.321187\tvalid_1's l2: 0.327862\n",
      "[183]\ttraining's l2: 0.321147\tvalid_1's l2: 0.327852\n",
      "[184]\ttraining's l2: 0.321098\tvalid_1's l2: 0.327796\n",
      "[185]\ttraining's l2: 0.321073\tvalid_1's l2: 0.327776\n",
      "[186]\ttraining's l2: 0.321016\tvalid_1's l2: 0.3278\n",
      "[187]\ttraining's l2: 0.320976\tvalid_1's l2: 0.327781\n",
      "[188]\ttraining's l2: 0.320939\tvalid_1's l2: 0.327762\n",
      "[189]\ttraining's l2: 0.320917\tvalid_1's l2: 0.327757\n",
      "[190]\ttraining's l2: 0.320894\tvalid_1's l2: 0.327747\n",
      "[191]\ttraining's l2: 0.320856\tvalid_1's l2: 0.327755\n",
      "[192]\ttraining's l2: 0.320816\tvalid_1's l2: 0.327737\n",
      "[193]\ttraining's l2: 0.320782\tvalid_1's l2: 0.327717\n",
      "[194]\ttraining's l2: 0.320742\tvalid_1's l2: 0.327646\n",
      "[195]\ttraining's l2: 0.32071\tvalid_1's l2: 0.327622\n",
      "[196]\ttraining's l2: 0.320673\tvalid_1's l2: 0.32761\n",
      "[197]\ttraining's l2: 0.320646\tvalid_1's l2: 0.327614\n",
      "[198]\ttraining's l2: 0.320613\tvalid_1's l2: 0.32758\n",
      "[199]\ttraining's l2: 0.320576\tvalid_1's l2: 0.327562\n",
      "[200]\ttraining's l2: 0.320546\tvalid_1's l2: 0.327554\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.320546\tvalid_1's l2: 0.327554\n",
      "mean_14_sales: 10560795.52\n",
      "mean_7_sales: 6341588.76\n",
      "mean_6_sales: 2011461.95\n",
      "mean_21_sales: 1456639.03\n",
      "mean_20_dow2_2017: 1332297.47\n",
      "mean_30_sales: 1191028.53\n",
      "mean_4_dow2_2017: 1144058.63\n",
      "mean_5_sales: 770456.57\n",
      "promo_2: 667607.05\n",
      "item_class_features: 321026.92\n",
      "sum_5_promo: 153705.45\n",
      "std_14_sales: 96565.99\n",
      "lag_1_sales: 89937.61\n",
      "mean_63_sales: 75381.30\n",
      "std_21_sales: 69365.58\n",
      "store_cluster_features: 55642.48\n",
      "std_30_sales: 53737.29\n",
      "item_family_features: 41559.10\n",
      "promo_3: 40349.23\n",
      "mean_3_sales: 36407.63\n",
      "sum_4_promo: 31790.64\n",
      "lag_5_sales: 30986.05\n",
      "std_63_sales: 28856.31\n",
      "mean_20_dow1_2017: 27810.89\n",
      "std_7_sales: 26396.26\n",
      "mean_4_sales: 23827.64\n",
      "std_6_sales: 21744.92\n",
      "promo_0: 20810.05\n",
      "promo_5: 19132.79\n",
      "lag_28_sales: 19018.24\n",
      "promo_7: 18138.42\n",
      "sum_2_promo: 17841.36\n",
      "promo_4: 14492.37\n",
      "mean_20_dow0_2017: 13700.40\n",
      "mean_4_dow1_2017: 12932.26\n",
      "std_5_sales: 10944.09\n",
      "mean_60_sales: 10473.84\n",
      "store_city_features: 10411.20\n",
      "promo_9: 9511.84\n",
      "lag_56_sales: 8787.38\n",
      "std_60_sales: 8626.08\n",
      "sum_14_promo: 8263.82\n",
      "store_type_features: 8200.31\n",
      "promo_1: 8128.40\n",
      "sum_7_promo: 8117.86\n",
      "sum_3_promo: 8029.82\n",
      "lag_4_sales: 6143.71\n",
      "promo_14: 5502.83\n",
      "mean_20_dow3_2017: 5491.32\n",
      "sum_21_promo: 4720.69\n",
      "promo_6: 4041.63\n",
      "mean_20_dow4_2017: 3791.67\n",
      "sum_6_promo: 3365.35\n",
      "lag_3_sales: 2964.12\n",
      "lag_6_sales: 2635.06\n",
      "mean_4_dow3_2017: 2426.14\n",
      "promo_8: 2311.60\n",
      "mean_20_dow5_2017: 2272.41\n",
      "lag_2_sales: 2074.34\n",
      "lag_21_sales: 1975.18\n",
      "mean_20_dow6_2017: 1875.42\n",
      "mean_4_dow0_2017: 1631.72\n",
      "promo_12: 1495.47\n",
      "store_state_features: 1473.56\n",
      "mean_4_dow6_2017: 1218.38\n",
      "std_4_sales: 1153.80\n",
      "mean_4_dow4_2017: 1143.59\n",
      "promo_13: 1044.85\n",
      "lag_7_sales: 1035.73\n",
      "promo_10: 1005.05\n",
      "lag_14_sales: 951.85\n",
      "lag_42_sales: 710.44\n",
      "lag_63_sales: 688.93\n",
      "promo_15: 274.17\n",
      "std_3_sales: 266.94\n",
      "mean_4_dow5_2017: 242.95\n",
      "lag_49_sales: 165.11\n",
      "lag_35_sales: 160.59\n",
      "promo_11: 142.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [04:34<19:55, 91.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.18942\tvalid_1's l2: 1.16019\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.11147\tvalid_1's l2: 1.08389\n",
      "[3]\ttraining's l2: 1.04188\tvalid_1's l2: 1.01577\n",
      "[4]\ttraining's l2: 0.978182\tvalid_1's l2: 0.953186\n",
      "[5]\ttraining's l2: 0.920572\tvalid_1's l2: 0.896693\n",
      "[6]\ttraining's l2: 0.868258\tvalid_1's l2: 0.845441\n",
      "[7]\ttraining's l2: 0.821523\tvalid_1's l2: 0.79984\n",
      "[8]\ttraining's l2: 0.779101\tvalid_1's l2: 0.758581\n",
      "[9]\ttraining's l2: 0.740348\tvalid_1's l2: 0.720697\n",
      "[10]\ttraining's l2: 0.705061\tvalid_1's l2: 0.686312\n",
      "[11]\ttraining's l2: 0.673215\tvalid_1's l2: 0.655142\n",
      "[12]\ttraining's l2: 0.644341\tvalid_1's l2: 0.626986\n",
      "[13]\ttraining's l2: 0.618248\tvalid_1's l2: 0.601596\n",
      "[14]\ttraining's l2: 0.594599\tvalid_1's l2: 0.578615\n",
      "[15]\ttraining's l2: 0.573163\tvalid_1's l2: 0.55776\n",
      "[16]\ttraining's l2: 0.553686\tvalid_1's l2: 0.538733\n",
      "[17]\ttraining's l2: 0.536161\tvalid_1's l2: 0.521788\n",
      "[18]\ttraining's l2: 0.52003\tvalid_1's l2: 0.506052\n",
      "[19]\ttraining's l2: 0.505483\tvalid_1's l2: 0.491929\n",
      "[20]\ttraining's l2: 0.492368\tvalid_1's l2: 0.479237\n",
      "[21]\ttraining's l2: 0.480633\tvalid_1's l2: 0.467939\n",
      "[22]\ttraining's l2: 0.470023\tvalid_1's l2: 0.457702\n",
      "[23]\ttraining's l2: 0.460137\tvalid_1's l2: 0.448121\n",
      "[24]\ttraining's l2: 0.451254\tvalid_1's l2: 0.439418\n",
      "[25]\ttraining's l2: 0.443027\tvalid_1's l2: 0.431409\n",
      "[26]\ttraining's l2: 0.435802\tvalid_1's l2: 0.424496\n",
      "[27]\ttraining's l2: 0.428998\tvalid_1's l2: 0.417925\n",
      "[28]\ttraining's l2: 0.422915\tvalid_1's l2: 0.412055\n",
      "[29]\ttraining's l2: 0.417477\tvalid_1's l2: 0.406906\n",
      "[30]\ttraining's l2: 0.412384\tvalid_1's l2: 0.401979\n",
      "[31]\ttraining's l2: 0.407872\tvalid_1's l2: 0.397662\n",
      "[32]\ttraining's l2: 0.403838\tvalid_1's l2: 0.393843\n",
      "[33]\ttraining's l2: 0.399992\tvalid_1's l2: 0.39011\n",
      "[34]\ttraining's l2: 0.396616\tvalid_1's l2: 0.386982\n",
      "[35]\ttraining's l2: 0.393404\tvalid_1's l2: 0.383862\n",
      "[36]\ttraining's l2: 0.390505\tvalid_1's l2: 0.38104\n",
      "[37]\ttraining's l2: 0.387915\tvalid_1's l2: 0.378669\n",
      "[38]\ttraining's l2: 0.385421\tvalid_1's l2: 0.37621\n",
      "[39]\ttraining's l2: 0.38327\tvalid_1's l2: 0.37425\n",
      "[40]\ttraining's l2: 0.381292\tvalid_1's l2: 0.37245\n",
      "[41]\ttraining's l2: 0.379346\tvalid_1's l2: 0.370556\n",
      "[42]\ttraining's l2: 0.377618\tvalid_1's l2: 0.368859\n",
      "[43]\ttraining's l2: 0.376124\tvalid_1's l2: 0.36752\n",
      "[44]\ttraining's l2: 0.374633\tvalid_1's l2: 0.366073\n",
      "[45]\ttraining's l2: 0.373218\tvalid_1's l2: 0.364668\n",
      "[46]\ttraining's l2: 0.371915\tvalid_1's l2: 0.363384\n",
      "[47]\ttraining's l2: 0.370762\tvalid_1's l2: 0.362221\n",
      "[48]\ttraining's l2: 0.36977\tvalid_1's l2: 0.361402\n",
      "[49]\ttraining's l2: 0.368726\tvalid_1's l2: 0.360369\n",
      "[50]\ttraining's l2: 0.36774\tvalid_1's l2: 0.359439\n",
      "[51]\ttraining's l2: 0.366831\tvalid_1's l2: 0.358527\n",
      "[52]\ttraining's l2: 0.366035\tvalid_1's l2: 0.357795\n",
      "[53]\ttraining's l2: 0.365295\tvalid_1's l2: 0.357168\n",
      "[54]\ttraining's l2: 0.364556\tvalid_1's l2: 0.356448\n",
      "[55]\ttraining's l2: 0.363939\tvalid_1's l2: 0.355894\n",
      "[56]\ttraining's l2: 0.363293\tvalid_1's l2: 0.355312\n",
      "[57]\ttraining's l2: 0.362706\tvalid_1's l2: 0.354777\n",
      "[58]\ttraining's l2: 0.362132\tvalid_1's l2: 0.35421\n",
      "[59]\ttraining's l2: 0.361665\tvalid_1's l2: 0.353852\n",
      "[60]\ttraining's l2: 0.361178\tvalid_1's l2: 0.353459\n",
      "[61]\ttraining's l2: 0.36073\tvalid_1's l2: 0.353049\n",
      "[62]\ttraining's l2: 0.360289\tvalid_1's l2: 0.35262\n",
      "[63]\ttraining's l2: 0.359902\tvalid_1's l2: 0.352242\n",
      "[64]\ttraining's l2: 0.35956\tvalid_1's l2: 0.35199\n",
      "[65]\ttraining's l2: 0.359251\tvalid_1's l2: 0.351713\n",
      "[66]\ttraining's l2: 0.358924\tvalid_1's l2: 0.351494\n",
      "[67]\ttraining's l2: 0.358584\tvalid_1's l2: 0.351244\n",
      "[68]\ttraining's l2: 0.358262\tvalid_1's l2: 0.351004\n",
      "[69]\ttraining's l2: 0.357963\tvalid_1's l2: 0.350799\n",
      "[70]\ttraining's l2: 0.357695\tvalid_1's l2: 0.350605\n",
      "[71]\ttraining's l2: 0.357428\tvalid_1's l2: 0.350416\n",
      "[72]\ttraining's l2: 0.357114\tvalid_1's l2: 0.350087\n",
      "[73]\ttraining's l2: 0.356868\tvalid_1's l2: 0.349876\n",
      "[74]\ttraining's l2: 0.356572\tvalid_1's l2: 0.349645\n",
      "[75]\ttraining's l2: 0.356382\tvalid_1's l2: 0.349495\n",
      "[76]\ttraining's l2: 0.35614\tvalid_1's l2: 0.349319\n",
      "[77]\ttraining's l2: 0.355925\tvalid_1's l2: 0.349126\n",
      "[78]\ttraining's l2: 0.355699\tvalid_1's l2: 0.348947\n",
      "[79]\ttraining's l2: 0.355527\tvalid_1's l2: 0.348811\n",
      "[80]\ttraining's l2: 0.355322\tvalid_1's l2: 0.34865\n",
      "[81]\ttraining's l2: 0.35513\tvalid_1's l2: 0.348484\n",
      "[82]\ttraining's l2: 0.354906\tvalid_1's l2: 0.348283\n",
      "[83]\ttraining's l2: 0.354706\tvalid_1's l2: 0.348128\n",
      "[84]\ttraining's l2: 0.35453\tvalid_1's l2: 0.348028\n",
      "[85]\ttraining's l2: 0.35438\tvalid_1's l2: 0.347932\n",
      "[86]\ttraining's l2: 0.354187\tvalid_1's l2: 0.347753\n",
      "[87]\ttraining's l2: 0.353993\tvalid_1's l2: 0.347614\n",
      "[88]\ttraining's l2: 0.353793\tvalid_1's l2: 0.347388\n",
      "[89]\ttraining's l2: 0.353634\tvalid_1's l2: 0.34729\n",
      "[90]\ttraining's l2: 0.353444\tvalid_1's l2: 0.347113\n",
      "[91]\ttraining's l2: 0.353328\tvalid_1's l2: 0.347024\n",
      "[92]\ttraining's l2: 0.35319\tvalid_1's l2: 0.346914\n",
      "[93]\ttraining's l2: 0.353014\tvalid_1's l2: 0.346803\n",
      "[94]\ttraining's l2: 0.352892\tvalid_1's l2: 0.346754\n",
      "[95]\ttraining's l2: 0.352708\tvalid_1's l2: 0.346571\n",
      "[96]\ttraining's l2: 0.352575\tvalid_1's l2: 0.3465\n",
      "[97]\ttraining's l2: 0.352439\tvalid_1's l2: 0.346375\n",
      "[98]\ttraining's l2: 0.352313\tvalid_1's l2: 0.346262\n",
      "[99]\ttraining's l2: 0.35219\tvalid_1's l2: 0.346214\n",
      "[100]\ttraining's l2: 0.352052\tvalid_1's l2: 0.346141\n",
      "[101]\ttraining's l2: 0.351922\tvalid_1's l2: 0.34598\n",
      "[102]\ttraining's l2: 0.351776\tvalid_1's l2: 0.345856\n",
      "[103]\ttraining's l2: 0.351662\tvalid_1's l2: 0.345794\n",
      "[104]\ttraining's l2: 0.35157\tvalid_1's l2: 0.345753\n",
      "[105]\ttraining's l2: 0.35145\tvalid_1's l2: 0.34569\n",
      "[106]\ttraining's l2: 0.35135\tvalid_1's l2: 0.345641\n",
      "[107]\ttraining's l2: 0.351234\tvalid_1's l2: 0.34555\n",
      "[108]\ttraining's l2: 0.35111\tvalid_1's l2: 0.345463\n",
      "[109]\ttraining's l2: 0.351034\tvalid_1's l2: 0.345406\n",
      "[110]\ttraining's l2: 0.350924\tvalid_1's l2: 0.345285\n",
      "[111]\ttraining's l2: 0.350855\tvalid_1's l2: 0.34524\n",
      "[112]\ttraining's l2: 0.350756\tvalid_1's l2: 0.345161\n",
      "[113]\ttraining's l2: 0.350615\tvalid_1's l2: 0.345041\n",
      "[114]\ttraining's l2: 0.350541\tvalid_1's l2: 0.345016\n",
      "[115]\ttraining's l2: 0.350473\tvalid_1's l2: 0.344986\n",
      "[116]\ttraining's l2: 0.35037\tvalid_1's l2: 0.344911\n",
      "[117]\ttraining's l2: 0.350281\tvalid_1's l2: 0.344816\n",
      "[118]\ttraining's l2: 0.350205\tvalid_1's l2: 0.344791\n",
      "[119]\ttraining's l2: 0.350113\tvalid_1's l2: 0.344758\n",
      "[120]\ttraining's l2: 0.349982\tvalid_1's l2: 0.344576\n",
      "[121]\ttraining's l2: 0.349915\tvalid_1's l2: 0.344528\n",
      "[122]\ttraining's l2: 0.349832\tvalid_1's l2: 0.344458\n",
      "[123]\ttraining's l2: 0.349751\tvalid_1's l2: 0.344406\n",
      "[124]\ttraining's l2: 0.349652\tvalid_1's l2: 0.344333\n",
      "[125]\ttraining's l2: 0.349591\tvalid_1's l2: 0.344307\n",
      "[126]\ttraining's l2: 0.349495\tvalid_1's l2: 0.344215\n",
      "[127]\ttraining's l2: 0.349441\tvalid_1's l2: 0.344183\n",
      "[128]\ttraining's l2: 0.34939\tvalid_1's l2: 0.344139\n",
      "[129]\ttraining's l2: 0.349283\tvalid_1's l2: 0.344034\n",
      "[130]\ttraining's l2: 0.34915\tvalid_1's l2: 0.343847\n",
      "[131]\ttraining's l2: 0.349076\tvalid_1's l2: 0.343793\n",
      "[132]\ttraining's l2: 0.34902\tvalid_1's l2: 0.343772\n",
      "[133]\ttraining's l2: 0.348965\tvalid_1's l2: 0.343739\n",
      "[134]\ttraining's l2: 0.348883\tvalid_1's l2: 0.343686\n",
      "[135]\ttraining's l2: 0.348834\tvalid_1's l2: 0.343648\n",
      "[136]\ttraining's l2: 0.348762\tvalid_1's l2: 0.343589\n",
      "[137]\ttraining's l2: 0.348668\tvalid_1's l2: 0.343533\n",
      "[138]\ttraining's l2: 0.348554\tvalid_1's l2: 0.343407\n",
      "[139]\ttraining's l2: 0.348462\tvalid_1's l2: 0.343279\n",
      "[140]\ttraining's l2: 0.34842\tvalid_1's l2: 0.343247\n",
      "[141]\ttraining's l2: 0.348363\tvalid_1's l2: 0.343226\n",
      "[142]\ttraining's l2: 0.348308\tvalid_1's l2: 0.343183\n",
      "[143]\ttraining's l2: 0.34819\tvalid_1's l2: 0.343065\n",
      "[144]\ttraining's l2: 0.348136\tvalid_1's l2: 0.34304\n",
      "[145]\ttraining's l2: 0.348093\tvalid_1's l2: 0.342998\n",
      "[146]\ttraining's l2: 0.348026\tvalid_1's l2: 0.342948\n",
      "[147]\ttraining's l2: 0.347935\tvalid_1's l2: 0.342834\n",
      "[148]\ttraining's l2: 0.347883\tvalid_1's l2: 0.342832\n",
      "[149]\ttraining's l2: 0.347786\tvalid_1's l2: 0.342774\n",
      "[150]\ttraining's l2: 0.347752\tvalid_1's l2: 0.342746\n",
      "[151]\ttraining's l2: 0.347698\tvalid_1's l2: 0.342725\n",
      "[152]\ttraining's l2: 0.347651\tvalid_1's l2: 0.342695\n",
      "[153]\ttraining's l2: 0.347609\tvalid_1's l2: 0.342673\n",
      "[154]\ttraining's l2: 0.347543\tvalid_1's l2: 0.342635\n",
      "[155]\ttraining's l2: 0.347457\tvalid_1's l2: 0.342468\n",
      "[156]\ttraining's l2: 0.347378\tvalid_1's l2: 0.342415\n",
      "[157]\ttraining's l2: 0.347299\tvalid_1's l2: 0.342312\n",
      "[158]\ttraining's l2: 0.347241\tvalid_1's l2: 0.342294\n",
      "[159]\ttraining's l2: 0.347165\tvalid_1's l2: 0.342205\n",
      "[160]\ttraining's l2: 0.347121\tvalid_1's l2: 0.342197\n",
      "[161]\ttraining's l2: 0.347072\tvalid_1's l2: 0.342179\n",
      "[162]\ttraining's l2: 0.347019\tvalid_1's l2: 0.342138\n",
      "[163]\ttraining's l2: 0.34696\tvalid_1's l2: 0.342101\n",
      "[164]\ttraining's l2: 0.346905\tvalid_1's l2: 0.342081\n",
      "[165]\ttraining's l2: 0.346824\tvalid_1's l2: 0.341946\n",
      "[166]\ttraining's l2: 0.346785\tvalid_1's l2: 0.341925\n",
      "[167]\ttraining's l2: 0.346744\tvalid_1's l2: 0.341886\n",
      "[168]\ttraining's l2: 0.346705\tvalid_1's l2: 0.34187\n",
      "[169]\ttraining's l2: 0.346668\tvalid_1's l2: 0.341851\n",
      "[170]\ttraining's l2: 0.346641\tvalid_1's l2: 0.341841\n",
      "[171]\ttraining's l2: 0.346608\tvalid_1's l2: 0.34183\n",
      "[172]\ttraining's l2: 0.346572\tvalid_1's l2: 0.34182\n",
      "[173]\ttraining's l2: 0.346541\tvalid_1's l2: 0.341808\n",
      "[174]\ttraining's l2: 0.346504\tvalid_1's l2: 0.341796\n",
      "[175]\ttraining's l2: 0.346477\tvalid_1's l2: 0.341769\n",
      "[176]\ttraining's l2: 0.34642\tvalid_1's l2: 0.341754\n",
      "[177]\ttraining's l2: 0.346368\tvalid_1's l2: 0.341698\n",
      "[178]\ttraining's l2: 0.346316\tvalid_1's l2: 0.341633\n",
      "[179]\ttraining's l2: 0.346289\tvalid_1's l2: 0.341604\n",
      "[180]\ttraining's l2: 0.34622\tvalid_1's l2: 0.341561\n",
      "[181]\ttraining's l2: 0.346168\tvalid_1's l2: 0.341544\n",
      "[182]\ttraining's l2: 0.346119\tvalid_1's l2: 0.341485\n",
      "[183]\ttraining's l2: 0.34607\tvalid_1's l2: 0.341436\n",
      "[184]\ttraining's l2: 0.346021\tvalid_1's l2: 0.341418\n",
      "[185]\ttraining's l2: 0.345967\tvalid_1's l2: 0.341373\n",
      "[186]\ttraining's l2: 0.345933\tvalid_1's l2: 0.341348\n",
      "[187]\ttraining's l2: 0.34588\tvalid_1's l2: 0.341322\n",
      "[188]\ttraining's l2: 0.345842\tvalid_1's l2: 0.341317\n",
      "[189]\ttraining's l2: 0.345798\tvalid_1's l2: 0.341299\n",
      "[190]\ttraining's l2: 0.345744\tvalid_1's l2: 0.341244\n",
      "[191]\ttraining's l2: 0.34569\tvalid_1's l2: 0.341208\n",
      "[192]\ttraining's l2: 0.345667\tvalid_1's l2: 0.341203\n",
      "[193]\ttraining's l2: 0.34563\tvalid_1's l2: 0.341176\n",
      "[194]\ttraining's l2: 0.34558\tvalid_1's l2: 0.341134\n",
      "[195]\ttraining's l2: 0.345549\tvalid_1's l2: 0.341127\n",
      "[196]\ttraining's l2: 0.345516\tvalid_1's l2: 0.341097\n",
      "[197]\ttraining's l2: 0.34546\tvalid_1's l2: 0.341036\n",
      "[198]\ttraining's l2: 0.345418\tvalid_1's l2: 0.341006\n",
      "[199]\ttraining's l2: 0.345385\tvalid_1's l2: 0.341007\n",
      "[200]\ttraining's l2: 0.345334\tvalid_1's l2: 0.340986\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.345334\tvalid_1's l2: 0.340986\n",
      "mean_14_sales: 12357583.42\n",
      "mean_5_sales: 4190143.71\n",
      "mean_6_sales: 3751173.28\n",
      "mean_21_sales: 2877641.85\n",
      "mean_30_sales: 2280591.71\n",
      "mean_7_sales: 1167495.12\n",
      "mean_4_dow3_2017: 1064081.22\n",
      "mean_20_dow3_2017: 1017500.91\n",
      "promo_3: 478956.73\n",
      "mean_60_sales: 335925.70\n",
      "mean_4_sales: 289830.26\n",
      "item_class_features: 202474.98\n",
      "std_14_sales: 133688.75\n",
      "mean_4_dow4_2017: 110167.28\n",
      "sum_4_promo: 100828.13\n",
      "mean_63_sales: 97541.28\n",
      "std_21_sales: 43431.10\n",
      "promo_7: 37072.61\n",
      "mean_3_sales: 36789.72\n",
      "store_cluster_features: 35389.14\n",
      "lag_1_sales: 30241.77\n",
      "promo_5: 28204.75\n",
      "std_30_sales: 27264.30\n",
      "sum_2_promo: 25673.46\n",
      "std_7_sales: 25331.23\n",
      "store_city_features: 25032.43\n",
      "std_6_sales: 23892.75\n",
      "lag_3_sales: 19959.48\n",
      "promo_4: 19871.19\n",
      "promo_2: 19334.46\n",
      "item_family_features: 15886.50\n",
      "lag_4_sales: 14931.06\n",
      "promo_0: 14846.47\n",
      "promo_6: 12748.67\n",
      "sum_3_promo: 12391.61\n",
      "sum_14_promo: 11817.26\n",
      "mean_20_dow0_2017: 11115.77\n",
      "std_60_sales: 10929.82\n",
      "std_5_sales: 10842.38\n",
      "std_63_sales: 10210.90\n",
      "lag_28_sales: 9245.38\n",
      "promo_1: 8899.69\n",
      "sum_6_promo: 8845.82\n",
      "lag_56_sales: 8036.62\n",
      "std_4_sales: 7874.35\n",
      "sum_7_promo: 7746.32\n",
      "promo_14: 7629.83\n",
      "sum_21_promo: 7217.25\n",
      "sum_5_promo: 6765.54\n",
      "store_type_features: 5038.54\n",
      "promo_10: 3989.91\n",
      "mean_20_dow2_2017: 3701.13\n",
      "mean_4_dow0_2017: 3325.09\n",
      "store_state_features: 3133.33\n",
      "mean_4_dow1_2017: 2935.45\n",
      "mean_20_dow1_2017: 2879.76\n",
      "lag_5_sales: 2489.89\n",
      "mean_20_dow4_2017: 2375.60\n",
      "promo_8: 2134.89\n",
      "lag_6_sales: 1763.65\n",
      "promo_9: 1635.91\n",
      "mean_20_dow5_2017: 1370.43\n",
      "mean_4_dow6_2017: 1336.02\n",
      "mean_4_dow2_2017: 1269.20\n",
      "mean_20_dow6_2017: 1142.07\n",
      "lag_2_sales: 1016.08\n",
      "promo_13: 959.63\n",
      "lag_14_sales: 958.56\n",
      "std_3_sales: 868.82\n",
      "lag_35_sales: 772.15\n",
      "lag_42_sales: 598.71\n",
      "mean_4_dow5_2017: 595.00\n",
      "lag_63_sales: 476.39\n",
      "promo_11: 402.50\n",
      "lag_21_sales: 341.42\n",
      "lag_49_sales: 323.74\n",
      "lag_7_sales: 86.43\n",
      "promo_15: 74.02\n",
      "promo_12: 60.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [06:02<18:07, 90.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.23175\tvalid_1's l2: 1.22124\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.15105\tvalid_1's l2: 1.13902\n",
      "[3]\ttraining's l2: 1.07797\tvalid_1's l2: 1.06504\n",
      "[4]\ttraining's l2: 1.01255\tvalid_1's l2: 0.998784\n",
      "[5]\ttraining's l2: 0.952821\tvalid_1's l2: 0.93777\n",
      "[6]\ttraining's l2: 0.898628\tvalid_1's l2: 0.883111\n",
      "[7]\ttraining's l2: 0.850085\tvalid_1's l2: 0.834468\n",
      "[8]\ttraining's l2: 0.805648\tvalid_1's l2: 0.789558\n",
      "[9]\ttraining's l2: 0.765296\tvalid_1's l2: 0.748775\n",
      "[10]\ttraining's l2: 0.728793\tvalid_1's l2: 0.712303\n",
      "[11]\ttraining's l2: 0.695795\tvalid_1's l2: 0.679277\n",
      "[12]\ttraining's l2: 0.666066\tvalid_1's l2: 0.649413\n",
      "[13]\ttraining's l2: 0.638947\tvalid_1's l2: 0.622355\n",
      "[14]\ttraining's l2: 0.614221\tvalid_1's l2: 0.597391\n",
      "[15]\ttraining's l2: 0.592184\tvalid_1's l2: 0.575397\n",
      "[16]\ttraining's l2: 0.572355\tvalid_1's l2: 0.555769\n",
      "[17]\ttraining's l2: 0.554234\tvalid_1's l2: 0.537699\n",
      "[18]\ttraining's l2: 0.537537\tvalid_1's l2: 0.521475\n",
      "[19]\ttraining's l2: 0.522464\tvalid_1's l2: 0.506589\n",
      "[20]\ttraining's l2: 0.50884\tvalid_1's l2: 0.493035\n",
      "[21]\ttraining's l2: 0.496656\tvalid_1's l2: 0.481068\n",
      "[22]\ttraining's l2: 0.485196\tvalid_1's l2: 0.469484\n",
      "[23]\ttraining's l2: 0.474718\tvalid_1's l2: 0.458942\n",
      "[24]\ttraining's l2: 0.465249\tvalid_1's l2: 0.449414\n",
      "[25]\ttraining's l2: 0.456902\tvalid_1's l2: 0.441294\n",
      "[26]\ttraining's l2: 0.448989\tvalid_1's l2: 0.433409\n",
      "[27]\ttraining's l2: 0.442062\tvalid_1's l2: 0.426752\n",
      "[28]\ttraining's l2: 0.435539\tvalid_1's l2: 0.420336\n",
      "[29]\ttraining's l2: 0.429718\tvalid_1's l2: 0.414669\n",
      "[30]\ttraining's l2: 0.424563\tvalid_1's l2: 0.409858\n",
      "[31]\ttraining's l2: 0.419689\tvalid_1's l2: 0.405149\n",
      "[32]\ttraining's l2: 0.415205\tvalid_1's l2: 0.400651\n",
      "[33]\ttraining's l2: 0.411277\tvalid_1's l2: 0.396908\n",
      "[34]\ttraining's l2: 0.407452\tvalid_1's l2: 0.393095\n",
      "[35]\ttraining's l2: 0.404045\tvalid_1's l2: 0.38986\n",
      "[36]\ttraining's l2: 0.400944\tvalid_1's l2: 0.386836\n",
      "[37]\ttraining's l2: 0.398122\tvalid_1's l2: 0.384103\n",
      "[38]\ttraining's l2: 0.395522\tvalid_1's l2: 0.381587\n",
      "[39]\ttraining's l2: 0.393167\tvalid_1's l2: 0.379465\n",
      "[40]\ttraining's l2: 0.39095\tvalid_1's l2: 0.377299\n",
      "[41]\ttraining's l2: 0.389028\tvalid_1's l2: 0.375557\n",
      "[42]\ttraining's l2: 0.387116\tvalid_1's l2: 0.373756\n",
      "[43]\ttraining's l2: 0.385426\tvalid_1's l2: 0.372202\n",
      "[44]\ttraining's l2: 0.383848\tvalid_1's l2: 0.370663\n",
      "[45]\ttraining's l2: 0.382391\tvalid_1's l2: 0.369296\n",
      "[46]\ttraining's l2: 0.381167\tvalid_1's l2: 0.368237\n",
      "[47]\ttraining's l2: 0.380029\tvalid_1's l2: 0.367266\n",
      "[48]\ttraining's l2: 0.378797\tvalid_1's l2: 0.366071\n",
      "[49]\ttraining's l2: 0.377757\tvalid_1's l2: 0.365127\n",
      "[50]\ttraining's l2: 0.376841\tvalid_1's l2: 0.364384\n",
      "[51]\ttraining's l2: 0.375823\tvalid_1's l2: 0.363395\n",
      "[52]\ttraining's l2: 0.374947\tvalid_1's l2: 0.362608\n",
      "[53]\ttraining's l2: 0.374134\tvalid_1's l2: 0.361853\n",
      "[54]\ttraining's l2: 0.373445\tvalid_1's l2: 0.361259\n",
      "[55]\ttraining's l2: 0.372798\tvalid_1's l2: 0.360727\n",
      "[56]\ttraining's l2: 0.372152\tvalid_1's l2: 0.360227\n",
      "[57]\ttraining's l2: 0.3715\tvalid_1's l2: 0.359577\n",
      "[58]\ttraining's l2: 0.370853\tvalid_1's l2: 0.358986\n",
      "[59]\ttraining's l2: 0.370344\tvalid_1's l2: 0.358546\n",
      "[60]\ttraining's l2: 0.36985\tvalid_1's l2: 0.358115\n",
      "[61]\ttraining's l2: 0.369352\tvalid_1's l2: 0.357714\n",
      "[62]\ttraining's l2: 0.368908\tvalid_1's l2: 0.357396\n",
      "[63]\ttraining's l2: 0.368536\tvalid_1's l2: 0.357081\n",
      "[64]\ttraining's l2: 0.368161\tvalid_1's l2: 0.356734\n",
      "[65]\ttraining's l2: 0.367746\tvalid_1's l2: 0.356332\n",
      "[66]\ttraining's l2: 0.367427\tvalid_1's l2: 0.356118\n",
      "[67]\ttraining's l2: 0.367088\tvalid_1's l2: 0.355888\n",
      "[68]\ttraining's l2: 0.366768\tvalid_1's l2: 0.355693\n",
      "[69]\ttraining's l2: 0.366436\tvalid_1's l2: 0.355393\n",
      "[70]\ttraining's l2: 0.36611\tvalid_1's l2: 0.355125\n",
      "[71]\ttraining's l2: 0.36571\tvalid_1's l2: 0.35473\n",
      "[72]\ttraining's l2: 0.365343\tvalid_1's l2: 0.354356\n",
      "[73]\ttraining's l2: 0.365042\tvalid_1's l2: 0.354147\n",
      "[74]\ttraining's l2: 0.36477\tvalid_1's l2: 0.353873\n",
      "[75]\ttraining's l2: 0.364421\tvalid_1's l2: 0.353532\n",
      "[76]\ttraining's l2: 0.364141\tvalid_1's l2: 0.353326\n",
      "[77]\ttraining's l2: 0.363901\tvalid_1's l2: 0.353126\n",
      "[78]\ttraining's l2: 0.363642\tvalid_1's l2: 0.35289\n",
      "[79]\ttraining's l2: 0.363388\tvalid_1's l2: 0.352709\n",
      "[80]\ttraining's l2: 0.363163\tvalid_1's l2: 0.352531\n",
      "[81]\ttraining's l2: 0.362945\tvalid_1's l2: 0.352329\n",
      "[82]\ttraining's l2: 0.362748\tvalid_1's l2: 0.35216\n",
      "[83]\ttraining's l2: 0.362511\tvalid_1's l2: 0.351942\n",
      "[84]\ttraining's l2: 0.362345\tvalid_1's l2: 0.351851\n",
      "[85]\ttraining's l2: 0.362106\tvalid_1's l2: 0.351651\n",
      "[86]\ttraining's l2: 0.36192\tvalid_1's l2: 0.351495\n",
      "[87]\ttraining's l2: 0.361718\tvalid_1's l2: 0.351377\n",
      "[88]\ttraining's l2: 0.361529\tvalid_1's l2: 0.351212\n",
      "[89]\ttraining's l2: 0.361362\tvalid_1's l2: 0.351111\n",
      "[90]\ttraining's l2: 0.361139\tvalid_1's l2: 0.350921\n",
      "[91]\ttraining's l2: 0.360996\tvalid_1's l2: 0.350824\n",
      "[92]\ttraining's l2: 0.360841\tvalid_1's l2: 0.350715\n",
      "[93]\ttraining's l2: 0.360653\tvalid_1's l2: 0.350592\n",
      "[94]\ttraining's l2: 0.36053\tvalid_1's l2: 0.350483\n",
      "[95]\ttraining's l2: 0.360348\tvalid_1's l2: 0.350362\n",
      "[96]\ttraining's l2: 0.360197\tvalid_1's l2: 0.350271\n",
      "[97]\ttraining's l2: 0.360056\tvalid_1's l2: 0.350125\n",
      "[98]\ttraining's l2: 0.359913\tvalid_1's l2: 0.350013\n",
      "[99]\ttraining's l2: 0.359798\tvalid_1's l2: 0.349905\n",
      "[100]\ttraining's l2: 0.359577\tvalid_1's l2: 0.349659\n",
      "[101]\ttraining's l2: 0.359417\tvalid_1's l2: 0.349482\n",
      "[102]\ttraining's l2: 0.359287\tvalid_1's l2: 0.349383\n",
      "[103]\ttraining's l2: 0.359156\tvalid_1's l2: 0.349283\n",
      "[104]\ttraining's l2: 0.359035\tvalid_1's l2: 0.349198\n",
      "[105]\ttraining's l2: 0.358904\tvalid_1's l2: 0.349152\n",
      "[106]\ttraining's l2: 0.358789\tvalid_1's l2: 0.349056\n",
      "[107]\ttraining's l2: 0.358618\tvalid_1's l2: 0.348857\n",
      "[108]\ttraining's l2: 0.358469\tvalid_1's l2: 0.348696\n",
      "[109]\ttraining's l2: 0.358361\tvalid_1's l2: 0.348561\n",
      "[110]\ttraining's l2: 0.358247\tvalid_1's l2: 0.34851\n",
      "[111]\ttraining's l2: 0.358161\tvalid_1's l2: 0.34844\n",
      "[112]\ttraining's l2: 0.357993\tvalid_1's l2: 0.348297\n",
      "[113]\ttraining's l2: 0.357895\tvalid_1's l2: 0.348218\n",
      "[114]\ttraining's l2: 0.357725\tvalid_1's l2: 0.34807\n",
      "[115]\ttraining's l2: 0.357653\tvalid_1's l2: 0.348037\n",
      "[116]\ttraining's l2: 0.357552\tvalid_1's l2: 0.347942\n",
      "[117]\ttraining's l2: 0.357424\tvalid_1's l2: 0.347825\n",
      "[118]\ttraining's l2: 0.35732\tvalid_1's l2: 0.347708\n",
      "[119]\ttraining's l2: 0.357191\tvalid_1's l2: 0.347549\n",
      "[120]\ttraining's l2: 0.357042\tvalid_1's l2: 0.347393\n",
      "[121]\ttraining's l2: 0.356908\tvalid_1's l2: 0.347309\n",
      "[122]\ttraining's l2: 0.356795\tvalid_1's l2: 0.347193\n",
      "[123]\ttraining's l2: 0.356738\tvalid_1's l2: 0.34715\n",
      "[124]\ttraining's l2: 0.356681\tvalid_1's l2: 0.347104\n",
      "[125]\ttraining's l2: 0.356622\tvalid_1's l2: 0.347064\n",
      "[126]\ttraining's l2: 0.356527\tvalid_1's l2: 0.347001\n",
      "[127]\ttraining's l2: 0.356472\tvalid_1's l2: 0.346965\n",
      "[128]\ttraining's l2: 0.356352\tvalid_1's l2: 0.34687\n",
      "[129]\ttraining's l2: 0.356303\tvalid_1's l2: 0.346836\n",
      "[130]\ttraining's l2: 0.356233\tvalid_1's l2: 0.34679\n",
      "[131]\ttraining's l2: 0.356108\tvalid_1's l2: 0.346614\n",
      "[132]\ttraining's l2: 0.356029\tvalid_1's l2: 0.346581\n",
      "[133]\ttraining's l2: 0.355958\tvalid_1's l2: 0.34653\n",
      "[134]\ttraining's l2: 0.355891\tvalid_1's l2: 0.346504\n",
      "[135]\ttraining's l2: 0.355816\tvalid_1's l2: 0.346482\n",
      "[136]\ttraining's l2: 0.355702\tvalid_1's l2: 0.346375\n",
      "[137]\ttraining's l2: 0.355582\tvalid_1's l2: 0.346294\n",
      "[138]\ttraining's l2: 0.355469\tvalid_1's l2: 0.346219\n",
      "[139]\ttraining's l2: 0.355415\tvalid_1's l2: 0.346189\n",
      "[140]\ttraining's l2: 0.355335\tvalid_1's l2: 0.346125\n",
      "[141]\ttraining's l2: 0.355237\tvalid_1's l2: 0.346069\n",
      "[142]\ttraining's l2: 0.355181\tvalid_1's l2: 0.34603\n",
      "[143]\ttraining's l2: 0.355109\tvalid_1's l2: 0.345991\n",
      "[144]\ttraining's l2: 0.354994\tvalid_1's l2: 0.345891\n",
      "[145]\ttraining's l2: 0.354936\tvalid_1's l2: 0.345826\n",
      "[146]\ttraining's l2: 0.354883\tvalid_1's l2: 0.345797\n",
      "[147]\ttraining's l2: 0.354808\tvalid_1's l2: 0.345713\n",
      "[148]\ttraining's l2: 0.354722\tvalid_1's l2: 0.34567\n",
      "[149]\ttraining's l2: 0.354618\tvalid_1's l2: 0.345571\n",
      "[150]\ttraining's l2: 0.354555\tvalid_1's l2: 0.345557\n",
      "[151]\ttraining's l2: 0.354486\tvalid_1's l2: 0.345499\n",
      "[152]\ttraining's l2: 0.35442\tvalid_1's l2: 0.345463\n",
      "[153]\ttraining's l2: 0.354358\tvalid_1's l2: 0.345428\n",
      "[154]\ttraining's l2: 0.354298\tvalid_1's l2: 0.345394\n",
      "[155]\ttraining's l2: 0.354215\tvalid_1's l2: 0.345297\n",
      "[156]\ttraining's l2: 0.354148\tvalid_1's l2: 0.345257\n",
      "[157]\ttraining's l2: 0.35408\tvalid_1's l2: 0.345225\n",
      "[158]\ttraining's l2: 0.354037\tvalid_1's l2: 0.345174\n",
      "[159]\ttraining's l2: 0.354001\tvalid_1's l2: 0.345141\n",
      "[160]\ttraining's l2: 0.353958\tvalid_1's l2: 0.345142\n",
      "[161]\ttraining's l2: 0.353914\tvalid_1's l2: 0.345133\n",
      "[162]\ttraining's l2: 0.353836\tvalid_1's l2: 0.345091\n",
      "[163]\ttraining's l2: 0.353775\tvalid_1's l2: 0.345064\n",
      "[164]\ttraining's l2: 0.353728\tvalid_1's l2: 0.345028\n",
      "[165]\ttraining's l2: 0.353699\tvalid_1's l2: 0.344996\n",
      "[166]\ttraining's l2: 0.353663\tvalid_1's l2: 0.344966\n",
      "[167]\ttraining's l2: 0.353591\tvalid_1's l2: 0.344918\n",
      "[168]\ttraining's l2: 0.353539\tvalid_1's l2: 0.344905\n",
      "[169]\ttraining's l2: 0.353463\tvalid_1's l2: 0.344856\n",
      "[170]\ttraining's l2: 0.35338\tvalid_1's l2: 0.344744\n",
      "[171]\ttraining's l2: 0.353332\tvalid_1's l2: 0.344713\n",
      "[172]\ttraining's l2: 0.353286\tvalid_1's l2: 0.344689\n",
      "[173]\ttraining's l2: 0.35323\tvalid_1's l2: 0.344643\n",
      "[174]\ttraining's l2: 0.353179\tvalid_1's l2: 0.344625\n",
      "[175]\ttraining's l2: 0.353141\tvalid_1's l2: 0.344604\n",
      "[176]\ttraining's l2: 0.353089\tvalid_1's l2: 0.344584\n",
      "[177]\ttraining's l2: 0.353023\tvalid_1's l2: 0.344484\n",
      "[178]\ttraining's l2: 0.352979\tvalid_1's l2: 0.344468\n",
      "[179]\ttraining's l2: 0.352949\tvalid_1's l2: 0.344454\n",
      "[180]\ttraining's l2: 0.35291\tvalid_1's l2: 0.344427\n",
      "[181]\ttraining's l2: 0.35285\tvalid_1's l2: 0.344405\n",
      "[182]\ttraining's l2: 0.352802\tvalid_1's l2: 0.34438\n",
      "[183]\ttraining's l2: 0.352768\tvalid_1's l2: 0.344354\n",
      "[184]\ttraining's l2: 0.352732\tvalid_1's l2: 0.344324\n",
      "[185]\ttraining's l2: 0.3527\tvalid_1's l2: 0.344302\n",
      "[186]\ttraining's l2: 0.352642\tvalid_1's l2: 0.344271\n",
      "[187]\ttraining's l2: 0.352602\tvalid_1's l2: 0.344259\n",
      "[188]\ttraining's l2: 0.35254\tvalid_1's l2: 0.344231\n",
      "[189]\ttraining's l2: 0.352512\tvalid_1's l2: 0.344204\n",
      "[190]\ttraining's l2: 0.352471\tvalid_1's l2: 0.344168\n",
      "[191]\ttraining's l2: 0.352426\tvalid_1's l2: 0.344141\n",
      "[192]\ttraining's l2: 0.352386\tvalid_1's l2: 0.344103\n",
      "[193]\ttraining's l2: 0.352342\tvalid_1's l2: 0.344084\n",
      "[194]\ttraining's l2: 0.352291\tvalid_1's l2: 0.34403\n",
      "[195]\ttraining's l2: 0.352249\tvalid_1's l2: 0.344009\n",
      "[196]\ttraining's l2: 0.352188\tvalid_1's l2: 0.343976\n",
      "[197]\ttraining's l2: 0.352127\tvalid_1's l2: 0.343929\n",
      "[198]\ttraining's l2: 0.352085\tvalid_1's l2: 0.343903\n",
      "[199]\ttraining's l2: 0.35204\tvalid_1's l2: 0.343869\n",
      "[200]\ttraining's l2: 0.351988\tvalid_1's l2: 0.343857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.351988\tvalid_1's l2: 0.343857\n",
      "mean_14_sales: 9959423.01\n",
      "mean_4_dow4_2017: 4298546.59\n",
      "mean_4_sales: 4206819.04\n",
      "mean_5_sales: 3381683.99\n",
      "mean_21_sales: 2966626.02\n",
      "mean_30_sales: 2149723.64\n",
      "mean_20_dow4_2017: 1759475.94\n",
      "mean_6_sales: 998524.85\n",
      "mean_7_sales: 669891.76\n",
      "promo_4: 490220.22\n",
      "item_class_features: 217704.46\n",
      "mean_60_sales: 155159.63\n",
      "sum_3_promo: 121494.08\n",
      "mean_3_sales: 121039.04\n",
      "std_14_sales: 105913.79\n",
      "store_cluster_features: 72900.87\n",
      "lag_3_sales: 63270.70\n",
      "std_21_sales: 59168.18\n",
      "mean_4_dow3_2017: 54811.70\n",
      "promo_7: 48093.08\n",
      "store_city_features: 36600.96\n",
      "promo_3: 32871.52\n",
      "lag_1_sales: 28303.59\n",
      "promo_5: 26630.54\n",
      "item_family_features: 22884.75\n",
      "sum_2_promo: 22520.60\n",
      "sum_4_promo: 19347.51\n",
      "std_30_sales: 18481.13\n",
      "promo_6: 18045.56\n",
      "promo_11: 17345.61\n",
      "mean_20_dow0_2017: 16122.51\n",
      "store_type_features: 14218.51\n",
      "promo_2: 13761.13\n",
      "promo_1: 13138.00\n",
      "std_60_sales: 11535.30\n",
      "mean_63_sales: 10760.03\n",
      "sum_7_promo: 10738.62\n",
      "mean_20_dow3_2017: 10559.56\n",
      "promo_14: 10426.75\n",
      "sum_14_promo: 9761.95\n",
      "promo_0: 9170.60\n",
      "std_4_sales: 8723.74\n",
      "std_5_sales: 8631.63\n",
      "std_63_sales: 8523.59\n",
      "std_6_sales: 7173.80\n",
      "lag_4_sales: 5890.74\n",
      "mean_20_dow2_2017: 5649.06\n",
      "mean_20_dow1_2017: 4935.27\n",
      "sum_21_promo: 4657.49\n",
      "std_7_sales: 4616.87\n",
      "std_3_sales: 3168.79\n",
      "mean_20_dow6_2017: 2711.12\n",
      "mean_4_dow0_2017: 2535.93\n",
      "lag_28_sales: 2432.42\n",
      "store_state_features: 2372.26\n",
      "promo_13: 2347.48\n",
      "lag_6_sales: 2265.70\n",
      "lag_2_sales: 2137.56\n",
      "sum_5_promo: 2034.38\n",
      "lag_5_sales: 1966.16\n",
      "mean_4_dow6_2017: 1875.61\n",
      "promo_8: 1827.64\n",
      "promo_12: 1796.33\n",
      "sum_6_promo: 1245.45\n",
      "promo_9: 1226.07\n",
      "promo_10: 1062.70\n",
      "mean_4_dow2_2017: 1054.03\n",
      "mean_4_dow1_2017: 1019.58\n",
      "lag_14_sales: 983.19\n",
      "lag_49_sales: 852.22\n",
      "lag_63_sales: 742.11\n",
      "mean_4_dow5_2017: 648.81\n",
      "mean_20_dow5_2017: 606.83\n",
      "lag_7_sales: 545.35\n",
      "lag_21_sales: 484.03\n",
      "lag_42_sales: 364.09\n",
      "lag_56_sales: 244.89\n",
      "lag_35_sales: 169.50\n",
      "promo_15: 147.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [07:29<16:26, 89.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.06252\tvalid_1's l2: 1.09768\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.997663\tvalid_1's l2: 1.03097\n",
      "[3]\ttraining's l2: 0.938964\tvalid_1's l2: 0.970305\n",
      "[4]\ttraining's l2: 0.88597\tvalid_1's l2: 0.915206\n",
      "[5]\ttraining's l2: 0.837951\tvalid_1's l2: 0.865389\n",
      "[6]\ttraining's l2: 0.794399\tvalid_1's l2: 0.820085\n",
      "[7]\ttraining's l2: 0.755152\tvalid_1's l2: 0.779093\n",
      "[8]\ttraining's l2: 0.719509\tvalid_1's l2: 0.741806\n",
      "[9]\ttraining's l2: 0.68727\tvalid_1's l2: 0.708251\n",
      "[10]\ttraining's l2: 0.658343\tvalid_1's l2: 0.67787\n",
      "[11]\ttraining's l2: 0.632285\tvalid_1's l2: 0.650537\n",
      "[12]\ttraining's l2: 0.608568\tvalid_1's l2: 0.625692\n",
      "[13]\ttraining's l2: 0.586662\tvalid_1's l2: 0.602527\n",
      "[14]\ttraining's l2: 0.566771\tvalid_1's l2: 0.581476\n",
      "[15]\ttraining's l2: 0.548816\tvalid_1's l2: 0.562416\n",
      "[16]\ttraining's l2: 0.532873\tvalid_1's l2: 0.545402\n",
      "[17]\ttraining's l2: 0.518407\tvalid_1's l2: 0.529991\n",
      "[18]\ttraining's l2: 0.504865\tvalid_1's l2: 0.515485\n",
      "[19]\ttraining's l2: 0.492654\tvalid_1's l2: 0.502314\n",
      "[20]\ttraining's l2: 0.481621\tvalid_1's l2: 0.490313\n",
      "[21]\ttraining's l2: 0.471619\tvalid_1's l2: 0.47942\n",
      "[22]\ttraining's l2: 0.462534\tvalid_1's l2: 0.469363\n",
      "[23]\ttraining's l2: 0.454426\tvalid_1's l2: 0.460607\n",
      "[24]\ttraining's l2: 0.446898\tvalid_1's l2: 0.452324\n",
      "[25]\ttraining's l2: 0.440024\tvalid_1's l2: 0.444748\n",
      "[26]\ttraining's l2: 0.433949\tvalid_1's l2: 0.438088\n",
      "[27]\ttraining's l2: 0.428274\tvalid_1's l2: 0.43179\n",
      "[28]\ttraining's l2: 0.4231\tvalid_1's l2: 0.425968\n",
      "[29]\ttraining's l2: 0.418548\tvalid_1's l2: 0.420962\n",
      "[30]\ttraining's l2: 0.414205\tvalid_1's l2: 0.416054\n",
      "[31]\ttraining's l2: 0.410322\tvalid_1's l2: 0.411618\n",
      "[32]\ttraining's l2: 0.406879\tvalid_1's l2: 0.407791\n",
      "[33]\ttraining's l2: 0.403753\tvalid_1's l2: 0.404256\n",
      "[34]\ttraining's l2: 0.40078\tvalid_1's l2: 0.400815\n",
      "[35]\ttraining's l2: 0.398167\tvalid_1's l2: 0.397793\n",
      "[36]\ttraining's l2: 0.395609\tvalid_1's l2: 0.394721\n",
      "[37]\ttraining's l2: 0.393336\tvalid_1's l2: 0.391996\n",
      "[38]\ttraining's l2: 0.391211\tvalid_1's l2: 0.389449\n",
      "[39]\ttraining's l2: 0.389302\tvalid_1's l2: 0.38715\n",
      "[40]\ttraining's l2: 0.387615\tvalid_1's l2: 0.385194\n",
      "[41]\ttraining's l2: 0.386099\tvalid_1's l2: 0.383392\n",
      "[42]\ttraining's l2: 0.384692\tvalid_1's l2: 0.381699\n",
      "[43]\ttraining's l2: 0.383301\tvalid_1's l2: 0.379948\n",
      "[44]\ttraining's l2: 0.38211\tvalid_1's l2: 0.378524\n",
      "[45]\ttraining's l2: 0.381017\tvalid_1's l2: 0.37721\n",
      "[46]\ttraining's l2: 0.379857\tvalid_1's l2: 0.375705\n",
      "[47]\ttraining's l2: 0.378834\tvalid_1's l2: 0.374362\n",
      "[48]\ttraining's l2: 0.377892\tvalid_1's l2: 0.373166\n",
      "[49]\ttraining's l2: 0.376979\tvalid_1's l2: 0.371991\n",
      "[50]\ttraining's l2: 0.376175\tvalid_1's l2: 0.370931\n",
      "[51]\ttraining's l2: 0.375409\tvalid_1's l2: 0.369942\n",
      "[52]\ttraining's l2: 0.374762\tvalid_1's l2: 0.369194\n",
      "[53]\ttraining's l2: 0.374128\tvalid_1's l2: 0.368445\n",
      "[54]\ttraining's l2: 0.373481\tvalid_1's l2: 0.367615\n",
      "[55]\ttraining's l2: 0.372877\tvalid_1's l2: 0.366831\n",
      "[56]\ttraining's l2: 0.372319\tvalid_1's l2: 0.366118\n",
      "[57]\ttraining's l2: 0.37181\tvalid_1's l2: 0.365441\n",
      "[58]\ttraining's l2: 0.371305\tvalid_1's l2: 0.364736\n",
      "[59]\ttraining's l2: 0.370872\tvalid_1's l2: 0.364213\n",
      "[60]\ttraining's l2: 0.370499\tvalid_1's l2: 0.363755\n",
      "[61]\ttraining's l2: 0.370143\tvalid_1's l2: 0.363332\n",
      "[62]\ttraining's l2: 0.369753\tvalid_1's l2: 0.362827\n",
      "[63]\ttraining's l2: 0.369383\tvalid_1's l2: 0.362272\n",
      "[64]\ttraining's l2: 0.369101\tvalid_1's l2: 0.361916\n",
      "[65]\ttraining's l2: 0.368774\tvalid_1's l2: 0.361494\n",
      "[66]\ttraining's l2: 0.368499\tvalid_1's l2: 0.361116\n",
      "[67]\ttraining's l2: 0.368215\tvalid_1's l2: 0.360767\n",
      "[68]\ttraining's l2: 0.367944\tvalid_1's l2: 0.360427\n",
      "[69]\ttraining's l2: 0.367701\tvalid_1's l2: 0.360137\n",
      "[70]\ttraining's l2: 0.367422\tvalid_1's l2: 0.359796\n",
      "[71]\ttraining's l2: 0.367171\tvalid_1's l2: 0.359468\n",
      "[72]\ttraining's l2: 0.366929\tvalid_1's l2: 0.359175\n",
      "[73]\ttraining's l2: 0.36669\tvalid_1's l2: 0.358892\n",
      "[74]\ttraining's l2: 0.366495\tvalid_1's l2: 0.358638\n",
      "[75]\ttraining's l2: 0.366246\tvalid_1's l2: 0.358405\n",
      "[76]\ttraining's l2: 0.36603\tvalid_1's l2: 0.358176\n",
      "[77]\ttraining's l2: 0.365827\tvalid_1's l2: 0.357986\n",
      "[78]\ttraining's l2: 0.36563\tvalid_1's l2: 0.357736\n",
      "[79]\ttraining's l2: 0.365378\tvalid_1's l2: 0.357391\n",
      "[80]\ttraining's l2: 0.365161\tvalid_1's l2: 0.357088\n",
      "[81]\ttraining's l2: 0.364998\tvalid_1's l2: 0.356911\n",
      "[82]\ttraining's l2: 0.364806\tvalid_1's l2: 0.356651\n",
      "[83]\ttraining's l2: 0.364645\tvalid_1's l2: 0.356459\n",
      "[84]\ttraining's l2: 0.364473\tvalid_1's l2: 0.35628\n",
      "[85]\ttraining's l2: 0.364323\tvalid_1's l2: 0.356119\n",
      "[86]\ttraining's l2: 0.36416\tvalid_1's l2: 0.355951\n",
      "[87]\ttraining's l2: 0.363965\tvalid_1's l2: 0.355783\n",
      "[88]\ttraining's l2: 0.36375\tvalid_1's l2: 0.355567\n",
      "[89]\ttraining's l2: 0.363581\tvalid_1's l2: 0.355375\n",
      "[90]\ttraining's l2: 0.363425\tvalid_1's l2: 0.355257\n",
      "[91]\ttraining's l2: 0.36327\tvalid_1's l2: 0.35512\n",
      "[92]\ttraining's l2: 0.36313\tvalid_1's l2: 0.354904\n",
      "[93]\ttraining's l2: 0.363005\tvalid_1's l2: 0.354803\n",
      "[94]\ttraining's l2: 0.362876\tvalid_1's l2: 0.354681\n",
      "[95]\ttraining's l2: 0.362736\tvalid_1's l2: 0.354495\n",
      "[96]\ttraining's l2: 0.362606\tvalid_1's l2: 0.354346\n",
      "[97]\ttraining's l2: 0.362483\tvalid_1's l2: 0.354221\n",
      "[98]\ttraining's l2: 0.362379\tvalid_1's l2: 0.354108\n",
      "[99]\ttraining's l2: 0.362268\tvalid_1's l2: 0.354039\n",
      "[100]\ttraining's l2: 0.362173\tvalid_1's l2: 0.353916\n",
      "[101]\ttraining's l2: 0.36207\tvalid_1's l2: 0.353782\n",
      "[102]\ttraining's l2: 0.361951\tvalid_1's l2: 0.353661\n",
      "[103]\ttraining's l2: 0.361804\tvalid_1's l2: 0.353526\n",
      "[104]\ttraining's l2: 0.361678\tvalid_1's l2: 0.353417\n",
      "[105]\ttraining's l2: 0.361501\tvalid_1's l2: 0.353242\n",
      "[106]\ttraining's l2: 0.361351\tvalid_1's l2: 0.353128\n",
      "[107]\ttraining's l2: 0.361281\tvalid_1's l2: 0.353084\n",
      "[108]\ttraining's l2: 0.361142\tvalid_1's l2: 0.352965\n",
      "[109]\ttraining's l2: 0.361066\tvalid_1's l2: 0.352883\n",
      "[110]\ttraining's l2: 0.360932\tvalid_1's l2: 0.352783\n",
      "[111]\ttraining's l2: 0.36086\tvalid_1's l2: 0.352717\n",
      "[112]\ttraining's l2: 0.360793\tvalid_1's l2: 0.352674\n",
      "[113]\ttraining's l2: 0.360643\tvalid_1's l2: 0.352565\n",
      "[114]\ttraining's l2: 0.360567\tvalid_1's l2: 0.352489\n",
      "[115]\ttraining's l2: 0.360489\tvalid_1's l2: 0.35244\n",
      "[116]\ttraining's l2: 0.360436\tvalid_1's l2: 0.352407\n",
      "[117]\ttraining's l2: 0.360351\tvalid_1's l2: 0.352318\n",
      "[118]\ttraining's l2: 0.36028\tvalid_1's l2: 0.352231\n",
      "[119]\ttraining's l2: 0.360156\tvalid_1's l2: 0.35215\n",
      "[120]\ttraining's l2: 0.360023\tvalid_1's l2: 0.352023\n",
      "[121]\ttraining's l2: 0.359963\tvalid_1's l2: 0.351973\n",
      "[122]\ttraining's l2: 0.359881\tvalid_1's l2: 0.351899\n",
      "[123]\ttraining's l2: 0.359805\tvalid_1's l2: 0.351819\n",
      "[124]\ttraining's l2: 0.359747\tvalid_1's l2: 0.351777\n",
      "[125]\ttraining's l2: 0.359636\tvalid_1's l2: 0.351679\n",
      "[126]\ttraining's l2: 0.359542\tvalid_1's l2: 0.351607\n",
      "[127]\ttraining's l2: 0.359489\tvalid_1's l2: 0.351576\n",
      "[128]\ttraining's l2: 0.35942\tvalid_1's l2: 0.351538\n",
      "[129]\ttraining's l2: 0.359363\tvalid_1's l2: 0.351503\n",
      "[130]\ttraining's l2: 0.35929\tvalid_1's l2: 0.35143\n",
      "[131]\ttraining's l2: 0.359235\tvalid_1's l2: 0.351401\n",
      "[132]\ttraining's l2: 0.359169\tvalid_1's l2: 0.351362\n",
      "[133]\ttraining's l2: 0.359064\tvalid_1's l2: 0.351256\n",
      "[134]\ttraining's l2: 0.359012\tvalid_1's l2: 0.351248\n",
      "[135]\ttraining's l2: 0.358938\tvalid_1's l2: 0.351177\n",
      "[136]\ttraining's l2: 0.358876\tvalid_1's l2: 0.351129\n",
      "[137]\ttraining's l2: 0.358844\tvalid_1's l2: 0.351103\n",
      "[138]\ttraining's l2: 0.358754\tvalid_1's l2: 0.351051\n",
      "[139]\ttraining's l2: 0.35871\tvalid_1's l2: 0.351012\n",
      "[140]\ttraining's l2: 0.358669\tvalid_1's l2: 0.350981\n",
      "[141]\ttraining's l2: 0.358622\tvalid_1's l2: 0.350949\n",
      "[142]\ttraining's l2: 0.358556\tvalid_1's l2: 0.350908\n",
      "[143]\ttraining's l2: 0.358507\tvalid_1's l2: 0.350885\n",
      "[144]\ttraining's l2: 0.358428\tvalid_1's l2: 0.350809\n",
      "[145]\ttraining's l2: 0.358334\tvalid_1's l2: 0.350743\n",
      "[146]\ttraining's l2: 0.35829\tvalid_1's l2: 0.350717\n",
      "[147]\ttraining's l2: 0.358245\tvalid_1's l2: 0.350666\n",
      "[148]\ttraining's l2: 0.358188\tvalid_1's l2: 0.350649\n",
      "[149]\ttraining's l2: 0.358148\tvalid_1's l2: 0.350628\n",
      "[150]\ttraining's l2: 0.358107\tvalid_1's l2: 0.350602\n",
      "[151]\ttraining's l2: 0.358071\tvalid_1's l2: 0.350575\n",
      "[152]\ttraining's l2: 0.358033\tvalid_1's l2: 0.350554\n",
      "[153]\ttraining's l2: 0.357986\tvalid_1's l2: 0.350537\n",
      "[154]\ttraining's l2: 0.357896\tvalid_1's l2: 0.350504\n",
      "[155]\ttraining's l2: 0.357834\tvalid_1's l2: 0.350433\n",
      "[156]\ttraining's l2: 0.357761\tvalid_1's l2: 0.350384\n",
      "[157]\ttraining's l2: 0.357714\tvalid_1's l2: 0.350386\n",
      "[158]\ttraining's l2: 0.357684\tvalid_1's l2: 0.350368\n",
      "[159]\ttraining's l2: 0.357657\tvalid_1's l2: 0.350342\n",
      "[160]\ttraining's l2: 0.357625\tvalid_1's l2: 0.350318\n",
      "[161]\ttraining's l2: 0.357575\tvalid_1's l2: 0.350288\n",
      "[162]\ttraining's l2: 0.357536\tvalid_1's l2: 0.350276\n",
      "[163]\ttraining's l2: 0.357473\tvalid_1's l2: 0.350239\n",
      "[164]\ttraining's l2: 0.357396\tvalid_1's l2: 0.350213\n",
      "[165]\ttraining's l2: 0.357368\tvalid_1's l2: 0.350201\n",
      "[166]\ttraining's l2: 0.35732\tvalid_1's l2: 0.350179\n",
      "[167]\ttraining's l2: 0.357271\tvalid_1's l2: 0.350153\n",
      "[168]\ttraining's l2: 0.357234\tvalid_1's l2: 0.350128\n",
      "[169]\ttraining's l2: 0.357165\tvalid_1's l2: 0.350095\n",
      "[170]\ttraining's l2: 0.357118\tvalid_1's l2: 0.350065\n",
      "[171]\ttraining's l2: 0.357085\tvalid_1's l2: 0.350052\n",
      "[172]\ttraining's l2: 0.357053\tvalid_1's l2: 0.350034\n",
      "[173]\ttraining's l2: 0.357012\tvalid_1's l2: 0.350018\n",
      "[174]\ttraining's l2: 0.356974\tvalid_1's l2: 0.350014\n",
      "[175]\ttraining's l2: 0.356945\tvalid_1's l2: 0.350002\n",
      "[176]\ttraining's l2: 0.356914\tvalid_1's l2: 0.349986\n",
      "[177]\ttraining's l2: 0.35687\tvalid_1's l2: 0.349954\n",
      "[178]\ttraining's l2: 0.356842\tvalid_1's l2: 0.349938\n",
      "[179]\ttraining's l2: 0.356794\tvalid_1's l2: 0.349919\n",
      "[180]\ttraining's l2: 0.356732\tvalid_1's l2: 0.349888\n",
      "[181]\ttraining's l2: 0.356696\tvalid_1's l2: 0.349862\n",
      "[182]\ttraining's l2: 0.356657\tvalid_1's l2: 0.349843\n",
      "[183]\ttraining's l2: 0.356592\tvalid_1's l2: 0.34981\n",
      "[184]\ttraining's l2: 0.356532\tvalid_1's l2: 0.349687\n",
      "[185]\ttraining's l2: 0.356502\tvalid_1's l2: 0.349677\n",
      "[186]\ttraining's l2: 0.356433\tvalid_1's l2: 0.349633\n",
      "[187]\ttraining's l2: 0.356395\tvalid_1's l2: 0.349619\n",
      "[188]\ttraining's l2: 0.356365\tvalid_1's l2: 0.349614\n",
      "[189]\ttraining's l2: 0.356322\tvalid_1's l2: 0.349601\n",
      "[190]\ttraining's l2: 0.356238\tvalid_1's l2: 0.349564\n",
      "[191]\ttraining's l2: 0.35621\tvalid_1's l2: 0.349546\n",
      "[192]\ttraining's l2: 0.356152\tvalid_1's l2: 0.349502\n",
      "[193]\ttraining's l2: 0.356117\tvalid_1's l2: 0.349478\n",
      "[194]\ttraining's l2: 0.356078\tvalid_1's l2: 0.349437\n",
      "[195]\ttraining's l2: 0.356056\tvalid_1's l2: 0.349429\n",
      "[196]\ttraining's l2: 0.356006\tvalid_1's l2: 0.349406\n",
      "[197]\ttraining's l2: 0.355984\tvalid_1's l2: 0.349397\n",
      "[198]\ttraining's l2: 0.355953\tvalid_1's l2: 0.349369\n",
      "[199]\ttraining's l2: 0.355931\tvalid_1's l2: 0.349368\n",
      "[200]\ttraining's l2: 0.355892\tvalid_1's l2: 0.349351\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.355892\tvalid_1's l2: 0.349351\n",
      "mean_14_sales: 11367879.47\n",
      "mean_7_sales: 3505565.07\n",
      "mean_30_sales: 3171291.46\n",
      "mean_21_sales: 2282909.83\n",
      "mean_3_sales: 1371166.28\n",
      "mean_4_sales: 796358.10\n",
      "mean_60_sales: 591133.24\n",
      "promo_5: 547278.81\n",
      "mean_20_dow5_2017: 534648.73\n",
      "mean_5_sales: 341229.07\n",
      "mean_4_dow5_2017: 243862.23\n",
      "item_class_features: 222178.23\n",
      "mean_63_sales: 179392.30\n",
      "sum_2_promo: 77325.25\n",
      "mean_6_sales: 74963.17\n",
      "std_14_sales: 69126.65\n",
      "promo_7: 67192.82\n",
      "mean_4_dow6_2017: 61467.58\n",
      "promo_3: 46541.30\n",
      "std_21_sales: 45493.41\n",
      "sum_4_promo: 42758.50\n",
      "promo_6: 31232.94\n",
      "std_30_sales: 31187.63\n",
      "mean_20_dow6_2017: 25326.28\n",
      "item_family_features: 24551.97\n",
      "lag_56_sales: 22487.70\n",
      "mean_20_dow0_2017: 19027.59\n",
      "lag_1_sales: 18789.95\n",
      "sum_7_promo: 12102.55\n",
      "store_cluster_features: 11989.06\n",
      "sum_14_promo: 10103.59\n",
      "promo_0: 9999.26\n",
      "promo_14: 9793.24\n",
      "std_63_sales: 9650.24\n",
      "std_60_sales: 8909.56\n",
      "promo_1: 8293.08\n",
      "promo_4: 8094.51\n",
      "store_city_features: 7945.66\n",
      "sum_21_promo: 7836.79\n",
      "sum_3_promo: 7763.76\n",
      "sum_6_promo: 6922.27\n",
      "lag_3_sales: 6895.46\n",
      "promo_2: 6145.81\n",
      "mean_20_dow3_2017: 5917.19\n",
      "std_7_sales: 5377.57\n",
      "lag_2_sales: 5008.09\n",
      "std_4_sales: 4591.56\n",
      "promo_11: 4568.46\n",
      "promo_12: 3666.68\n",
      "mean_4_dow0_2017: 3345.87\n",
      "lag_28_sales: 3340.52\n",
      "lag_4_sales: 3271.36\n",
      "std_5_sales: 3137.05\n",
      "promo_8: 2928.23\n",
      "mean_4_dow1_2017: 2843.47\n",
      "promo_10: 2748.12\n",
      "sum_5_promo: 2689.39\n",
      "mean_20_dow2_2017: 2556.55\n",
      "std_6_sales: 2430.92\n",
      "store_type_features: 2365.80\n",
      "std_3_sales: 2311.90\n",
      "promo_13: 2275.83\n",
      "lag_7_sales: 2097.86\n",
      "lag_6_sales: 1918.53\n",
      "mean_4_dow3_2017: 1637.11\n",
      "mean_4_dow4_2017: 1606.27\n",
      "lag_42_sales: 1577.32\n",
      "lag_14_sales: 1557.65\n",
      "lag_21_sales: 1483.17\n",
      "mean_20_dow1_2017: 1468.62\n",
      "store_state_features: 1453.82\n",
      "promo_9: 1352.36\n",
      "lag_5_sales: 1054.36\n",
      "lag_63_sales: 1025.56\n",
      "lag_35_sales: 920.84\n",
      "mean_4_dow2_2017: 813.51\n",
      "mean_20_dow4_2017: 664.17\n",
      "lag_49_sales: 489.43\n",
      "promo_15: 72.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [08:56<14:48, 88.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.0197\tvalid_1's l2: 1.18349\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.959133\tvalid_1's l2: 1.11792\n",
      "[3]\ttraining's l2: 0.902667\tvalid_1's l2: 1.05694\n",
      "[4]\ttraining's l2: 0.851696\tvalid_1's l2: 1.00128\n",
      "[5]\ttraining's l2: 0.807051\tvalid_1's l2: 0.951967\n",
      "[6]\ttraining's l2: 0.765047\tvalid_1's l2: 0.905686\n",
      "[7]\ttraining's l2: 0.728367\tvalid_1's l2: 0.864904\n",
      "[8]\ttraining's l2: 0.693972\tvalid_1's l2: 0.826829\n",
      "[9]\ttraining's l2: 0.662853\tvalid_1's l2: 0.792183\n",
      "[10]\ttraining's l2: 0.635644\tvalid_1's l2: 0.761404\n",
      "[11]\ttraining's l2: 0.610947\tvalid_1's l2: 0.733454\n",
      "[12]\ttraining's l2: 0.587578\tvalid_1's l2: 0.707083\n",
      "[13]\ttraining's l2: 0.567183\tvalid_1's l2: 0.683549\n",
      "[14]\ttraining's l2: 0.548608\tvalid_1's l2: 0.662045\n",
      "[15]\ttraining's l2: 0.531022\tvalid_1's l2: 0.641762\n",
      "[16]\ttraining's l2: 0.515875\tvalid_1's l2: 0.623876\n",
      "[17]\ttraining's l2: 0.502157\tvalid_1's l2: 0.607578\n",
      "[18]\ttraining's l2: 0.488812\tvalid_1's l2: 0.592116\n",
      "[19]\ttraining's l2: 0.476784\tvalid_1's l2: 0.577867\n",
      "[20]\ttraining's l2: 0.465929\tvalid_1's l2: 0.564807\n",
      "[21]\ttraining's l2: 0.456048\tvalid_1's l2: 0.552884\n",
      "[22]\ttraining's l2: 0.44713\tvalid_1's l2: 0.542015\n",
      "[23]\ttraining's l2: 0.439038\tvalid_1's l2: 0.53199\n",
      "[24]\ttraining's l2: 0.43163\tvalid_1's l2: 0.522844\n",
      "[25]\ttraining's l2: 0.424886\tvalid_1's l2: 0.51447\n",
      "[26]\ttraining's l2: 0.418783\tvalid_1's l2: 0.506603\n",
      "[27]\ttraining's l2: 0.413232\tvalid_1's l2: 0.499581\n",
      "[28]\ttraining's l2: 0.408232\tvalid_1's l2: 0.493027\n",
      "[29]\ttraining's l2: 0.403882\tvalid_1's l2: 0.487274\n",
      "[30]\ttraining's l2: 0.399892\tvalid_1's l2: 0.481979\n",
      "[31]\ttraining's l2: 0.396045\tvalid_1's l2: 0.47698\n",
      "[32]\ttraining's l2: 0.392471\tvalid_1's l2: 0.472282\n",
      "[33]\ttraining's l2: 0.389228\tvalid_1's l2: 0.467976\n",
      "[34]\ttraining's l2: 0.386495\tvalid_1's l2: 0.46408\n",
      "[35]\ttraining's l2: 0.383776\tvalid_1's l2: 0.460246\n",
      "[36]\ttraining's l2: 0.381263\tvalid_1's l2: 0.456901\n",
      "[37]\ttraining's l2: 0.379212\tvalid_1's l2: 0.453915\n",
      "[38]\ttraining's l2: 0.377114\tvalid_1's l2: 0.451049\n",
      "[39]\ttraining's l2: 0.375125\tvalid_1's l2: 0.448331\n",
      "[40]\ttraining's l2: 0.373519\tvalid_1's l2: 0.445897\n",
      "[41]\ttraining's l2: 0.371862\tvalid_1's l2: 0.443548\n",
      "[42]\ttraining's l2: 0.370277\tvalid_1's l2: 0.441348\n",
      "[43]\ttraining's l2: 0.368906\tvalid_1's l2: 0.439381\n",
      "[44]\ttraining's l2: 0.367628\tvalid_1's l2: 0.437477\n",
      "[45]\ttraining's l2: 0.366391\tvalid_1's l2: 0.43566\n",
      "[46]\ttraining's l2: 0.365408\tvalid_1's l2: 0.434057\n",
      "[47]\ttraining's l2: 0.364374\tvalid_1's l2: 0.432594\n",
      "[48]\ttraining's l2: 0.363471\tvalid_1's l2: 0.431218\n",
      "[49]\ttraining's l2: 0.362648\tvalid_1's l2: 0.429872\n",
      "[50]\ttraining's l2: 0.361926\tvalid_1's l2: 0.428743\n",
      "[51]\ttraining's l2: 0.361016\tvalid_1's l2: 0.427553\n",
      "[52]\ttraining's l2: 0.360393\tvalid_1's l2: 0.426558\n",
      "[53]\ttraining's l2: 0.359633\tvalid_1's l2: 0.425472\n",
      "[54]\ttraining's l2: 0.358928\tvalid_1's l2: 0.42446\n",
      "[55]\ttraining's l2: 0.358296\tvalid_1's l2: 0.423493\n",
      "[56]\ttraining's l2: 0.357694\tvalid_1's l2: 0.42266\n",
      "[57]\ttraining's l2: 0.35717\tvalid_1's l2: 0.421907\n",
      "[58]\ttraining's l2: 0.356587\tvalid_1's l2: 0.421066\n",
      "[59]\ttraining's l2: 0.35604\tvalid_1's l2: 0.420415\n",
      "[60]\ttraining's l2: 0.355578\tvalid_1's l2: 0.419732\n",
      "[61]\ttraining's l2: 0.355058\tvalid_1's l2: 0.419074\n",
      "[62]\ttraining's l2: 0.35467\tvalid_1's l2: 0.418495\n",
      "[63]\ttraining's l2: 0.354358\tvalid_1's l2: 0.41794\n",
      "[64]\ttraining's l2: 0.354091\tvalid_1's l2: 0.417424\n",
      "[65]\ttraining's l2: 0.353602\tvalid_1's l2: 0.416841\n",
      "[66]\ttraining's l2: 0.353289\tvalid_1's l2: 0.41635\n",
      "[67]\ttraining's l2: 0.352913\tvalid_1's l2: 0.415899\n",
      "[68]\ttraining's l2: 0.352577\tvalid_1's l2: 0.415546\n",
      "[69]\ttraining's l2: 0.352312\tvalid_1's l2: 0.415193\n",
      "[70]\ttraining's l2: 0.352005\tvalid_1's l2: 0.414908\n",
      "[71]\ttraining's l2: 0.351639\tvalid_1's l2: 0.414611\n",
      "[72]\ttraining's l2: 0.35139\tvalid_1's l2: 0.414243\n",
      "[73]\ttraining's l2: 0.351206\tvalid_1's l2: 0.413932\n",
      "[74]\ttraining's l2: 0.350846\tvalid_1's l2: 0.413594\n",
      "[75]\ttraining's l2: 0.350566\tvalid_1's l2: 0.413312\n",
      "[76]\ttraining's l2: 0.350299\tvalid_1's l2: 0.413043\n",
      "[77]\ttraining's l2: 0.350135\tvalid_1's l2: 0.4128\n",
      "[78]\ttraining's l2: 0.349843\tvalid_1's l2: 0.412474\n",
      "[79]\ttraining's l2: 0.349548\tvalid_1's l2: 0.412142\n",
      "[80]\ttraining's l2: 0.349385\tvalid_1's l2: 0.411866\n",
      "[81]\ttraining's l2: 0.349231\tvalid_1's l2: 0.41165\n",
      "[82]\ttraining's l2: 0.349058\tvalid_1's l2: 0.411438\n",
      "[83]\ttraining's l2: 0.34882\tvalid_1's l2: 0.411181\n",
      "[84]\ttraining's l2: 0.348668\tvalid_1's l2: 0.410993\n",
      "[85]\ttraining's l2: 0.348536\tvalid_1's l2: 0.410863\n",
      "[86]\ttraining's l2: 0.348333\tvalid_1's l2: 0.410635\n",
      "[87]\ttraining's l2: 0.348152\tvalid_1's l2: 0.41038\n",
      "[88]\ttraining's l2: 0.347974\tvalid_1's l2: 0.410209\n",
      "[89]\ttraining's l2: 0.347781\tvalid_1's l2: 0.410081\n",
      "[90]\ttraining's l2: 0.347632\tvalid_1's l2: 0.40994\n",
      "[91]\ttraining's l2: 0.347487\tvalid_1's l2: 0.409811\n",
      "[92]\ttraining's l2: 0.347362\tvalid_1's l2: 0.409641\n",
      "[93]\ttraining's l2: 0.347185\tvalid_1's l2: 0.409401\n",
      "[94]\ttraining's l2: 0.347064\tvalid_1's l2: 0.409266\n",
      "[95]\ttraining's l2: 0.346934\tvalid_1's l2: 0.409178\n",
      "[96]\ttraining's l2: 0.346816\tvalid_1's l2: 0.409032\n",
      "[97]\ttraining's l2: 0.346667\tvalid_1's l2: 0.40894\n",
      "[98]\ttraining's l2: 0.346542\tvalid_1's l2: 0.408829\n",
      "[99]\ttraining's l2: 0.346421\tvalid_1's l2: 0.408779\n",
      "[100]\ttraining's l2: 0.346286\tvalid_1's l2: 0.408745\n",
      "[101]\ttraining's l2: 0.346165\tvalid_1's l2: 0.408583\n",
      "[102]\ttraining's l2: 0.34597\tvalid_1's l2: 0.408562\n",
      "[103]\ttraining's l2: 0.345892\tvalid_1's l2: 0.408462\n",
      "[104]\ttraining's l2: 0.345756\tvalid_1's l2: 0.408455\n",
      "[105]\ttraining's l2: 0.345592\tvalid_1's l2: 0.408387\n",
      "[106]\ttraining's l2: 0.345509\tvalid_1's l2: 0.408307\n",
      "[107]\ttraining's l2: 0.345439\tvalid_1's l2: 0.408248\n",
      "[108]\ttraining's l2: 0.345353\tvalid_1's l2: 0.408179\n",
      "[109]\ttraining's l2: 0.34517\tvalid_1's l2: 0.408149\n",
      "[110]\ttraining's l2: 0.345096\tvalid_1's l2: 0.408079\n",
      "[111]\ttraining's l2: 0.345027\tvalid_1's l2: 0.408006\n",
      "[112]\ttraining's l2: 0.344912\tvalid_1's l2: 0.407894\n",
      "[113]\ttraining's l2: 0.344835\tvalid_1's l2: 0.407842\n",
      "[114]\ttraining's l2: 0.344714\tvalid_1's l2: 0.407824\n",
      "[115]\ttraining's l2: 0.344645\tvalid_1's l2: 0.407782\n",
      "[116]\ttraining's l2: 0.344588\tvalid_1's l2: 0.407724\n",
      "[117]\ttraining's l2: 0.34452\tvalid_1's l2: 0.407732\n",
      "[118]\ttraining's l2: 0.344373\tvalid_1's l2: 0.407718\n",
      "[119]\ttraining's l2: 0.344314\tvalid_1's l2: 0.407669\n",
      "[120]\ttraining's l2: 0.344232\tvalid_1's l2: 0.407597\n",
      "[121]\ttraining's l2: 0.344177\tvalid_1's l2: 0.407571\n",
      "[122]\ttraining's l2: 0.344112\tvalid_1's l2: 0.407496\n",
      "[123]\ttraining's l2: 0.343994\tvalid_1's l2: 0.407448\n",
      "[124]\ttraining's l2: 0.343876\tvalid_1's l2: 0.407388\n",
      "[125]\ttraining's l2: 0.343815\tvalid_1's l2: 0.407334\n",
      "[126]\ttraining's l2: 0.34374\tvalid_1's l2: 0.407302\n",
      "[127]\ttraining's l2: 0.343688\tvalid_1's l2: 0.407312\n",
      "[128]\ttraining's l2: 0.343607\tvalid_1's l2: 0.407245\n",
      "[129]\ttraining's l2: 0.343568\tvalid_1's l2: 0.407208\n",
      "[130]\ttraining's l2: 0.343476\tvalid_1's l2: 0.407129\n",
      "[131]\ttraining's l2: 0.343417\tvalid_1's l2: 0.407095\n",
      "[132]\ttraining's l2: 0.343357\tvalid_1's l2: 0.407056\n",
      "[133]\ttraining's l2: 0.343251\tvalid_1's l2: 0.406986\n",
      "[134]\ttraining's l2: 0.343204\tvalid_1's l2: 0.407049\n",
      "[135]\ttraining's l2: 0.343117\tvalid_1's l2: 0.4069\n",
      "[136]\ttraining's l2: 0.343054\tvalid_1's l2: 0.406878\n",
      "[137]\ttraining's l2: 0.342986\tvalid_1's l2: 0.406912\n",
      "[138]\ttraining's l2: 0.342917\tvalid_1's l2: 0.40681\n",
      "[139]\ttraining's l2: 0.342842\tvalid_1's l2: 0.406711\n",
      "[140]\ttraining's l2: 0.342808\tvalid_1's l2: 0.406707\n",
      "[141]\ttraining's l2: 0.342748\tvalid_1's l2: 0.406677\n",
      "[142]\ttraining's l2: 0.342706\tvalid_1's l2: 0.40666\n",
      "[143]\ttraining's l2: 0.342641\tvalid_1's l2: 0.406571\n",
      "[144]\ttraining's l2: 0.342598\tvalid_1's l2: 0.406561\n",
      "[145]\ttraining's l2: 0.342561\tvalid_1's l2: 0.406538\n",
      "[146]\ttraining's l2: 0.342522\tvalid_1's l2: 0.406487\n",
      "[147]\ttraining's l2: 0.342447\tvalid_1's l2: 0.406477\n",
      "[148]\ttraining's l2: 0.342407\tvalid_1's l2: 0.406463\n",
      "[149]\ttraining's l2: 0.342331\tvalid_1's l2: 0.406433\n",
      "[150]\ttraining's l2: 0.342292\tvalid_1's l2: 0.406414\n",
      "[151]\ttraining's l2: 0.342247\tvalid_1's l2: 0.406379\n",
      "[152]\ttraining's l2: 0.342147\tvalid_1's l2: 0.406438\n",
      "[153]\ttraining's l2: 0.342108\tvalid_1's l2: 0.406418\n",
      "[154]\ttraining's l2: 0.342043\tvalid_1's l2: 0.406395\n",
      "[155]\ttraining's l2: 0.342006\tvalid_1's l2: 0.406392\n",
      "[156]\ttraining's l2: 0.341967\tvalid_1's l2: 0.406404\n",
      "[157]\ttraining's l2: 0.341929\tvalid_1's l2: 0.406402\n",
      "[158]\ttraining's l2: 0.341881\tvalid_1's l2: 0.406378\n",
      "[159]\ttraining's l2: 0.341836\tvalid_1's l2: 0.406326\n",
      "[160]\ttraining's l2: 0.3418\tvalid_1's l2: 0.406282\n",
      "[161]\ttraining's l2: 0.341754\tvalid_1's l2: 0.406271\n",
      "[162]\ttraining's l2: 0.34172\tvalid_1's l2: 0.406242\n",
      "[163]\ttraining's l2: 0.341688\tvalid_1's l2: 0.406241\n",
      "[164]\ttraining's l2: 0.341609\tvalid_1's l2: 0.406284\n",
      "[165]\ttraining's l2: 0.341578\tvalid_1's l2: 0.406293\n",
      "[166]\ttraining's l2: 0.341497\tvalid_1's l2: 0.406324\n",
      "[167]\ttraining's l2: 0.341455\tvalid_1's l2: 0.406296\n",
      "[168]\ttraining's l2: 0.341395\tvalid_1's l2: 0.406242\n",
      "[169]\ttraining's l2: 0.341341\tvalid_1's l2: 0.406234\n",
      "[170]\ttraining's l2: 0.341316\tvalid_1's l2: 0.40622\n",
      "[171]\ttraining's l2: 0.341254\tvalid_1's l2: 0.406131\n",
      "[172]\ttraining's l2: 0.341228\tvalid_1's l2: 0.406103\n",
      "[173]\ttraining's l2: 0.341194\tvalid_1's l2: 0.406065\n",
      "[174]\ttraining's l2: 0.341161\tvalid_1's l2: 0.406063\n",
      "[175]\ttraining's l2: 0.341129\tvalid_1's l2: 0.406066\n",
      "[176]\ttraining's l2: 0.34107\tvalid_1's l2: 0.406042\n",
      "[177]\ttraining's l2: 0.341033\tvalid_1's l2: 0.405946\n",
      "[178]\ttraining's l2: 0.340996\tvalid_1's l2: 0.405948\n",
      "[179]\ttraining's l2: 0.340967\tvalid_1's l2: 0.405956\n",
      "[180]\ttraining's l2: 0.340943\tvalid_1's l2: 0.405935\n",
      "[181]\ttraining's l2: 0.340887\tvalid_1's l2: 0.405832\n",
      "[182]\ttraining's l2: 0.340821\tvalid_1's l2: 0.405839\n",
      "[183]\ttraining's l2: 0.340788\tvalid_1's l2: 0.40583\n",
      "[184]\ttraining's l2: 0.340758\tvalid_1's l2: 0.405917\n",
      "[185]\ttraining's l2: 0.340729\tvalid_1's l2: 0.405893\n",
      "[186]\ttraining's l2: 0.340677\tvalid_1's l2: 0.405846\n",
      "[187]\ttraining's l2: 0.340619\tvalid_1's l2: 0.405787\n",
      "[188]\ttraining's l2: 0.3406\tvalid_1's l2: 0.40579\n",
      "[189]\ttraining's l2: 0.340579\tvalid_1's l2: 0.405782\n",
      "[190]\ttraining's l2: 0.340549\tvalid_1's l2: 0.405766\n",
      "[191]\ttraining's l2: 0.340524\tvalid_1's l2: 0.405758\n",
      "[192]\ttraining's l2: 0.34049\tvalid_1's l2: 0.405748\n",
      "[193]\ttraining's l2: 0.340449\tvalid_1's l2: 0.40567\n",
      "[194]\ttraining's l2: 0.34041\tvalid_1's l2: 0.405669\n",
      "[195]\ttraining's l2: 0.340384\tvalid_1's l2: 0.405674\n",
      "[196]\ttraining's l2: 0.340353\tvalid_1's l2: 0.405646\n",
      "[197]\ttraining's l2: 0.340324\tvalid_1's l2: 0.405648\n",
      "[198]\ttraining's l2: 0.340292\tvalid_1's l2: 0.405623\n",
      "[199]\ttraining's l2: 0.340256\tvalid_1's l2: 0.405586\n",
      "[200]\ttraining's l2: 0.34023\tvalid_1's l2: 0.405573\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.34023\tvalid_1's l2: 0.405573\n",
      "mean_14_sales: 10064946.11\n",
      "mean_30_sales: 3391552.86\n",
      "mean_7_sales: 2873265.76\n",
      "mean_21_sales: 2513661.95\n",
      "mean_20_dow6_2017: 1028358.52\n",
      "mean_4_dow6_2017: 911901.57\n",
      "promo_6: 786250.94\n",
      "mean_3_sales: 778052.93\n",
      "mean_6_sales: 681001.97\n",
      "item_class_features: 239354.98\n",
      "mean_4_sales: 235580.00\n",
      "mean_5_sales: 211605.15\n",
      "mean_63_sales: 158077.97\n",
      "mean_60_sales: 140159.08\n",
      "lag_1_sales: 108495.13\n",
      "promo_7: 102623.13\n",
      "sum_4_promo: 61274.00\n",
      "std_30_sales: 57860.23\n",
      "promo_3: 53862.12\n",
      "item_family_features: 52181.76\n",
      "std_21_sales: 46010.72\n",
      "std_14_sales: 41089.58\n",
      "mean_20_dow5_2017: 40589.08\n",
      "sum_2_promo: 39341.33\n",
      "promo_13: 38150.09\n",
      "promo_5: 37412.40\n",
      "mean_4_dow5_2017: 27181.80\n",
      "lag_56_sales: 22251.71\n",
      "store_cluster_features: 18334.03\n",
      "sum_14_promo: 16176.79\n",
      "std_63_sales: 16011.96\n",
      "sum_3_promo: 15171.29\n",
      "std_7_sales: 15102.13\n",
      "std_60_sales: 14434.24\n",
      "store_type_features: 13594.94\n",
      "sum_7_promo: 11641.96\n",
      "promo_14: 11249.59\n",
      "mean_20_dow3_2017: 10399.40\n",
      "mean_20_dow0_2017: 9731.75\n",
      "mean_20_dow1_2017: 9164.88\n",
      "mean_4_dow1_2017: 8879.69\n",
      "promo_1: 8874.93\n",
      "promo_4: 8406.46\n",
      "lag_28_sales: 7597.54\n",
      "store_city_features: 7024.57\n",
      "sum_21_promo: 6455.68\n",
      "promo_0: 5881.53\n",
      "promo_2: 4568.56\n",
      "sum_5_promo: 3575.43\n",
      "promo_11: 3515.70\n",
      "lag_2_sales: 3425.11\n",
      "sum_6_promo: 3396.97\n",
      "lag_21_sales: 3154.06\n",
      "std_6_sales: 2610.05\n",
      "lag_3_sales: 2408.25\n",
      "lag_42_sales: 2236.68\n",
      "lag_4_sales: 2105.62\n",
      "mean_4_dow0_2017: 2085.38\n",
      "mean_20_dow4_2017: 2071.25\n",
      "promo_8: 2042.14\n",
      "std_4_sales: 2028.95\n",
      "lag_5_sales: 1960.16\n",
      "lag_49_sales: 1759.13\n",
      "std_5_sales: 1735.60\n",
      "lag_14_sales: 1726.19\n",
      "lag_6_sales: 1679.66\n",
      "mean_20_dow2_2017: 1612.80\n",
      "store_state_features: 1497.05\n",
      "mean_4_dow4_2017: 1491.59\n",
      "promo_9: 1190.62\n",
      "std_3_sales: 1175.26\n",
      "promo_10: 1154.98\n",
      "mean_4_dow3_2017: 925.69\n",
      "lag_35_sales: 922.60\n",
      "lag_7_sales: 890.60\n",
      "promo_12: 869.88\n",
      "promo_15: 808.48\n",
      "mean_4_dow2_2017: 762.48\n",
      "lag_63_sales: 570.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [10:23<13:14, 88.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05148\tvalid_1's l2: 1.16034\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.987952\tvalid_1's l2: 1.09364\n",
      "[3]\ttraining's l2: 0.92803\tvalid_1's l2: 1.03118\n",
      "[4]\ttraining's l2: 0.87386\tvalid_1's l2: 0.973964\n",
      "[5]\ttraining's l2: 0.824654\tvalid_1's l2: 0.922195\n",
      "[6]\ttraining's l2: 0.782184\tvalid_1's l2: 0.876596\n",
      "[7]\ttraining's l2: 0.741697\tvalid_1's l2: 0.833897\n",
      "[8]\ttraining's l2: 0.706986\tvalid_1's l2: 0.796163\n",
      "[9]\ttraining's l2: 0.673632\tvalid_1's l2: 0.760914\n",
      "[10]\ttraining's l2: 0.644783\tvalid_1's l2: 0.729728\n",
      "[11]\ttraining's l2: 0.618699\tvalid_1's l2: 0.701392\n",
      "[12]\ttraining's l2: 0.595258\tvalid_1's l2: 0.675829\n",
      "[13]\ttraining's l2: 0.572261\tvalid_1's l2: 0.65098\n",
      "[14]\ttraining's l2: 0.551426\tvalid_1's l2: 0.628393\n",
      "[15]\ttraining's l2: 0.533804\tvalid_1's l2: 0.608824\n",
      "[16]\ttraining's l2: 0.516495\tvalid_1's l2: 0.590056\n",
      "[17]\ttraining's l2: 0.500876\tvalid_1's l2: 0.573065\n",
      "[18]\ttraining's l2: 0.487861\tvalid_1's l2: 0.558158\n",
      "[19]\ttraining's l2: 0.474845\tvalid_1's l2: 0.54375\n",
      "[20]\ttraining's l2: 0.462993\tvalid_1's l2: 0.53071\n",
      "[21]\ttraining's l2: 0.452243\tvalid_1's l2: 0.518746\n",
      "[22]\ttraining's l2: 0.442622\tvalid_1's l2: 0.507826\n",
      "[23]\ttraining's l2: 0.433678\tvalid_1's l2: 0.497691\n",
      "[24]\ttraining's l2: 0.426417\tvalid_1's l2: 0.489088\n",
      "[25]\ttraining's l2: 0.419049\tvalid_1's l2: 0.480531\n",
      "[26]\ttraining's l2: 0.412246\tvalid_1's l2: 0.472738\n",
      "[27]\ttraining's l2: 0.4062\tvalid_1's l2: 0.465596\n",
      "[28]\ttraining's l2: 0.401254\tvalid_1's l2: 0.459584\n",
      "[29]\ttraining's l2: 0.396049\tvalid_1's l2: 0.453403\n",
      "[30]\ttraining's l2: 0.391368\tvalid_1's l2: 0.447885\n",
      "[31]\ttraining's l2: 0.387568\tvalid_1's l2: 0.443152\n",
      "[32]\ttraining's l2: 0.383596\tvalid_1's l2: 0.438399\n",
      "[33]\ttraining's l2: 0.379888\tvalid_1's l2: 0.434013\n",
      "[34]\ttraining's l2: 0.37656\tvalid_1's l2: 0.429864\n",
      "[35]\ttraining's l2: 0.373496\tvalid_1's l2: 0.426143\n",
      "[36]\ttraining's l2: 0.370706\tvalid_1's l2: 0.422672\n",
      "[37]\ttraining's l2: 0.36822\tvalid_1's l2: 0.419546\n",
      "[38]\ttraining's l2: 0.366216\tvalid_1's l2: 0.416923\n",
      "[39]\ttraining's l2: 0.364035\tvalid_1's l2: 0.41425\n",
      "[40]\ttraining's l2: 0.362119\tvalid_1's l2: 0.411754\n",
      "[41]\ttraining's l2: 0.36057\tvalid_1's l2: 0.409681\n",
      "[42]\ttraining's l2: 0.35886\tvalid_1's l2: 0.40743\n",
      "[43]\ttraining's l2: 0.357256\tvalid_1's l2: 0.405362\n",
      "[44]\ttraining's l2: 0.355783\tvalid_1's l2: 0.403423\n",
      "[45]\ttraining's l2: 0.354457\tvalid_1's l2: 0.401609\n",
      "[46]\ttraining's l2: 0.353233\tvalid_1's l2: 0.399995\n",
      "[47]\ttraining's l2: 0.35228\tvalid_1's l2: 0.398644\n",
      "[48]\ttraining's l2: 0.351132\tvalid_1's l2: 0.397162\n",
      "[49]\ttraining's l2: 0.350134\tvalid_1's l2: 0.395812\n",
      "[50]\ttraining's l2: 0.349155\tvalid_1's l2: 0.394477\n",
      "[51]\ttraining's l2: 0.348247\tvalid_1's l2: 0.393278\n",
      "[52]\ttraining's l2: 0.347455\tvalid_1's l2: 0.392113\n",
      "[53]\ttraining's l2: 0.346654\tvalid_1's l2: 0.391092\n",
      "[54]\ttraining's l2: 0.345953\tvalid_1's l2: 0.390167\n",
      "[55]\ttraining's l2: 0.345266\tvalid_1's l2: 0.389307\n",
      "[56]\ttraining's l2: 0.344667\tvalid_1's l2: 0.388454\n",
      "[57]\ttraining's l2: 0.344218\tvalid_1's l2: 0.387765\n",
      "[58]\ttraining's l2: 0.343609\tvalid_1's l2: 0.387007\n",
      "[59]\ttraining's l2: 0.343059\tvalid_1's l2: 0.386316\n",
      "[60]\ttraining's l2: 0.342659\tvalid_1's l2: 0.385809\n",
      "[61]\ttraining's l2: 0.342183\tvalid_1's l2: 0.385083\n",
      "[62]\ttraining's l2: 0.341751\tvalid_1's l2: 0.384488\n",
      "[63]\ttraining's l2: 0.34145\tvalid_1's l2: 0.384006\n",
      "[64]\ttraining's l2: 0.341168\tvalid_1's l2: 0.383603\n",
      "[65]\ttraining's l2: 0.340759\tvalid_1's l2: 0.383048\n",
      "[66]\ttraining's l2: 0.340497\tvalid_1's l2: 0.38266\n",
      "[67]\ttraining's l2: 0.340107\tvalid_1's l2: 0.382101\n",
      "[68]\ttraining's l2: 0.339661\tvalid_1's l2: 0.381596\n",
      "[69]\ttraining's l2: 0.339432\tvalid_1's l2: 0.381274\n",
      "[70]\ttraining's l2: 0.339182\tvalid_1's l2: 0.380933\n",
      "[71]\ttraining's l2: 0.338807\tvalid_1's l2: 0.380428\n",
      "[72]\ttraining's l2: 0.33858\tvalid_1's l2: 0.380139\n",
      "[73]\ttraining's l2: 0.338371\tvalid_1's l2: 0.379901\n",
      "[74]\ttraining's l2: 0.338037\tvalid_1's l2: 0.379457\n",
      "[75]\ttraining's l2: 0.33771\tvalid_1's l2: 0.379078\n",
      "[76]\ttraining's l2: 0.337406\tvalid_1's l2: 0.378689\n",
      "[77]\ttraining's l2: 0.337166\tvalid_1's l2: 0.378322\n",
      "[78]\ttraining's l2: 0.336906\tvalid_1's l2: 0.378009\n",
      "[79]\ttraining's l2: 0.336711\tvalid_1's l2: 0.37777\n",
      "[80]\ttraining's l2: 0.336486\tvalid_1's l2: 0.377563\n",
      "[81]\ttraining's l2: 0.336322\tvalid_1's l2: 0.377336\n",
      "[82]\ttraining's l2: 0.336103\tvalid_1's l2: 0.377036\n",
      "[83]\ttraining's l2: 0.335918\tvalid_1's l2: 0.376817\n",
      "[84]\ttraining's l2: 0.33576\tvalid_1's l2: 0.376636\n",
      "[85]\ttraining's l2: 0.33562\tvalid_1's l2: 0.376464\n",
      "[86]\ttraining's l2: 0.335353\tvalid_1's l2: 0.376124\n",
      "[87]\ttraining's l2: 0.335157\tvalid_1's l2: 0.375963\n",
      "[88]\ttraining's l2: 0.335005\tvalid_1's l2: 0.375737\n",
      "[89]\ttraining's l2: 0.334809\tvalid_1's l2: 0.375554\n",
      "[90]\ttraining's l2: 0.334637\tvalid_1's l2: 0.375294\n",
      "[91]\ttraining's l2: 0.334528\tvalid_1's l2: 0.375191\n",
      "[92]\ttraining's l2: 0.334394\tvalid_1's l2: 0.375051\n",
      "[93]\ttraining's l2: 0.334181\tvalid_1's l2: 0.374744\n",
      "[94]\ttraining's l2: 0.334052\tvalid_1's l2: 0.374557\n",
      "[95]\ttraining's l2: 0.33393\tvalid_1's l2: 0.374445\n",
      "[96]\ttraining's l2: 0.333794\tvalid_1's l2: 0.374342\n",
      "[97]\ttraining's l2: 0.333673\tvalid_1's l2: 0.374183\n",
      "[98]\ttraining's l2: 0.333581\tvalid_1's l2: 0.374085\n",
      "[99]\ttraining's l2: 0.333442\tvalid_1's l2: 0.373962\n",
      "[100]\ttraining's l2: 0.333334\tvalid_1's l2: 0.37385\n",
      "[101]\ttraining's l2: 0.333143\tvalid_1's l2: 0.373549\n",
      "[102]\ttraining's l2: 0.333043\tvalid_1's l2: 0.373425\n",
      "[103]\ttraining's l2: 0.332942\tvalid_1's l2: 0.373315\n",
      "[104]\ttraining's l2: 0.332767\tvalid_1's l2: 0.373136\n",
      "[105]\ttraining's l2: 0.33264\tvalid_1's l2: 0.373037\n",
      "[106]\ttraining's l2: 0.332564\tvalid_1's l2: 0.372963\n",
      "[107]\ttraining's l2: 0.332503\tvalid_1's l2: 0.372906\n",
      "[108]\ttraining's l2: 0.33242\tvalid_1's l2: 0.37284\n",
      "[109]\ttraining's l2: 0.332334\tvalid_1's l2: 0.372777\n",
      "[110]\ttraining's l2: 0.332245\tvalid_1's l2: 0.372708\n",
      "[111]\ttraining's l2: 0.332172\tvalid_1's l2: 0.372611\n",
      "[112]\ttraining's l2: 0.332072\tvalid_1's l2: 0.37252\n",
      "[113]\ttraining's l2: 0.331935\tvalid_1's l2: 0.372381\n",
      "[114]\ttraining's l2: 0.331771\tvalid_1's l2: 0.372261\n",
      "[115]\ttraining's l2: 0.331712\tvalid_1's l2: 0.372231\n",
      "[116]\ttraining's l2: 0.331646\tvalid_1's l2: 0.372184\n",
      "[117]\ttraining's l2: 0.331571\tvalid_1's l2: 0.372131\n",
      "[118]\ttraining's l2: 0.331489\tvalid_1's l2: 0.372054\n",
      "[119]\ttraining's l2: 0.331392\tvalid_1's l2: 0.372028\n",
      "[120]\ttraining's l2: 0.331299\tvalid_1's l2: 0.371969\n",
      "[121]\ttraining's l2: 0.331199\tvalid_1's l2: 0.371907\n",
      "[122]\ttraining's l2: 0.331144\tvalid_1's l2: 0.371886\n",
      "[123]\ttraining's l2: 0.331039\tvalid_1's l2: 0.371795\n",
      "[124]\ttraining's l2: 0.330983\tvalid_1's l2: 0.371745\n",
      "[125]\ttraining's l2: 0.330909\tvalid_1's l2: 0.3717\n",
      "[126]\ttraining's l2: 0.330804\tvalid_1's l2: 0.371544\n",
      "[127]\ttraining's l2: 0.330731\tvalid_1's l2: 0.371442\n",
      "[128]\ttraining's l2: 0.330672\tvalid_1's l2: 0.371426\n",
      "[129]\ttraining's l2: 0.33061\tvalid_1's l2: 0.371395\n",
      "[130]\ttraining's l2: 0.33052\tvalid_1's l2: 0.371304\n",
      "[131]\ttraining's l2: 0.330421\tvalid_1's l2: 0.371153\n",
      "[132]\ttraining's l2: 0.330345\tvalid_1's l2: 0.371102\n",
      "[133]\ttraining's l2: 0.330284\tvalid_1's l2: 0.371066\n",
      "[134]\ttraining's l2: 0.330205\tvalid_1's l2: 0.370995\n",
      "[135]\ttraining's l2: 0.330132\tvalid_1's l2: 0.370924\n",
      "[136]\ttraining's l2: 0.330083\tvalid_1's l2: 0.37093\n",
      "[137]\ttraining's l2: 0.330027\tvalid_1's l2: 0.370908\n",
      "[138]\ttraining's l2: 0.329973\tvalid_1's l2: 0.370887\n",
      "[139]\ttraining's l2: 0.32992\tvalid_1's l2: 0.370882\n",
      "[140]\ttraining's l2: 0.329874\tvalid_1's l2: 0.370844\n",
      "[141]\ttraining's l2: 0.32983\tvalid_1's l2: 0.370847\n",
      "[142]\ttraining's l2: 0.32976\tvalid_1's l2: 0.370767\n",
      "[143]\ttraining's l2: 0.329714\tvalid_1's l2: 0.370737\n",
      "[144]\ttraining's l2: 0.329663\tvalid_1's l2: 0.37075\n",
      "[145]\ttraining's l2: 0.329598\tvalid_1's l2: 0.370742\n",
      "[146]\ttraining's l2: 0.329539\tvalid_1's l2: 0.370696\n",
      "[147]\ttraining's l2: 0.329481\tvalid_1's l2: 0.370668\n",
      "[148]\ttraining's l2: 0.329426\tvalid_1's l2: 0.370672\n",
      "[149]\ttraining's l2: 0.329341\tvalid_1's l2: 0.370593\n",
      "[150]\ttraining's l2: 0.329289\tvalid_1's l2: 0.370582\n",
      "[151]\ttraining's l2: 0.329255\tvalid_1's l2: 0.370573\n",
      "[152]\ttraining's l2: 0.329206\tvalid_1's l2: 0.370545\n",
      "[153]\ttraining's l2: 0.329147\tvalid_1's l2: 0.370523\n",
      "[154]\ttraining's l2: 0.329102\tvalid_1's l2: 0.370523\n",
      "[155]\ttraining's l2: 0.329039\tvalid_1's l2: 0.370463\n",
      "[156]\ttraining's l2: 0.32899\tvalid_1's l2: 0.370438\n",
      "[157]\ttraining's l2: 0.328926\tvalid_1's l2: 0.370401\n",
      "[158]\ttraining's l2: 0.328877\tvalid_1's l2: 0.3704\n",
      "[159]\ttraining's l2: 0.328843\tvalid_1's l2: 0.370385\n",
      "[160]\ttraining's l2: 0.3288\tvalid_1's l2: 0.370382\n",
      "[161]\ttraining's l2: 0.328747\tvalid_1's l2: 0.370372\n",
      "[162]\ttraining's l2: 0.328706\tvalid_1's l2: 0.370363\n",
      "[163]\ttraining's l2: 0.328663\tvalid_1's l2: 0.370332\n",
      "[164]\ttraining's l2: 0.328603\tvalid_1's l2: 0.370269\n",
      "[165]\ttraining's l2: 0.328571\tvalid_1's l2: 0.370263\n",
      "[166]\ttraining's l2: 0.328542\tvalid_1's l2: 0.370278\n",
      "[167]\ttraining's l2: 0.328511\tvalid_1's l2: 0.370281\n",
      "[168]\ttraining's l2: 0.328475\tvalid_1's l2: 0.370291\n",
      "[169]\ttraining's l2: 0.328445\tvalid_1's l2: 0.370283\n",
      "[170]\ttraining's l2: 0.328405\tvalid_1's l2: 0.370268\n",
      "[171]\ttraining's l2: 0.32836\tvalid_1's l2: 0.37026\n",
      "[172]\ttraining's l2: 0.32832\tvalid_1's l2: 0.37027\n",
      "[173]\ttraining's l2: 0.328291\tvalid_1's l2: 0.370237\n",
      "[174]\ttraining's l2: 0.328235\tvalid_1's l2: 0.370194\n",
      "[175]\ttraining's l2: 0.328205\tvalid_1's l2: 0.370182\n",
      "[176]\ttraining's l2: 0.328165\tvalid_1's l2: 0.370206\n",
      "[177]\ttraining's l2: 0.32813\tvalid_1's l2: 0.370195\n",
      "[178]\ttraining's l2: 0.328089\tvalid_1's l2: 0.370212\n",
      "[179]\ttraining's l2: 0.328062\tvalid_1's l2: 0.370221\n",
      "[180]\ttraining's l2: 0.328018\tvalid_1's l2: 0.370202\n",
      "[181]\ttraining's l2: 0.32797\tvalid_1's l2: 0.370158\n",
      "[182]\ttraining's l2: 0.327933\tvalid_1's l2: 0.370139\n",
      "[183]\ttraining's l2: 0.327883\tvalid_1's l2: 0.370132\n",
      "[184]\ttraining's l2: 0.327844\tvalid_1's l2: 0.370095\n",
      "[185]\ttraining's l2: 0.327819\tvalid_1's l2: 0.370089\n",
      "[186]\ttraining's l2: 0.327793\tvalid_1's l2: 0.370087\n",
      "[187]\ttraining's l2: 0.327745\tvalid_1's l2: 0.370051\n",
      "[188]\ttraining's l2: 0.327709\tvalid_1's l2: 0.370052\n",
      "[189]\ttraining's l2: 0.327682\tvalid_1's l2: 0.370037\n",
      "[190]\ttraining's l2: 0.327642\tvalid_1's l2: 0.370006\n",
      "[191]\ttraining's l2: 0.327616\tvalid_1's l2: 0.37\n",
      "[192]\ttraining's l2: 0.327574\tvalid_1's l2: 0.369991\n",
      "[193]\ttraining's l2: 0.32755\tvalid_1's l2: 0.370013\n",
      "[194]\ttraining's l2: 0.327514\tvalid_1's l2: 0.369979\n",
      "[195]\ttraining's l2: 0.327485\tvalid_1's l2: 0.369954\n",
      "[196]\ttraining's l2: 0.327444\tvalid_1's l2: 0.369959\n",
      "[197]\ttraining's l2: 0.327411\tvalid_1's l2: 0.369944\n",
      "[198]\ttraining's l2: 0.327371\tvalid_1's l2: 0.36992\n",
      "[199]\ttraining's l2: 0.327339\tvalid_1's l2: 0.369923\n",
      "[200]\ttraining's l2: 0.327308\tvalid_1's l2: 0.369939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.327308\tvalid_1's l2: 0.369939\n",
      "mean_14_sales: 7938256.59\n",
      "mean_7_sales: 5934851.25\n",
      "mean_21_sales: 4501485.92\n",
      "mean_30_sales: 3174837.66\n",
      "mean_20_dow0_2017: 1575659.73\n",
      "promo_7: 1093995.91\n",
      "mean_4_dow0_2017: 373539.68\n",
      "item_class_features: 278948.41\n",
      "mean_63_sales: 251484.02\n",
      "promo_0: 151036.34\n",
      "sum_7_promo: 129482.31\n",
      "lag_1_sales: 101886.23\n",
      "promo_14: 86148.56\n",
      "mean_6_sales: 82317.49\n",
      "mean_3_sales: 78759.95\n",
      "mean_5_sales: 71324.98\n",
      "item_family_features: 67797.56\n",
      "std_21_sales: 59430.44\n",
      "store_cluster_features: 55933.65\n",
      "std_14_sales: 55408.33\n",
      "std_30_sales: 46004.46\n",
      "sum_14_promo: 42505.74\n",
      "promo_6: 37625.11\n",
      "std_63_sales: 33478.37\n",
      "lag_56_sales: 30010.64\n",
      "lag_21_sales: 28317.57\n",
      "promo_8: 26596.30\n",
      "sum_21_promo: 24574.55\n",
      "promo_3: 22923.80\n",
      "store_type_features: 18837.73\n",
      "promo_5: 18582.97\n",
      "std_60_sales: 18209.01\n",
      "mean_4_sales: 14652.46\n",
      "std_7_sales: 14583.01\n",
      "mean_60_sales: 14500.46\n",
      "mean_4_dow6_2017: 14023.96\n",
      "mean_4_dow5_2017: 12503.48\n",
      "lag_49_sales: 12089.86\n",
      "mean_20_dow1_2017: 11289.76\n",
      "sum_4_promo: 10908.78\n",
      "mean_20_dow3_2017: 9786.31\n",
      "lag_2_sales: 9566.30\n",
      "store_city_features: 9393.11\n",
      "mean_20_dow6_2017: 7915.81\n",
      "promo_13: 7334.37\n",
      "lag_35_sales: 6842.54\n",
      "promo_4: 6253.96\n",
      "lag_7_sales: 5929.25\n",
      "promo_2: 5599.80\n",
      "mean_20_dow4_2017: 5361.51\n",
      "mean_20_dow2_2017: 5277.79\n",
      "promo_9: 4121.85\n",
      "mean_20_dow5_2017: 3994.88\n",
      "promo_10: 3826.60\n",
      "lag_42_sales: 3770.79\n",
      "sum_2_promo: 3257.59\n",
      "lag_5_sales: 3199.45\n",
      "lag_28_sales: 2885.55\n",
      "promo_11: 2456.96\n",
      "std_5_sales: 2369.98\n",
      "sum_6_promo: 2132.03\n",
      "lag_4_sales: 2095.54\n",
      "lag_6_sales: 2027.21\n",
      "std_4_sales: 1829.16\n",
      "std_6_sales: 1716.56\n",
      "sum_5_promo: 1695.77\n",
      "promo_1: 1568.00\n",
      "promo_12: 1525.43\n",
      "mean_4_dow1_2017: 1511.24\n",
      "sum_3_promo: 1447.74\n",
      "store_state_features: 1295.22\n",
      "mean_4_dow4_2017: 1172.99\n",
      "mean_4_dow2_2017: 1162.30\n",
      "lag_14_sales: 1116.82\n",
      "lag_3_sales: 912.23\n",
      "mean_4_dow3_2017: 642.83\n",
      "promo_15: 488.92\n",
      "lag_63_sales: 387.46\n",
      "std_3_sales: 173.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [11:50<11:44, 88.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.951534\tvalid_1's l2: 0.997163\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.896285\tvalid_1's l2: 0.940745\n",
      "[3]\ttraining's l2: 0.846202\tvalid_1's l2: 0.889279\n",
      "[4]\ttraining's l2: 0.801998\tvalid_1's l2: 0.843598\n",
      "[5]\ttraining's l2: 0.760911\tvalid_1's l2: 0.801476\n",
      "[6]\ttraining's l2: 0.723614\tvalid_1's l2: 0.763265\n",
      "[7]\ttraining's l2: 0.690013\tvalid_1's l2: 0.728053\n",
      "[8]\ttraining's l2: 0.659635\tvalid_1's l2: 0.69639\n",
      "[9]\ttraining's l2: 0.632055\tvalid_1's l2: 0.66787\n",
      "[10]\ttraining's l2: 0.606888\tvalid_1's l2: 0.641943\n",
      "[11]\ttraining's l2: 0.584133\tvalid_1's l2: 0.618389\n",
      "[12]\ttraining's l2: 0.563644\tvalid_1's l2: 0.596853\n",
      "[13]\ttraining's l2: 0.545067\tvalid_1's l2: 0.577219\n",
      "[14]\ttraining's l2: 0.528212\tvalid_1's l2: 0.559308\n",
      "[15]\ttraining's l2: 0.512977\tvalid_1's l2: 0.543211\n",
      "[16]\ttraining's l2: 0.49906\tvalid_1's l2: 0.528577\n",
      "[17]\ttraining's l2: 0.486541\tvalid_1's l2: 0.515218\n",
      "[18]\ttraining's l2: 0.475072\tvalid_1's l2: 0.503087\n",
      "[19]\ttraining's l2: 0.464707\tvalid_1's l2: 0.491989\n",
      "[20]\ttraining's l2: 0.455352\tvalid_1's l2: 0.481902\n",
      "[21]\ttraining's l2: 0.447019\tvalid_1's l2: 0.472783\n",
      "[22]\ttraining's l2: 0.439367\tvalid_1's l2: 0.464341\n",
      "[23]\ttraining's l2: 0.432296\tvalid_1's l2: 0.45664\n",
      "[24]\ttraining's l2: 0.425859\tvalid_1's l2: 0.449652\n",
      "[25]\ttraining's l2: 0.420023\tvalid_1's l2: 0.443314\n",
      "[26]\ttraining's l2: 0.41472\tvalid_1's l2: 0.437479\n",
      "[27]\ttraining's l2: 0.409929\tvalid_1's l2: 0.432236\n",
      "[28]\ttraining's l2: 0.405692\tvalid_1's l2: 0.427527\n",
      "[29]\ttraining's l2: 0.401705\tvalid_1's l2: 0.423018\n",
      "[30]\ttraining's l2: 0.398047\tvalid_1's l2: 0.418937\n",
      "[31]\ttraining's l2: 0.394736\tvalid_1's l2: 0.415204\n",
      "[32]\ttraining's l2: 0.391744\tvalid_1's l2: 0.411803\n",
      "[33]\ttraining's l2: 0.388961\tvalid_1's l2: 0.408601\n",
      "[34]\ttraining's l2: 0.386399\tvalid_1's l2: 0.405623\n",
      "[35]\ttraining's l2: 0.384084\tvalid_1's l2: 0.402898\n",
      "[36]\ttraining's l2: 0.382022\tvalid_1's l2: 0.400467\n",
      "[37]\ttraining's l2: 0.380066\tvalid_1's l2: 0.398209\n",
      "[38]\ttraining's l2: 0.378348\tvalid_1's l2: 0.396247\n",
      "[39]\ttraining's l2: 0.376697\tvalid_1's l2: 0.394255\n",
      "[40]\ttraining's l2: 0.375167\tvalid_1's l2: 0.392433\n",
      "[41]\ttraining's l2: 0.373844\tvalid_1's l2: 0.39087\n",
      "[42]\ttraining's l2: 0.372551\tvalid_1's l2: 0.389297\n",
      "[43]\ttraining's l2: 0.37135\tvalid_1's l2: 0.387908\n",
      "[44]\ttraining's l2: 0.370253\tvalid_1's l2: 0.386533\n",
      "[45]\ttraining's l2: 0.369258\tvalid_1's l2: 0.38534\n",
      "[46]\ttraining's l2: 0.368323\tvalid_1's l2: 0.38416\n",
      "[47]\ttraining's l2: 0.367461\tvalid_1's l2: 0.383145\n",
      "[48]\ttraining's l2: 0.366567\tvalid_1's l2: 0.382104\n",
      "[49]\ttraining's l2: 0.365718\tvalid_1's l2: 0.381104\n",
      "[50]\ttraining's l2: 0.36502\tvalid_1's l2: 0.380207\n",
      "[51]\ttraining's l2: 0.364315\tvalid_1's l2: 0.379405\n",
      "[52]\ttraining's l2: 0.363664\tvalid_1's l2: 0.378656\n",
      "[53]\ttraining's l2: 0.363045\tvalid_1's l2: 0.377915\n",
      "[54]\ttraining's l2: 0.362477\tvalid_1's l2: 0.377228\n",
      "[55]\ttraining's l2: 0.361909\tvalid_1's l2: 0.376587\n",
      "[56]\ttraining's l2: 0.361416\tvalid_1's l2: 0.376007\n",
      "[57]\ttraining's l2: 0.361\tvalid_1's l2: 0.375481\n",
      "[58]\ttraining's l2: 0.360529\tvalid_1's l2: 0.37491\n",
      "[59]\ttraining's l2: 0.360136\tvalid_1's l2: 0.374397\n",
      "[60]\ttraining's l2: 0.359742\tvalid_1's l2: 0.373891\n",
      "[61]\ttraining's l2: 0.359364\tvalid_1's l2: 0.373468\n",
      "[62]\ttraining's l2: 0.358946\tvalid_1's l2: 0.37305\n",
      "[63]\ttraining's l2: 0.35865\tvalid_1's l2: 0.372665\n",
      "[64]\ttraining's l2: 0.358364\tvalid_1's l2: 0.372322\n",
      "[65]\ttraining's l2: 0.358007\tvalid_1's l2: 0.371918\n",
      "[66]\ttraining's l2: 0.357773\tvalid_1's l2: 0.371672\n",
      "[67]\ttraining's l2: 0.357493\tvalid_1's l2: 0.37138\n",
      "[68]\ttraining's l2: 0.357128\tvalid_1's l2: 0.371003\n",
      "[69]\ttraining's l2: 0.356896\tvalid_1's l2: 0.370726\n",
      "[70]\ttraining's l2: 0.356622\tvalid_1's l2: 0.370413\n",
      "[71]\ttraining's l2: 0.356331\tvalid_1's l2: 0.370109\n",
      "[72]\ttraining's l2: 0.356085\tvalid_1's l2: 0.369906\n",
      "[73]\ttraining's l2: 0.355878\tvalid_1's l2: 0.369709\n",
      "[74]\ttraining's l2: 0.35556\tvalid_1's l2: 0.369497\n",
      "[75]\ttraining's l2: 0.355263\tvalid_1's l2: 0.369268\n",
      "[76]\ttraining's l2: 0.355014\tvalid_1's l2: 0.369031\n",
      "[77]\ttraining's l2: 0.354806\tvalid_1's l2: 0.368765\n",
      "[78]\ttraining's l2: 0.354618\tvalid_1's l2: 0.368571\n",
      "[79]\ttraining's l2: 0.354375\tvalid_1's l2: 0.368383\n",
      "[80]\ttraining's l2: 0.354116\tvalid_1's l2: 0.368168\n",
      "[81]\ttraining's l2: 0.353921\tvalid_1's l2: 0.367942\n",
      "[82]\ttraining's l2: 0.353706\tvalid_1's l2: 0.367721\n",
      "[83]\ttraining's l2: 0.353487\tvalid_1's l2: 0.367556\n",
      "[84]\ttraining's l2: 0.353307\tvalid_1's l2: 0.367376\n",
      "[85]\ttraining's l2: 0.353137\tvalid_1's l2: 0.367178\n",
      "[86]\ttraining's l2: 0.352963\tvalid_1's l2: 0.367083\n",
      "[87]\ttraining's l2: 0.352803\tvalid_1's l2: 0.366953\n",
      "[88]\ttraining's l2: 0.352652\tvalid_1's l2: 0.366867\n",
      "[89]\ttraining's l2: 0.352468\tvalid_1's l2: 0.366722\n",
      "[90]\ttraining's l2: 0.352323\tvalid_1's l2: 0.366646\n",
      "[91]\ttraining's l2: 0.352207\tvalid_1's l2: 0.366552\n",
      "[92]\ttraining's l2: 0.352033\tvalid_1's l2: 0.366389\n",
      "[93]\ttraining's l2: 0.351884\tvalid_1's l2: 0.366253\n",
      "[94]\ttraining's l2: 0.351753\tvalid_1's l2: 0.36615\n",
      "[95]\ttraining's l2: 0.351592\tvalid_1's l2: 0.366063\n",
      "[96]\ttraining's l2: 0.351483\tvalid_1's l2: 0.365973\n",
      "[97]\ttraining's l2: 0.351382\tvalid_1's l2: 0.365888\n",
      "[98]\ttraining's l2: 0.351232\tvalid_1's l2: 0.365719\n",
      "[99]\ttraining's l2: 0.351128\tvalid_1's l2: 0.365617\n",
      "[100]\ttraining's l2: 0.351027\tvalid_1's l2: 0.365483\n",
      "[101]\ttraining's l2: 0.350907\tvalid_1's l2: 0.36535\n",
      "[102]\ttraining's l2: 0.3508\tvalid_1's l2: 0.365259\n",
      "[103]\ttraining's l2: 0.350679\tvalid_1's l2: 0.365115\n",
      "[104]\ttraining's l2: 0.350588\tvalid_1's l2: 0.365048\n",
      "[105]\ttraining's l2: 0.350452\tvalid_1's l2: 0.364953\n",
      "[106]\ttraining's l2: 0.350339\tvalid_1's l2: 0.364895\n",
      "[107]\ttraining's l2: 0.350245\tvalid_1's l2: 0.36482\n",
      "[108]\ttraining's l2: 0.350176\tvalid_1's l2: 0.364777\n",
      "[109]\ttraining's l2: 0.3501\tvalid_1's l2: 0.364731\n",
      "[110]\ttraining's l2: 0.350012\tvalid_1's l2: 0.364623\n",
      "[111]\ttraining's l2: 0.349948\tvalid_1's l2: 0.364571\n",
      "[112]\ttraining's l2: 0.349845\tvalid_1's l2: 0.364529\n",
      "[113]\ttraining's l2: 0.349771\tvalid_1's l2: 0.364466\n",
      "[114]\ttraining's l2: 0.34966\tvalid_1's l2: 0.364356\n",
      "[115]\ttraining's l2: 0.349587\tvalid_1's l2: 0.364345\n",
      "[116]\ttraining's l2: 0.349512\tvalid_1's l2: 0.364323\n",
      "[117]\ttraining's l2: 0.34944\tvalid_1's l2: 0.364252\n",
      "[118]\ttraining's l2: 0.349355\tvalid_1's l2: 0.364218\n",
      "[119]\ttraining's l2: 0.349257\tvalid_1's l2: 0.364107\n",
      "[120]\ttraining's l2: 0.349136\tvalid_1's l2: 0.364037\n",
      "[121]\ttraining's l2: 0.349049\tvalid_1's l2: 0.364004\n",
      "[122]\ttraining's l2: 0.349004\tvalid_1's l2: 0.36398\n",
      "[123]\ttraining's l2: 0.348887\tvalid_1's l2: 0.363939\n",
      "[124]\ttraining's l2: 0.348829\tvalid_1's l2: 0.363891\n",
      "[125]\ttraining's l2: 0.348765\tvalid_1's l2: 0.363867\n",
      "[126]\ttraining's l2: 0.348711\tvalid_1's l2: 0.363863\n",
      "[127]\ttraining's l2: 0.348605\tvalid_1's l2: 0.363791\n",
      "[128]\ttraining's l2: 0.348489\tvalid_1's l2: 0.363753\n",
      "[129]\ttraining's l2: 0.348443\tvalid_1's l2: 0.363734\n",
      "[130]\ttraining's l2: 0.348403\tvalid_1's l2: 0.363722\n",
      "[131]\ttraining's l2: 0.348349\tvalid_1's l2: 0.363703\n",
      "[132]\ttraining's l2: 0.348288\tvalid_1's l2: 0.363661\n",
      "[133]\ttraining's l2: 0.348171\tvalid_1's l2: 0.363598\n",
      "[134]\ttraining's l2: 0.348132\tvalid_1's l2: 0.363589\n",
      "[135]\ttraining's l2: 0.348045\tvalid_1's l2: 0.363556\n",
      "[136]\ttraining's l2: 0.34797\tvalid_1's l2: 0.363513\n",
      "[137]\ttraining's l2: 0.347905\tvalid_1's l2: 0.363492\n",
      "[138]\ttraining's l2: 0.347863\tvalid_1's l2: 0.363464\n",
      "[139]\ttraining's l2: 0.347798\tvalid_1's l2: 0.363381\n",
      "[140]\ttraining's l2: 0.347744\tvalid_1's l2: 0.363349\n",
      "[141]\ttraining's l2: 0.347707\tvalid_1's l2: 0.363337\n",
      "[142]\ttraining's l2: 0.347634\tvalid_1's l2: 0.36327\n",
      "[143]\ttraining's l2: 0.347539\tvalid_1's l2: 0.363217\n",
      "[144]\ttraining's l2: 0.347468\tvalid_1's l2: 0.363204\n",
      "[145]\ttraining's l2: 0.347427\tvalid_1's l2: 0.363191\n",
      "[146]\ttraining's l2: 0.347387\tvalid_1's l2: 0.363176\n",
      "[147]\ttraining's l2: 0.347346\tvalid_1's l2: 0.363163\n",
      "[148]\ttraining's l2: 0.347305\tvalid_1's l2: 0.36316\n",
      "[149]\ttraining's l2: 0.347263\tvalid_1's l2: 0.363155\n",
      "[150]\ttraining's l2: 0.347225\tvalid_1's l2: 0.363154\n",
      "[151]\ttraining's l2: 0.347183\tvalid_1's l2: 0.363131\n",
      "[152]\ttraining's l2: 0.347147\tvalid_1's l2: 0.363135\n",
      "[153]\ttraining's l2: 0.347115\tvalid_1's l2: 0.363122\n",
      "[154]\ttraining's l2: 0.347072\tvalid_1's l2: 0.363096\n",
      "[155]\ttraining's l2: 0.34704\tvalid_1's l2: 0.363096\n",
      "[156]\ttraining's l2: 0.346959\tvalid_1's l2: 0.363077\n",
      "[157]\ttraining's l2: 0.346886\tvalid_1's l2: 0.363008\n",
      "[158]\ttraining's l2: 0.346857\tvalid_1's l2: 0.362989\n",
      "[159]\ttraining's l2: 0.346822\tvalid_1's l2: 0.362982\n",
      "[160]\ttraining's l2: 0.346791\tvalid_1's l2: 0.362961\n",
      "[161]\ttraining's l2: 0.346684\tvalid_1's l2: 0.362879\n",
      "[162]\ttraining's l2: 0.346653\tvalid_1's l2: 0.36287\n",
      "[163]\ttraining's l2: 0.34662\tvalid_1's l2: 0.362864\n",
      "[164]\ttraining's l2: 0.346544\tvalid_1's l2: 0.362803\n",
      "[165]\ttraining's l2: 0.346519\tvalid_1's l2: 0.362796\n",
      "[166]\ttraining's l2: 0.346486\tvalid_1's l2: 0.362781\n",
      "[167]\ttraining's l2: 0.346448\tvalid_1's l2: 0.362779\n",
      "[168]\ttraining's l2: 0.346406\tvalid_1's l2: 0.362782\n",
      "[169]\ttraining's l2: 0.346328\tvalid_1's l2: 0.362737\n",
      "[170]\ttraining's l2: 0.346283\tvalid_1's l2: 0.362735\n",
      "[171]\ttraining's l2: 0.346236\tvalid_1's l2: 0.362741\n",
      "[172]\ttraining's l2: 0.346198\tvalid_1's l2: 0.362753\n",
      "[173]\ttraining's l2: 0.34617\tvalid_1's l2: 0.362742\n",
      "[174]\ttraining's l2: 0.346103\tvalid_1's l2: 0.362673\n",
      "[175]\ttraining's l2: 0.346073\tvalid_1's l2: 0.362663\n",
      "[176]\ttraining's l2: 0.346027\tvalid_1's l2: 0.362634\n",
      "[177]\ttraining's l2: 0.345996\tvalid_1's l2: 0.362605\n",
      "[178]\ttraining's l2: 0.345963\tvalid_1's l2: 0.362609\n",
      "[179]\ttraining's l2: 0.345932\tvalid_1's l2: 0.362596\n",
      "[180]\ttraining's l2: 0.345888\tvalid_1's l2: 0.362604\n",
      "[181]\ttraining's l2: 0.345855\tvalid_1's l2: 0.362593\n",
      "[182]\ttraining's l2: 0.345818\tvalid_1's l2: 0.362595\n",
      "[183]\ttraining's l2: 0.345778\tvalid_1's l2: 0.362572\n",
      "[184]\ttraining's l2: 0.345701\tvalid_1's l2: 0.362518\n",
      "[185]\ttraining's l2: 0.34563\tvalid_1's l2: 0.362467\n",
      "[186]\ttraining's l2: 0.345574\tvalid_1's l2: 0.362442\n",
      "[187]\ttraining's l2: 0.345539\tvalid_1's l2: 0.362448\n",
      "[188]\ttraining's l2: 0.345519\tvalid_1's l2: 0.36243\n",
      "[189]\ttraining's l2: 0.34549\tvalid_1's l2: 0.362437\n",
      "[190]\ttraining's l2: 0.345464\tvalid_1's l2: 0.36242\n",
      "[191]\ttraining's l2: 0.345378\tvalid_1's l2: 0.362218\n",
      "[192]\ttraining's l2: 0.345347\tvalid_1's l2: 0.362205\n",
      "[193]\ttraining's l2: 0.345321\tvalid_1's l2: 0.362205\n",
      "[194]\ttraining's l2: 0.345295\tvalid_1's l2: 0.362189\n",
      "[195]\ttraining's l2: 0.345227\tvalid_1's l2: 0.362116\n",
      "[196]\ttraining's l2: 0.345188\tvalid_1's l2: 0.362111\n",
      "[197]\ttraining's l2: 0.345155\tvalid_1's l2: 0.362104\n",
      "[198]\ttraining's l2: 0.345121\tvalid_1's l2: 0.362084\n",
      "[199]\ttraining's l2: 0.345088\tvalid_1's l2: 0.362081\n",
      "[200]\ttraining's l2: 0.34506\tvalid_1's l2: 0.362083\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.34506\tvalid_1's l2: 0.362083\n",
      "mean_21_sales: 4939378.04\n",
      "mean_7_sales: 4385176.06\n",
      "mean_30_sales: 4190715.83\n",
      "mean_14_sales: 4041727.00\n",
      "mean_63_sales: 1216253.95\n",
      "mean_20_dow1_2017: 914484.86\n",
      "promo_8: 741243.66\n",
      "mean_6_sales: 535943.60\n",
      "item_class_features: 257204.71\n",
      "lag_1_sales: 96737.38\n",
      "mean_4_dow1_2017: 80526.16\n",
      "mean_5_sales: 70863.47\n",
      "sum_4_promo: 59432.67\n",
      "promo_7: 58416.25\n",
      "mean_20_dow2_2017: 45786.67\n",
      "mean_60_sales: 43656.18\n",
      "std_21_sales: 42622.73\n",
      "promo_10: 39708.26\n",
      "std_14_sales: 38144.22\n",
      "mean_4_dow6_2017: 37779.81\n",
      "std_30_sales: 36072.04\n",
      "sum_6_promo: 29778.30\n",
      "sum_2_promo: 26763.75\n",
      "item_family_features: 26087.60\n",
      "std_63_sales: 23956.25\n",
      "promo_14: 19424.64\n",
      "sum_7_promo: 19335.63\n",
      "mean_4_sales: 19022.35\n",
      "promo_9: 16143.64\n",
      "store_cluster_features: 15193.80\n",
      "std_60_sales: 15121.55\n",
      "mean_3_sales: 14977.26\n",
      "lag_21_sales: 14541.34\n",
      "promo_12: 12564.27\n",
      "store_city_features: 12429.21\n",
      "sum_21_promo: 12182.03\n",
      "mean_20_dow0_2017: 11818.19\n",
      "promo_11: 9335.90\n",
      "sum_14_promo: 9152.21\n",
      "lag_56_sales: 8319.58\n",
      "lag_5_sales: 8194.78\n",
      "promo_1: 8091.78\n",
      "promo_3: 7808.86\n",
      "lag_6_sales: 7780.78\n",
      "mean_20_dow3_2017: 7762.74\n",
      "std_7_sales: 7562.21\n",
      "promo_6: 7349.97\n",
      "sum_3_promo: 6859.06\n",
      "sum_5_promo: 6684.67\n",
      "std_6_sales: 6642.26\n",
      "promo_13: 5231.69\n",
      "mean_20_dow6_2017: 5105.93\n",
      "promo_4: 4809.49\n",
      "mean_20_dow4_2017: 4307.30\n",
      "promo_0: 4117.79\n",
      "std_5_sales: 3661.12\n",
      "mean_4_dow0_2017: 3541.31\n",
      "lag_4_sales: 3534.12\n",
      "promo_5: 3466.51\n",
      "lag_35_sales: 3072.79\n",
      "lag_49_sales: 2731.44\n",
      "mean_4_dow2_2017: 2678.24\n",
      "lag_2_sales: 2269.48\n",
      "store_type_features: 2113.99\n",
      "promo_15: 1866.74\n",
      "mean_20_dow5_2017: 1832.96\n",
      "lag_3_sales: 1767.70\n",
      "lag_7_sales: 1608.93\n",
      "promo_2: 1239.42\n",
      "std_4_sales: 1229.85\n",
      "mean_4_dow3_2017: 1213.20\n",
      "mean_4_dow4_2017: 824.50\n",
      "lag_14_sales: 802.10\n",
      "store_state_features: 582.25\n",
      "mean_4_dow5_2017: 480.01\n",
      "lag_42_sales: 463.34\n",
      "lag_63_sales: 340.84\n",
      "std_3_sales: 292.79\n",
      "lag_28_sales: 204.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [13:18<10:16, 88.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.06013\tvalid_1's l2: 1.07278\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.995915\tvalid_1's l2: 1.00856\n",
      "[3]\ttraining's l2: 0.937465\tvalid_1's l2: 0.949567\n",
      "[4]\ttraining's l2: 0.884733\tvalid_1's l2: 0.896285\n",
      "[5]\ttraining's l2: 0.836903\tvalid_1's l2: 0.847886\n",
      "[6]\ttraining's l2: 0.793404\tvalid_1's l2: 0.804368\n",
      "[7]\ttraining's l2: 0.754173\tvalid_1's l2: 0.764597\n",
      "[8]\ttraining's l2: 0.718641\tvalid_1's l2: 0.728737\n",
      "[9]\ttraining's l2: 0.68641\tvalid_1's l2: 0.695984\n",
      "[10]\ttraining's l2: 0.657787\tvalid_1's l2: 0.667238\n",
      "[11]\ttraining's l2: 0.631085\tvalid_1's l2: 0.640177\n",
      "[12]\ttraining's l2: 0.607789\tvalid_1's l2: 0.616661\n",
      "[13]\ttraining's l2: 0.585774\tvalid_1's l2: 0.594107\n",
      "[14]\ttraining's l2: 0.565807\tvalid_1's l2: 0.573696\n",
      "[15]\ttraining's l2: 0.547689\tvalid_1's l2: 0.555239\n",
      "[16]\ttraining's l2: 0.531215\tvalid_1's l2: 0.538561\n",
      "[17]\ttraining's l2: 0.516385\tvalid_1's l2: 0.523285\n",
      "[18]\ttraining's l2: 0.502783\tvalid_1's l2: 0.509382\n",
      "[19]\ttraining's l2: 0.490962\tvalid_1's l2: 0.497277\n",
      "[20]\ttraining's l2: 0.479756\tvalid_1's l2: 0.485624\n",
      "[21]\ttraining's l2: 0.469494\tvalid_1's l2: 0.475174\n",
      "[22]\ttraining's l2: 0.46036\tvalid_1's l2: 0.46573\n",
      "[23]\ttraining's l2: 0.452249\tvalid_1's l2: 0.457435\n",
      "[24]\ttraining's l2: 0.444562\tvalid_1's l2: 0.449481\n",
      "[25]\ttraining's l2: 0.437509\tvalid_1's l2: 0.442226\n",
      "[26]\ttraining's l2: 0.43142\tvalid_1's l2: 0.435903\n",
      "[27]\ttraining's l2: 0.425883\tvalid_1's l2: 0.430125\n",
      "[28]\ttraining's l2: 0.420465\tvalid_1's l2: 0.424601\n",
      "[29]\ttraining's l2: 0.415569\tvalid_1's l2: 0.419547\n",
      "[30]\ttraining's l2: 0.411383\tvalid_1's l2: 0.415286\n",
      "[31]\ttraining's l2: 0.407279\tvalid_1's l2: 0.410937\n",
      "[32]\ttraining's l2: 0.403503\tvalid_1's l2: 0.406998\n",
      "[33]\ttraining's l2: 0.400077\tvalid_1's l2: 0.403312\n",
      "[34]\ttraining's l2: 0.396878\tvalid_1's l2: 0.399922\n",
      "[35]\ttraining's l2: 0.393977\tvalid_1's l2: 0.396857\n",
      "[36]\ttraining's l2: 0.391382\tvalid_1's l2: 0.393977\n",
      "[37]\ttraining's l2: 0.388999\tvalid_1's l2: 0.391488\n",
      "[38]\ttraining's l2: 0.38693\tvalid_1's l2: 0.389312\n",
      "[39]\ttraining's l2: 0.384808\tvalid_1's l2: 0.38706\n",
      "[40]\ttraining's l2: 0.382961\tvalid_1's l2: 0.385069\n",
      "[41]\ttraining's l2: 0.381143\tvalid_1's l2: 0.383125\n",
      "[42]\ttraining's l2: 0.379528\tvalid_1's l2: 0.381382\n",
      "[43]\ttraining's l2: 0.377995\tvalid_1's l2: 0.379789\n",
      "[44]\ttraining's l2: 0.376646\tvalid_1's l2: 0.378369\n",
      "[45]\ttraining's l2: 0.375321\tvalid_1's l2: 0.376978\n",
      "[46]\ttraining's l2: 0.374156\tvalid_1's l2: 0.375775\n",
      "[47]\ttraining's l2: 0.373031\tvalid_1's l2: 0.374632\n",
      "[48]\ttraining's l2: 0.372071\tvalid_1's l2: 0.373618\n",
      "[49]\ttraining's l2: 0.37117\tvalid_1's l2: 0.372689\n",
      "[50]\ttraining's l2: 0.370324\tvalid_1's l2: 0.371901\n",
      "[51]\ttraining's l2: 0.36944\tvalid_1's l2: 0.370953\n",
      "[52]\ttraining's l2: 0.368583\tvalid_1's l2: 0.370044\n",
      "[53]\ttraining's l2: 0.367763\tvalid_1's l2: 0.369179\n",
      "[54]\ttraining's l2: 0.367056\tvalid_1's l2: 0.3685\n",
      "[55]\ttraining's l2: 0.366426\tvalid_1's l2: 0.367858\n",
      "[56]\ttraining's l2: 0.365762\tvalid_1's l2: 0.367184\n",
      "[57]\ttraining's l2: 0.365272\tvalid_1's l2: 0.366663\n",
      "[58]\ttraining's l2: 0.364737\tvalid_1's l2: 0.366197\n",
      "[59]\ttraining's l2: 0.364245\tvalid_1's l2: 0.365732\n",
      "[60]\ttraining's l2: 0.363744\tvalid_1's l2: 0.365223\n",
      "[61]\ttraining's l2: 0.363223\tvalid_1's l2: 0.364731\n",
      "[62]\ttraining's l2: 0.362721\tvalid_1's l2: 0.364263\n",
      "[63]\ttraining's l2: 0.3623\tvalid_1's l2: 0.363862\n",
      "[64]\ttraining's l2: 0.361872\tvalid_1's l2: 0.363445\n",
      "[65]\ttraining's l2: 0.36145\tvalid_1's l2: 0.362972\n",
      "[66]\ttraining's l2: 0.361165\tvalid_1's l2: 0.362722\n",
      "[67]\ttraining's l2: 0.360804\tvalid_1's l2: 0.362409\n",
      "[68]\ttraining's l2: 0.360431\tvalid_1's l2: 0.362056\n",
      "[69]\ttraining's l2: 0.360048\tvalid_1's l2: 0.361671\n",
      "[70]\ttraining's l2: 0.35971\tvalid_1's l2: 0.361448\n",
      "[71]\ttraining's l2: 0.359378\tvalid_1's l2: 0.361216\n",
      "[72]\ttraining's l2: 0.358982\tvalid_1's l2: 0.360854\n",
      "[73]\ttraining's l2: 0.358664\tvalid_1's l2: 0.360544\n",
      "[74]\ttraining's l2: 0.358374\tvalid_1's l2: 0.360295\n",
      "[75]\ttraining's l2: 0.358071\tvalid_1's l2: 0.360026\n",
      "[76]\ttraining's l2: 0.357778\tvalid_1's l2: 0.359765\n",
      "[77]\ttraining's l2: 0.357525\tvalid_1's l2: 0.359571\n",
      "[78]\ttraining's l2: 0.357216\tvalid_1's l2: 0.359274\n",
      "[79]\ttraining's l2: 0.356941\tvalid_1's l2: 0.359036\n",
      "[80]\ttraining's l2: 0.356672\tvalid_1's l2: 0.358801\n",
      "[81]\ttraining's l2: 0.356424\tvalid_1's l2: 0.358629\n",
      "[82]\ttraining's l2: 0.356223\tvalid_1's l2: 0.358491\n",
      "[83]\ttraining's l2: 0.356025\tvalid_1's l2: 0.358335\n",
      "[84]\ttraining's l2: 0.355807\tvalid_1's l2: 0.358224\n",
      "[85]\ttraining's l2: 0.355573\tvalid_1's l2: 0.358034\n",
      "[86]\ttraining's l2: 0.355322\tvalid_1's l2: 0.357845\n",
      "[87]\ttraining's l2: 0.35512\tvalid_1's l2: 0.357685\n",
      "[88]\ttraining's l2: 0.354956\tvalid_1's l2: 0.357556\n",
      "[89]\ttraining's l2: 0.354751\tvalid_1's l2: 0.357443\n",
      "[90]\ttraining's l2: 0.354578\tvalid_1's l2: 0.357347\n",
      "[91]\ttraining's l2: 0.354365\tvalid_1's l2: 0.357122\n",
      "[92]\ttraining's l2: 0.354193\tvalid_1's l2: 0.356957\n",
      "[93]\ttraining's l2: 0.354039\tvalid_1's l2: 0.356833\n",
      "[94]\ttraining's l2: 0.353888\tvalid_1's l2: 0.356795\n",
      "[95]\ttraining's l2: 0.353755\tvalid_1's l2: 0.356709\n",
      "[96]\ttraining's l2: 0.353479\tvalid_1's l2: 0.356498\n",
      "[97]\ttraining's l2: 0.353332\tvalid_1's l2: 0.356364\n",
      "[98]\ttraining's l2: 0.353135\tvalid_1's l2: 0.356117\n",
      "[99]\ttraining's l2: 0.352979\tvalid_1's l2: 0.356067\n",
      "[100]\ttraining's l2: 0.352829\tvalid_1's l2: 0.355904\n",
      "[101]\ttraining's l2: 0.352685\tvalid_1's l2: 0.355739\n",
      "[102]\ttraining's l2: 0.352557\tvalid_1's l2: 0.355688\n",
      "[103]\ttraining's l2: 0.352398\tvalid_1's l2: 0.355558\n",
      "[104]\ttraining's l2: 0.352262\tvalid_1's l2: 0.355498\n",
      "[105]\ttraining's l2: 0.352071\tvalid_1's l2: 0.355359\n",
      "[106]\ttraining's l2: 0.351931\tvalid_1's l2: 0.355273\n",
      "[107]\ttraining's l2: 0.351825\tvalid_1's l2: 0.355185\n",
      "[108]\ttraining's l2: 0.351712\tvalid_1's l2: 0.355092\n",
      "[109]\ttraining's l2: 0.351604\tvalid_1's l2: 0.35503\n",
      "[110]\ttraining's l2: 0.351502\tvalid_1's l2: 0.354974\n",
      "[111]\ttraining's l2: 0.351401\tvalid_1's l2: 0.354903\n",
      "[112]\ttraining's l2: 0.351324\tvalid_1's l2: 0.354849\n",
      "[113]\ttraining's l2: 0.351138\tvalid_1's l2: 0.354725\n",
      "[114]\ttraining's l2: 0.35106\tvalid_1's l2: 0.354653\n",
      "[115]\ttraining's l2: 0.350985\tvalid_1's l2: 0.354626\n",
      "[116]\ttraining's l2: 0.350868\tvalid_1's l2: 0.354532\n",
      "[117]\ttraining's l2: 0.35074\tvalid_1's l2: 0.354396\n",
      "[118]\ttraining's l2: 0.350627\tvalid_1's l2: 0.354334\n",
      "[119]\ttraining's l2: 0.350539\tvalid_1's l2: 0.354277\n",
      "[120]\ttraining's l2: 0.350435\tvalid_1's l2: 0.354274\n",
      "[121]\ttraining's l2: 0.350371\tvalid_1's l2: 0.354264\n",
      "[122]\ttraining's l2: 0.350289\tvalid_1's l2: 0.354188\n",
      "[123]\ttraining's l2: 0.350207\tvalid_1's l2: 0.354163\n",
      "[124]\ttraining's l2: 0.350122\tvalid_1's l2: 0.354115\n",
      "[125]\ttraining's l2: 0.350005\tvalid_1's l2: 0.354016\n",
      "[126]\ttraining's l2: 0.349928\tvalid_1's l2: 0.353983\n",
      "[127]\ttraining's l2: 0.34984\tvalid_1's l2: 0.353909\n",
      "[128]\ttraining's l2: 0.349779\tvalid_1's l2: 0.353878\n",
      "[129]\ttraining's l2: 0.349703\tvalid_1's l2: 0.353869\n",
      "[130]\ttraining's l2: 0.349562\tvalid_1's l2: 0.353807\n",
      "[131]\ttraining's l2: 0.349466\tvalid_1's l2: 0.353774\n",
      "[132]\ttraining's l2: 0.349414\tvalid_1's l2: 0.353736\n",
      "[133]\ttraining's l2: 0.349293\tvalid_1's l2: 0.353662\n",
      "[134]\ttraining's l2: 0.349236\tvalid_1's l2: 0.353635\n",
      "[135]\ttraining's l2: 0.349135\tvalid_1's l2: 0.353598\n",
      "[136]\ttraining's l2: 0.349068\tvalid_1's l2: 0.353572\n",
      "[137]\ttraining's l2: 0.349023\tvalid_1's l2: 0.353545\n",
      "[138]\ttraining's l2: 0.34893\tvalid_1's l2: 0.353497\n",
      "[139]\ttraining's l2: 0.348869\tvalid_1's l2: 0.353468\n",
      "[140]\ttraining's l2: 0.348813\tvalid_1's l2: 0.353461\n",
      "[141]\ttraining's l2: 0.348762\tvalid_1's l2: 0.353446\n",
      "[142]\ttraining's l2: 0.348669\tvalid_1's l2: 0.353337\n",
      "[143]\ttraining's l2: 0.348598\tvalid_1's l2: 0.353273\n",
      "[144]\ttraining's l2: 0.34855\tvalid_1's l2: 0.353273\n",
      "[145]\ttraining's l2: 0.348479\tvalid_1's l2: 0.353231\n",
      "[146]\ttraining's l2: 0.348395\tvalid_1's l2: 0.353184\n",
      "[147]\ttraining's l2: 0.348355\tvalid_1's l2: 0.353156\n",
      "[148]\ttraining's l2: 0.348283\tvalid_1's l2: 0.353078\n",
      "[149]\ttraining's l2: 0.348228\tvalid_1's l2: 0.353032\n",
      "[150]\ttraining's l2: 0.348167\tvalid_1's l2: 0.35299\n",
      "[151]\ttraining's l2: 0.348117\tvalid_1's l2: 0.352973\n",
      "[152]\ttraining's l2: 0.348061\tvalid_1's l2: 0.352967\n",
      "[153]\ttraining's l2: 0.348008\tvalid_1's l2: 0.352972\n",
      "[154]\ttraining's l2: 0.347928\tvalid_1's l2: 0.352921\n",
      "[155]\ttraining's l2: 0.347899\tvalid_1's l2: 0.352901\n",
      "[156]\ttraining's l2: 0.347858\tvalid_1's l2: 0.352865\n",
      "[157]\ttraining's l2: 0.347814\tvalid_1's l2: 0.352861\n",
      "[158]\ttraining's l2: 0.34777\tvalid_1's l2: 0.352831\n",
      "[159]\ttraining's l2: 0.347725\tvalid_1's l2: 0.352811\n",
      "[160]\ttraining's l2: 0.347671\tvalid_1's l2: 0.35281\n",
      "[161]\ttraining's l2: 0.347589\tvalid_1's l2: 0.352768\n",
      "[162]\ttraining's l2: 0.347511\tvalid_1's l2: 0.352757\n",
      "[163]\ttraining's l2: 0.347468\tvalid_1's l2: 0.352747\n",
      "[164]\ttraining's l2: 0.347412\tvalid_1's l2: 0.352704\n",
      "[165]\ttraining's l2: 0.347326\tvalid_1's l2: 0.352625\n",
      "[166]\ttraining's l2: 0.347282\tvalid_1's l2: 0.352597\n",
      "[167]\ttraining's l2: 0.347243\tvalid_1's l2: 0.352579\n",
      "[168]\ttraining's l2: 0.347188\tvalid_1's l2: 0.352563\n",
      "[169]\ttraining's l2: 0.347156\tvalid_1's l2: 0.352557\n",
      "[170]\ttraining's l2: 0.347094\tvalid_1's l2: 0.352586\n",
      "[171]\ttraining's l2: 0.34704\tvalid_1's l2: 0.35257\n",
      "[172]\ttraining's l2: 0.346958\tvalid_1's l2: 0.352515\n",
      "[173]\ttraining's l2: 0.346931\tvalid_1's l2: 0.352497\n",
      "[174]\ttraining's l2: 0.346885\tvalid_1's l2: 0.352481\n",
      "[175]\ttraining's l2: 0.346852\tvalid_1's l2: 0.352463\n",
      "[176]\ttraining's l2: 0.346792\tvalid_1's l2: 0.352496\n",
      "[177]\ttraining's l2: 0.346757\tvalid_1's l2: 0.352478\n",
      "[178]\ttraining's l2: 0.346712\tvalid_1's l2: 0.352463\n",
      "[179]\ttraining's l2: 0.346681\tvalid_1's l2: 0.352461\n",
      "[180]\ttraining's l2: 0.346638\tvalid_1's l2: 0.352431\n",
      "[181]\ttraining's l2: 0.346535\tvalid_1's l2: 0.352368\n",
      "[182]\ttraining's l2: 0.346487\tvalid_1's l2: 0.352356\n",
      "[183]\ttraining's l2: 0.346392\tvalid_1's l2: 0.352291\n",
      "[184]\ttraining's l2: 0.346346\tvalid_1's l2: 0.352278\n",
      "[185]\ttraining's l2: 0.34631\tvalid_1's l2: 0.352255\n",
      "[186]\ttraining's l2: 0.346232\tvalid_1's l2: 0.352222\n",
      "[187]\ttraining's l2: 0.346186\tvalid_1's l2: 0.352193\n",
      "[188]\ttraining's l2: 0.346158\tvalid_1's l2: 0.352195\n",
      "[189]\ttraining's l2: 0.346117\tvalid_1's l2: 0.352173\n",
      "[190]\ttraining's l2: 0.34608\tvalid_1's l2: 0.352161\n",
      "[191]\ttraining's l2: 0.346051\tvalid_1's l2: 0.352161\n",
      "[192]\ttraining's l2: 0.346007\tvalid_1's l2: 0.352156\n",
      "[193]\ttraining's l2: 0.345976\tvalid_1's l2: 0.352139\n",
      "[194]\ttraining's l2: 0.345942\tvalid_1's l2: 0.352128\n",
      "[195]\ttraining's l2: 0.345912\tvalid_1's l2: 0.352109\n",
      "[196]\ttraining's l2: 0.345874\tvalid_1's l2: 0.352105\n",
      "[197]\ttraining's l2: 0.345848\tvalid_1's l2: 0.352097\n",
      "[198]\ttraining's l2: 0.345813\tvalid_1's l2: 0.352068\n",
      "[199]\ttraining's l2: 0.34578\tvalid_1's l2: 0.352047\n",
      "[200]\ttraining's l2: 0.34575\tvalid_1's l2: 0.35204\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.34575\tvalid_1's l2: 0.35204\n",
      "mean_21_sales: 9097203.56\n",
      "mean_7_sales: 4054613.16\n",
      "mean_14_sales: 3340360.20\n",
      "mean_20_dow2_2017: 2811865.58\n",
      "mean_30_sales: 1909329.45\n",
      "mean_4_dow2_2017: 1113351.26\n",
      "mean_6_sales: 956081.19\n",
      "promo_9: 932917.08\n",
      "item_class_features: 425744.53\n",
      "mean_63_sales: 192705.57\n",
      "mean_5_sales: 154693.75\n",
      "sum_5_promo: 104532.31\n",
      "std_21_sales: 79387.78\n",
      "promo_10: 76578.32\n",
      "item_family_features: 75490.57\n",
      "std_30_sales: 65983.55\n",
      "store_cluster_features: 63146.82\n",
      "mean_60_sales: 55737.61\n",
      "lag_1_sales: 53779.10\n",
      "promo_7: 49651.80\n",
      "std_63_sales: 45439.91\n",
      "promo_14: 43713.36\n",
      "mean_20_dow1_2017: 42053.79\n",
      "std_14_sales: 32572.97\n",
      "promo_2: 32137.77\n",
      "lag_5_sales: 31674.91\n",
      "promo_8: 24998.63\n",
      "promo_12: 23615.29\n",
      "std_60_sales: 22971.83\n",
      "sum_4_promo: 20655.96\n",
      "mean_4_sales: 16990.97\n",
      "promo_11: 16940.56\n",
      "sum_2_promo: 15646.63\n",
      "lag_4_sales: 14776.53\n",
      "sum_7_promo: 14538.39\n",
      "store_city_features: 14212.18\n",
      "mean_20_dow0_2017: 14076.98\n",
      "mean_20_dow3_2017: 13954.67\n",
      "lag_49_sales: 13324.82\n",
      "sum_14_promo: 11203.39\n",
      "std_5_sales: 10806.38\n",
      "sum_3_promo: 10518.98\n",
      "lag_21_sales: 10496.22\n",
      "mean_3_sales: 9466.33\n",
      "store_type_features: 8495.31\n",
      "sum_21_promo: 7787.60\n",
      "sum_6_promo: 7745.19\n",
      "std_7_sales: 7638.35\n",
      "promo_13: 7463.25\n",
      "std_6_sales: 6433.92\n",
      "promo_15: 4151.83\n",
      "mean_4_dow0_2017: 3974.64\n",
      "mean_20_dow4_2017: 3346.20\n",
      "promo_6: 2875.15\n",
      "mean_4_dow1_2017: 2694.03\n",
      "mean_20_dow6_2017: 2284.69\n",
      "mean_4_dow4_2017: 2084.06\n",
      "lag_14_sales: 2059.30\n",
      "store_state_features: 1885.04\n",
      "lag_2_sales: 1876.54\n",
      "promo_0: 1730.68\n",
      "lag_6_sales: 1392.16\n",
      "mean_4_dow3_2017: 1196.05\n",
      "std_4_sales: 1155.90\n",
      "mean_20_dow5_2017: 1098.82\n",
      "promo_3: 1069.59\n",
      "lag_3_sales: 953.64\n",
      "lag_56_sales: 911.27\n",
      "lag_7_sales: 906.33\n",
      "lag_35_sales: 902.71\n",
      "lag_63_sales: 838.10\n",
      "mean_4_dow6_2017: 703.29\n",
      "lag_28_sales: 549.59\n",
      "promo_4: 452.59\n",
      "promo_5: 394.45\n",
      "lag_42_sales: 348.58\n",
      "std_3_sales: 277.79\n",
      "mean_4_dow5_2017: 205.92\n",
      "promo_1: 124.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [14:45<08:45, 87.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.19375\tvalid_1's l2: 1.14467\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.11904\tvalid_1's l2: 1.07137\n",
      "[3]\ttraining's l2: 1.05158\tvalid_1's l2: 1.00539\n",
      "[4]\ttraining's l2: 0.990555\tvalid_1's l2: 0.945449\n",
      "[5]\ttraining's l2: 0.935925\tvalid_1's l2: 0.89209\n",
      "[6]\ttraining's l2: 0.885695\tvalid_1's l2: 0.842973\n",
      "[7]\ttraining's l2: 0.840938\tvalid_1's l2: 0.799426\n",
      "[8]\ttraining's l2: 0.799551\tvalid_1's l2: 0.759303\n",
      "[9]\ttraining's l2: 0.762075\tvalid_1's l2: 0.723005\n",
      "[10]\ttraining's l2: 0.728369\tvalid_1's l2: 0.690239\n",
      "[11]\ttraining's l2: 0.697653\tvalid_1's l2: 0.66049\n",
      "[12]\ttraining's l2: 0.669745\tvalid_1's l2: 0.633496\n",
      "[13]\ttraining's l2: 0.6446\tvalid_1's l2: 0.609328\n",
      "[14]\ttraining's l2: 0.621719\tvalid_1's l2: 0.587379\n",
      "[15]\ttraining's l2: 0.601328\tvalid_1's l2: 0.567963\n",
      "[16]\ttraining's l2: 0.582601\tvalid_1's l2: 0.550021\n",
      "[17]\ttraining's l2: 0.565614\tvalid_1's l2: 0.533859\n",
      "[18]\ttraining's l2: 0.550068\tvalid_1's l2: 0.518984\n",
      "[19]\ttraining's l2: 0.536198\tvalid_1's l2: 0.505731\n",
      "[20]\ttraining's l2: 0.523474\tvalid_1's l2: 0.493682\n",
      "[21]\ttraining's l2: 0.511879\tvalid_1's l2: 0.482623\n",
      "[22]\ttraining's l2: 0.501592\tvalid_1's l2: 0.472911\n",
      "[23]\ttraining's l2: 0.492006\tvalid_1's l2: 0.46379\n",
      "[24]\ttraining's l2: 0.483548\tvalid_1's l2: 0.455896\n",
      "[25]\ttraining's l2: 0.475565\tvalid_1's l2: 0.448374\n",
      "[26]\ttraining's l2: 0.468345\tvalid_1's l2: 0.441539\n",
      "[27]\ttraining's l2: 0.461796\tvalid_1's l2: 0.435303\n",
      "[28]\ttraining's l2: 0.455859\tvalid_1's l2: 0.429743\n",
      "[29]\ttraining's l2: 0.450452\tvalid_1's l2: 0.424696\n",
      "[30]\ttraining's l2: 0.445487\tvalid_1's l2: 0.420045\n",
      "[31]\ttraining's l2: 0.44102\tvalid_1's l2: 0.415958\n",
      "[32]\ttraining's l2: 0.436886\tvalid_1's l2: 0.412092\n",
      "[33]\ttraining's l2: 0.433141\tvalid_1's l2: 0.408677\n",
      "[34]\ttraining's l2: 0.429723\tvalid_1's l2: 0.405447\n",
      "[35]\ttraining's l2: 0.426603\tvalid_1's l2: 0.402483\n",
      "[36]\ttraining's l2: 0.42373\tvalid_1's l2: 0.399825\n",
      "[37]\ttraining's l2: 0.421076\tvalid_1's l2: 0.397383\n",
      "[38]\ttraining's l2: 0.418681\tvalid_1's l2: 0.395193\n",
      "[39]\ttraining's l2: 0.416513\tvalid_1's l2: 0.393268\n",
      "[40]\ttraining's l2: 0.414489\tvalid_1's l2: 0.391496\n",
      "[41]\ttraining's l2: 0.412656\tvalid_1's l2: 0.389861\n",
      "[42]\ttraining's l2: 0.410944\tvalid_1's l2: 0.388292\n",
      "[43]\ttraining's l2: 0.409417\tvalid_1's l2: 0.387002\n",
      "[44]\ttraining's l2: 0.407948\tvalid_1's l2: 0.385648\n",
      "[45]\ttraining's l2: 0.406598\tvalid_1's l2: 0.384479\n",
      "[46]\ttraining's l2: 0.405336\tvalid_1's l2: 0.383345\n",
      "[47]\ttraining's l2: 0.40424\tvalid_1's l2: 0.382434\n",
      "[48]\ttraining's l2: 0.403095\tvalid_1's l2: 0.381383\n",
      "[49]\ttraining's l2: 0.402121\tvalid_1's l2: 0.380576\n",
      "[50]\ttraining's l2: 0.401235\tvalid_1's l2: 0.379861\n",
      "[51]\ttraining's l2: 0.400334\tvalid_1's l2: 0.379048\n",
      "[52]\ttraining's l2: 0.399496\tvalid_1's l2: 0.378329\n",
      "[53]\ttraining's l2: 0.398653\tvalid_1's l2: 0.37752\n",
      "[54]\ttraining's l2: 0.39796\tvalid_1's l2: 0.376948\n",
      "[55]\ttraining's l2: 0.397267\tvalid_1's l2: 0.376343\n",
      "[56]\ttraining's l2: 0.396554\tvalid_1's l2: 0.375823\n",
      "[57]\ttraining's l2: 0.396042\tvalid_1's l2: 0.375417\n",
      "[58]\ttraining's l2: 0.395527\tvalid_1's l2: 0.374991\n",
      "[59]\ttraining's l2: 0.394997\tvalid_1's l2: 0.374492\n",
      "[60]\ttraining's l2: 0.394502\tvalid_1's l2: 0.374096\n",
      "[61]\ttraining's l2: 0.393985\tvalid_1's l2: 0.373687\n",
      "[62]\ttraining's l2: 0.393444\tvalid_1's l2: 0.373237\n",
      "[63]\ttraining's l2: 0.392997\tvalid_1's l2: 0.372825\n",
      "[64]\ttraining's l2: 0.392591\tvalid_1's l2: 0.372463\n",
      "[65]\ttraining's l2: 0.392229\tvalid_1's l2: 0.372137\n",
      "[66]\ttraining's l2: 0.391912\tvalid_1's l2: 0.371881\n",
      "[67]\ttraining's l2: 0.391554\tvalid_1's l2: 0.371652\n",
      "[68]\ttraining's l2: 0.391104\tvalid_1's l2: 0.37134\n",
      "[69]\ttraining's l2: 0.390779\tvalid_1's l2: 0.371073\n",
      "[70]\ttraining's l2: 0.39052\tvalid_1's l2: 0.370871\n",
      "[71]\ttraining's l2: 0.390173\tvalid_1's l2: 0.37067\n",
      "[72]\ttraining's l2: 0.389852\tvalid_1's l2: 0.370455\n",
      "[73]\ttraining's l2: 0.389578\tvalid_1's l2: 0.370284\n",
      "[74]\ttraining's l2: 0.389262\tvalid_1's l2: 0.370062\n",
      "[75]\ttraining's l2: 0.388956\tvalid_1's l2: 0.369833\n",
      "[76]\ttraining's l2: 0.38863\tvalid_1's l2: 0.369587\n",
      "[77]\ttraining's l2: 0.3884\tvalid_1's l2: 0.369373\n",
      "[78]\ttraining's l2: 0.388158\tvalid_1's l2: 0.369202\n",
      "[79]\ttraining's l2: 0.387939\tvalid_1's l2: 0.369082\n",
      "[80]\ttraining's l2: 0.387741\tvalid_1's l2: 0.368927\n",
      "[81]\ttraining's l2: 0.387506\tvalid_1's l2: 0.368773\n",
      "[82]\ttraining's l2: 0.387315\tvalid_1's l2: 0.368604\n",
      "[83]\ttraining's l2: 0.38711\tvalid_1's l2: 0.368461\n",
      "[84]\ttraining's l2: 0.386863\tvalid_1's l2: 0.368322\n",
      "[85]\ttraining's l2: 0.386657\tvalid_1's l2: 0.368227\n",
      "[86]\ttraining's l2: 0.386438\tvalid_1's l2: 0.368126\n",
      "[87]\ttraining's l2: 0.386231\tvalid_1's l2: 0.368025\n",
      "[88]\ttraining's l2: 0.386072\tvalid_1's l2: 0.367923\n",
      "[89]\ttraining's l2: 0.385897\tvalid_1's l2: 0.367845\n",
      "[90]\ttraining's l2: 0.38568\tvalid_1's l2: 0.367738\n",
      "[91]\ttraining's l2: 0.38549\tvalid_1's l2: 0.367607\n",
      "[92]\ttraining's l2: 0.385332\tvalid_1's l2: 0.367494\n",
      "[93]\ttraining's l2: 0.385131\tvalid_1's l2: 0.367338\n",
      "[94]\ttraining's l2: 0.384993\tvalid_1's l2: 0.367262\n",
      "[95]\ttraining's l2: 0.384815\tvalid_1's l2: 0.367175\n",
      "[96]\ttraining's l2: 0.384668\tvalid_1's l2: 0.367127\n",
      "[97]\ttraining's l2: 0.384498\tvalid_1's l2: 0.366972\n",
      "[98]\ttraining's l2: 0.384255\tvalid_1's l2: 0.366773\n",
      "[99]\ttraining's l2: 0.384151\tvalid_1's l2: 0.366716\n",
      "[100]\ttraining's l2: 0.384031\tvalid_1's l2: 0.366635\n",
      "[101]\ttraining's l2: 0.383841\tvalid_1's l2: 0.366509\n",
      "[102]\ttraining's l2: 0.383645\tvalid_1's l2: 0.366373\n",
      "[103]\ttraining's l2: 0.383504\tvalid_1's l2: 0.366278\n",
      "[104]\ttraining's l2: 0.383315\tvalid_1's l2: 0.366116\n",
      "[105]\ttraining's l2: 0.383082\tvalid_1's l2: 0.365998\n",
      "[106]\ttraining's l2: 0.382881\tvalid_1's l2: 0.365874\n",
      "[107]\ttraining's l2: 0.382735\tvalid_1's l2: 0.365789\n",
      "[108]\ttraining's l2: 0.382636\tvalid_1's l2: 0.365738\n",
      "[109]\ttraining's l2: 0.382507\tvalid_1's l2: 0.365678\n",
      "[110]\ttraining's l2: 0.382386\tvalid_1's l2: 0.365639\n",
      "[111]\ttraining's l2: 0.382299\tvalid_1's l2: 0.365581\n",
      "[112]\ttraining's l2: 0.382167\tvalid_1's l2: 0.365515\n",
      "[113]\ttraining's l2: 0.382027\tvalid_1's l2: 0.365457\n",
      "[114]\ttraining's l2: 0.38186\tvalid_1's l2: 0.365357\n",
      "[115]\ttraining's l2: 0.381728\tvalid_1's l2: 0.365293\n",
      "[116]\ttraining's l2: 0.381622\tvalid_1's l2: 0.365225\n",
      "[117]\ttraining's l2: 0.38146\tvalid_1's l2: 0.365073\n",
      "[118]\ttraining's l2: 0.381347\tvalid_1's l2: 0.365008\n",
      "[119]\ttraining's l2: 0.38125\tvalid_1's l2: 0.364969\n",
      "[120]\ttraining's l2: 0.381124\tvalid_1's l2: 0.364925\n",
      "[121]\ttraining's l2: 0.38107\tvalid_1's l2: 0.364892\n",
      "[122]\ttraining's l2: 0.381011\tvalid_1's l2: 0.364851\n",
      "[123]\ttraining's l2: 0.380878\tvalid_1's l2: 0.364831\n",
      "[124]\ttraining's l2: 0.380789\tvalid_1's l2: 0.364787\n",
      "[125]\ttraining's l2: 0.380684\tvalid_1's l2: 0.364729\n",
      "[126]\ttraining's l2: 0.380518\tvalid_1's l2: 0.364589\n",
      "[127]\ttraining's l2: 0.38036\tvalid_1's l2: 0.36449\n",
      "[128]\ttraining's l2: 0.380284\tvalid_1's l2: 0.364458\n",
      "[129]\ttraining's l2: 0.380222\tvalid_1's l2: 0.364413\n",
      "[130]\ttraining's l2: 0.38017\tvalid_1's l2: 0.364376\n",
      "[131]\ttraining's l2: 0.380001\tvalid_1's l2: 0.364292\n",
      "[132]\ttraining's l2: 0.379934\tvalid_1's l2: 0.364274\n",
      "[133]\ttraining's l2: 0.379888\tvalid_1's l2: 0.36424\n",
      "[134]\ttraining's l2: 0.379807\tvalid_1's l2: 0.364219\n",
      "[135]\ttraining's l2: 0.379764\tvalid_1's l2: 0.364201\n",
      "[136]\ttraining's l2: 0.379716\tvalid_1's l2: 0.364172\n",
      "[137]\ttraining's l2: 0.379647\tvalid_1's l2: 0.364144\n",
      "[138]\ttraining's l2: 0.379491\tvalid_1's l2: 0.364052\n",
      "[139]\ttraining's l2: 0.379347\tvalid_1's l2: 0.363978\n",
      "[140]\ttraining's l2: 0.379231\tvalid_1's l2: 0.363893\n",
      "[141]\ttraining's l2: 0.379065\tvalid_1's l2: 0.363791\n",
      "[142]\ttraining's l2: 0.379021\tvalid_1's l2: 0.363765\n",
      "[143]\ttraining's l2: 0.378961\tvalid_1's l2: 0.363758\n",
      "[144]\ttraining's l2: 0.378916\tvalid_1's l2: 0.363751\n",
      "[145]\ttraining's l2: 0.378841\tvalid_1's l2: 0.363695\n",
      "[146]\ttraining's l2: 0.378728\tvalid_1's l2: 0.363636\n",
      "[147]\ttraining's l2: 0.378671\tvalid_1's l2: 0.363609\n",
      "[148]\ttraining's l2: 0.378604\tvalid_1's l2: 0.363588\n",
      "[149]\ttraining's l2: 0.378567\tvalid_1's l2: 0.363574\n",
      "[150]\ttraining's l2: 0.378536\tvalid_1's l2: 0.363561\n",
      "[151]\ttraining's l2: 0.378479\tvalid_1's l2: 0.363539\n",
      "[152]\ttraining's l2: 0.378424\tvalid_1's l2: 0.363527\n",
      "[153]\ttraining's l2: 0.378327\tvalid_1's l2: 0.363544\n",
      "[154]\ttraining's l2: 0.378214\tvalid_1's l2: 0.36348\n",
      "[155]\ttraining's l2: 0.378109\tvalid_1's l2: 0.363428\n",
      "[156]\ttraining's l2: 0.378033\tvalid_1's l2: 0.363404\n",
      "[157]\ttraining's l2: 0.377964\tvalid_1's l2: 0.363387\n",
      "[158]\ttraining's l2: 0.37792\tvalid_1's l2: 0.363355\n",
      "[159]\ttraining's l2: 0.377879\tvalid_1's l2: 0.363317\n",
      "[160]\ttraining's l2: 0.377825\tvalid_1's l2: 0.363332\n",
      "[161]\ttraining's l2: 0.377774\tvalid_1's l2: 0.363312\n",
      "[162]\ttraining's l2: 0.377681\tvalid_1's l2: 0.363234\n",
      "[163]\ttraining's l2: 0.377574\tvalid_1's l2: 0.363199\n",
      "[164]\ttraining's l2: 0.377533\tvalid_1's l2: 0.363182\n",
      "[165]\ttraining's l2: 0.377498\tvalid_1's l2: 0.363157\n",
      "[166]\ttraining's l2: 0.377448\tvalid_1's l2: 0.363136\n",
      "[167]\ttraining's l2: 0.377402\tvalid_1's l2: 0.363111\n",
      "[168]\ttraining's l2: 0.377369\tvalid_1's l2: 0.363093\n",
      "[169]\ttraining's l2: 0.377318\tvalid_1's l2: 0.36309\n",
      "[170]\ttraining's l2: 0.377265\tvalid_1's l2: 0.363073\n",
      "[171]\ttraining's l2: 0.377214\tvalid_1's l2: 0.363054\n",
      "[172]\ttraining's l2: 0.37717\tvalid_1's l2: 0.363049\n",
      "[173]\ttraining's l2: 0.377094\tvalid_1's l2: 0.362972\n",
      "[174]\ttraining's l2: 0.377034\tvalid_1's l2: 0.362967\n",
      "[175]\ttraining's l2: 0.37701\tvalid_1's l2: 0.362951\n",
      "[176]\ttraining's l2: 0.376923\tvalid_1's l2: 0.362921\n",
      "[177]\ttraining's l2: 0.376867\tvalid_1's l2: 0.362876\n",
      "[178]\ttraining's l2: 0.376803\tvalid_1's l2: 0.362871\n",
      "[179]\ttraining's l2: 0.37674\tvalid_1's l2: 0.362865\n",
      "[180]\ttraining's l2: 0.376704\tvalid_1's l2: 0.36285\n",
      "[181]\ttraining's l2: 0.376631\tvalid_1's l2: 0.362844\n",
      "[182]\ttraining's l2: 0.376588\tvalid_1's l2: 0.362831\n",
      "[183]\ttraining's l2: 0.376551\tvalid_1's l2: 0.362821\n",
      "[184]\ttraining's l2: 0.376486\tvalid_1's l2: 0.362745\n",
      "[185]\ttraining's l2: 0.376452\tvalid_1's l2: 0.362742\n",
      "[186]\ttraining's l2: 0.376404\tvalid_1's l2: 0.362738\n",
      "[187]\ttraining's l2: 0.376358\tvalid_1's l2: 0.362729\n",
      "[188]\ttraining's l2: 0.376308\tvalid_1's l2: 0.362717\n",
      "[189]\ttraining's l2: 0.376268\tvalid_1's l2: 0.362717\n",
      "[190]\ttraining's l2: 0.376211\tvalid_1's l2: 0.362683\n",
      "[191]\ttraining's l2: 0.376162\tvalid_1's l2: 0.362634\n",
      "[192]\ttraining's l2: 0.376113\tvalid_1's l2: 0.362624\n",
      "[193]\ttraining's l2: 0.376063\tvalid_1's l2: 0.36261\n",
      "[194]\ttraining's l2: 0.376021\tvalid_1's l2: 0.362586\n",
      "[195]\ttraining's l2: 0.375941\tvalid_1's l2: 0.362557\n",
      "[196]\ttraining's l2: 0.375904\tvalid_1's l2: 0.362543\n",
      "[197]\ttraining's l2: 0.375843\tvalid_1's l2: 0.362487\n",
      "[198]\ttraining's l2: 0.375804\tvalid_1's l2: 0.36248\n",
      "[199]\ttraining's l2: 0.375763\tvalid_1's l2: 0.362475\n",
      "[200]\ttraining's l2: 0.375727\tvalid_1's l2: 0.362468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.375727\tvalid_1's l2: 0.362468\n",
      "mean_21_sales: 12679199.77\n",
      "mean_6_sales: 3099207.44\n",
      "mean_30_sales: 2729922.02\n",
      "mean_14_sales: 2064902.21\n",
      "mean_5_sales: 1876377.15\n",
      "mean_20_dow3_2017: 1402515.19\n",
      "mean_7_sales: 1394725.06\n",
      "mean_4_dow3_2017: 1098319.83\n",
      "mean_60_sales: 1061285.51\n",
      "promo_10: 727942.71\n",
      "mean_4_sales: 404452.88\n",
      "item_class_features: 316934.58\n",
      "mean_63_sales: 257788.04\n",
      "std_21_sales: 107057.20\n",
      "std_30_sales: 75930.86\n",
      "promo_14: 60159.26\n",
      "sum_4_promo: 56511.52\n",
      "store_cluster_features: 53575.20\n",
      "lag_3_sales: 53571.90\n",
      "promo_7: 48785.01\n",
      "mean_4_dow4_2017: 37277.26\n",
      "item_family_features: 34708.96\n",
      "sum_2_promo: 33651.09\n",
      "promo_9: 33043.14\n",
      "std_14_sales: 32653.18\n",
      "promo_11: 27943.96\n",
      "promo_12: 27037.56\n",
      "store_city_features: 25525.86\n",
      "promo_13: 20519.49\n",
      "sum_14_promo: 17233.56\n",
      "std_60_sales: 16699.83\n",
      "lag_4_sales: 15263.20\n",
      "mean_20_dow0_2017: 15016.52\n",
      "std_63_sales: 14558.48\n",
      "promo_3: 14473.10\n",
      "sum_7_promo: 13268.97\n",
      "sum_3_promo: 13195.55\n",
      "mean_3_sales: 12225.84\n",
      "lag_49_sales: 11558.04\n",
      "promo_8: 11239.70\n",
      "lag_1_sales: 10069.37\n",
      "std_5_sales: 9529.14\n",
      "sum_21_promo: 8732.20\n",
      "sum_6_promo: 8531.78\n",
      "store_type_features: 8201.40\n",
      "mean_20_dow4_2017: 7647.53\n",
      "sum_5_promo: 7019.71\n",
      "mean_20_dow2_2017: 5626.38\n",
      "lag_21_sales: 4016.20\n",
      "promo_6: 3902.87\n",
      "std_7_sales: 3748.39\n",
      "std_6_sales: 3716.92\n",
      "promo_15: 3110.88\n",
      "store_state_features: 2763.37\n",
      "mean_4_dow1_2017: 2730.50\n",
      "mean_20_dow6_2017: 2651.56\n",
      "mean_4_dow0_2017: 2650.59\n",
      "lag_2_sales: 2512.05\n",
      "mean_20_dow1_2017: 2344.10\n",
      "mean_4_dow2_2017: 2299.47\n",
      "std_4_sales: 2158.14\n",
      "lag_14_sales: 1941.71\n",
      "lag_63_sales: 1911.24\n",
      "lag_5_sales: 1844.93\n",
      "promo_0: 1476.73\n",
      "promo_2: 1442.66\n",
      "mean_4_dow6_2017: 1250.81\n",
      "std_3_sales: 1093.82\n",
      "mean_20_dow5_2017: 1008.25\n",
      "lag_56_sales: 933.66\n",
      "lag_6_sales: 731.35\n",
      "lag_7_sales: 575.17\n",
      "lag_42_sales: 439.97\n",
      "promo_1: 337.45\n",
      "lag_35_sales: 292.20\n",
      "promo_4: 250.32\n",
      "lag_28_sales: 205.65\n",
      "mean_4_dow5_2017: 198.18\n",
      "promo_5: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [16:12<07:16, 87.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.23424\tvalid_1's l2: 1.20859\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.15682\tvalid_1's l2: 1.12938\n",
      "[3]\ttraining's l2: 1.08659\tvalid_1's l2: 1.05813\n",
      "[4]\ttraining's l2: 1.02326\tvalid_1's l2: 0.993768\n",
      "[5]\ttraining's l2: 0.965985\tvalid_1's l2: 0.935376\n",
      "[6]\ttraining's l2: 0.913972\tvalid_1's l2: 0.883067\n",
      "[7]\ttraining's l2: 0.867528\tvalid_1's l2: 0.836233\n",
      "[8]\ttraining's l2: 0.824838\tvalid_1's l2: 0.793281\n",
      "[9]\ttraining's l2: 0.78667\tvalid_1's l2: 0.754966\n",
      "[10]\ttraining's l2: 0.752096\tvalid_1's l2: 0.720616\n",
      "[11]\ttraining's l2: 0.720198\tvalid_1's l2: 0.688811\n",
      "[12]\ttraining's l2: 0.691746\tvalid_1's l2: 0.66083\n",
      "[13]\ttraining's l2: 0.665486\tvalid_1's l2: 0.635227\n",
      "[14]\ttraining's l2: 0.641577\tvalid_1's l2: 0.611268\n",
      "[15]\ttraining's l2: 0.619986\tvalid_1's l2: 0.590103\n",
      "[16]\ttraining's l2: 0.600489\tvalid_1's l2: 0.571236\n",
      "[17]\ttraining's l2: 0.582674\tvalid_1's l2: 0.55352\n",
      "[18]\ttraining's l2: 0.566896\tvalid_1's l2: 0.538627\n",
      "[19]\ttraining's l2: 0.552289\tvalid_1's l2: 0.524425\n",
      "[20]\ttraining's l2: 0.539008\tvalid_1's l2: 0.511414\n",
      "[21]\ttraining's l2: 0.527273\tvalid_1's l2: 0.500298\n",
      "[22]\ttraining's l2: 0.516426\tvalid_1's l2: 0.489789\n",
      "[23]\ttraining's l2: 0.506305\tvalid_1's l2: 0.479885\n",
      "[24]\ttraining's l2: 0.497113\tvalid_1's l2: 0.471161\n",
      "[25]\ttraining's l2: 0.488757\tvalid_1's l2: 0.463308\n",
      "[26]\ttraining's l2: 0.481184\tvalid_1's l2: 0.456112\n",
      "[27]\ttraining's l2: 0.474415\tvalid_1's l2: 0.449639\n",
      "[28]\ttraining's l2: 0.468223\tvalid_1's l2: 0.44399\n",
      "[29]\ttraining's l2: 0.462535\tvalid_1's l2: 0.438671\n",
      "[30]\ttraining's l2: 0.457331\tvalid_1's l2: 0.433864\n",
      "[31]\ttraining's l2: 0.452724\tvalid_1's l2: 0.429728\n",
      "[32]\ttraining's l2: 0.448448\tvalid_1's l2: 0.425915\n",
      "[33]\ttraining's l2: 0.444355\tvalid_1's l2: 0.422141\n",
      "[34]\ttraining's l2: 0.440602\tvalid_1's l2: 0.418615\n",
      "[35]\ttraining's l2: 0.437236\tvalid_1's l2: 0.415496\n",
      "[36]\ttraining's l2: 0.434175\tvalid_1's l2: 0.412619\n",
      "[37]\ttraining's l2: 0.431471\tvalid_1's l2: 0.410246\n",
      "[38]\ttraining's l2: 0.428892\tvalid_1's l2: 0.407934\n",
      "[39]\ttraining's l2: 0.426484\tvalid_1's l2: 0.405823\n",
      "[40]\ttraining's l2: 0.424217\tvalid_1's l2: 0.403905\n",
      "[41]\ttraining's l2: 0.422129\tvalid_1's l2: 0.402085\n",
      "[42]\ttraining's l2: 0.420331\tvalid_1's l2: 0.400486\n",
      "[43]\ttraining's l2: 0.418601\tvalid_1's l2: 0.399022\n",
      "[44]\ttraining's l2: 0.417027\tvalid_1's l2: 0.39762\n",
      "[45]\ttraining's l2: 0.415621\tvalid_1's l2: 0.39641\n",
      "[46]\ttraining's l2: 0.414343\tvalid_1's l2: 0.395288\n",
      "[47]\ttraining's l2: 0.413096\tvalid_1's l2: 0.394266\n",
      "[48]\ttraining's l2: 0.411894\tvalid_1's l2: 0.393326\n",
      "[49]\ttraining's l2: 0.410852\tvalid_1's l2: 0.392562\n",
      "[50]\ttraining's l2: 0.40987\tvalid_1's l2: 0.391774\n",
      "[51]\ttraining's l2: 0.408854\tvalid_1's l2: 0.390962\n",
      "[52]\ttraining's l2: 0.407969\tvalid_1's l2: 0.390249\n",
      "[53]\ttraining's l2: 0.407144\tvalid_1's l2: 0.389602\n",
      "[54]\ttraining's l2: 0.406383\tvalid_1's l2: 0.389\n",
      "[55]\ttraining's l2: 0.405661\tvalid_1's l2: 0.388357\n",
      "[56]\ttraining's l2: 0.40502\tvalid_1's l2: 0.387881\n",
      "[57]\ttraining's l2: 0.404332\tvalid_1's l2: 0.387259\n",
      "[58]\ttraining's l2: 0.403735\tvalid_1's l2: 0.386745\n",
      "[59]\ttraining's l2: 0.403156\tvalid_1's l2: 0.386274\n",
      "[60]\ttraining's l2: 0.40259\tvalid_1's l2: 0.385875\n",
      "[61]\ttraining's l2: 0.402014\tvalid_1's l2: 0.38543\n",
      "[62]\ttraining's l2: 0.401463\tvalid_1's l2: 0.385088\n",
      "[63]\ttraining's l2: 0.400983\tvalid_1's l2: 0.384675\n",
      "[64]\ttraining's l2: 0.400512\tvalid_1's l2: 0.384306\n",
      "[65]\ttraining's l2: 0.400075\tvalid_1's l2: 0.383919\n",
      "[66]\ttraining's l2: 0.399699\tvalid_1's l2: 0.383628\n",
      "[67]\ttraining's l2: 0.399304\tvalid_1's l2: 0.383339\n",
      "[68]\ttraining's l2: 0.398921\tvalid_1's l2: 0.383039\n",
      "[69]\ttraining's l2: 0.39849\tvalid_1's l2: 0.382683\n",
      "[70]\ttraining's l2: 0.398107\tvalid_1's l2: 0.382447\n",
      "[71]\ttraining's l2: 0.397726\tvalid_1's l2: 0.382226\n",
      "[72]\ttraining's l2: 0.397384\tvalid_1's l2: 0.381971\n",
      "[73]\ttraining's l2: 0.397084\tvalid_1's l2: 0.381776\n",
      "[74]\ttraining's l2: 0.396671\tvalid_1's l2: 0.381521\n",
      "[75]\ttraining's l2: 0.39636\tvalid_1's l2: 0.381242\n",
      "[76]\ttraining's l2: 0.396042\tvalid_1's l2: 0.381075\n",
      "[77]\ttraining's l2: 0.395801\tvalid_1's l2: 0.380879\n",
      "[78]\ttraining's l2: 0.395576\tvalid_1's l2: 0.380742\n",
      "[79]\ttraining's l2: 0.395274\tvalid_1's l2: 0.380517\n",
      "[80]\ttraining's l2: 0.394897\tvalid_1's l2: 0.380229\n",
      "[81]\ttraining's l2: 0.394672\tvalid_1's l2: 0.380053\n",
      "[82]\ttraining's l2: 0.394461\tvalid_1's l2: 0.379874\n",
      "[83]\ttraining's l2: 0.394165\tvalid_1's l2: 0.379684\n",
      "[84]\ttraining's l2: 0.393903\tvalid_1's l2: 0.379576\n",
      "[85]\ttraining's l2: 0.393654\tvalid_1's l2: 0.379448\n",
      "[86]\ttraining's l2: 0.393454\tvalid_1's l2: 0.379374\n",
      "[87]\ttraining's l2: 0.393253\tvalid_1's l2: 0.379279\n",
      "[88]\ttraining's l2: 0.393048\tvalid_1's l2: 0.379104\n",
      "[89]\ttraining's l2: 0.392706\tvalid_1's l2: 0.378804\n",
      "[90]\ttraining's l2: 0.392463\tvalid_1's l2: 0.378564\n",
      "[91]\ttraining's l2: 0.392282\tvalid_1's l2: 0.378453\n",
      "[92]\ttraining's l2: 0.3921\tvalid_1's l2: 0.378312\n",
      "[93]\ttraining's l2: 0.391939\tvalid_1's l2: 0.378166\n",
      "[94]\ttraining's l2: 0.391647\tvalid_1's l2: 0.37801\n",
      "[95]\ttraining's l2: 0.39147\tvalid_1's l2: 0.377882\n",
      "[96]\ttraining's l2: 0.391264\tvalid_1's l2: 0.37775\n",
      "[97]\ttraining's l2: 0.391096\tvalid_1's l2: 0.377613\n",
      "[98]\ttraining's l2: 0.390949\tvalid_1's l2: 0.377483\n",
      "[99]\ttraining's l2: 0.390727\tvalid_1's l2: 0.377354\n",
      "[100]\ttraining's l2: 0.390478\tvalid_1's l2: 0.377176\n",
      "[101]\ttraining's l2: 0.390297\tvalid_1's l2: 0.377019\n",
      "[102]\ttraining's l2: 0.390188\tvalid_1's l2: 0.376948\n",
      "[103]\ttraining's l2: 0.39003\tvalid_1's l2: 0.376771\n",
      "[104]\ttraining's l2: 0.389922\tvalid_1's l2: 0.376667\n",
      "[105]\ttraining's l2: 0.389709\tvalid_1's l2: 0.376483\n",
      "[106]\ttraining's l2: 0.389567\tvalid_1's l2: 0.376402\n",
      "[107]\ttraining's l2: 0.389461\tvalid_1's l2: 0.376346\n",
      "[108]\ttraining's l2: 0.389335\tvalid_1's l2: 0.376321\n",
      "[109]\ttraining's l2: 0.38916\tvalid_1's l2: 0.376213\n",
      "[110]\ttraining's l2: 0.388995\tvalid_1's l2: 0.376084\n",
      "[111]\ttraining's l2: 0.388843\tvalid_1's l2: 0.37597\n",
      "[112]\ttraining's l2: 0.388754\tvalid_1's l2: 0.375943\n",
      "[113]\ttraining's l2: 0.388663\tvalid_1's l2: 0.375903\n",
      "[114]\ttraining's l2: 0.388559\tvalid_1's l2: 0.37582\n",
      "[115]\ttraining's l2: 0.388392\tvalid_1's l2: 0.375749\n",
      "[116]\ttraining's l2: 0.388259\tvalid_1's l2: 0.375671\n",
      "[117]\ttraining's l2: 0.388143\tvalid_1's l2: 0.375603\n",
      "[118]\ttraining's l2: 0.388065\tvalid_1's l2: 0.375541\n",
      "[119]\ttraining's l2: 0.388001\tvalid_1's l2: 0.375489\n",
      "[120]\ttraining's l2: 0.387843\tvalid_1's l2: 0.375368\n",
      "[121]\ttraining's l2: 0.387727\tvalid_1's l2: 0.375344\n",
      "[122]\ttraining's l2: 0.387637\tvalid_1's l2: 0.37525\n",
      "[123]\ttraining's l2: 0.387541\tvalid_1's l2: 0.375212\n",
      "[124]\ttraining's l2: 0.387434\tvalid_1's l2: 0.375169\n",
      "[125]\ttraining's l2: 0.387359\tvalid_1's l2: 0.375119\n",
      "[126]\ttraining's l2: 0.387254\tvalid_1's l2: 0.375036\n",
      "[127]\ttraining's l2: 0.387132\tvalid_1's l2: 0.374967\n",
      "[128]\ttraining's l2: 0.386958\tvalid_1's l2: 0.374824\n",
      "[129]\ttraining's l2: 0.386877\tvalid_1's l2: 0.374755\n",
      "[130]\ttraining's l2: 0.386786\tvalid_1's l2: 0.374725\n",
      "[131]\ttraining's l2: 0.386622\tvalid_1's l2: 0.374615\n",
      "[132]\ttraining's l2: 0.386547\tvalid_1's l2: 0.37458\n",
      "[133]\ttraining's l2: 0.386475\tvalid_1's l2: 0.374542\n",
      "[134]\ttraining's l2: 0.386422\tvalid_1's l2: 0.374514\n",
      "[135]\ttraining's l2: 0.386336\tvalid_1's l2: 0.374506\n",
      "[136]\ttraining's l2: 0.386144\tvalid_1's l2: 0.374387\n",
      "[137]\ttraining's l2: 0.385986\tvalid_1's l2: 0.37431\n",
      "[138]\ttraining's l2: 0.385926\tvalid_1's l2: 0.374293\n",
      "[139]\ttraining's l2: 0.385844\tvalid_1's l2: 0.374265\n",
      "[140]\ttraining's l2: 0.38578\tvalid_1's l2: 0.374215\n",
      "[141]\ttraining's l2: 0.385715\tvalid_1's l2: 0.37419\n",
      "[142]\ttraining's l2: 0.385611\tvalid_1's l2: 0.374146\n",
      "[143]\ttraining's l2: 0.385531\tvalid_1's l2: 0.374112\n",
      "[144]\ttraining's l2: 0.385441\tvalid_1's l2: 0.374014\n",
      "[145]\ttraining's l2: 0.385393\tvalid_1's l2: 0.373971\n",
      "[146]\ttraining's l2: 0.385322\tvalid_1's l2: 0.373948\n",
      "[147]\ttraining's l2: 0.385231\tvalid_1's l2: 0.373909\n",
      "[148]\ttraining's l2: 0.385134\tvalid_1's l2: 0.373829\n",
      "[149]\ttraining's l2: 0.38507\tvalid_1's l2: 0.373801\n",
      "[150]\ttraining's l2: 0.385028\tvalid_1's l2: 0.373766\n",
      "[151]\ttraining's l2: 0.384978\tvalid_1's l2: 0.373727\n",
      "[152]\ttraining's l2: 0.384923\tvalid_1's l2: 0.373715\n",
      "[153]\ttraining's l2: 0.384851\tvalid_1's l2: 0.37369\n",
      "[154]\ttraining's l2: 0.384803\tvalid_1's l2: 0.373646\n",
      "[155]\ttraining's l2: 0.384682\tvalid_1's l2: 0.373577\n",
      "[156]\ttraining's l2: 0.38461\tvalid_1's l2: 0.373554\n",
      "[157]\ttraining's l2: 0.384553\tvalid_1's l2: 0.373537\n",
      "[158]\ttraining's l2: 0.384474\tvalid_1's l2: 0.373513\n",
      "[159]\ttraining's l2: 0.38441\tvalid_1's l2: 0.373483\n",
      "[160]\ttraining's l2: 0.384338\tvalid_1's l2: 0.373462\n",
      "[161]\ttraining's l2: 0.384262\tvalid_1's l2: 0.373415\n",
      "[162]\ttraining's l2: 0.384206\tvalid_1's l2: 0.373392\n",
      "[163]\ttraining's l2: 0.384149\tvalid_1's l2: 0.373368\n",
      "[164]\ttraining's l2: 0.3841\tvalid_1's l2: 0.373337\n",
      "[165]\ttraining's l2: 0.384024\tvalid_1's l2: 0.373327\n",
      "[166]\ttraining's l2: 0.383969\tvalid_1's l2: 0.373282\n",
      "[167]\ttraining's l2: 0.383919\tvalid_1's l2: 0.373262\n",
      "[168]\ttraining's l2: 0.383889\tvalid_1's l2: 0.373246\n",
      "[169]\ttraining's l2: 0.383788\tvalid_1's l2: 0.373223\n",
      "[170]\ttraining's l2: 0.383692\tvalid_1's l2: 0.373182\n",
      "[171]\ttraining's l2: 0.383646\tvalid_1's l2: 0.37315\n",
      "[172]\ttraining's l2: 0.383597\tvalid_1's l2: 0.373156\n",
      "[173]\ttraining's l2: 0.383527\tvalid_1's l2: 0.373086\n",
      "[174]\ttraining's l2: 0.383456\tvalid_1's l2: 0.373038\n",
      "[175]\ttraining's l2: 0.383415\tvalid_1's l2: 0.372995\n",
      "[176]\ttraining's l2: 0.383323\tvalid_1's l2: 0.372967\n",
      "[177]\ttraining's l2: 0.383274\tvalid_1's l2: 0.372937\n",
      "[178]\ttraining's l2: 0.383223\tvalid_1's l2: 0.372925\n",
      "[179]\ttraining's l2: 0.38316\tvalid_1's l2: 0.3729\n",
      "[180]\ttraining's l2: 0.383132\tvalid_1's l2: 0.372875\n",
      "[181]\ttraining's l2: 0.383094\tvalid_1's l2: 0.372871\n",
      "[182]\ttraining's l2: 0.382995\tvalid_1's l2: 0.372768\n",
      "[183]\ttraining's l2: 0.382926\tvalid_1's l2: 0.372762\n",
      "[184]\ttraining's l2: 0.382882\tvalid_1's l2: 0.372744\n",
      "[185]\ttraining's l2: 0.382823\tvalid_1's l2: 0.372675\n",
      "[186]\ttraining's l2: 0.382788\tvalid_1's l2: 0.372668\n",
      "[187]\ttraining's l2: 0.382753\tvalid_1's l2: 0.372654\n",
      "[188]\ttraining's l2: 0.382707\tvalid_1's l2: 0.372644\n",
      "[189]\ttraining's l2: 0.382627\tvalid_1's l2: 0.372626\n",
      "[190]\ttraining's l2: 0.382594\tvalid_1's l2: 0.372603\n",
      "[191]\ttraining's l2: 0.382545\tvalid_1's l2: 0.372577\n",
      "[192]\ttraining's l2: 0.382497\tvalid_1's l2: 0.372563\n",
      "[193]\ttraining's l2: 0.382448\tvalid_1's l2: 0.372516\n",
      "[194]\ttraining's l2: 0.382409\tvalid_1's l2: 0.372485\n",
      "[195]\ttraining's l2: 0.382368\tvalid_1's l2: 0.372466\n",
      "[196]\ttraining's l2: 0.382319\tvalid_1's l2: 0.37242\n",
      "[197]\ttraining's l2: 0.382265\tvalid_1's l2: 0.372396\n",
      "[198]\ttraining's l2: 0.382232\tvalid_1's l2: 0.37238\n",
      "[199]\ttraining's l2: 0.38218\tvalid_1's l2: 0.37234\n",
      "[200]\ttraining's l2: 0.382121\tvalid_1's l2: 0.372339\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.382121\tvalid_1's l2: 0.372339\n",
      "mean_21_sales: 9042587.88\n",
      "mean_4_dow4_2017: 5881106.92\n",
      "mean_14_sales: 3581387.95\n",
      "mean_20_dow4_2017: 2506756.67\n",
      "mean_4_sales: 2470831.19\n",
      "mean_30_sales: 2207510.34\n",
      "mean_5_sales: 1628590.47\n",
      "mean_60_sales: 869932.21\n",
      "mean_6_sales: 718168.39\n",
      "promo_11: 716795.33\n",
      "item_class_features: 335944.01\n",
      "mean_7_sales: 155769.17\n",
      "lag_3_sales: 103201.25\n",
      "mean_4_dow3_2017: 102175.54\n",
      "store_cluster_features: 88420.41\n",
      "sum_3_promo: 85111.98\n",
      "promo_14: 79599.50\n",
      "std_21_sales: 72812.07\n",
      "promo_12: 56676.79\n",
      "std_30_sales: 53136.87\n",
      "promo_10: 45058.66\n",
      "item_family_features: 41725.90\n",
      "store_city_features: 36885.46\n",
      "mean_63_sales: 34810.87\n",
      "promo_7: 33039.04\n",
      "std_14_sales: 31315.03\n",
      "promo_13: 31176.56\n",
      "promo_9: 26579.49\n",
      "mean_3_sales: 25739.74\n",
      "mean_20_dow0_2017: 21872.73\n",
      "lag_1_sales: 21683.33\n",
      "promo_4: 19499.85\n",
      "sum_2_promo: 19472.29\n",
      "std_63_sales: 17400.56\n",
      "store_type_features: 16979.00\n",
      "promo_8: 16333.63\n",
      "mean_20_dow3_2017: 15748.14\n",
      "std_60_sales: 15704.79\n",
      "sum_7_promo: 14063.76\n",
      "sum_4_promo: 12871.88\n",
      "sum_14_promo: 10403.84\n",
      "sum_21_promo: 9121.32\n",
      "mean_20_dow2_2017: 8969.77\n",
      "lag_4_sales: 6663.28\n",
      "mean_20_dow1_2017: 5822.32\n",
      "std_5_sales: 5722.17\n",
      "std_4_sales: 4219.85\n",
      "mean_4_dow6_2017: 3991.79\n",
      "mean_20_dow6_2017: 3474.66\n",
      "promo_6: 3438.17\n",
      "sum_5_promo: 3348.22\n",
      "promo_15: 2948.62\n",
      "std_6_sales: 2186.14\n",
      "lag_21_sales: 2125.42\n",
      "lag_63_sales: 1728.50\n",
      "lag_2_sales: 1714.94\n",
      "store_state_features: 1703.55\n",
      "promo_2: 1590.67\n",
      "mean_4_dow5_2017: 1557.21\n",
      "lag_6_sales: 1343.48\n",
      "lag_28_sales: 1223.23\n",
      "mean_4_dow0_2017: 1192.13\n",
      "promo_0: 1174.31\n",
      "lag_5_sales: 1085.12\n",
      "lag_14_sales: 1078.72\n",
      "lag_42_sales: 1066.48\n",
      "std_7_sales: 1032.66\n",
      "mean_20_dow5_2017: 860.89\n",
      "mean_4_dow2_2017: 802.64\n",
      "std_3_sales: 727.55\n",
      "sum_6_promo: 653.15\n",
      "mean_4_dow1_2017: 626.84\n",
      "lag_49_sales: 619.94\n",
      "promo_1: 514.36\n",
      "lag_7_sales: 486.63\n",
      "lag_56_sales: 451.32\n",
      "lag_35_sales: 284.88\n",
      "promo_5: 267.97\n",
      "promo_3: 235.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [17:40<05:49, 87.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.06641\tvalid_1's l2: 1.04936\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.00343\tvalid_1's l2: 0.986732\n",
      "[3]\ttraining's l2: 0.947526\tvalid_1's l2: 0.930572\n",
      "[4]\ttraining's l2: 0.897006\tvalid_1's l2: 0.879612\n",
      "[5]\ttraining's l2: 0.851248\tvalid_1's l2: 0.833714\n",
      "[6]\ttraining's l2: 0.808764\tvalid_1's l2: 0.791104\n",
      "[7]\ttraining's l2: 0.771323\tvalid_1's l2: 0.753348\n",
      "[8]\ttraining's l2: 0.736437\tvalid_1's l2: 0.718445\n",
      "[9]\ttraining's l2: 0.70483\tvalid_1's l2: 0.686779\n",
      "[10]\ttraining's l2: 0.676773\tvalid_1's l2: 0.658794\n",
      "[11]\ttraining's l2: 0.650729\tvalid_1's l2: 0.632753\n",
      "[12]\ttraining's l2: 0.627323\tvalid_1's l2: 0.609165\n",
      "[13]\ttraining's l2: 0.60589\tvalid_1's l2: 0.587735\n",
      "[14]\ttraining's l2: 0.586481\tvalid_1's l2: 0.568302\n",
      "[15]\ttraining's l2: 0.568928\tvalid_1's l2: 0.55084\n",
      "[16]\ttraining's l2: 0.552943\tvalid_1's l2: 0.534899\n",
      "[17]\ttraining's l2: 0.538884\tvalid_1's l2: 0.520814\n",
      "[18]\ttraining's l2: 0.525705\tvalid_1's l2: 0.507707\n",
      "[19]\ttraining's l2: 0.513777\tvalid_1's l2: 0.495778\n",
      "[20]\ttraining's l2: 0.502923\tvalid_1's l2: 0.484896\n",
      "[21]\ttraining's l2: 0.493106\tvalid_1's l2: 0.475059\n",
      "[22]\ttraining's l2: 0.484274\tvalid_1's l2: 0.466203\n",
      "[23]\ttraining's l2: 0.476139\tvalid_1's l2: 0.45809\n",
      "[24]\ttraining's l2: 0.468829\tvalid_1's l2: 0.450783\n",
      "[25]\ttraining's l2: 0.462175\tvalid_1's l2: 0.444097\n",
      "[26]\ttraining's l2: 0.45627\tvalid_1's l2: 0.438116\n",
      "[27]\ttraining's l2: 0.450721\tvalid_1's l2: 0.432513\n",
      "[28]\ttraining's l2: 0.445812\tvalid_1's l2: 0.427552\n",
      "[29]\ttraining's l2: 0.441338\tvalid_1's l2: 0.423108\n",
      "[30]\ttraining's l2: 0.437098\tvalid_1's l2: 0.418851\n",
      "[31]\ttraining's l2: 0.433381\tvalid_1's l2: 0.415134\n",
      "[32]\ttraining's l2: 0.429843\tvalid_1's l2: 0.411631\n",
      "[33]\ttraining's l2: 0.426604\tvalid_1's l2: 0.408326\n",
      "[34]\ttraining's l2: 0.423665\tvalid_1's l2: 0.405348\n",
      "[35]\ttraining's l2: 0.420998\tvalid_1's l2: 0.402682\n",
      "[36]\ttraining's l2: 0.41851\tvalid_1's l2: 0.400199\n",
      "[37]\ttraining's l2: 0.416231\tvalid_1's l2: 0.397917\n",
      "[38]\ttraining's l2: 0.414241\tvalid_1's l2: 0.395966\n",
      "[39]\ttraining's l2: 0.412334\tvalid_1's l2: 0.3941\n",
      "[40]\ttraining's l2: 0.410666\tvalid_1's l2: 0.39253\n",
      "[41]\ttraining's l2: 0.409039\tvalid_1's l2: 0.390881\n",
      "[42]\ttraining's l2: 0.407566\tvalid_1's l2: 0.389335\n",
      "[43]\ttraining's l2: 0.406166\tvalid_1's l2: 0.387961\n",
      "[44]\ttraining's l2: 0.404903\tvalid_1's l2: 0.3867\n",
      "[45]\ttraining's l2: 0.403761\tvalid_1's l2: 0.385535\n",
      "[46]\ttraining's l2: 0.40269\tvalid_1's l2: 0.384416\n",
      "[47]\ttraining's l2: 0.401736\tvalid_1's l2: 0.383557\n",
      "[48]\ttraining's l2: 0.400808\tvalid_1's l2: 0.382678\n",
      "[49]\ttraining's l2: 0.399953\tvalid_1's l2: 0.381864\n",
      "[50]\ttraining's l2: 0.399177\tvalid_1's l2: 0.381153\n",
      "[51]\ttraining's l2: 0.39841\tvalid_1's l2: 0.38038\n",
      "[52]\ttraining's l2: 0.397725\tvalid_1's l2: 0.379734\n",
      "[53]\ttraining's l2: 0.397061\tvalid_1's l2: 0.379195\n",
      "[54]\ttraining's l2: 0.396407\tvalid_1's l2: 0.378588\n",
      "[55]\ttraining's l2: 0.395784\tvalid_1's l2: 0.377985\n",
      "[56]\ttraining's l2: 0.395241\tvalid_1's l2: 0.377469\n",
      "[57]\ttraining's l2: 0.394726\tvalid_1's l2: 0.376944\n",
      "[58]\ttraining's l2: 0.394242\tvalid_1's l2: 0.376534\n",
      "[59]\ttraining's l2: 0.393784\tvalid_1's l2: 0.37604\n",
      "[60]\ttraining's l2: 0.393357\tvalid_1's l2: 0.375631\n",
      "[61]\ttraining's l2: 0.392855\tvalid_1's l2: 0.375241\n",
      "[62]\ttraining's l2: 0.3924\tvalid_1's l2: 0.374832\n",
      "[63]\ttraining's l2: 0.392012\tvalid_1's l2: 0.374479\n",
      "[64]\ttraining's l2: 0.391627\tvalid_1's l2: 0.374164\n",
      "[65]\ttraining's l2: 0.391287\tvalid_1's l2: 0.373852\n",
      "[66]\ttraining's l2: 0.39104\tvalid_1's l2: 0.373621\n",
      "[67]\ttraining's l2: 0.390722\tvalid_1's l2: 0.373402\n",
      "[68]\ttraining's l2: 0.390477\tvalid_1's l2: 0.373225\n",
      "[69]\ttraining's l2: 0.390169\tvalid_1's l2: 0.37293\n",
      "[70]\ttraining's l2: 0.389787\tvalid_1's l2: 0.372632\n",
      "[71]\ttraining's l2: 0.389402\tvalid_1's l2: 0.372322\n",
      "[72]\ttraining's l2: 0.389035\tvalid_1's l2: 0.372099\n",
      "[73]\ttraining's l2: 0.38867\tvalid_1's l2: 0.371861\n",
      "[74]\ttraining's l2: 0.388442\tvalid_1's l2: 0.371655\n",
      "[75]\ttraining's l2: 0.388202\tvalid_1's l2: 0.371465\n",
      "[76]\ttraining's l2: 0.387922\tvalid_1's l2: 0.37126\n",
      "[77]\ttraining's l2: 0.387694\tvalid_1's l2: 0.371043\n",
      "[78]\ttraining's l2: 0.387465\tvalid_1's l2: 0.370883\n",
      "[79]\ttraining's l2: 0.387238\tvalid_1's l2: 0.370706\n",
      "[80]\ttraining's l2: 0.387014\tvalid_1's l2: 0.370485\n",
      "[81]\ttraining's l2: 0.38673\tvalid_1's l2: 0.370311\n",
      "[82]\ttraining's l2: 0.386569\tvalid_1's l2: 0.370126\n",
      "[83]\ttraining's l2: 0.386373\tvalid_1's l2: 0.370013\n",
      "[84]\ttraining's l2: 0.386208\tvalid_1's l2: 0.369938\n",
      "[85]\ttraining's l2: 0.386078\tvalid_1's l2: 0.369863\n",
      "[86]\ttraining's l2: 0.385939\tvalid_1's l2: 0.369787\n",
      "[87]\ttraining's l2: 0.385785\tvalid_1's l2: 0.369641\n",
      "[88]\ttraining's l2: 0.385631\tvalid_1's l2: 0.369512\n",
      "[89]\ttraining's l2: 0.385496\tvalid_1's l2: 0.369411\n",
      "[90]\ttraining's l2: 0.385357\tvalid_1's l2: 0.369352\n",
      "[91]\ttraining's l2: 0.385166\tvalid_1's l2: 0.369205\n",
      "[92]\ttraining's l2: 0.385028\tvalid_1's l2: 0.369074\n",
      "[93]\ttraining's l2: 0.384874\tvalid_1's l2: 0.368919\n",
      "[94]\ttraining's l2: 0.384698\tvalid_1's l2: 0.368817\n",
      "[95]\ttraining's l2: 0.38455\tvalid_1's l2: 0.368729\n",
      "[96]\ttraining's l2: 0.384368\tvalid_1's l2: 0.368605\n",
      "[97]\ttraining's l2: 0.38423\tvalid_1's l2: 0.368491\n",
      "[98]\ttraining's l2: 0.384092\tvalid_1's l2: 0.368353\n",
      "[99]\ttraining's l2: 0.383884\tvalid_1's l2: 0.368199\n",
      "[100]\ttraining's l2: 0.383783\tvalid_1's l2: 0.368148\n",
      "[101]\ttraining's l2: 0.38367\tvalid_1's l2: 0.368068\n",
      "[102]\ttraining's l2: 0.3835\tvalid_1's l2: 0.367935\n",
      "[103]\ttraining's l2: 0.383264\tvalid_1's l2: 0.367773\n",
      "[104]\ttraining's l2: 0.383155\tvalid_1's l2: 0.367664\n",
      "[105]\ttraining's l2: 0.382882\tvalid_1's l2: 0.367511\n",
      "[106]\ttraining's l2: 0.382807\tvalid_1's l2: 0.367459\n",
      "[107]\ttraining's l2: 0.382704\tvalid_1's l2: 0.367341\n",
      "[108]\ttraining's l2: 0.382615\tvalid_1's l2: 0.367259\n",
      "[109]\ttraining's l2: 0.382519\tvalid_1's l2: 0.367172\n",
      "[110]\ttraining's l2: 0.382297\tvalid_1's l2: 0.367059\n",
      "[111]\ttraining's l2: 0.3822\tvalid_1's l2: 0.366977\n",
      "[112]\ttraining's l2: 0.38211\tvalid_1's l2: 0.366951\n",
      "[113]\ttraining's l2: 0.381972\tvalid_1's l2: 0.366863\n",
      "[114]\ttraining's l2: 0.381825\tvalid_1's l2: 0.366734\n",
      "[115]\ttraining's l2: 0.38172\tvalid_1's l2: 0.366714\n",
      "[116]\ttraining's l2: 0.381635\tvalid_1's l2: 0.366669\n",
      "[117]\ttraining's l2: 0.38155\tvalid_1's l2: 0.366606\n",
      "[118]\ttraining's l2: 0.381468\tvalid_1's l2: 0.366557\n",
      "[119]\ttraining's l2: 0.381399\tvalid_1's l2: 0.366517\n",
      "[120]\ttraining's l2: 0.381279\tvalid_1's l2: 0.366449\n",
      "[121]\ttraining's l2: 0.381211\tvalid_1's l2: 0.366406\n",
      "[122]\ttraining's l2: 0.381105\tvalid_1's l2: 0.366354\n",
      "[123]\ttraining's l2: 0.381042\tvalid_1's l2: 0.366317\n",
      "[124]\ttraining's l2: 0.380907\tvalid_1's l2: 0.366244\n",
      "[125]\ttraining's l2: 0.380823\tvalid_1's l2: 0.366202\n",
      "[126]\ttraining's l2: 0.380726\tvalid_1's l2: 0.366117\n",
      "[127]\ttraining's l2: 0.380648\tvalid_1's l2: 0.366071\n",
      "[128]\ttraining's l2: 0.380585\tvalid_1's l2: 0.366044\n",
      "[129]\ttraining's l2: 0.380529\tvalid_1's l2: 0.366005\n",
      "[130]\ttraining's l2: 0.380459\tvalid_1's l2: 0.365959\n",
      "[131]\ttraining's l2: 0.380392\tvalid_1's l2: 0.365945\n",
      "[132]\ttraining's l2: 0.380343\tvalid_1's l2: 0.36593\n",
      "[133]\ttraining's l2: 0.380292\tvalid_1's l2: 0.365908\n",
      "[134]\ttraining's l2: 0.380215\tvalid_1's l2: 0.365857\n",
      "[135]\ttraining's l2: 0.380124\tvalid_1's l2: 0.365865\n",
      "[136]\ttraining's l2: 0.380063\tvalid_1's l2: 0.365818\n",
      "[137]\ttraining's l2: 0.379984\tvalid_1's l2: 0.365749\n",
      "[138]\ttraining's l2: 0.379835\tvalid_1's l2: 0.365667\n",
      "[139]\ttraining's l2: 0.379786\tvalid_1's l2: 0.365652\n",
      "[140]\ttraining's l2: 0.37974\tvalid_1's l2: 0.365625\n",
      "[141]\ttraining's l2: 0.379687\tvalid_1's l2: 0.36559\n",
      "[142]\ttraining's l2: 0.37964\tvalid_1's l2: 0.365583\n",
      "[143]\ttraining's l2: 0.379534\tvalid_1's l2: 0.365547\n",
      "[144]\ttraining's l2: 0.379496\tvalid_1's l2: 0.365532\n",
      "[145]\ttraining's l2: 0.379365\tvalid_1's l2: 0.365442\n",
      "[146]\ttraining's l2: 0.379295\tvalid_1's l2: 0.365398\n",
      "[147]\ttraining's l2: 0.379254\tvalid_1's l2: 0.365378\n",
      "[148]\ttraining's l2: 0.37918\tvalid_1's l2: 0.365353\n",
      "[149]\ttraining's l2: 0.379105\tvalid_1's l2: 0.365318\n",
      "[150]\ttraining's l2: 0.379044\tvalid_1's l2: 0.365291\n",
      "[151]\ttraining's l2: 0.378996\tvalid_1's l2: 0.365252\n",
      "[152]\ttraining's l2: 0.378935\tvalid_1's l2: 0.365235\n",
      "[153]\ttraining's l2: 0.378853\tvalid_1's l2: 0.365194\n",
      "[154]\ttraining's l2: 0.378816\tvalid_1's l2: 0.365175\n",
      "[155]\ttraining's l2: 0.378779\tvalid_1's l2: 0.365168\n",
      "[156]\ttraining's l2: 0.378672\tvalid_1's l2: 0.365137\n",
      "[157]\ttraining's l2: 0.378625\tvalid_1's l2: 0.365097\n",
      "[158]\ttraining's l2: 0.378597\tvalid_1's l2: 0.365088\n",
      "[159]\ttraining's l2: 0.378564\tvalid_1's l2: 0.365072\n",
      "[160]\ttraining's l2: 0.378496\tvalid_1's l2: 0.365048\n",
      "[161]\ttraining's l2: 0.378428\tvalid_1's l2: 0.365031\n",
      "[162]\ttraining's l2: 0.378391\tvalid_1's l2: 0.365016\n",
      "[163]\ttraining's l2: 0.378356\tvalid_1's l2: 0.365006\n",
      "[164]\ttraining's l2: 0.378256\tvalid_1's l2: 0.364938\n",
      "[165]\ttraining's l2: 0.378203\tvalid_1's l2: 0.364912\n",
      "[166]\ttraining's l2: 0.378168\tvalid_1's l2: 0.364916\n",
      "[167]\ttraining's l2: 0.378135\tvalid_1's l2: 0.364908\n",
      "[168]\ttraining's l2: 0.378087\tvalid_1's l2: 0.364904\n",
      "[169]\ttraining's l2: 0.378032\tvalid_1's l2: 0.364887\n",
      "[170]\ttraining's l2: 0.378005\tvalid_1's l2: 0.364878\n",
      "[171]\ttraining's l2: 0.377955\tvalid_1's l2: 0.364842\n",
      "[172]\ttraining's l2: 0.377901\tvalid_1's l2: 0.364839\n",
      "[173]\ttraining's l2: 0.377869\tvalid_1's l2: 0.364826\n",
      "[174]\ttraining's l2: 0.377806\tvalid_1's l2: 0.364812\n",
      "[175]\ttraining's l2: 0.377756\tvalid_1's l2: 0.364795\n",
      "[176]\ttraining's l2: 0.377727\tvalid_1's l2: 0.364789\n",
      "[177]\ttraining's l2: 0.377701\tvalid_1's l2: 0.364779\n",
      "[178]\ttraining's l2: 0.377669\tvalid_1's l2: 0.364758\n",
      "[179]\ttraining's l2: 0.377634\tvalid_1's l2: 0.364751\n",
      "[180]\ttraining's l2: 0.377551\tvalid_1's l2: 0.364699\n",
      "[181]\ttraining's l2: 0.377522\tvalid_1's l2: 0.364687\n",
      "[182]\ttraining's l2: 0.377467\tvalid_1's l2: 0.364661\n",
      "[183]\ttraining's l2: 0.377421\tvalid_1's l2: 0.364636\n",
      "[184]\ttraining's l2: 0.377377\tvalid_1's l2: 0.364622\n",
      "[185]\ttraining's l2: 0.377291\tvalid_1's l2: 0.364548\n",
      "[186]\ttraining's l2: 0.377211\tvalid_1's l2: 0.364491\n",
      "[187]\ttraining's l2: 0.377144\tvalid_1's l2: 0.364472\n",
      "[188]\ttraining's l2: 0.37711\tvalid_1's l2: 0.364466\n",
      "[189]\ttraining's l2: 0.377085\tvalid_1's l2: 0.364461\n",
      "[190]\ttraining's l2: 0.377052\tvalid_1's l2: 0.364454\n",
      "[191]\ttraining's l2: 0.376995\tvalid_1's l2: 0.364433\n",
      "[192]\ttraining's l2: 0.376958\tvalid_1's l2: 0.364424\n",
      "[193]\ttraining's l2: 0.376924\tvalid_1's l2: 0.364389\n",
      "[194]\ttraining's l2: 0.376884\tvalid_1's l2: 0.364362\n",
      "[195]\ttraining's l2: 0.376855\tvalid_1's l2: 0.36435\n",
      "[196]\ttraining's l2: 0.37683\tvalid_1's l2: 0.364344\n",
      "[197]\ttraining's l2: 0.376809\tvalid_1's l2: 0.364336\n",
      "[198]\ttraining's l2: 0.376783\tvalid_1's l2: 0.364331\n",
      "[199]\ttraining's l2: 0.376757\tvalid_1's l2: 0.364315\n",
      "[200]\ttraining's l2: 0.376725\tvalid_1's l2: 0.364316\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.376725\tvalid_1's l2: 0.364316\n",
      "mean_21_sales: 9855442.88\n",
      "mean_30_sales: 3581703.35\n",
      "mean_7_sales: 3031710.94\n",
      "mean_14_sales: 2206488.34\n",
      "mean_60_sales: 1317860.19\n",
      "mean_3_sales: 1016408.50\n",
      "mean_20_dow5_2017: 850762.28\n",
      "promo_12: 707788.76\n",
      "mean_4_sales: 536201.32\n",
      "mean_6_sales: 472209.51\n",
      "item_class_features: 323762.84\n",
      "mean_63_sales: 217160.37\n",
      "mean_5_sales: 213936.83\n",
      "mean_4_dow5_2017: 206348.84\n",
      "promo_14: 101026.72\n",
      "promo_13: 96367.08\n",
      "sum_2_promo: 55406.58\n",
      "promo_10: 53715.38\n",
      "std_30_sales: 52557.64\n",
      "item_family_features: 38260.62\n",
      "sum_4_promo: 36837.76\n",
      "std_21_sales: 34007.84\n",
      "lag_1_sales: 30299.04\n",
      "promo_11: 29991.99\n",
      "mean_20_dow6_2017: 29931.00\n",
      "lag_49_sales: 23993.95\n",
      "store_cluster_features: 20064.41\n",
      "std_63_sales: 18045.62\n",
      "promo_9: 15210.88\n",
      "promo_7: 15208.49\n",
      "std_60_sales: 13796.48\n",
      "mean_20_dow0_2017: 12139.44\n",
      "mean_20_dow3_2017: 12038.03\n",
      "sum_14_promo: 11851.35\n",
      "promo_8: 10689.78\n",
      "lag_2_sales: 9825.24\n",
      "sum_21_promo: 9707.08\n",
      "sum_7_promo: 9473.22\n",
      "store_city_features: 9033.42\n",
      "promo_15: 8231.14\n",
      "mean_4_dow6_2017: 6694.65\n",
      "sum_6_promo: 6685.75\n",
      "std_14_sales: 6154.09\n",
      "lag_6_sales: 5219.30\n",
      "sum_3_promo: 5078.46\n",
      "sum_5_promo: 4639.41\n",
      "mean_20_dow1_2017: 4297.75\n",
      "promo_5: 3967.25\n",
      "promo_0: 3896.87\n",
      "mean_4_dow0_2017: 3735.85\n",
      "mean_4_dow1_2017: 3192.95\n",
      "mean_20_dow2_2017: 3123.47\n",
      "promo_6: 3021.79\n",
      "std_4_sales: 2990.27\n",
      "lag_3_sales: 2943.38\n",
      "store_type_features: 2874.82\n",
      "std_6_sales: 2728.19\n",
      "lag_4_sales: 2591.52\n",
      "mean_20_dow4_2017: 1941.08\n",
      "lag_21_sales: 1752.28\n",
      "std_7_sales: 1738.45\n",
      "std_5_sales: 1693.50\n",
      "lag_14_sales: 1622.75\n",
      "store_state_features: 1619.69\n",
      "lag_56_sales: 1553.33\n",
      "promo_2: 1451.44\n",
      "lag_28_sales: 1344.59\n",
      "mean_4_dow4_2017: 1333.33\n",
      "lag_35_sales: 1118.23\n",
      "std_3_sales: 1115.50\n",
      "mean_4_dow2_2017: 1091.85\n",
      "mean_4_dow3_2017: 1007.44\n",
      "lag_42_sales: 944.78\n",
      "lag_5_sales: 943.76\n",
      "lag_63_sales: 751.75\n",
      "lag_7_sales: 612.93\n",
      "promo_3: 411.59\n",
      "promo_4: 282.96\n",
      "promo_1: 63.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [19:08<04:23, 87.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.03104\tvalid_1's l2: 0.994067\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.971751\tvalid_1's l2: 0.93585\n",
      "[3]\ttraining's l2: 0.918264\tvalid_1's l2: 0.882947\n",
      "[4]\ttraining's l2: 0.868077\tvalid_1's l2: 0.833571\n",
      "[5]\ttraining's l2: 0.822606\tvalid_1's l2: 0.788867\n",
      "[6]\ttraining's l2: 0.781454\tvalid_1's l2: 0.748363\n",
      "[7]\ttraining's l2: 0.74554\tvalid_1's l2: 0.713176\n",
      "[8]\ttraining's l2: 0.711712\tvalid_1's l2: 0.680062\n",
      "[9]\ttraining's l2: 0.682238\tvalid_1's l2: 0.651323\n",
      "[10]\ttraining's l2: 0.654412\tvalid_1's l2: 0.624042\n",
      "[11]\ttraining's l2: 0.629105\tvalid_1's l2: 0.599616\n",
      "[12]\ttraining's l2: 0.606311\tvalid_1's l2: 0.577302\n",
      "[13]\ttraining's l2: 0.58556\tvalid_1's l2: 0.557063\n",
      "[14]\ttraining's l2: 0.566801\tvalid_1's l2: 0.538823\n",
      "[15]\ttraining's l2: 0.549794\tvalid_1's l2: 0.522193\n",
      "[16]\ttraining's l2: 0.5342\tvalid_1's l2: 0.507138\n",
      "[17]\ttraining's l2: 0.520189\tvalid_1's l2: 0.49369\n",
      "[18]\ttraining's l2: 0.507466\tvalid_1's l2: 0.481399\n",
      "[19]\ttraining's l2: 0.495856\tvalid_1's l2: 0.470251\n",
      "[20]\ttraining's l2: 0.485678\tvalid_1's l2: 0.460503\n",
      "[21]\ttraining's l2: 0.476058\tvalid_1's l2: 0.451269\n",
      "[22]\ttraining's l2: 0.467761\tvalid_1's l2: 0.44324\n",
      "[23]\ttraining's l2: 0.459822\tvalid_1's l2: 0.435623\n",
      "[24]\ttraining's l2: 0.45287\tvalid_1's l2: 0.428998\n",
      "[25]\ttraining's l2: 0.446254\tvalid_1's l2: 0.422739\n",
      "[26]\ttraining's l2: 0.440196\tvalid_1's l2: 0.416936\n",
      "[27]\ttraining's l2: 0.434974\tvalid_1's l2: 0.412028\n",
      "[28]\ttraining's l2: 0.430243\tvalid_1's l2: 0.407543\n",
      "[29]\ttraining's l2: 0.425639\tvalid_1's l2: 0.403163\n",
      "[30]\ttraining's l2: 0.421416\tvalid_1's l2: 0.399169\n",
      "[31]\ttraining's l2: 0.417726\tvalid_1's l2: 0.395752\n",
      "[32]\ttraining's l2: 0.414179\tvalid_1's l2: 0.392494\n",
      "[33]\ttraining's l2: 0.410911\tvalid_1's l2: 0.389449\n",
      "[34]\ttraining's l2: 0.407984\tvalid_1's l2: 0.386658\n",
      "[35]\ttraining's l2: 0.405239\tvalid_1's l2: 0.3841\n",
      "[36]\ttraining's l2: 0.402673\tvalid_1's l2: 0.381757\n",
      "[37]\ttraining's l2: 0.400442\tvalid_1's l2: 0.379684\n",
      "[38]\ttraining's l2: 0.398355\tvalid_1's l2: 0.377755\n",
      "[39]\ttraining's l2: 0.396429\tvalid_1's l2: 0.376011\n",
      "[40]\ttraining's l2: 0.394757\tvalid_1's l2: 0.374505\n",
      "[41]\ttraining's l2: 0.392966\tvalid_1's l2: 0.372981\n",
      "[42]\ttraining's l2: 0.391514\tvalid_1's l2: 0.371634\n",
      "[43]\ttraining's l2: 0.390116\tvalid_1's l2: 0.370429\n",
      "[44]\ttraining's l2: 0.388761\tvalid_1's l2: 0.369261\n",
      "[45]\ttraining's l2: 0.387593\tvalid_1's l2: 0.368206\n",
      "[46]\ttraining's l2: 0.386364\tvalid_1's l2: 0.367152\n",
      "[47]\ttraining's l2: 0.385339\tvalid_1's l2: 0.36627\n",
      "[48]\ttraining's l2: 0.384379\tvalid_1's l2: 0.365515\n",
      "[49]\ttraining's l2: 0.383524\tvalid_1's l2: 0.364805\n",
      "[50]\ttraining's l2: 0.382744\tvalid_1's l2: 0.364159\n",
      "[51]\ttraining's l2: 0.381987\tvalid_1's l2: 0.363593\n",
      "[52]\ttraining's l2: 0.381257\tvalid_1's l2: 0.363009\n",
      "[53]\ttraining's l2: 0.38058\tvalid_1's l2: 0.362451\n",
      "[54]\ttraining's l2: 0.379918\tvalid_1's l2: 0.361919\n",
      "[55]\ttraining's l2: 0.379241\tvalid_1's l2: 0.361408\n",
      "[56]\ttraining's l2: 0.378679\tvalid_1's l2: 0.360995\n",
      "[57]\ttraining's l2: 0.378142\tvalid_1's l2: 0.360541\n",
      "[58]\ttraining's l2: 0.377711\tvalid_1's l2: 0.360233\n",
      "[59]\ttraining's l2: 0.377234\tvalid_1's l2: 0.35983\n",
      "[60]\ttraining's l2: 0.376809\tvalid_1's l2: 0.359498\n",
      "[61]\ttraining's l2: 0.376355\tvalid_1's l2: 0.35919\n",
      "[62]\ttraining's l2: 0.375975\tvalid_1's l2: 0.35894\n",
      "[63]\ttraining's l2: 0.375604\tvalid_1's l2: 0.358625\n",
      "[64]\ttraining's l2: 0.375131\tvalid_1's l2: 0.35829\n",
      "[65]\ttraining's l2: 0.374868\tvalid_1's l2: 0.35811\n",
      "[66]\ttraining's l2: 0.374563\tvalid_1's l2: 0.357851\n",
      "[67]\ttraining's l2: 0.374244\tvalid_1's l2: 0.357626\n",
      "[68]\ttraining's l2: 0.37393\tvalid_1's l2: 0.357426\n",
      "[69]\ttraining's l2: 0.373584\tvalid_1's l2: 0.357137\n",
      "[70]\ttraining's l2: 0.373311\tvalid_1's l2: 0.35699\n",
      "[71]\ttraining's l2: 0.373029\tvalid_1's l2: 0.356851\n",
      "[72]\ttraining's l2: 0.372598\tvalid_1's l2: 0.356576\n",
      "[73]\ttraining's l2: 0.372212\tvalid_1's l2: 0.356283\n",
      "[74]\ttraining's l2: 0.371969\tvalid_1's l2: 0.356151\n",
      "[75]\ttraining's l2: 0.37157\tvalid_1's l2: 0.355894\n",
      "[76]\ttraining's l2: 0.371341\tvalid_1's l2: 0.355749\n",
      "[77]\ttraining's l2: 0.371138\tvalid_1's l2: 0.355595\n",
      "[78]\ttraining's l2: 0.370976\tvalid_1's l2: 0.355511\n",
      "[79]\ttraining's l2: 0.370728\tvalid_1's l2: 0.355325\n",
      "[80]\ttraining's l2: 0.370453\tvalid_1's l2: 0.35512\n",
      "[81]\ttraining's l2: 0.37017\tvalid_1's l2: 0.354936\n",
      "[82]\ttraining's l2: 0.370046\tvalid_1's l2: 0.35488\n",
      "[83]\ttraining's l2: 0.369773\tvalid_1's l2: 0.354732\n",
      "[84]\ttraining's l2: 0.369562\tvalid_1's l2: 0.354591\n",
      "[85]\ttraining's l2: 0.369375\tvalid_1's l2: 0.35448\n",
      "[86]\ttraining's l2: 0.369173\tvalid_1's l2: 0.354335\n",
      "[87]\ttraining's l2: 0.369035\tvalid_1's l2: 0.354251\n",
      "[88]\ttraining's l2: 0.368919\tvalid_1's l2: 0.354161\n",
      "[89]\ttraining's l2: 0.368707\tvalid_1's l2: 0.354026\n",
      "[90]\ttraining's l2: 0.368476\tvalid_1's l2: 0.3539\n",
      "[91]\ttraining's l2: 0.36834\tvalid_1's l2: 0.353841\n",
      "[92]\ttraining's l2: 0.368204\tvalid_1's l2: 0.35372\n",
      "[93]\ttraining's l2: 0.368109\tvalid_1's l2: 0.353661\n",
      "[94]\ttraining's l2: 0.367751\tvalid_1's l2: 0.353435\n",
      "[95]\ttraining's l2: 0.367589\tvalid_1's l2: 0.353302\n",
      "[96]\ttraining's l2: 0.367461\tvalid_1's l2: 0.353263\n",
      "[97]\ttraining's l2: 0.367344\tvalid_1's l2: 0.353154\n",
      "[98]\ttraining's l2: 0.367235\tvalid_1's l2: 0.353077\n",
      "[99]\ttraining's l2: 0.367116\tvalid_1's l2: 0.35302\n",
      "[100]\ttraining's l2: 0.36693\tvalid_1's l2: 0.352886\n",
      "[101]\ttraining's l2: 0.366688\tvalid_1's l2: 0.35273\n",
      "[102]\ttraining's l2: 0.366482\tvalid_1's l2: 0.3526\n",
      "[103]\ttraining's l2: 0.366303\tvalid_1's l2: 0.352455\n",
      "[104]\ttraining's l2: 0.366214\tvalid_1's l2: 0.352397\n",
      "[105]\ttraining's l2: 0.36603\tvalid_1's l2: 0.352248\n",
      "[106]\ttraining's l2: 0.365954\tvalid_1's l2: 0.352225\n",
      "[107]\ttraining's l2: 0.365829\tvalid_1's l2: 0.352123\n",
      "[108]\ttraining's l2: 0.365677\tvalid_1's l2: 0.352016\n",
      "[109]\ttraining's l2: 0.365576\tvalid_1's l2: 0.351983\n",
      "[110]\ttraining's l2: 0.365499\tvalid_1's l2: 0.351955\n",
      "[111]\ttraining's l2: 0.365372\tvalid_1's l2: 0.351855\n",
      "[112]\ttraining's l2: 0.365304\tvalid_1's l2: 0.351827\n",
      "[113]\ttraining's l2: 0.365222\tvalid_1's l2: 0.351804\n",
      "[114]\ttraining's l2: 0.365117\tvalid_1's l2: 0.351729\n",
      "[115]\ttraining's l2: 0.365053\tvalid_1's l2: 0.351721\n",
      "[116]\ttraining's l2: 0.364866\tvalid_1's l2: 0.351603\n",
      "[117]\ttraining's l2: 0.36477\tvalid_1's l2: 0.351558\n",
      "[118]\ttraining's l2: 0.364697\tvalid_1's l2: 0.351539\n",
      "[119]\ttraining's l2: 0.3646\tvalid_1's l2: 0.351507\n",
      "[120]\ttraining's l2: 0.364445\tvalid_1's l2: 0.351429\n",
      "[121]\ttraining's l2: 0.364379\tvalid_1's l2: 0.351399\n",
      "[122]\ttraining's l2: 0.364278\tvalid_1's l2: 0.3513\n",
      "[123]\ttraining's l2: 0.364187\tvalid_1's l2: 0.351277\n",
      "[124]\ttraining's l2: 0.364116\tvalid_1's l2: 0.351245\n",
      "[125]\ttraining's l2: 0.364073\tvalid_1's l2: 0.351231\n",
      "[126]\ttraining's l2: 0.364022\tvalid_1's l2: 0.351197\n",
      "[127]\ttraining's l2: 0.36392\tvalid_1's l2: 0.35112\n",
      "[128]\ttraining's l2: 0.363805\tvalid_1's l2: 0.351047\n",
      "[129]\ttraining's l2: 0.363746\tvalid_1's l2: 0.351007\n",
      "[130]\ttraining's l2: 0.363671\tvalid_1's l2: 0.350985\n",
      "[131]\ttraining's l2: 0.363522\tvalid_1's l2: 0.35091\n",
      "[132]\ttraining's l2: 0.363436\tvalid_1's l2: 0.350888\n",
      "[133]\ttraining's l2: 0.363375\tvalid_1's l2: 0.35086\n",
      "[134]\ttraining's l2: 0.363333\tvalid_1's l2: 0.350833\n",
      "[135]\ttraining's l2: 0.363243\tvalid_1's l2: 0.350804\n",
      "[136]\ttraining's l2: 0.363169\tvalid_1's l2: 0.350772\n",
      "[137]\ttraining's l2: 0.363119\tvalid_1's l2: 0.35076\n",
      "[138]\ttraining's l2: 0.363076\tvalid_1's l2: 0.350751\n",
      "[139]\ttraining's l2: 0.363027\tvalid_1's l2: 0.350745\n",
      "[140]\ttraining's l2: 0.362896\tvalid_1's l2: 0.350676\n",
      "[141]\ttraining's l2: 0.362848\tvalid_1's l2: 0.350673\n",
      "[142]\ttraining's l2: 0.362804\tvalid_1's l2: 0.350653\n",
      "[143]\ttraining's l2: 0.362719\tvalid_1's l2: 0.350623\n",
      "[144]\ttraining's l2: 0.362631\tvalid_1's l2: 0.350607\n",
      "[145]\ttraining's l2: 0.362556\tvalid_1's l2: 0.350555\n",
      "[146]\ttraining's l2: 0.36251\tvalid_1's l2: 0.350536\n",
      "[147]\ttraining's l2: 0.362472\tvalid_1's l2: 0.350542\n",
      "[148]\ttraining's l2: 0.362393\tvalid_1's l2: 0.350496\n",
      "[149]\ttraining's l2: 0.362351\tvalid_1's l2: 0.350463\n",
      "[150]\ttraining's l2: 0.362312\tvalid_1's l2: 0.350445\n",
      "[151]\ttraining's l2: 0.36227\tvalid_1's l2: 0.350429\n",
      "[152]\ttraining's l2: 0.36223\tvalid_1's l2: 0.350425\n",
      "[153]\ttraining's l2: 0.362178\tvalid_1's l2: 0.350409\n",
      "[154]\ttraining's l2: 0.362148\tvalid_1's l2: 0.350388\n",
      "[155]\ttraining's l2: 0.362076\tvalid_1's l2: 0.350351\n",
      "[156]\ttraining's l2: 0.362038\tvalid_1's l2: 0.350334\n",
      "[157]\ttraining's l2: 0.361947\tvalid_1's l2: 0.350298\n",
      "[158]\ttraining's l2: 0.361844\tvalid_1's l2: 0.350248\n",
      "[159]\ttraining's l2: 0.361811\tvalid_1's l2: 0.350227\n",
      "[160]\ttraining's l2: 0.361765\tvalid_1's l2: 0.350209\n",
      "[161]\ttraining's l2: 0.36172\tvalid_1's l2: 0.350205\n",
      "[162]\ttraining's l2: 0.361682\tvalid_1's l2: 0.350189\n",
      "[163]\ttraining's l2: 0.361649\tvalid_1's l2: 0.35019\n",
      "[164]\ttraining's l2: 0.361569\tvalid_1's l2: 0.350139\n",
      "[165]\ttraining's l2: 0.361514\tvalid_1's l2: 0.350131\n",
      "[166]\ttraining's l2: 0.36147\tvalid_1's l2: 0.350116\n",
      "[167]\ttraining's l2: 0.361438\tvalid_1's l2: 0.350103\n",
      "[168]\ttraining's l2: 0.361408\tvalid_1's l2: 0.350098\n",
      "[169]\ttraining's l2: 0.361372\tvalid_1's l2: 0.350092\n",
      "[170]\ttraining's l2: 0.361249\tvalid_1's l2: 0.350001\n",
      "[171]\ttraining's l2: 0.361216\tvalid_1's l2: 0.349988\n",
      "[172]\ttraining's l2: 0.361183\tvalid_1's l2: 0.349988\n",
      "[173]\ttraining's l2: 0.361157\tvalid_1's l2: 0.349971\n",
      "[174]\ttraining's l2: 0.361114\tvalid_1's l2: 0.349951\n",
      "[175]\ttraining's l2: 0.361085\tvalid_1's l2: 0.349929\n",
      "[176]\ttraining's l2: 0.36104\tvalid_1's l2: 0.349891\n",
      "[177]\ttraining's l2: 0.360999\tvalid_1's l2: 0.349867\n",
      "[178]\ttraining's l2: 0.360953\tvalid_1's l2: 0.349855\n",
      "[179]\ttraining's l2: 0.360927\tvalid_1's l2: 0.349862\n",
      "[180]\ttraining's l2: 0.360882\tvalid_1's l2: 0.349856\n",
      "[181]\ttraining's l2: 0.360862\tvalid_1's l2: 0.349855\n",
      "[182]\ttraining's l2: 0.360823\tvalid_1's l2: 0.349846\n",
      "[183]\ttraining's l2: 0.360722\tvalid_1's l2: 0.349801\n",
      "[184]\ttraining's l2: 0.360676\tvalid_1's l2: 0.3498\n",
      "[185]\ttraining's l2: 0.360647\tvalid_1's l2: 0.349776\n",
      "[186]\ttraining's l2: 0.360582\tvalid_1's l2: 0.349758\n",
      "[187]\ttraining's l2: 0.360545\tvalid_1's l2: 0.349749\n",
      "[188]\ttraining's l2: 0.36051\tvalid_1's l2: 0.349749\n",
      "[189]\ttraining's l2: 0.360474\tvalid_1's l2: 0.349743\n",
      "[190]\ttraining's l2: 0.360431\tvalid_1's l2: 0.349718\n",
      "[191]\ttraining's l2: 0.36039\tvalid_1's l2: 0.349691\n",
      "[192]\ttraining's l2: 0.360341\tvalid_1's l2: 0.349679\n",
      "[193]\ttraining's l2: 0.360317\tvalid_1's l2: 0.349681\n",
      "[194]\ttraining's l2: 0.360278\tvalid_1's l2: 0.34966\n",
      "[195]\ttraining's l2: 0.360247\tvalid_1's l2: 0.349647\n",
      "[196]\ttraining's l2: 0.360219\tvalid_1's l2: 0.34963\n",
      "[197]\ttraining's l2: 0.360164\tvalid_1's l2: 0.349619\n",
      "[198]\ttraining's l2: 0.360137\tvalid_1's l2: 0.349613\n",
      "[199]\ttraining's l2: 0.360113\tvalid_1's l2: 0.349605\n",
      "[200]\ttraining's l2: 0.360083\tvalid_1's l2: 0.349599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.360083\tvalid_1's l2: 0.349599\n",
      "mean_21_sales: 7283934.58\n",
      "mean_30_sales: 5122593.01\n",
      "mean_14_sales: 3076766.17\n",
      "mean_20_dow6_2017: 1829235.31\n",
      "mean_7_sales: 1804060.85\n",
      "promo_13: 1003708.84\n",
      "mean_3_sales: 942018.61\n",
      "mean_6_sales: 864217.34\n",
      "mean_4_dow6_2017: 517711.29\n",
      "mean_60_sales: 387473.50\n",
      "item_class_features: 317715.34\n",
      "mean_4_sales: 188212.18\n",
      "mean_5_sales: 187333.69\n",
      "promo_14: 152830.99\n",
      "mean_63_sales: 142858.62\n",
      "item_family_features: 70629.75\n",
      "lag_1_sales: 69635.68\n",
      "mean_20_dow5_2017: 66341.97\n",
      "std_30_sales: 60725.72\n",
      "promo_12: 58766.60\n",
      "std_21_sales: 45424.77\n",
      "promo_10: 42883.55\n",
      "sum_4_promo: 38685.98\n",
      "promo_6: 35563.12\n",
      "std_63_sales: 30324.58\n",
      "sum_2_promo: 29002.31\n",
      "lag_2_sales: 22722.55\n",
      "store_cluster_features: 22706.99\n",
      "std_60_sales: 22590.41\n",
      "lag_49_sales: 20523.55\n",
      "mean_20_dow0_2017: 15303.00\n",
      "sum_7_promo: 14931.22\n",
      "promo_0: 13939.36\n",
      "promo_11: 13797.33\n",
      "sum_14_promo: 12419.24\n",
      "mean_20_dow3_2017: 11931.46\n",
      "mean_20_dow1_2017: 10716.55\n",
      "sum_21_promo: 10431.00\n",
      "store_type_features: 9783.94\n",
      "sum_6_promo: 9748.86\n",
      "promo_9: 9624.40\n",
      "store_city_features: 9447.53\n",
      "promo_7: 9017.28\n",
      "std_14_sales: 6854.52\n",
      "sum_5_promo: 6457.23\n",
      "promo_15: 6290.78\n",
      "std_7_sales: 6043.46\n",
      "lag_6_sales: 5838.74\n",
      "sum_3_promo: 5623.25\n",
      "lag_14_sales: 4365.00\n",
      "promo_8: 3822.22\n",
      "mean_4_dow1_2017: 3180.12\n",
      "lag_3_sales: 3132.19\n",
      "mean_20_dow2_2017: 2905.95\n",
      "mean_4_dow5_2017: 2689.51\n",
      "lag_42_sales: 2551.98\n",
      "std_5_sales: 2490.00\n",
      "mean_20_dow4_2017: 2309.39\n",
      "std_4_sales: 2212.94\n",
      "std_6_sales: 1948.61\n",
      "lag_35_sales: 1708.84\n",
      "lag_4_sales: 1704.07\n",
      "lag_21_sales: 1628.06\n",
      "mean_4_dow3_2017: 1575.67\n",
      "mean_4_dow0_2017: 1543.23\n",
      "store_state_features: 1534.38\n",
      "lag_7_sales: 1529.42\n",
      "lag_28_sales: 1510.61\n",
      "mean_4_dow4_2017: 1408.23\n",
      "std_3_sales: 1063.50\n",
      "promo_2: 907.58\n",
      "lag_56_sales: 907.35\n",
      "mean_4_dow2_2017: 769.34\n",
      "lag_63_sales: 737.03\n",
      "lag_5_sales: 634.48\n",
      "promo_1: 295.43\n",
      "promo_5: 226.67\n",
      "promo_4: 76.12\n",
      "promo_3: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [20:35<02:55, 87.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05903\tvalid_1's l2: 1.00853\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.994475\tvalid_1's l2: 0.946353\n",
      "[3]\ttraining's l2: 0.936067\tvalid_1's l2: 0.889915\n",
      "[4]\ttraining's l2: 0.885673\tvalid_1's l2: 0.84078\n",
      "[5]\ttraining's l2: 0.84001\tvalid_1's l2: 0.796495\n",
      "[6]\ttraining's l2: 0.796148\tvalid_1's l2: 0.754043\n",
      "[7]\ttraining's l2: 0.756604\tvalid_1's l2: 0.715939\n",
      "[8]\ttraining's l2: 0.720641\tvalid_1's l2: 0.681266\n",
      "[9]\ttraining's l2: 0.68995\tvalid_1's l2: 0.651676\n",
      "[10]\ttraining's l2: 0.660304\tvalid_1's l2: 0.623119\n",
      "[11]\ttraining's l2: 0.635027\tvalid_1's l2: 0.598858\n",
      "[12]\ttraining's l2: 0.612237\tvalid_1's l2: 0.576931\n",
      "[13]\ttraining's l2: 0.591579\tvalid_1's l2: 0.557057\n",
      "[14]\ttraining's l2: 0.571073\tvalid_1's l2: 0.537718\n",
      "[15]\ttraining's l2: 0.552456\tvalid_1's l2: 0.520148\n",
      "[16]\ttraining's l2: 0.535596\tvalid_1's l2: 0.504286\n",
      "[17]\ttraining's l2: 0.520351\tvalid_1's l2: 0.489746\n",
      "[18]\ttraining's l2: 0.507666\tvalid_1's l2: 0.477596\n",
      "[19]\ttraining's l2: 0.494896\tvalid_1's l2: 0.465566\n",
      "[20]\ttraining's l2: 0.483296\tvalid_1's l2: 0.454775\n",
      "[21]\ttraining's l2: 0.473705\tvalid_1's l2: 0.44576\n",
      "[22]\ttraining's l2: 0.464034\tvalid_1's l2: 0.436672\n",
      "[23]\ttraining's l2: 0.45531\tvalid_1's l2: 0.428543\n",
      "[24]\ttraining's l2: 0.447248\tvalid_1's l2: 0.421067\n",
      "[25]\ttraining's l2: 0.440674\tvalid_1's l2: 0.41493\n",
      "[26]\ttraining's l2: 0.433954\tvalid_1's l2: 0.408741\n",
      "[27]\ttraining's l2: 0.427812\tvalid_1's l2: 0.40313\n",
      "[28]\ttraining's l2: 0.42222\tvalid_1's l2: 0.39802\n",
      "[29]\ttraining's l2: 0.417109\tvalid_1's l2: 0.393366\n",
      "[30]\ttraining's l2: 0.412432\tvalid_1's l2: 0.389097\n",
      "[31]\ttraining's l2: 0.408145\tvalid_1's l2: 0.385212\n",
      "[32]\ttraining's l2: 0.404262\tvalid_1's l2: 0.381663\n",
      "[33]\ttraining's l2: 0.401138\tvalid_1's l2: 0.378819\n",
      "[34]\ttraining's l2: 0.397802\tvalid_1's l2: 0.375767\n",
      "[35]\ttraining's l2: 0.395184\tvalid_1's l2: 0.373391\n",
      "[36]\ttraining's l2: 0.392327\tvalid_1's l2: 0.370888\n",
      "[37]\ttraining's l2: 0.389804\tvalid_1's l2: 0.368646\n",
      "[38]\ttraining's l2: 0.387429\tvalid_1's l2: 0.366497\n",
      "[39]\ttraining's l2: 0.385174\tvalid_1's l2: 0.364505\n",
      "[40]\ttraining's l2: 0.383184\tvalid_1's l2: 0.362799\n",
      "[41]\ttraining's l2: 0.381243\tvalid_1's l2: 0.361169\n",
      "[42]\ttraining's l2: 0.379829\tvalid_1's l2: 0.359888\n",
      "[43]\ttraining's l2: 0.378194\tvalid_1's l2: 0.358518\n",
      "[44]\ttraining's l2: 0.376722\tvalid_1's l2: 0.357238\n",
      "[45]\ttraining's l2: 0.375592\tvalid_1's l2: 0.356302\n",
      "[46]\ttraining's l2: 0.374246\tvalid_1's l2: 0.355142\n",
      "[47]\ttraining's l2: 0.37302\tvalid_1's l2: 0.354091\n",
      "[48]\ttraining's l2: 0.371849\tvalid_1's l2: 0.353161\n",
      "[49]\ttraining's l2: 0.370784\tvalid_1's l2: 0.352308\n",
      "[50]\ttraining's l2: 0.369791\tvalid_1's l2: 0.35151\n",
      "[51]\ttraining's l2: 0.368912\tvalid_1's l2: 0.350796\n",
      "[52]\ttraining's l2: 0.368097\tvalid_1's l2: 0.350092\n",
      "[53]\ttraining's l2: 0.367328\tvalid_1's l2: 0.349494\n",
      "[54]\ttraining's l2: 0.366569\tvalid_1's l2: 0.348911\n",
      "[55]\ttraining's l2: 0.365984\tvalid_1's l2: 0.348465\n",
      "[56]\ttraining's l2: 0.365453\tvalid_1's l2: 0.348102\n",
      "[57]\ttraining's l2: 0.364986\tvalid_1's l2: 0.347709\n",
      "[58]\ttraining's l2: 0.364527\tvalid_1's l2: 0.347384\n",
      "[59]\ttraining's l2: 0.364098\tvalid_1's l2: 0.347068\n",
      "[60]\ttraining's l2: 0.363677\tvalid_1's l2: 0.34679\n",
      "[61]\ttraining's l2: 0.363092\tvalid_1's l2: 0.346292\n",
      "[62]\ttraining's l2: 0.362584\tvalid_1's l2: 0.345917\n",
      "[63]\ttraining's l2: 0.362021\tvalid_1's l2: 0.345407\n",
      "[64]\ttraining's l2: 0.361498\tvalid_1's l2: 0.344961\n",
      "[65]\ttraining's l2: 0.361208\tvalid_1's l2: 0.344756\n",
      "[66]\ttraining's l2: 0.360917\tvalid_1's l2: 0.344553\n",
      "[67]\ttraining's l2: 0.360457\tvalid_1's l2: 0.344177\n",
      "[68]\ttraining's l2: 0.360138\tvalid_1's l2: 0.344005\n",
      "[69]\ttraining's l2: 0.359682\tvalid_1's l2: 0.343622\n",
      "[70]\ttraining's l2: 0.359357\tvalid_1's l2: 0.343385\n",
      "[71]\ttraining's l2: 0.358917\tvalid_1's l2: 0.343068\n",
      "[72]\ttraining's l2: 0.358548\tvalid_1's l2: 0.342781\n",
      "[73]\ttraining's l2: 0.358169\tvalid_1's l2: 0.342541\n",
      "[74]\ttraining's l2: 0.357836\tvalid_1's l2: 0.3423\n",
      "[75]\ttraining's l2: 0.357533\tvalid_1's l2: 0.342092\n",
      "[76]\ttraining's l2: 0.357252\tvalid_1's l2: 0.34189\n",
      "[77]\ttraining's l2: 0.357028\tvalid_1's l2: 0.341725\n",
      "[78]\ttraining's l2: 0.356783\tvalid_1's l2: 0.341567\n",
      "[79]\ttraining's l2: 0.356488\tvalid_1's l2: 0.341378\n",
      "[80]\ttraining's l2: 0.356192\tvalid_1's l2: 0.34114\n",
      "[81]\ttraining's l2: 0.356033\tvalid_1's l2: 0.341064\n",
      "[82]\ttraining's l2: 0.355898\tvalid_1's l2: 0.340953\n",
      "[83]\ttraining's l2: 0.355674\tvalid_1's l2: 0.340775\n",
      "[84]\ttraining's l2: 0.355483\tvalid_1's l2: 0.340678\n",
      "[85]\ttraining's l2: 0.355294\tvalid_1's l2: 0.340533\n",
      "[86]\ttraining's l2: 0.355126\tvalid_1's l2: 0.340445\n",
      "[87]\ttraining's l2: 0.354973\tvalid_1's l2: 0.340373\n",
      "[88]\ttraining's l2: 0.354846\tvalid_1's l2: 0.340283\n",
      "[89]\ttraining's l2: 0.35453\tvalid_1's l2: 0.340028\n",
      "[90]\ttraining's l2: 0.354272\tvalid_1's l2: 0.339879\n",
      "[91]\ttraining's l2: 0.354114\tvalid_1's l2: 0.339734\n",
      "[92]\ttraining's l2: 0.353951\tvalid_1's l2: 0.33961\n",
      "[93]\ttraining's l2: 0.353859\tvalid_1's l2: 0.339546\n",
      "[94]\ttraining's l2: 0.353636\tvalid_1's l2: 0.339396\n",
      "[95]\ttraining's l2: 0.353521\tvalid_1's l2: 0.339325\n",
      "[96]\ttraining's l2: 0.353418\tvalid_1's l2: 0.339265\n",
      "[97]\ttraining's l2: 0.353296\tvalid_1's l2: 0.339195\n",
      "[98]\ttraining's l2: 0.353194\tvalid_1's l2: 0.339118\n",
      "[99]\ttraining's l2: 0.353088\tvalid_1's l2: 0.339071\n",
      "[100]\ttraining's l2: 0.352897\tvalid_1's l2: 0.338926\n",
      "[101]\ttraining's l2: 0.352811\tvalid_1's l2: 0.33888\n",
      "[102]\ttraining's l2: 0.352698\tvalid_1's l2: 0.33882\n",
      "[103]\ttraining's l2: 0.352495\tvalid_1's l2: 0.33865\n",
      "[104]\ttraining's l2: 0.352401\tvalid_1's l2: 0.338572\n",
      "[105]\ttraining's l2: 0.35222\tvalid_1's l2: 0.338471\n",
      "[106]\ttraining's l2: 0.352056\tvalid_1's l2: 0.338384\n",
      "[107]\ttraining's l2: 0.351946\tvalid_1's l2: 0.338306\n",
      "[108]\ttraining's l2: 0.351855\tvalid_1's l2: 0.338233\n",
      "[109]\ttraining's l2: 0.351764\tvalid_1's l2: 0.338221\n",
      "[110]\ttraining's l2: 0.351612\tvalid_1's l2: 0.338128\n",
      "[111]\ttraining's l2: 0.351535\tvalid_1's l2: 0.338057\n",
      "[112]\ttraining's l2: 0.351463\tvalid_1's l2: 0.338031\n",
      "[113]\ttraining's l2: 0.351327\tvalid_1's l2: 0.337931\n",
      "[114]\ttraining's l2: 0.351223\tvalid_1's l2: 0.337846\n",
      "[115]\ttraining's l2: 0.351119\tvalid_1's l2: 0.337756\n",
      "[116]\ttraining's l2: 0.351032\tvalid_1's l2: 0.337738\n",
      "[117]\ttraining's l2: 0.350914\tvalid_1's l2: 0.337637\n",
      "[118]\ttraining's l2: 0.350834\tvalid_1's l2: 0.337602\n",
      "[119]\ttraining's l2: 0.3507\tvalid_1's l2: 0.337512\n",
      "[120]\ttraining's l2: 0.350628\tvalid_1's l2: 0.337491\n",
      "[121]\ttraining's l2: 0.350558\tvalid_1's l2: 0.337467\n",
      "[122]\ttraining's l2: 0.350448\tvalid_1's l2: 0.337374\n",
      "[123]\ttraining's l2: 0.350377\tvalid_1's l2: 0.337315\n",
      "[124]\ttraining's l2: 0.350311\tvalid_1's l2: 0.337286\n",
      "[125]\ttraining's l2: 0.350247\tvalid_1's l2: 0.337262\n",
      "[126]\ttraining's l2: 0.350167\tvalid_1's l2: 0.337194\n",
      "[127]\ttraining's l2: 0.350079\tvalid_1's l2: 0.337122\n",
      "[128]\ttraining's l2: 0.349968\tvalid_1's l2: 0.337066\n",
      "[129]\ttraining's l2: 0.349892\tvalid_1's l2: 0.337012\n",
      "[130]\ttraining's l2: 0.349821\tvalid_1's l2: 0.336994\n",
      "[131]\ttraining's l2: 0.349741\tvalid_1's l2: 0.336961\n",
      "[132]\ttraining's l2: 0.349681\tvalid_1's l2: 0.336935\n",
      "[133]\ttraining's l2: 0.349591\tvalid_1's l2: 0.336867\n",
      "[134]\ttraining's l2: 0.349524\tvalid_1's l2: 0.336848\n",
      "[135]\ttraining's l2: 0.349446\tvalid_1's l2: 0.336795\n",
      "[136]\ttraining's l2: 0.349385\tvalid_1's l2: 0.336759\n",
      "[137]\ttraining's l2: 0.349316\tvalid_1's l2: 0.336717\n",
      "[138]\ttraining's l2: 0.349256\tvalid_1's l2: 0.336712\n",
      "[139]\ttraining's l2: 0.349205\tvalid_1's l2: 0.336701\n",
      "[140]\ttraining's l2: 0.349157\tvalid_1's l2: 0.336698\n",
      "[141]\ttraining's l2: 0.349098\tvalid_1's l2: 0.336682\n",
      "[142]\ttraining's l2: 0.349035\tvalid_1's l2: 0.336654\n",
      "[143]\ttraining's l2: 0.348949\tvalid_1's l2: 0.336598\n",
      "[144]\ttraining's l2: 0.348868\tvalid_1's l2: 0.336558\n",
      "[145]\ttraining's l2: 0.348811\tvalid_1's l2: 0.336524\n",
      "[146]\ttraining's l2: 0.348728\tvalid_1's l2: 0.336453\n",
      "[147]\ttraining's l2: 0.348659\tvalid_1's l2: 0.336451\n",
      "[148]\ttraining's l2: 0.34859\tvalid_1's l2: 0.336418\n",
      "[149]\ttraining's l2: 0.348543\tvalid_1's l2: 0.336406\n",
      "[150]\ttraining's l2: 0.348477\tvalid_1's l2: 0.336399\n",
      "[151]\ttraining's l2: 0.348434\tvalid_1's l2: 0.336372\n",
      "[152]\ttraining's l2: 0.348386\tvalid_1's l2: 0.336373\n",
      "[153]\ttraining's l2: 0.348336\tvalid_1's l2: 0.336358\n",
      "[154]\ttraining's l2: 0.348294\tvalid_1's l2: 0.336323\n",
      "[155]\ttraining's l2: 0.348226\tvalid_1's l2: 0.336302\n",
      "[156]\ttraining's l2: 0.348183\tvalid_1's l2: 0.336314\n",
      "[157]\ttraining's l2: 0.348064\tvalid_1's l2: 0.336204\n",
      "[158]\ttraining's l2: 0.348023\tvalid_1's l2: 0.336183\n",
      "[159]\ttraining's l2: 0.34799\tvalid_1's l2: 0.336167\n",
      "[160]\ttraining's l2: 0.347938\tvalid_1's l2: 0.336161\n",
      "[161]\ttraining's l2: 0.347883\tvalid_1's l2: 0.336123\n",
      "[162]\ttraining's l2: 0.347833\tvalid_1's l2: 0.336111\n",
      "[163]\ttraining's l2: 0.3478\tvalid_1's l2: 0.336109\n",
      "[164]\ttraining's l2: 0.347732\tvalid_1's l2: 0.33611\n",
      "[165]\ttraining's l2: 0.347701\tvalid_1's l2: 0.336113\n",
      "[166]\ttraining's l2: 0.34767\tvalid_1's l2: 0.3361\n",
      "[167]\ttraining's l2: 0.347637\tvalid_1's l2: 0.336074\n",
      "[168]\ttraining's l2: 0.347588\tvalid_1's l2: 0.336063\n",
      "[169]\ttraining's l2: 0.347554\tvalid_1's l2: 0.336046\n",
      "[170]\ttraining's l2: 0.347521\tvalid_1's l2: 0.336057\n",
      "[171]\ttraining's l2: 0.347453\tvalid_1's l2: 0.336024\n",
      "[172]\ttraining's l2: 0.347405\tvalid_1's l2: 0.336014\n",
      "[173]\ttraining's l2: 0.347373\tvalid_1's l2: 0.335981\n",
      "[174]\ttraining's l2: 0.347329\tvalid_1's l2: 0.335963\n",
      "[175]\ttraining's l2: 0.347287\tvalid_1's l2: 0.335917\n",
      "[176]\ttraining's l2: 0.347239\tvalid_1's l2: 0.33589\n",
      "[177]\ttraining's l2: 0.347204\tvalid_1's l2: 0.335872\n",
      "[178]\ttraining's l2: 0.347146\tvalid_1's l2: 0.335838\n",
      "[179]\ttraining's l2: 0.347098\tvalid_1's l2: 0.335833\n",
      "[180]\ttraining's l2: 0.347059\tvalid_1's l2: 0.33583\n",
      "[181]\ttraining's l2: 0.347012\tvalid_1's l2: 0.335819\n",
      "[182]\ttraining's l2: 0.346961\tvalid_1's l2: 0.33582\n",
      "[183]\ttraining's l2: 0.346915\tvalid_1's l2: 0.3358\n",
      "[184]\ttraining's l2: 0.346866\tvalid_1's l2: 0.335791\n",
      "[185]\ttraining's l2: 0.346844\tvalid_1's l2: 0.335783\n",
      "[186]\ttraining's l2: 0.346799\tvalid_1's l2: 0.335796\n",
      "[187]\ttraining's l2: 0.346721\tvalid_1's l2: 0.335752\n",
      "[188]\ttraining's l2: 0.346677\tvalid_1's l2: 0.335758\n",
      "[189]\ttraining's l2: 0.346632\tvalid_1's l2: 0.335748\n",
      "[190]\ttraining's l2: 0.34659\tvalid_1's l2: 0.335733\n",
      "[191]\ttraining's l2: 0.346538\tvalid_1's l2: 0.335692\n",
      "[192]\ttraining's l2: 0.34649\tvalid_1's l2: 0.335688\n",
      "[193]\ttraining's l2: 0.346455\tvalid_1's l2: 0.33567\n",
      "[194]\ttraining's l2: 0.346417\tvalid_1's l2: 0.335646\n",
      "[195]\ttraining's l2: 0.346383\tvalid_1's l2: 0.335627\n",
      "[196]\ttraining's l2: 0.346352\tvalid_1's l2: 0.335632\n",
      "[197]\ttraining's l2: 0.346322\tvalid_1's l2: 0.335621\n",
      "[198]\ttraining's l2: 0.346281\tvalid_1's l2: 0.335587\n",
      "[199]\ttraining's l2: 0.34624\tvalid_1's l2: 0.335566\n",
      "[200]\ttraining's l2: 0.34619\tvalid_1's l2: 0.335555\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.34619\tvalid_1's l2: 0.335555\n",
      "mean_21_sales: 9103997.87\n",
      "mean_14_sales: 4205246.36\n",
      "mean_30_sales: 3617902.10\n",
      "mean_7_sales: 2448409.48\n",
      "mean_20_dow0_2017: 2054572.74\n",
      "promo_14: 1326606.03\n",
      "mean_63_sales: 900294.63\n",
      "item_class_features: 374043.78\n",
      "mean_4_dow0_2017: 271029.03\n",
      "mean_60_sales: 233078.62\n",
      "mean_3_sales: 147476.16\n",
      "mean_6_sales: 137263.80\n",
      "promo_13: 115997.43\n",
      "item_family_features: 102047.60\n",
      "sum_7_promo: 95997.73\n",
      "std_30_sales: 79046.40\n",
      "promo_0: 77570.90\n",
      "lag_1_sales: 74600.00\n",
      "store_cluster_features: 64682.13\n",
      "promo_7: 63777.49\n",
      "sum_14_promo: 48000.76\n",
      "std_63_sales: 44383.22\n",
      "sum_21_promo: 39678.75\n",
      "std_21_sales: 37716.06\n",
      "promo_12: 37660.06\n",
      "lag_2_sales: 37191.97\n",
      "promo_15: 36991.85\n",
      "mean_5_sales: 35275.45\n",
      "std_60_sales: 30619.46\n",
      "mean_4_sales: 30582.57\n",
      "lag_49_sales: 30029.57\n",
      "promo_10: 28512.17\n",
      "lag_14_sales: 27213.49\n",
      "std_14_sales: 23869.33\n",
      "mean_20_dow2_2017: 22620.49\n",
      "lag_42_sales: 21993.86\n",
      "store_type_features: 21963.20\n",
      "mean_20_dow3_2017: 17051.45\n",
      "mean_20_dow1_2017: 15049.03\n",
      "promo_9: 14689.78\n",
      "store_city_features: 12738.98\n",
      "promo_6: 10855.19\n",
      "mean_20_dow6_2017: 9722.51\n",
      "sum_2_promo: 8813.93\n",
      "promo_11: 6641.37\n",
      "mean_20_dow5_2017: 6530.76\n",
      "std_7_sales: 5606.87\n",
      "sum_4_promo: 5434.70\n",
      "sum_5_promo: 5171.45\n",
      "mean_4_dow6_2017: 4861.65\n",
      "sum_3_promo: 4203.67\n",
      "mean_20_dow4_2017: 3532.94\n",
      "promo_8: 3039.67\n",
      "lag_35_sales: 2655.28\n",
      "mean_4_dow4_2017: 2226.13\n",
      "lag_28_sales: 2103.22\n",
      "std_6_sales: 2085.38\n",
      "lag_7_sales: 2033.04\n",
      "std_5_sales: 2023.75\n",
      "store_state_features: 2011.23\n",
      "lag_63_sales: 1950.41\n",
      "lag_21_sales: 1901.12\n",
      "promo_2: 1894.27\n",
      "sum_6_promo: 1804.14\n",
      "lag_56_sales: 1544.92\n",
      "mean_4_dow3_2017: 1366.21\n",
      "lag_4_sales: 1344.84\n",
      "promo_4: 1328.41\n",
      "std_4_sales: 1299.60\n",
      "mean_4_dow2_2017: 1209.98\n",
      "lag_3_sales: 1046.18\n",
      "lag_5_sales: 992.56\n",
      "mean_4_dow5_2017: 649.36\n",
      "mean_4_dow1_2017: 476.02\n",
      "std_3_sales: 381.89\n",
      "lag_6_sales: 322.61\n",
      "promo_5: 126.18\n",
      "promo_1: 43.70\n",
      "promo_3: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [22:02<01:27, 87.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.957024\tvalid_1's l2: 0.938696\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.902736\tvalid_1's l2: 0.885382\n",
      "[3]\ttraining's l2: 0.853669\tvalid_1's l2: 0.836832\n",
      "[4]\ttraining's l2: 0.80938\tvalid_1's l2: 0.793062\n",
      "[5]\ttraining's l2: 0.769242\tvalid_1's l2: 0.753288\n",
      "[6]\ttraining's l2: 0.732861\tvalid_1's l2: 0.717433\n",
      "[7]\ttraining's l2: 0.700055\tvalid_1's l2: 0.684937\n",
      "[8]\ttraining's l2: 0.670381\tvalid_1's l2: 0.65549\n",
      "[9]\ttraining's l2: 0.644377\tvalid_1's l2: 0.629698\n",
      "[10]\ttraining's l2: 0.619915\tvalid_1's l2: 0.605598\n",
      "[11]\ttraining's l2: 0.597714\tvalid_1's l2: 0.583727\n",
      "[12]\ttraining's l2: 0.577712\tvalid_1's l2: 0.563918\n",
      "[13]\ttraining's l2: 0.559637\tvalid_1's l2: 0.546048\n",
      "[14]\ttraining's l2: 0.543108\tvalid_1's l2: 0.529748\n",
      "[15]\ttraining's l2: 0.52824\tvalid_1's l2: 0.515055\n",
      "[16]\ttraining's l2: 0.514728\tvalid_1's l2: 0.50179\n",
      "[17]\ttraining's l2: 0.502474\tvalid_1's l2: 0.489825\n",
      "[18]\ttraining's l2: 0.491286\tvalid_1's l2: 0.47894\n",
      "[19]\ttraining's l2: 0.481178\tvalid_1's l2: 0.468968\n",
      "[20]\ttraining's l2: 0.472202\tvalid_1's l2: 0.460136\n",
      "[21]\ttraining's l2: 0.463848\tvalid_1's l2: 0.451946\n",
      "[22]\ttraining's l2: 0.456308\tvalid_1's l2: 0.444558\n",
      "[23]\ttraining's l2: 0.449386\tvalid_1's l2: 0.437736\n",
      "[24]\ttraining's l2: 0.443085\tvalid_1's l2: 0.431648\n",
      "[25]\ttraining's l2: 0.437366\tvalid_1's l2: 0.426088\n",
      "[26]\ttraining's l2: 0.432201\tvalid_1's l2: 0.421017\n",
      "[27]\ttraining's l2: 0.427471\tvalid_1's l2: 0.416423\n",
      "[28]\ttraining's l2: 0.423162\tvalid_1's l2: 0.412258\n",
      "[29]\ttraining's l2: 0.419263\tvalid_1's l2: 0.408398\n",
      "[30]\ttraining's l2: 0.415664\tvalid_1's l2: 0.404925\n",
      "[31]\ttraining's l2: 0.412397\tvalid_1's l2: 0.401786\n",
      "[32]\ttraining's l2: 0.409424\tvalid_1's l2: 0.398881\n",
      "[33]\ttraining's l2: 0.406735\tvalid_1's l2: 0.396299\n",
      "[34]\ttraining's l2: 0.40422\tvalid_1's l2: 0.393808\n",
      "[35]\ttraining's l2: 0.401934\tvalid_1's l2: 0.391601\n",
      "[36]\ttraining's l2: 0.399851\tvalid_1's l2: 0.389595\n",
      "[37]\ttraining's l2: 0.397962\tvalid_1's l2: 0.387748\n",
      "[38]\ttraining's l2: 0.396255\tvalid_1's l2: 0.386103\n",
      "[39]\ttraining's l2: 0.394667\tvalid_1's l2: 0.384616\n",
      "[40]\ttraining's l2: 0.393171\tvalid_1's l2: 0.383148\n",
      "[41]\ttraining's l2: 0.391819\tvalid_1's l2: 0.381901\n",
      "[42]\ttraining's l2: 0.39055\tvalid_1's l2: 0.380718\n",
      "[43]\ttraining's l2: 0.389379\tvalid_1's l2: 0.379628\n",
      "[44]\ttraining's l2: 0.388286\tvalid_1's l2: 0.378594\n",
      "[45]\ttraining's l2: 0.387297\tvalid_1's l2: 0.377688\n",
      "[46]\ttraining's l2: 0.386298\tvalid_1's l2: 0.376766\n",
      "[47]\ttraining's l2: 0.38541\tvalid_1's l2: 0.375985\n",
      "[48]\ttraining's l2: 0.384573\tvalid_1's l2: 0.375231\n",
      "[49]\ttraining's l2: 0.38372\tvalid_1's l2: 0.374461\n",
      "[50]\ttraining's l2: 0.383012\tvalid_1's l2: 0.373815\n",
      "[51]\ttraining's l2: 0.38223\tvalid_1's l2: 0.373154\n",
      "[52]\ttraining's l2: 0.381624\tvalid_1's l2: 0.372657\n",
      "[53]\ttraining's l2: 0.38096\tvalid_1's l2: 0.372122\n",
      "[54]\ttraining's l2: 0.380398\tvalid_1's l2: 0.371637\n",
      "[55]\ttraining's l2: 0.379921\tvalid_1's l2: 0.371211\n",
      "[56]\ttraining's l2: 0.379419\tvalid_1's l2: 0.370809\n",
      "[57]\ttraining's l2: 0.379026\tvalid_1's l2: 0.370447\n",
      "[58]\ttraining's l2: 0.378594\tvalid_1's l2: 0.370061\n",
      "[59]\ttraining's l2: 0.378218\tvalid_1's l2: 0.369734\n",
      "[60]\ttraining's l2: 0.377841\tvalid_1's l2: 0.369421\n",
      "[61]\ttraining's l2: 0.377438\tvalid_1's l2: 0.369136\n",
      "[62]\ttraining's l2: 0.377047\tvalid_1's l2: 0.36883\n",
      "[63]\ttraining's l2: 0.376657\tvalid_1's l2: 0.368505\n",
      "[64]\ttraining's l2: 0.376254\tvalid_1's l2: 0.368183\n",
      "[65]\ttraining's l2: 0.375996\tvalid_1's l2: 0.367953\n",
      "[66]\ttraining's l2: 0.375747\tvalid_1's l2: 0.367742\n",
      "[67]\ttraining's l2: 0.375477\tvalid_1's l2: 0.367553\n",
      "[68]\ttraining's l2: 0.375232\tvalid_1's l2: 0.367376\n",
      "[69]\ttraining's l2: 0.374933\tvalid_1's l2: 0.36714\n",
      "[70]\ttraining's l2: 0.374657\tvalid_1's l2: 0.366941\n",
      "[71]\ttraining's l2: 0.374333\tvalid_1's l2: 0.366711\n",
      "[72]\ttraining's l2: 0.374058\tvalid_1's l2: 0.366499\n",
      "[73]\ttraining's l2: 0.373706\tvalid_1's l2: 0.366216\n",
      "[74]\ttraining's l2: 0.37347\tvalid_1's l2: 0.366033\n",
      "[75]\ttraining's l2: 0.37316\tvalid_1's l2: 0.365835\n",
      "[76]\ttraining's l2: 0.372921\tvalid_1's l2: 0.365671\n",
      "[77]\ttraining's l2: 0.372724\tvalid_1's l2: 0.365528\n",
      "[78]\ttraining's l2: 0.372541\tvalid_1's l2: 0.365407\n",
      "[79]\ttraining's l2: 0.372278\tvalid_1's l2: 0.365211\n",
      "[80]\ttraining's l2: 0.37209\tvalid_1's l2: 0.365073\n",
      "[81]\ttraining's l2: 0.371848\tvalid_1's l2: 0.364911\n",
      "[82]\ttraining's l2: 0.371691\tvalid_1's l2: 0.36478\n",
      "[83]\ttraining's l2: 0.371529\tvalid_1's l2: 0.364629\n",
      "[84]\ttraining's l2: 0.371322\tvalid_1's l2: 0.364463\n",
      "[85]\ttraining's l2: 0.371143\tvalid_1's l2: 0.364361\n",
      "[86]\ttraining's l2: 0.371\tvalid_1's l2: 0.364262\n",
      "[87]\ttraining's l2: 0.370894\tvalid_1's l2: 0.364201\n",
      "[88]\ttraining's l2: 0.370754\tvalid_1's l2: 0.36409\n",
      "[89]\ttraining's l2: 0.370554\tvalid_1's l2: 0.363987\n",
      "[90]\ttraining's l2: 0.370357\tvalid_1's l2: 0.363878\n",
      "[91]\ttraining's l2: 0.370195\tvalid_1's l2: 0.363804\n",
      "[92]\ttraining's l2: 0.370096\tvalid_1's l2: 0.363735\n",
      "[93]\ttraining's l2: 0.369991\tvalid_1's l2: 0.363634\n",
      "[94]\ttraining's l2: 0.369881\tvalid_1's l2: 0.363536\n",
      "[95]\ttraining's l2: 0.369798\tvalid_1's l2: 0.363467\n",
      "[96]\ttraining's l2: 0.369679\tvalid_1's l2: 0.363405\n",
      "[97]\ttraining's l2: 0.369562\tvalid_1's l2: 0.363299\n",
      "[98]\ttraining's l2: 0.369452\tvalid_1's l2: 0.363202\n",
      "[99]\ttraining's l2: 0.369339\tvalid_1's l2: 0.363139\n",
      "[100]\ttraining's l2: 0.369133\tvalid_1's l2: 0.363048\n",
      "[101]\ttraining's l2: 0.369029\tvalid_1's l2: 0.362952\n",
      "[102]\ttraining's l2: 0.368936\tvalid_1's l2: 0.362891\n",
      "[103]\ttraining's l2: 0.368742\tvalid_1's l2: 0.362769\n",
      "[104]\ttraining's l2: 0.368677\tvalid_1's l2: 0.3627\n",
      "[105]\ttraining's l2: 0.368492\tvalid_1's l2: 0.362594\n",
      "[106]\ttraining's l2: 0.368325\tvalid_1's l2: 0.362487\n",
      "[107]\ttraining's l2: 0.368232\tvalid_1's l2: 0.362426\n",
      "[108]\ttraining's l2: 0.368153\tvalid_1's l2: 0.362362\n",
      "[109]\ttraining's l2: 0.367999\tvalid_1's l2: 0.362238\n",
      "[110]\ttraining's l2: 0.36789\tvalid_1's l2: 0.36219\n",
      "[111]\ttraining's l2: 0.367788\tvalid_1's l2: 0.362098\n",
      "[112]\ttraining's l2: 0.367698\tvalid_1's l2: 0.362066\n",
      "[113]\ttraining's l2: 0.36763\tvalid_1's l2: 0.362041\n",
      "[114]\ttraining's l2: 0.367497\tvalid_1's l2: 0.361958\n",
      "[115]\ttraining's l2: 0.36735\tvalid_1's l2: 0.361859\n",
      "[116]\ttraining's l2: 0.367274\tvalid_1's l2: 0.361833\n",
      "[117]\ttraining's l2: 0.36717\tvalid_1's l2: 0.361746\n",
      "[118]\ttraining's l2: 0.367105\tvalid_1's l2: 0.361693\n",
      "[119]\ttraining's l2: 0.367031\tvalid_1's l2: 0.361666\n",
      "[120]\ttraining's l2: 0.366887\tvalid_1's l2: 0.361583\n",
      "[121]\ttraining's l2: 0.366781\tvalid_1's l2: 0.361506\n",
      "[122]\ttraining's l2: 0.366736\tvalid_1's l2: 0.361444\n",
      "[123]\ttraining's l2: 0.36664\tvalid_1's l2: 0.361381\n",
      "[124]\ttraining's l2: 0.366591\tvalid_1's l2: 0.361364\n",
      "[125]\ttraining's l2: 0.366479\tvalid_1's l2: 0.36129\n",
      "[126]\ttraining's l2: 0.366431\tvalid_1's l2: 0.361251\n",
      "[127]\ttraining's l2: 0.366379\tvalid_1's l2: 0.361213\n",
      "[128]\ttraining's l2: 0.366328\tvalid_1's l2: 0.361193\n",
      "[129]\ttraining's l2: 0.366271\tvalid_1's l2: 0.361148\n",
      "[130]\ttraining's l2: 0.366177\tvalid_1's l2: 0.361093\n",
      "[131]\ttraining's l2: 0.366132\tvalid_1's l2: 0.361052\n",
      "[132]\ttraining's l2: 0.366082\tvalid_1's l2: 0.361032\n",
      "[133]\ttraining's l2: 0.366043\tvalid_1's l2: 0.361008\n",
      "[134]\ttraining's l2: 0.365977\tvalid_1's l2: 0.360946\n",
      "[135]\ttraining's l2: 0.365914\tvalid_1's l2: 0.360934\n",
      "[136]\ttraining's l2: 0.365819\tvalid_1's l2: 0.360874\n",
      "[137]\ttraining's l2: 0.365739\tvalid_1's l2: 0.360823\n",
      "[138]\ttraining's l2: 0.365658\tvalid_1's l2: 0.360768\n",
      "[139]\ttraining's l2: 0.365613\tvalid_1's l2: 0.360727\n",
      "[140]\ttraining's l2: 0.36553\tvalid_1's l2: 0.360675\n",
      "[141]\ttraining's l2: 0.365457\tvalid_1's l2: 0.360651\n",
      "[142]\ttraining's l2: 0.365341\tvalid_1's l2: 0.360584\n",
      "[143]\ttraining's l2: 0.365222\tvalid_1's l2: 0.36052\n",
      "[144]\ttraining's l2: 0.365174\tvalid_1's l2: 0.360511\n",
      "[145]\ttraining's l2: 0.365096\tvalid_1's l2: 0.360456\n",
      "[146]\ttraining's l2: 0.365055\tvalid_1's l2: 0.360407\n",
      "[147]\ttraining's l2: 0.365005\tvalid_1's l2: 0.360383\n",
      "[148]\ttraining's l2: 0.364963\tvalid_1's l2: 0.360364\n",
      "[149]\ttraining's l2: 0.364873\tvalid_1's l2: 0.360306\n",
      "[150]\ttraining's l2: 0.364823\tvalid_1's l2: 0.360287\n",
      "[151]\ttraining's l2: 0.364767\tvalid_1's l2: 0.360223\n",
      "[152]\ttraining's l2: 0.36472\tvalid_1's l2: 0.360201\n",
      "[153]\ttraining's l2: 0.364671\tvalid_1's l2: 0.360201\n",
      "[154]\ttraining's l2: 0.364609\tvalid_1's l2: 0.360175\n",
      "[155]\ttraining's l2: 0.364574\tvalid_1's l2: 0.360152\n",
      "[156]\ttraining's l2: 0.364492\tvalid_1's l2: 0.360117\n",
      "[157]\ttraining's l2: 0.36443\tvalid_1's l2: 0.360097\n",
      "[158]\ttraining's l2: 0.364329\tvalid_1's l2: 0.360025\n",
      "[159]\ttraining's l2: 0.364292\tvalid_1's l2: 0.35999\n",
      "[160]\ttraining's l2: 0.364254\tvalid_1's l2: 0.359983\n",
      "[161]\ttraining's l2: 0.364202\tvalid_1's l2: 0.359964\n",
      "[162]\ttraining's l2: 0.364166\tvalid_1's l2: 0.359934\n",
      "[163]\ttraining's l2: 0.364114\tvalid_1's l2: 0.359924\n",
      "[164]\ttraining's l2: 0.364084\tvalid_1's l2: 0.359914\n",
      "[165]\ttraining's l2: 0.364055\tvalid_1's l2: 0.359898\n",
      "[166]\ttraining's l2: 0.363992\tvalid_1's l2: 0.359875\n",
      "[167]\ttraining's l2: 0.363957\tvalid_1's l2: 0.359846\n",
      "[168]\ttraining's l2: 0.363911\tvalid_1's l2: 0.359821\n",
      "[169]\ttraining's l2: 0.363874\tvalid_1's l2: 0.359807\n",
      "[170]\ttraining's l2: 0.363829\tvalid_1's l2: 0.359797\n",
      "[171]\ttraining's l2: 0.363781\tvalid_1's l2: 0.359792\n",
      "[172]\ttraining's l2: 0.363734\tvalid_1's l2: 0.359794\n",
      "[173]\ttraining's l2: 0.363698\tvalid_1's l2: 0.359772\n",
      "[174]\ttraining's l2: 0.363653\tvalid_1's l2: 0.359761\n",
      "[175]\ttraining's l2: 0.363626\tvalid_1's l2: 0.359737\n",
      "[176]\ttraining's l2: 0.363584\tvalid_1's l2: 0.35972\n",
      "[177]\ttraining's l2: 0.363526\tvalid_1's l2: 0.359678\n",
      "[178]\ttraining's l2: 0.363486\tvalid_1's l2: 0.359665\n",
      "[179]\ttraining's l2: 0.363401\tvalid_1's l2: 0.359622\n",
      "[180]\ttraining's l2: 0.363362\tvalid_1's l2: 0.359606\n",
      "[181]\ttraining's l2: 0.363306\tvalid_1's l2: 0.359598\n",
      "[182]\ttraining's l2: 0.363277\tvalid_1's l2: 0.359594\n",
      "[183]\ttraining's l2: 0.363212\tvalid_1's l2: 0.359562\n",
      "[184]\ttraining's l2: 0.363166\tvalid_1's l2: 0.359561\n",
      "[185]\ttraining's l2: 0.363137\tvalid_1's l2: 0.359548\n",
      "[186]\ttraining's l2: 0.363113\tvalid_1's l2: 0.359527\n",
      "[187]\ttraining's l2: 0.36307\tvalid_1's l2: 0.35951\n",
      "[188]\ttraining's l2: 0.363044\tvalid_1's l2: 0.359506\n",
      "[189]\ttraining's l2: 0.363013\tvalid_1's l2: 0.359494\n",
      "[190]\ttraining's l2: 0.362974\tvalid_1's l2: 0.359464\n",
      "[191]\ttraining's l2: 0.362942\tvalid_1's l2: 0.359445\n",
      "[192]\ttraining's l2: 0.362905\tvalid_1's l2: 0.35944\n",
      "[193]\ttraining's l2: 0.362823\tvalid_1's l2: 0.359368\n",
      "[194]\ttraining's l2: 0.36279\tvalid_1's l2: 0.359341\n",
      "[195]\ttraining's l2: 0.362767\tvalid_1's l2: 0.359315\n",
      "[196]\ttraining's l2: 0.362729\tvalid_1's l2: 0.359313\n",
      "[197]\ttraining's l2: 0.362695\tvalid_1's l2: 0.35931\n",
      "[198]\ttraining's l2: 0.362644\tvalid_1's l2: 0.359272\n",
      "[199]\ttraining's l2: 0.362621\tvalid_1's l2: 0.359256\n",
      "[200]\ttraining's l2: 0.36258\tvalid_1's l2: 0.359247\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.36258\tvalid_1's l2: 0.359247\n",
      "mean_21_sales: 6560545.33\n",
      "mean_30_sales: 5785205.38\n",
      "mean_14_sales: 2744978.64\n",
      "mean_63_sales: 1233277.48\n",
      "mean_20_dow1_2017: 1121090.66\n",
      "promo_15: 862011.75\n",
      "mean_60_sales: 819243.96\n",
      "mean_7_sales: 754477.12\n",
      "mean_6_sales: 608002.25\n",
      "item_class_features: 340629.00\n",
      "lag_1_sales: 105130.35\n",
      "promo_14: 96655.25\n",
      "std_30_sales: 66925.48\n",
      "mean_20_dow2_2017: 59335.81\n",
      "mean_5_sales: 58112.17\n",
      "mean_4_dow1_2017: 50042.99\n",
      "std_21_sales: 37999.78\n",
      "item_family_features: 36861.62\n",
      "std_63_sales: 35562.69\n",
      "sum_4_promo: 35242.10\n",
      "std_60_sales: 26084.32\n",
      "store_cluster_features: 21043.35\n",
      "sum_6_promo: 20674.72\n",
      "mean_4_sales: 19802.64\n",
      "promo_13: 18101.04\n",
      "sum_2_promo: 17564.58\n",
      "mean_3_sales: 15857.45\n",
      "std_14_sales: 15728.01\n",
      "promo_10: 15718.58\n",
      "sum_14_promo: 15440.44\n",
      "store_city_features: 15324.13\n",
      "sum_21_promo: 15274.03\n",
      "sum_7_promo: 13966.08\n",
      "mean_20_dow0_2017: 13436.03\n",
      "mean_20_dow6_2017: 12499.67\n",
      "lag_14_sales: 11848.93\n",
      "lag_42_sales: 11641.83\n",
      "promo_12: 9320.61\n",
      "lag_49_sales: 9192.01\n",
      "promo_8: 8769.32\n",
      "mean_20_dow3_2017: 8575.39\n",
      "lag_2_sales: 7648.64\n",
      "mean_4_dow6_2017: 7124.42\n",
      "promo_9: 6231.35\n",
      "sum_3_promo: 5812.95\n",
      "std_7_sales: 5805.34\n",
      "promo_7: 4839.88\n",
      "lag_5_sales: 4195.78\n",
      "std_6_sales: 4138.94\n",
      "sum_5_promo: 3898.59\n",
      "mean_20_dow4_2017: 3584.28\n",
      "promo_0: 3262.27\n",
      "lag_6_sales: 2811.79\n",
      "lag_4_sales: 2451.66\n",
      "mean_4_dow0_2017: 2225.39\n",
      "lag_7_sales: 2175.23\n",
      "mean_4_dow2_2017: 2143.05\n",
      "mean_4_dow3_2017: 1985.34\n",
      "mean_4_dow5_2017: 1982.84\n",
      "store_type_features: 1956.04\n",
      "mean_4_dow4_2017: 1922.92\n",
      "std_5_sales: 1846.32\n",
      "promo_11: 1824.93\n",
      "lag_3_sales: 1699.72\n",
      "lag_28_sales: 1671.79\n",
      "std_4_sales: 1562.87\n",
      "promo_6: 1558.92\n",
      "lag_63_sales: 1548.63\n",
      "lag_21_sales: 1306.82\n",
      "mean_20_dow5_2017: 1218.73\n",
      "lag_56_sales: 775.30\n",
      "store_state_features: 572.51\n",
      "lag_35_sales: 500.65\n",
      "promo_5: 491.82\n",
      "promo_1: 475.33\n",
      "promo_2: 418.19\n",
      "std_3_sales: 363.86\n",
      "promo_4: 130.71\n",
      "promo_3: 82.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [23:30<00:00, 87.47s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(16)):\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * nbr_weeks) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "\n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=MAX_ROUNDS,\n",
    "#         verbose_eval = False,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50)\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3498481141075822"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 0.35123858092295934\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "\n",
    "mlflow.set_experiment('grocery forecasting')\n",
    "with mlflow.start_run(run_name='lgbm'):\n",
    "    mlflow.log_param('model', 'lgbm')\n",
    "    mlflow.log_param('train starts', train_start)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param('lagging', LAG_DICT.values())\n",
    "    mlflow.log_param('slidingWindows', SLIDING_DICT.values())\n",
    "    mlflow.log_param('item_info', 'Yes')\n",
    "    mlflow.log_param('store_info', 'Yes')\n",
    "    mlflow.log_param('private score', 0.52193)\n",
    "    mlflow.log_param('private rank', '14%')\n",
    "    mlflow.log_param('public score', 0.51609)\n",
    "\n",
    "    mlflow.log_metric('mse', mse)\n",
    "    \n",
    "print(\"Validation mse:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_train.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
