{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from config import (\n",
    "    RAW_DATA_DIR,\n",
    "    FEATURE_DIR,\n",
    "    LAG_DICT,\n",
    "    SLIDING_DICT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve lightgbm error on MAC\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv(\n",
    "    RAW_DATA_DIR+'train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    RAW_DATA_DIR+'test.csv', usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    RAW_DATA_DIR+'items.csv',\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    RAW_DATA_DIR+'stores.csv',\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Period\n",
    "\n",
    "2017-08-16 to 2017-08-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = date(2017, 8, 16)\n",
    "test_end = date(2017,8, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid starts from 2017-07-26 to 2017-08-10\n"
     ]
    }
   ],
   "source": [
    "valid_start = test_start - timedelta(16)\n",
    "while(1):\n",
    "    if valid_start.weekday() == test_start.weekday():\n",
    "        break\n",
    "    valid_start = valid_start-timedelta(days=1)\n",
    "valid_end = valid_start + timedelta(15)\n",
    "print('valid starts from {} to {}'.format(valid_start, valid_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Period\n",
    "\n",
    "Considering the more nearer peiods of sales data may have more in common, it would be better to find the nearest period as valid period.\n",
    "\n",
    "Based on the analysis before, we assume the sales data is periodically with the frequency of 7 days, so we want to keep that feature same\n",
    "in the train, valid and test period.\n",
    "\n",
    "So finally, we choose valid period:\n",
    "\n",
    "2017-07-26 to 2017-08-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_start = date(2017, 7, 26)\n",
    "valid_end = date(2017, 8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Period\n",
    "\n",
    "#### Earthquake happended on April 16, 2016. It may affect for the next several weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train datasets starts from 2016-10-05\n"
     ]
    }
   ],
   "source": [
    "# filter the period which is affected by earthquake.\n",
    "filter_date = date(2016,4,16) + timedelta(7*4)\n",
    "lag_max = 140\n",
    "train_start=  filter_date+timedelta(days=lag_max)\n",
    "\n",
    "while(1):\n",
    "    train_start = train_start + timedelta(1)\n",
    "    if train_start.weekday() == valid_start.weekday():\n",
    "        break\n",
    "print('train datasets starts from {}'.format(train_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = date(2017, 2, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train[df_train['date']>=filter_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_train = df_train.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]]\n",
    "\n",
    "# missing onpromotions filling\n",
    "promo_train = promo_train.unstack(level=-1).fillna(False)\n",
    "promo_train.columns = promo_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing test onpromotions filling\n",
    "promo_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_test.columns = promo_test.columns.get_level_values(1)\n",
    "# filter those items/stores in promo_test but not in promo_train\n",
    "promo_test = promo_test.reindex(promo_train.index).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_features = pd.concat([promo_train, promo_test], axis=1)\n",
    "del promo_test, promo_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "df_train = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_train.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['family'] = items['family'].astype('category')\n",
    "item_family_features = items.family.cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['class'] = items['class'].astype('category')\n",
    "item_class_features = items['class'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = stores.reindex(df_train.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['city'] = stores['city'].astype('category')\n",
    "store_city_features = stores['city'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['state'] = stores['state'].astype('category')\n",
    "store_state_features = stores['state'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['type'] = stores['type'].astype('category')\n",
    "store_type_features = stores['type'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['cluster'] = stores['cluster'].astype('category')\n",
    "store_cluster_features = stores['cluster'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = df_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = df_train.columns\n",
    "obj_list = pd.date_range(filter_date, test_start-timedelta(1))\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    df_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = promo_features.columns\n",
    "obj_list = pd.date_range(filter_date, test_end)\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    promo_features[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagging and sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG_DICT = {'unit_sales': [1,2,3,4,5,6,7,14,21,28,35,42,49,56,63],\n",
    "            'onpromotion': [2, 3,4,5,6, 7, 14, 21]}\n",
    "\n",
    "SLIDING_DICT = {'unit_sales': [3, 4, 5, 6, 7, 14, 21, 30, 60, 63]}\n",
    "\n",
    "# initialise dirs\n",
    "RAW_DATA_DIR = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, \n",
    "                 start_time,\n",
    "                 minus,\n",
    "                 periods,\n",
    "                 freq='D'):\n",
    "    return df[pd.date_range(start_time - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def gen_dataset(df, \n",
    "                promo_features,\n",
    "                item_family_features,\n",
    "                item_class_features,\n",
    "                store_city_features,\n",
    "                store_state_features,\n",
    "                store_type_features,\n",
    "                store_cluster_features,\n",
    "                start_time,\n",
    "                is_train=True):\n",
    "    # init\n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    for i in LAG_DICT['unit_sales']:\n",
    "        X['lag_{}_sales'.format(i)] = get_timespan(df, start_time, i, 1).values.ravel()\n",
    "    \n",
    "    for i in LAG_DICT['onpromotion']:\n",
    "        X['sum_{}_promo'.format(i)] = get_timespan(promo_features, start_time, i, 1).sum(axis=1).ravel()\n",
    "\n",
    "    for i in SLIDING_DICT['unit_sales']:\n",
    "        X[\"mean_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).mean(axis=1).values\n",
    "        X[\"std_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).std(axis=1).values\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, start_time, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, start_time, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "        \n",
    "    # for the next to-predict 16 days \n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_features[start_time + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X['item_family_features'] = item_family_features\n",
    "\n",
    "    X['item_class_features'] = item_class_features\n",
    "\n",
    "    X['store_city_features'] = store_city_features\n",
    "\n",
    "    X['store_state_features'] = store_state_features\n",
    "\n",
    "    X['store_type_features'] = store_type_features\n",
    "\n",
    "    X['store_cluster_features'] = store_cluster_features\n",
    "        \n",
    "    if is_train:\n",
    "        y = df[pd.date_range(start_time, periods=16)].values\n",
    "        return X, y\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train, valid and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No. of week:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No. of week: 100%|██████████| 16/16 [00:10<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "\n",
    "nbr_weeks = int((valid_start - train_start).days/7)\n",
    "\n",
    "X_l, y_l = [], []\n",
    "\n",
    "for i in tqdm(range(nbr_weeks), desc = 'No. of week'):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = gen_dataset(\n",
    "        df_train,\n",
    "        promo_features,\n",
    "        item_family_features,\n",
    "        item_class_features,\n",
    "        store_city_features,\n",
    "        store_state_features,\n",
    "        store_type_features,\n",
    "        store_cluster_features,\n",
    "        train_start + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_val, y_val = gen_dataset(df_train,\n",
    "                           promo_features,\n",
    "                           item_family_features,\n",
    "                           item_class_features,\n",
    "                           store_city_features,\n",
    "                           store_state_features,\n",
    "                           store_type_features,\n",
    "                           store_cluster_features,\n",
    "                           valid_start)\n",
    "X_test = gen_dataset(df_train, \n",
    "                    promo_features,\n",
    "                    item_family_features,\n",
    "                    item_class_features,\n",
    "                    store_city_features,\n",
    "                    store_state_features,\n",
    "                    store_type_features,\n",
    "                    store_cluster_features,\n",
    "                    test_start, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 200\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = ['item_family_features',\n",
    "            'item_class_features',\n",
    "            'store_city_features',\n",
    "            'store_state_features',\n",
    "            'store_type_features',\n",
    "            'store_cluster_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.04527\tvalid_1's l2: 1.00397\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.977625\tvalid_1's l2: 0.938305\n",
      "[3]\ttraining's l2: 0.915068\tvalid_1's l2: 0.877657\n",
      "[4]\ttraining's l2: 0.859484\tvalid_1's l2: 0.82379\n",
      "[5]\ttraining's l2: 0.807876\tvalid_1's l2: 0.773734\n",
      "[6]\ttraining's l2: 0.761179\tvalid_1's l2: 0.728453\n",
      "[7]\ttraining's l2: 0.718861\tvalid_1's l2: 0.687584\n",
      "[8]\ttraining's l2: 0.680703\tvalid_1's l2: 0.650498\n",
      "[9]\ttraining's l2: 0.646204\tvalid_1's l2: 0.617178\n",
      "[10]\ttraining's l2: 0.614835\tvalid_1's l2: 0.586917\n",
      "[11]\ttraining's l2: 0.586478\tvalid_1's l2: 0.559611\n",
      "[12]\ttraining's l2: 0.561491\tvalid_1's l2: 0.535655\n",
      "[13]\ttraining's l2: 0.538848\tvalid_1's l2: 0.513894\n",
      "[14]\ttraining's l2: 0.517553\tvalid_1's l2: 0.493325\n",
      "[15]\ttraining's l2: 0.498306\tvalid_1's l2: 0.474906\n",
      "[16]\ttraining's l2: 0.480889\tvalid_1's l2: 0.458186\n",
      "[17]\ttraining's l2: 0.465057\tvalid_1's l2: 0.443102\n",
      "[18]\ttraining's l2: 0.450613\tvalid_1's l2: 0.429152\n",
      "[19]\ttraining's l2: 0.437581\tvalid_1's l2: 0.416625\n",
      "[20]\ttraining's l2: 0.425746\tvalid_1's l2: 0.405309\n",
      "[21]\ttraining's l2: 0.415035\tvalid_1's l2: 0.395114\n",
      "[22]\ttraining's l2: 0.405249\tvalid_1's l2: 0.385849\n",
      "[23]\ttraining's l2: 0.396738\tvalid_1's l2: 0.377801\n",
      "[24]\ttraining's l2: 0.388614\tvalid_1's l2: 0.370003\n",
      "[25]\ttraining's l2: 0.381246\tvalid_1's l2: 0.362983\n",
      "[26]\ttraining's l2: 0.374489\tvalid_1's l2: 0.356575\n",
      "[27]\ttraining's l2: 0.36864\tvalid_1's l2: 0.351057\n",
      "[28]\ttraining's l2: 0.363361\tvalid_1's l2: 0.346139\n",
      "[29]\ttraining's l2: 0.358142\tvalid_1's l2: 0.341197\n",
      "[30]\ttraining's l2: 0.353288\tvalid_1's l2: 0.336624\n",
      "[31]\ttraining's l2: 0.348944\tvalid_1's l2: 0.33251\n",
      "[32]\ttraining's l2: 0.344936\tvalid_1's l2: 0.328823\n",
      "[33]\ttraining's l2: 0.341621\tvalid_1's l2: 0.325776\n",
      "[34]\ttraining's l2: 0.338512\tvalid_1's l2: 0.32296\n",
      "[35]\ttraining's l2: 0.335406\tvalid_1's l2: 0.320067\n",
      "[36]\ttraining's l2: 0.332484\tvalid_1's l2: 0.317338\n",
      "[37]\ttraining's l2: 0.329895\tvalid_1's l2: 0.314941\n",
      "[38]\ttraining's l2: 0.327528\tvalid_1's l2: 0.312705\n",
      "[39]\ttraining's l2: 0.325332\tvalid_1's l2: 0.310714\n",
      "[40]\ttraining's l2: 0.323288\tvalid_1's l2: 0.308869\n",
      "[41]\ttraining's l2: 0.3216\tvalid_1's l2: 0.307355\n",
      "[42]\ttraining's l2: 0.319873\tvalid_1's l2: 0.305767\n",
      "[43]\ttraining's l2: 0.318463\tvalid_1's l2: 0.304518\n",
      "[44]\ttraining's l2: 0.317187\tvalid_1's l2: 0.303376\n",
      "[45]\ttraining's l2: 0.31575\tvalid_1's l2: 0.302084\n",
      "[46]\ttraining's l2: 0.314421\tvalid_1's l2: 0.300837\n",
      "[47]\ttraining's l2: 0.313214\tvalid_1's l2: 0.299735\n",
      "[48]\ttraining's l2: 0.312065\tvalid_1's l2: 0.298681\n",
      "[49]\ttraining's l2: 0.31107\tvalid_1's l2: 0.297789\n",
      "[50]\ttraining's l2: 0.310298\tvalid_1's l2: 0.297134\n",
      "[51]\ttraining's l2: 0.30955\tvalid_1's l2: 0.296513\n",
      "[52]\ttraining's l2: 0.308718\tvalid_1's l2: 0.29577\n",
      "[53]\ttraining's l2: 0.307941\tvalid_1's l2: 0.295085\n",
      "[54]\ttraining's l2: 0.307406\tvalid_1's l2: 0.294656\n",
      "[55]\ttraining's l2: 0.306661\tvalid_1's l2: 0.293989\n",
      "[56]\ttraining's l2: 0.305992\tvalid_1's l2: 0.293422\n",
      "[57]\ttraining's l2: 0.305357\tvalid_1's l2: 0.292846\n",
      "[58]\ttraining's l2: 0.304792\tvalid_1's l2: 0.292347\n",
      "[59]\ttraining's l2: 0.30437\tvalid_1's l2: 0.292004\n",
      "[60]\ttraining's l2: 0.303881\tvalid_1's l2: 0.291583\n",
      "[61]\ttraining's l2: 0.303496\tvalid_1's l2: 0.291269\n",
      "[62]\ttraining's l2: 0.30304\tvalid_1's l2: 0.290904\n",
      "[63]\ttraining's l2: 0.302585\tvalid_1's l2: 0.290481\n",
      "[64]\ttraining's l2: 0.302143\tvalid_1's l2: 0.290056\n",
      "[65]\ttraining's l2: 0.301702\tvalid_1's l2: 0.289626\n",
      "[66]\ttraining's l2: 0.301322\tvalid_1's l2: 0.2893\n",
      "[67]\ttraining's l2: 0.300991\tvalid_1's l2: 0.289036\n",
      "[68]\ttraining's l2: 0.300708\tvalid_1's l2: 0.288804\n",
      "[69]\ttraining's l2: 0.300409\tvalid_1's l2: 0.288544\n",
      "[70]\ttraining's l2: 0.30019\tvalid_1's l2: 0.288367\n",
      "[71]\ttraining's l2: 0.299988\tvalid_1's l2: 0.288214\n",
      "[72]\ttraining's l2: 0.299691\tvalid_1's l2: 0.287936\n",
      "[73]\ttraining's l2: 0.299444\tvalid_1's l2: 0.287735\n",
      "[74]\ttraining's l2: 0.299283\tvalid_1's l2: 0.28761\n",
      "[75]\ttraining's l2: 0.299084\tvalid_1's l2: 0.287463\n",
      "[76]\ttraining's l2: 0.298833\tvalid_1's l2: 0.287237\n",
      "[77]\ttraining's l2: 0.298585\tvalid_1's l2: 0.287\n",
      "[78]\ttraining's l2: 0.298389\tvalid_1's l2: 0.286857\n",
      "[79]\ttraining's l2: 0.298151\tvalid_1's l2: 0.28663\n",
      "[80]\ttraining's l2: 0.297921\tvalid_1's l2: 0.28641\n",
      "[81]\ttraining's l2: 0.297749\tvalid_1's l2: 0.286278\n",
      "[82]\ttraining's l2: 0.297557\tvalid_1's l2: 0.286108\n",
      "[83]\ttraining's l2: 0.297438\tvalid_1's l2: 0.286019\n",
      "[84]\ttraining's l2: 0.297326\tvalid_1's l2: 0.285944\n",
      "[85]\ttraining's l2: 0.297206\tvalid_1's l2: 0.285856\n",
      "[86]\ttraining's l2: 0.297062\tvalid_1's l2: 0.285738\n",
      "[87]\ttraining's l2: 0.296944\tvalid_1's l2: 0.285662\n",
      "[88]\ttraining's l2: 0.296824\tvalid_1's l2: 0.285562\n",
      "[89]\ttraining's l2: 0.296601\tvalid_1's l2: 0.285346\n",
      "[90]\ttraining's l2: 0.296493\tvalid_1's l2: 0.285273\n",
      "[91]\ttraining's l2: 0.296295\tvalid_1's l2: 0.285139\n",
      "[92]\ttraining's l2: 0.296112\tvalid_1's l2: 0.284975\n",
      "[93]\ttraining's l2: 0.295979\tvalid_1's l2: 0.284848\n",
      "[94]\ttraining's l2: 0.295886\tvalid_1's l2: 0.284772\n",
      "[95]\ttraining's l2: 0.295717\tvalid_1's l2: 0.284628\n",
      "[96]\ttraining's l2: 0.295617\tvalid_1's l2: 0.284526\n",
      "[97]\ttraining's l2: 0.295548\tvalid_1's l2: 0.284482\n",
      "[98]\ttraining's l2: 0.295466\tvalid_1's l2: 0.284416\n",
      "[99]\ttraining's l2: 0.29532\tvalid_1's l2: 0.28429\n",
      "[100]\ttraining's l2: 0.295243\tvalid_1's l2: 0.284234\n",
      "[101]\ttraining's l2: 0.295094\tvalid_1's l2: 0.284101\n",
      "[102]\ttraining's l2: 0.29503\tvalid_1's l2: 0.284065\n",
      "[103]\ttraining's l2: 0.294978\tvalid_1's l2: 0.284026\n",
      "[104]\ttraining's l2: 0.294902\tvalid_1's l2: 0.283952\n",
      "[105]\ttraining's l2: 0.294777\tvalid_1's l2: 0.283867\n",
      "[106]\ttraining's l2: 0.294663\tvalid_1's l2: 0.283779\n",
      "[107]\ttraining's l2: 0.294586\tvalid_1's l2: 0.283726\n",
      "[108]\ttraining's l2: 0.294469\tvalid_1's l2: 0.283647\n",
      "[109]\ttraining's l2: 0.294419\tvalid_1's l2: 0.283619\n",
      "[110]\ttraining's l2: 0.294356\tvalid_1's l2: 0.283577\n",
      "[111]\ttraining's l2: 0.294295\tvalid_1's l2: 0.283526\n",
      "[112]\ttraining's l2: 0.294228\tvalid_1's l2: 0.283501\n",
      "[113]\ttraining's l2: 0.294121\tvalid_1's l2: 0.283437\n",
      "[114]\ttraining's l2: 0.294067\tvalid_1's l2: 0.283407\n",
      "[115]\ttraining's l2: 0.294021\tvalid_1's l2: 0.283377\n",
      "[116]\ttraining's l2: 0.29393\tvalid_1's l2: 0.283345\n",
      "[117]\ttraining's l2: 0.293874\tvalid_1's l2: 0.283299\n",
      "[118]\ttraining's l2: 0.293774\tvalid_1's l2: 0.283219\n",
      "[119]\ttraining's l2: 0.293683\tvalid_1's l2: 0.283143\n",
      "[120]\ttraining's l2: 0.293597\tvalid_1's l2: 0.283067\n",
      "[121]\ttraining's l2: 0.293546\tvalid_1's l2: 0.283027\n",
      "[122]\ttraining's l2: 0.293477\tvalid_1's l2: 0.282983\n",
      "[123]\ttraining's l2: 0.293393\tvalid_1's l2: 0.282932\n",
      "[124]\ttraining's l2: 0.293331\tvalid_1's l2: 0.2829\n",
      "[125]\ttraining's l2: 0.293292\tvalid_1's l2: 0.282881\n",
      "[126]\ttraining's l2: 0.293246\tvalid_1's l2: 0.282852\n",
      "[127]\ttraining's l2: 0.293164\tvalid_1's l2: 0.282777\n",
      "[128]\ttraining's l2: 0.293094\tvalid_1's l2: 0.28274\n",
      "[129]\ttraining's l2: 0.29305\tvalid_1's l2: 0.282698\n",
      "[130]\ttraining's l2: 0.292999\tvalid_1's l2: 0.282666\n",
      "[131]\ttraining's l2: 0.292915\tvalid_1's l2: 0.282615\n",
      "[132]\ttraining's l2: 0.292874\tvalid_1's l2: 0.28259\n",
      "[133]\ttraining's l2: 0.292823\tvalid_1's l2: 0.282554\n",
      "[134]\ttraining's l2: 0.292789\tvalid_1's l2: 0.28253\n",
      "[135]\ttraining's l2: 0.292739\tvalid_1's l2: 0.282503\n",
      "[136]\ttraining's l2: 0.292703\tvalid_1's l2: 0.282478\n",
      "[137]\ttraining's l2: 0.292635\tvalid_1's l2: 0.282427\n",
      "[138]\ttraining's l2: 0.292577\tvalid_1's l2: 0.282388\n",
      "[139]\ttraining's l2: 0.292522\tvalid_1's l2: 0.282358\n",
      "[140]\ttraining's l2: 0.292489\tvalid_1's l2: 0.282335\n",
      "[141]\ttraining's l2: 0.292425\tvalid_1's l2: 0.282295\n",
      "[142]\ttraining's l2: 0.292373\tvalid_1's l2: 0.282267\n",
      "[143]\ttraining's l2: 0.292323\tvalid_1's l2: 0.282244\n",
      "[144]\ttraining's l2: 0.292276\tvalid_1's l2: 0.282217\n",
      "[145]\ttraining's l2: 0.292245\tvalid_1's l2: 0.282193\n",
      "[146]\ttraining's l2: 0.292188\tvalid_1's l2: 0.282127\n",
      "[147]\ttraining's l2: 0.292142\tvalid_1's l2: 0.282114\n",
      "[148]\ttraining's l2: 0.29209\tvalid_1's l2: 0.2821\n",
      "[149]\ttraining's l2: 0.292035\tvalid_1's l2: 0.282073\n",
      "[150]\ttraining's l2: 0.291979\tvalid_1's l2: 0.282034\n",
      "[151]\ttraining's l2: 0.291929\tvalid_1's l2: 0.281987\n",
      "[152]\ttraining's l2: 0.291874\tvalid_1's l2: 0.281956\n",
      "[153]\ttraining's l2: 0.291829\tvalid_1's l2: 0.281929\n",
      "[154]\ttraining's l2: 0.291791\tvalid_1's l2: 0.281896\n",
      "[155]\ttraining's l2: 0.291736\tvalid_1's l2: 0.281879\n",
      "[156]\ttraining's l2: 0.291695\tvalid_1's l2: 0.281868\n",
      "[157]\ttraining's l2: 0.291643\tvalid_1's l2: 0.281851\n",
      "[158]\ttraining's l2: 0.291584\tvalid_1's l2: 0.281827\n",
      "[159]\ttraining's l2: 0.291554\tvalid_1's l2: 0.281804\n",
      "[160]\ttraining's l2: 0.291505\tvalid_1's l2: 0.281774\n",
      "[161]\ttraining's l2: 0.291463\tvalid_1's l2: 0.281743\n",
      "[162]\ttraining's l2: 0.291414\tvalid_1's l2: 0.281719\n",
      "[163]\ttraining's l2: 0.291367\tvalid_1's l2: 0.281693\n",
      "[164]\ttraining's l2: 0.291324\tvalid_1's l2: 0.281659\n",
      "[165]\ttraining's l2: 0.291274\tvalid_1's l2: 0.281618\n",
      "[166]\ttraining's l2: 0.29124\tvalid_1's l2: 0.281599\n",
      "[167]\ttraining's l2: 0.291195\tvalid_1's l2: 0.281566\n",
      "[168]\ttraining's l2: 0.291172\tvalid_1's l2: 0.281556\n",
      "[169]\ttraining's l2: 0.291106\tvalid_1's l2: 0.281503\n",
      "[170]\ttraining's l2: 0.291064\tvalid_1's l2: 0.281478\n",
      "[171]\ttraining's l2: 0.291032\tvalid_1's l2: 0.281462\n",
      "[172]\ttraining's l2: 0.290993\tvalid_1's l2: 0.281442\n",
      "[173]\ttraining's l2: 0.290938\tvalid_1's l2: 0.281409\n",
      "[174]\ttraining's l2: 0.290899\tvalid_1's l2: 0.281383\n",
      "[175]\ttraining's l2: 0.290871\tvalid_1's l2: 0.281377\n",
      "[176]\ttraining's l2: 0.290832\tvalid_1's l2: 0.281362\n",
      "[177]\ttraining's l2: 0.290786\tvalid_1's l2: 0.281318\n",
      "[178]\ttraining's l2: 0.290745\tvalid_1's l2: 0.281293\n",
      "[179]\ttraining's l2: 0.290708\tvalid_1's l2: 0.281276\n",
      "[180]\ttraining's l2: 0.290678\tvalid_1's l2: 0.281261\n",
      "[181]\ttraining's l2: 0.290644\tvalid_1's l2: 0.281256\n",
      "[182]\ttraining's l2: 0.290611\tvalid_1's l2: 0.281237\n",
      "[183]\ttraining's l2: 0.290578\tvalid_1's l2: 0.281227\n",
      "[184]\ttraining's l2: 0.290546\tvalid_1's l2: 0.281203\n",
      "[185]\ttraining's l2: 0.290514\tvalid_1's l2: 0.281184\n",
      "[186]\ttraining's l2: 0.290489\tvalid_1's l2: 0.281165\n",
      "[187]\ttraining's l2: 0.290456\tvalid_1's l2: 0.281149\n",
      "[188]\ttraining's l2: 0.290422\tvalid_1's l2: 0.281134\n",
      "[189]\ttraining's l2: 0.2904\tvalid_1's l2: 0.281121\n",
      "[190]\ttraining's l2: 0.29037\tvalid_1's l2: 0.281093\n",
      "[191]\ttraining's l2: 0.290332\tvalid_1's l2: 0.281061\n",
      "[192]\ttraining's l2: 0.290304\tvalid_1's l2: 0.281057\n",
      "[193]\ttraining's l2: 0.290274\tvalid_1's l2: 0.281035\n",
      "[194]\ttraining's l2: 0.290238\tvalid_1's l2: 0.281003\n",
      "[195]\ttraining's l2: 0.290211\tvalid_1's l2: 0.280977\n",
      "[196]\ttraining's l2: 0.290182\tvalid_1's l2: 0.280953\n",
      "[197]\ttraining's l2: 0.290146\tvalid_1's l2: 0.280946\n",
      "[198]\ttraining's l2: 0.290117\tvalid_1's l2: 0.280932\n",
      "[199]\ttraining's l2: 0.290081\tvalid_1's l2: 0.280927\n",
      "[200]\ttraining's l2: 0.290057\tvalid_1's l2: 0.280916\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.290057\tvalid_1's l2: 0.280916\n",
      "mean_7_sales: 9591365.06\n",
      "mean_14_sales: 5132410.21\n",
      "lag_1_sales: 520079.96\n",
      "promo_0: 510311.16\n",
      "mean_5_sales: 415781.67\n",
      "mean_20_dow0_2017: 395561.48\n",
      "mean_3_sales: 307382.11\n",
      "mean_4_dow0_2017: 230111.18\n",
      "mean_30_sales: 229266.55\n",
      "mean_6_sales: 152167.50\n",
      "mean_21_sales: 134979.23\n",
      "item_class_features: 127545.44\n",
      "mean_63_sales: 99312.16\n",
      "sum_7_promo: 91395.36\n",
      "std_14_sales: 80056.22\n",
      "store_cluster_features: 47263.38\n",
      "sum_2_promo: 35618.98\n",
      "item_family_features: 31297.95\n",
      "sum_4_promo: 29859.04\n",
      "std_7_sales: 27389.69\n",
      "lag_2_sales: 26642.86\n",
      "promo_7: 23698.62\n",
      "mean_4_dow6_2017: 22972.16\n",
      "sum_14_promo: 21135.20\n",
      "lag_14_sales: 19567.79\n",
      "mean_4_sales: 19040.30\n",
      "std_21_sales: 18422.51\n",
      "lag_63_sales: 14773.05\n",
      "store_type_features: 13032.64\n",
      "std_30_sales: 12514.41\n",
      "std_63_sales: 12446.63\n",
      "lag_35_sales: 11371.83\n",
      "std_6_sales: 10442.52\n",
      "mean_60_sales: 9726.83\n",
      "sum_3_promo: 8863.33\n",
      "sum_21_promo: 7779.21\n",
      "std_5_sales: 7625.47\n",
      "store_city_features: 5818.95\n",
      "std_60_sales: 5680.62\n",
      "lag_28_sales: 5112.65\n",
      "promo_14: 4927.02\n",
      "lag_7_sales: 4778.14\n",
      "mean_20_dow2_2017: 4649.46\n",
      "promo_3: 4576.19\n",
      "std_3_sales: 4443.55\n",
      "lag_3_sales: 4374.53\n",
      "mean_4_dow5_2017: 4272.54\n",
      "mean_20_dow1_2017: 3869.03\n",
      "mean_20_dow4_2017: 3657.20\n",
      "promo_1: 2468.04\n",
      "sum_5_promo: 2442.64\n",
      "mean_20_dow3_2017: 2434.95\n",
      "std_4_sales: 2339.69\n",
      "lag_42_sales: 2310.05\n",
      "lag_4_sales: 2261.68\n",
      "lag_5_sales: 2203.33\n",
      "lag_49_sales: 2036.84\n",
      "promo_13: 1681.83\n",
      "mean_20_dow6_2017: 1520.53\n",
      "lag_56_sales: 1482.53\n",
      "promo_6: 1403.62\n",
      "sum_6_promo: 1294.40\n",
      "mean_4_dow2_2017: 1161.41\n",
      "promo_5: 1155.79\n",
      "lag_21_sales: 1085.02\n",
      "promo_4: 1076.64\n",
      "mean_4_dow3_2017: 991.24\n",
      "mean_20_dow5_2017: 905.65\n",
      "lag_6_sales: 896.19\n",
      "store_state_features: 750.98\n",
      "mean_4_dow1_2017: 739.50\n",
      "mean_4_dow4_2017: 640.21\n",
      "promo_9: 515.68\n",
      "promo_8: 346.13\n",
      "promo_15: 265.02\n",
      "promo_10: 225.49\n",
      "promo_2: 173.45\n",
      "promo_11: 130.03\n",
      "promo_12: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [01:15<18:55, 75.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.943767\tvalid_1's l2: 0.92528\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.886554\tvalid_1's l2: 0.869257\n",
      "[3]\ttraining's l2: 0.834857\tvalid_1's l2: 0.818485\n",
      "[4]\ttraining's l2: 0.787832\tvalid_1's l2: 0.77227\n",
      "[5]\ttraining's l2: 0.745386\tvalid_1's l2: 0.730549\n",
      "[6]\ttraining's l2: 0.707661\tvalid_1's l2: 0.693672\n",
      "[7]\ttraining's l2: 0.672799\tvalid_1's l2: 0.659269\n",
      "[8]\ttraining's l2: 0.641954\tvalid_1's l2: 0.628939\n",
      "[9]\ttraining's l2: 0.61359\tvalid_1's l2: 0.601086\n",
      "[10]\ttraining's l2: 0.587667\tvalid_1's l2: 0.575659\n",
      "[11]\ttraining's l2: 0.564615\tvalid_1's l2: 0.553139\n",
      "[12]\ttraining's l2: 0.543306\tvalid_1's l2: 0.532076\n",
      "[13]\ttraining's l2: 0.524002\tvalid_1's l2: 0.513121\n",
      "[14]\ttraining's l2: 0.506913\tvalid_1's l2: 0.496404\n",
      "[15]\ttraining's l2: 0.490965\tvalid_1's l2: 0.480794\n",
      "[16]\ttraining's l2: 0.476592\tvalid_1's l2: 0.466728\n",
      "[17]\ttraining's l2: 0.463545\tvalid_1's l2: 0.453943\n",
      "[18]\ttraining's l2: 0.45172\tvalid_1's l2: 0.442382\n",
      "[19]\ttraining's l2: 0.44095\tvalid_1's l2: 0.431824\n",
      "[20]\ttraining's l2: 0.431477\tvalid_1's l2: 0.42269\n",
      "[21]\ttraining's l2: 0.422586\tvalid_1's l2: 0.413979\n",
      "[22]\ttraining's l2: 0.414526\tvalid_1's l2: 0.406034\n",
      "[23]\ttraining's l2: 0.407476\tvalid_1's l2: 0.399256\n",
      "[24]\ttraining's l2: 0.400792\tvalid_1's l2: 0.392695\n",
      "[25]\ttraining's l2: 0.394729\tvalid_1's l2: 0.386789\n",
      "[26]\ttraining's l2: 0.389277\tvalid_1's l2: 0.381414\n",
      "[27]\ttraining's l2: 0.384246\tvalid_1's l2: 0.376434\n",
      "[28]\ttraining's l2: 0.379713\tvalid_1's l2: 0.371962\n",
      "[29]\ttraining's l2: 0.375632\tvalid_1's l2: 0.367925\n",
      "[30]\ttraining's l2: 0.371872\tvalid_1's l2: 0.364208\n",
      "[31]\ttraining's l2: 0.368429\tvalid_1's l2: 0.360822\n",
      "[32]\ttraining's l2: 0.365261\tvalid_1's l2: 0.357653\n",
      "[33]\ttraining's l2: 0.362465\tvalid_1's l2: 0.354933\n",
      "[34]\ttraining's l2: 0.35996\tvalid_1's l2: 0.352588\n",
      "[35]\ttraining's l2: 0.357547\tvalid_1's l2: 0.350154\n",
      "[36]\ttraining's l2: 0.355368\tvalid_1's l2: 0.348039\n",
      "[37]\ttraining's l2: 0.35338\tvalid_1's l2: 0.346099\n",
      "[38]\ttraining's l2: 0.351632\tvalid_1's l2: 0.344461\n",
      "[39]\ttraining's l2: 0.349862\tvalid_1's l2: 0.342671\n",
      "[40]\ttraining's l2: 0.348228\tvalid_1's l2: 0.341099\n",
      "[41]\ttraining's l2: 0.346766\tvalid_1's l2: 0.339655\n",
      "[42]\ttraining's l2: 0.345413\tvalid_1's l2: 0.338358\n",
      "[43]\ttraining's l2: 0.34422\tvalid_1's l2: 0.337237\n",
      "[44]\ttraining's l2: 0.343095\tvalid_1's l2: 0.336184\n",
      "[45]\ttraining's l2: 0.342044\tvalid_1's l2: 0.335217\n",
      "[46]\ttraining's l2: 0.341175\tvalid_1's l2: 0.334437\n",
      "[47]\ttraining's l2: 0.340337\tvalid_1's l2: 0.333706\n",
      "[48]\ttraining's l2: 0.33947\tvalid_1's l2: 0.332848\n",
      "[49]\ttraining's l2: 0.338649\tvalid_1's l2: 0.332081\n",
      "[50]\ttraining's l2: 0.337899\tvalid_1's l2: 0.331337\n",
      "[51]\ttraining's l2: 0.33726\tvalid_1's l2: 0.330795\n",
      "[52]\ttraining's l2: 0.336642\tvalid_1's l2: 0.330215\n",
      "[53]\ttraining's l2: 0.336026\tvalid_1's l2: 0.329597\n",
      "[54]\ttraining's l2: 0.335451\tvalid_1's l2: 0.329009\n",
      "[55]\ttraining's l2: 0.334938\tvalid_1's l2: 0.328513\n",
      "[56]\ttraining's l2: 0.334404\tvalid_1's l2: 0.328019\n",
      "[57]\ttraining's l2: 0.333955\tvalid_1's l2: 0.327561\n",
      "[58]\ttraining's l2: 0.333514\tvalid_1's l2: 0.327127\n",
      "[59]\ttraining's l2: 0.333095\tvalid_1's l2: 0.326713\n",
      "[60]\ttraining's l2: 0.332674\tvalid_1's l2: 0.326333\n",
      "[61]\ttraining's l2: 0.332309\tvalid_1's l2: 0.325978\n",
      "[62]\ttraining's l2: 0.331914\tvalid_1's l2: 0.325597\n",
      "[63]\ttraining's l2: 0.331583\tvalid_1's l2: 0.325235\n",
      "[64]\ttraining's l2: 0.331262\tvalid_1's l2: 0.324879\n",
      "[65]\ttraining's l2: 0.330968\tvalid_1's l2: 0.324603\n",
      "[66]\ttraining's l2: 0.330703\tvalid_1's l2: 0.324383\n",
      "[67]\ttraining's l2: 0.330416\tvalid_1's l2: 0.324131\n",
      "[68]\ttraining's l2: 0.330144\tvalid_1's l2: 0.323893\n",
      "[69]\ttraining's l2: 0.329909\tvalid_1's l2: 0.323721\n",
      "[70]\ttraining's l2: 0.329652\tvalid_1's l2: 0.323501\n",
      "[71]\ttraining's l2: 0.329377\tvalid_1's l2: 0.32322\n",
      "[72]\ttraining's l2: 0.329177\tvalid_1's l2: 0.323038\n",
      "[73]\ttraining's l2: 0.328928\tvalid_1's l2: 0.322764\n",
      "[74]\ttraining's l2: 0.328751\tvalid_1's l2: 0.322648\n",
      "[75]\ttraining's l2: 0.328556\tvalid_1's l2: 0.322466\n",
      "[76]\ttraining's l2: 0.328363\tvalid_1's l2: 0.322323\n",
      "[77]\ttraining's l2: 0.328156\tvalid_1's l2: 0.322094\n",
      "[78]\ttraining's l2: 0.327958\tvalid_1's l2: 0.321875\n",
      "[79]\ttraining's l2: 0.327783\tvalid_1's l2: 0.321731\n",
      "[80]\ttraining's l2: 0.327597\tvalid_1's l2: 0.321528\n",
      "[81]\ttraining's l2: 0.327413\tvalid_1's l2: 0.321301\n",
      "[82]\ttraining's l2: 0.327239\tvalid_1's l2: 0.321106\n",
      "[83]\ttraining's l2: 0.327094\tvalid_1's l2: 0.321011\n",
      "[84]\ttraining's l2: 0.326928\tvalid_1's l2: 0.320869\n",
      "[85]\ttraining's l2: 0.326781\tvalid_1's l2: 0.320694\n",
      "[86]\ttraining's l2: 0.326642\tvalid_1's l2: 0.320568\n",
      "[87]\ttraining's l2: 0.326499\tvalid_1's l2: 0.320456\n",
      "[88]\ttraining's l2: 0.326369\tvalid_1's l2: 0.320336\n",
      "[89]\ttraining's l2: 0.326236\tvalid_1's l2: 0.320222\n",
      "[90]\ttraining's l2: 0.326129\tvalid_1's l2: 0.320147\n",
      "[91]\ttraining's l2: 0.325992\tvalid_1's l2: 0.319978\n",
      "[92]\ttraining's l2: 0.325861\tvalid_1's l2: 0.319844\n",
      "[93]\ttraining's l2: 0.325737\tvalid_1's l2: 0.319735\n",
      "[94]\ttraining's l2: 0.325634\tvalid_1's l2: 0.319624\n",
      "[95]\ttraining's l2: 0.325517\tvalid_1's l2: 0.319504\n",
      "[96]\ttraining's l2: 0.325395\tvalid_1's l2: 0.319393\n",
      "[97]\ttraining's l2: 0.325304\tvalid_1's l2: 0.319282\n",
      "[98]\ttraining's l2: 0.325211\tvalid_1's l2: 0.319187\n",
      "[99]\ttraining's l2: 0.325132\tvalid_1's l2: 0.319151\n",
      "[100]\ttraining's l2: 0.325027\tvalid_1's l2: 0.319045\n",
      "[101]\ttraining's l2: 0.324951\tvalid_1's l2: 0.318989\n",
      "[102]\ttraining's l2: 0.324853\tvalid_1's l2: 0.318959\n",
      "[103]\ttraining's l2: 0.324769\tvalid_1's l2: 0.318901\n",
      "[104]\ttraining's l2: 0.32469\tvalid_1's l2: 0.318812\n",
      "[105]\ttraining's l2: 0.32461\tvalid_1's l2: 0.31876\n",
      "[106]\ttraining's l2: 0.32454\tvalid_1's l2: 0.318716\n",
      "[107]\ttraining's l2: 0.324476\tvalid_1's l2: 0.318669\n",
      "[108]\ttraining's l2: 0.324379\tvalid_1's l2: 0.318583\n",
      "[109]\ttraining's l2: 0.324313\tvalid_1's l2: 0.318547\n",
      "[110]\ttraining's l2: 0.324244\tvalid_1's l2: 0.318468\n",
      "[111]\ttraining's l2: 0.324164\tvalid_1's l2: 0.318401\n",
      "[112]\ttraining's l2: 0.324104\tvalid_1's l2: 0.318352\n",
      "[113]\ttraining's l2: 0.324038\tvalid_1's l2: 0.318324\n",
      "[114]\ttraining's l2: 0.323981\tvalid_1's l2: 0.31828\n",
      "[115]\ttraining's l2: 0.323901\tvalid_1's l2: 0.318213\n",
      "[116]\ttraining's l2: 0.323825\tvalid_1's l2: 0.318175\n",
      "[117]\ttraining's l2: 0.323766\tvalid_1's l2: 0.318122\n",
      "[118]\ttraining's l2: 0.32369\tvalid_1's l2: 0.318046\n",
      "[119]\ttraining's l2: 0.323622\tvalid_1's l2: 0.317978\n",
      "[120]\ttraining's l2: 0.32352\tvalid_1's l2: 0.317889\n",
      "[121]\ttraining's l2: 0.323468\tvalid_1's l2: 0.317869\n",
      "[122]\ttraining's l2: 0.323391\tvalid_1's l2: 0.317794\n",
      "[123]\ttraining's l2: 0.323318\tvalid_1's l2: 0.317765\n",
      "[124]\ttraining's l2: 0.323266\tvalid_1's l2: 0.317756\n",
      "[125]\ttraining's l2: 0.323196\tvalid_1's l2: 0.31772\n",
      "[126]\ttraining's l2: 0.323122\tvalid_1's l2: 0.317633\n",
      "[127]\ttraining's l2: 0.323011\tvalid_1's l2: 0.317508\n",
      "[128]\ttraining's l2: 0.322973\tvalid_1's l2: 0.317482\n",
      "[129]\ttraining's l2: 0.322918\tvalid_1's l2: 0.317457\n",
      "[130]\ttraining's l2: 0.322874\tvalid_1's l2: 0.317435\n",
      "[131]\ttraining's l2: 0.322765\tvalid_1's l2: 0.317351\n",
      "[132]\ttraining's l2: 0.32271\tvalid_1's l2: 0.317341\n",
      "[133]\ttraining's l2: 0.322662\tvalid_1's l2: 0.317315\n",
      "[134]\ttraining's l2: 0.322626\tvalid_1's l2: 0.3173\n",
      "[135]\ttraining's l2: 0.322583\tvalid_1's l2: 0.317286\n",
      "[136]\ttraining's l2: 0.322531\tvalid_1's l2: 0.317251\n",
      "[137]\ttraining's l2: 0.322477\tvalid_1's l2: 0.317222\n",
      "[138]\ttraining's l2: 0.322406\tvalid_1's l2: 0.317136\n",
      "[139]\ttraining's l2: 0.322352\tvalid_1's l2: 0.317097\n",
      "[140]\ttraining's l2: 0.322278\tvalid_1's l2: 0.317013\n",
      "[141]\ttraining's l2: 0.322211\tvalid_1's l2: 0.31694\n",
      "[142]\ttraining's l2: 0.322172\tvalid_1's l2: 0.316922\n",
      "[143]\ttraining's l2: 0.322112\tvalid_1's l2: 0.316851\n",
      "[144]\ttraining's l2: 0.322073\tvalid_1's l2: 0.316836\n",
      "[145]\ttraining's l2: 0.322032\tvalid_1's l2: 0.316804\n",
      "[146]\ttraining's l2: 0.321991\tvalid_1's l2: 0.316781\n",
      "[147]\ttraining's l2: 0.321923\tvalid_1's l2: 0.316705\n",
      "[148]\ttraining's l2: 0.321886\tvalid_1's l2: 0.316686\n",
      "[149]\ttraining's l2: 0.321822\tvalid_1's l2: 0.316661\n",
      "[150]\ttraining's l2: 0.32179\tvalid_1's l2: 0.316653\n",
      "[151]\ttraining's l2: 0.321754\tvalid_1's l2: 0.316643\n",
      "[152]\ttraining's l2: 0.321701\tvalid_1's l2: 0.316608\n",
      "[153]\ttraining's l2: 0.321653\tvalid_1's l2: 0.316587\n",
      "[154]\ttraining's l2: 0.32161\tvalid_1's l2: 0.316576\n",
      "[155]\ttraining's l2: 0.321574\tvalid_1's l2: 0.31656\n",
      "[156]\ttraining's l2: 0.321545\tvalid_1's l2: 0.316553\n",
      "[157]\ttraining's l2: 0.321503\tvalid_1's l2: 0.316529\n",
      "[158]\ttraining's l2: 0.321434\tvalid_1's l2: 0.316488\n",
      "[159]\ttraining's l2: 0.321374\tvalid_1's l2: 0.316431\n",
      "[160]\ttraining's l2: 0.321328\tvalid_1's l2: 0.316411\n",
      "[161]\ttraining's l2: 0.321282\tvalid_1's l2: 0.316388\n",
      "[162]\ttraining's l2: 0.32124\tvalid_1's l2: 0.316365\n",
      "[163]\ttraining's l2: 0.32119\tvalid_1's l2: 0.316328\n",
      "[164]\ttraining's l2: 0.321149\tvalid_1's l2: 0.316307\n",
      "[165]\ttraining's l2: 0.321114\tvalid_1's l2: 0.316296\n",
      "[166]\ttraining's l2: 0.321061\tvalid_1's l2: 0.316257\n",
      "[167]\ttraining's l2: 0.321015\tvalid_1's l2: 0.316218\n",
      "[168]\ttraining's l2: 0.320971\tvalid_1's l2: 0.316204\n",
      "[169]\ttraining's l2: 0.320934\tvalid_1's l2: 0.316184\n",
      "[170]\ttraining's l2: 0.320887\tvalid_1's l2: 0.316139\n",
      "[171]\ttraining's l2: 0.320854\tvalid_1's l2: 0.31613\n",
      "[172]\ttraining's l2: 0.32081\tvalid_1's l2: 0.316091\n",
      "[173]\ttraining's l2: 0.320768\tvalid_1's l2: 0.316042\n",
      "[174]\ttraining's l2: 0.320725\tvalid_1's l2: 0.316028\n",
      "[175]\ttraining's l2: 0.320698\tvalid_1's l2: 0.316012\n",
      "[176]\ttraining's l2: 0.32065\tvalid_1's l2: 0.315999\n",
      "[177]\ttraining's l2: 0.320618\tvalid_1's l2: 0.315979\n",
      "[178]\ttraining's l2: 0.320592\tvalid_1's l2: 0.31597\n",
      "[179]\ttraining's l2: 0.320559\tvalid_1's l2: 0.315962\n",
      "[180]\ttraining's l2: 0.320538\tvalid_1's l2: 0.315945\n",
      "[181]\ttraining's l2: 0.32051\tvalid_1's l2: 0.315932\n",
      "[182]\ttraining's l2: 0.320467\tvalid_1's l2: 0.315871\n",
      "[183]\ttraining's l2: 0.320432\tvalid_1's l2: 0.315857\n",
      "[184]\ttraining's l2: 0.320399\tvalid_1's l2: 0.315843\n",
      "[185]\ttraining's l2: 0.320362\tvalid_1's l2: 0.315806\n",
      "[186]\ttraining's l2: 0.320338\tvalid_1's l2: 0.315797\n",
      "[187]\ttraining's l2: 0.320308\tvalid_1's l2: 0.315785\n",
      "[188]\ttraining's l2: 0.320277\tvalid_1's l2: 0.315775\n",
      "[189]\ttraining's l2: 0.320255\tvalid_1's l2: 0.31576\n",
      "[190]\ttraining's l2: 0.320226\tvalid_1's l2: 0.315743\n",
      "[191]\ttraining's l2: 0.320195\tvalid_1's l2: 0.315725\n",
      "[192]\ttraining's l2: 0.320168\tvalid_1's l2: 0.315712\n",
      "[193]\ttraining's l2: 0.320142\tvalid_1's l2: 0.315689\n",
      "[194]\ttraining's l2: 0.320111\tvalid_1's l2: 0.315672\n",
      "[195]\ttraining's l2: 0.320084\tvalid_1's l2: 0.31566\n",
      "[196]\ttraining's l2: 0.320045\tvalid_1's l2: 0.315638\n",
      "[197]\ttraining's l2: 0.320021\tvalid_1's l2: 0.315629\n",
      "[198]\ttraining's l2: 0.319998\tvalid_1's l2: 0.315613\n",
      "[199]\ttraining's l2: 0.319968\tvalid_1's l2: 0.315602\n",
      "[200]\ttraining's l2: 0.319931\tvalid_1's l2: 0.315599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.319931\tvalid_1's l2: 0.315599\n",
      "mean_14_sales: 5783868.13\n",
      "mean_7_sales: 5131592.97\n",
      "mean_6_sales: 1995964.89\n",
      "mean_30_sales: 442257.30\n",
      "mean_20_dow1_2017: 329431.12\n",
      "promo_1: 303010.61\n",
      "mean_21_sales: 199190.36\n",
      "lag_1_sales: 177138.25\n",
      "item_class_features: 130637.74\n",
      "mean_63_sales: 129687.09\n",
      "mean_5_sales: 95648.90\n",
      "mean_4_dow1_2017: 62534.53\n",
      "std_14_sales: 48468.15\n",
      "mean_60_sales: 39795.27\n",
      "sum_2_promo: 39584.23\n",
      "mean_3_sales: 38860.93\n",
      "sum_4_promo: 36187.53\n",
      "sum_6_promo: 24970.81\n",
      "mean_20_dow2_2017: 24749.59\n",
      "promo_0: 23450.69\n",
      "promo_3: 18035.12\n",
      "mean_4_dow6_2017: 16140.82\n",
      "std_30_sales: 14339.84\n",
      "store_city_features: 12906.76\n",
      "std_21_sales: 11688.98\n",
      "mean_4_sales: 10597.38\n",
      "mean_4_dow2_2017: 9983.04\n",
      "store_cluster_features: 9310.48\n",
      "lag_28_sales: 9122.76\n",
      "promo_4: 8925.91\n",
      "std_7_sales: 8543.39\n",
      "sum_7_promo: 8362.56\n",
      "promo_7: 8198.62\n",
      "promo_2: 7749.86\n",
      "lag_2_sales: 7637.71\n",
      "lag_5_sales: 7269.53\n",
      "item_family_features: 6976.12\n",
      "std_60_sales: 6934.95\n",
      "std_63_sales: 6832.76\n",
      "promo_5: 6698.89\n",
      "std_6_sales: 6513.29\n",
      "sum_3_promo: 6058.26\n",
      "lag_6_sales: 5177.19\n",
      "sum_14_promo: 4586.20\n",
      "mean_20_dow0_2017: 4503.31\n",
      "mean_20_dow4_2017: 3654.15\n",
      "promo_6: 3176.04\n",
      "mean_20_dow3_2017: 3042.61\n",
      "sum_5_promo: 2687.17\n",
      "sum_21_promo: 2624.20\n",
      "std_4_sales: 2507.41\n",
      "promo_14: 1938.74\n",
      "lag_3_sales: 1937.49\n",
      "lag_14_sales: 1902.68\n",
      "lag_4_sales: 1792.73\n",
      "std_5_sales: 1786.53\n",
      "lag_42_sales: 1726.19\n",
      "mean_20_dow6_2017: 1504.76\n",
      "mean_4_dow4_2017: 1423.06\n",
      "store_type_features: 1323.59\n",
      "lag_7_sales: 1123.77\n",
      "lag_56_sales: 1090.96\n",
      "lag_63_sales: 1051.67\n",
      "std_3_sales: 1014.43\n",
      "promo_8: 989.93\n",
      "mean_4_dow5_2017: 695.97\n",
      "mean_4_dow0_2017: 598.92\n",
      "mean_20_dow5_2017: 469.76\n",
      "store_state_features: 413.36\n",
      "promo_15: 399.62\n",
      "mean_4_dow3_2017: 293.30\n",
      "lag_35_sales: 267.13\n",
      "lag_21_sales: 249.97\n",
      "promo_12: 237.55\n",
      "promo_9: 224.43\n",
      "promo_13: 127.77\n",
      "lag_49_sales: 125.92\n",
      "promo_11: 41.52\n",
      "promo_10: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [02:23<17:05, 73.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05193\tvalid_1's l2: 1.06005\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.986159\tvalid_1's l2: 0.994185\n",
      "[3]\ttraining's l2: 0.927303\tvalid_1's l2: 0.935074\n",
      "[4]\ttraining's l2: 0.872793\tvalid_1's l2: 0.8803\n",
      "[5]\ttraining's l2: 0.823647\tvalid_1's l2: 0.830858\n",
      "[6]\ttraining's l2: 0.780024\tvalid_1's l2: 0.78703\n",
      "[7]\ttraining's l2: 0.739567\tvalid_1's l2: 0.746389\n",
      "[8]\ttraining's l2: 0.702908\tvalid_1's l2: 0.709601\n",
      "[9]\ttraining's l2: 0.669646\tvalid_1's l2: 0.67621\n",
      "[10]\ttraining's l2: 0.640211\tvalid_1's l2: 0.646507\n",
      "[11]\ttraining's l2: 0.612694\tvalid_1's l2: 0.618847\n",
      "[12]\ttraining's l2: 0.587884\tvalid_1's l2: 0.59401\n",
      "[13]\ttraining's l2: 0.565365\tvalid_1's l2: 0.571236\n",
      "[14]\ttraining's l2: 0.544873\tvalid_1's l2: 0.550452\n",
      "[15]\ttraining's l2: 0.526853\tvalid_1's l2: 0.532223\n",
      "[16]\ttraining's l2: 0.510602\tvalid_1's l2: 0.515827\n",
      "[17]\ttraining's l2: 0.495211\tvalid_1's l2: 0.500299\n",
      "[18]\ttraining's l2: 0.481183\tvalid_1's l2: 0.486166\n",
      "[19]\ttraining's l2: 0.468477\tvalid_1's l2: 0.473288\n",
      "[20]\ttraining's l2: 0.456949\tvalid_1's l2: 0.461614\n",
      "[21]\ttraining's l2: 0.446937\tvalid_1's l2: 0.451438\n",
      "[22]\ttraining's l2: 0.437525\tvalid_1's l2: 0.441826\n",
      "[23]\ttraining's l2: 0.428832\tvalid_1's l2: 0.433007\n",
      "[24]\ttraining's l2: 0.420908\tvalid_1's l2: 0.424978\n",
      "[25]\ttraining's l2: 0.41403\tvalid_1's l2: 0.41802\n",
      "[26]\ttraining's l2: 0.407492\tvalid_1's l2: 0.411407\n",
      "[27]\ttraining's l2: 0.401837\tvalid_1's l2: 0.405666\n",
      "[28]\ttraining's l2: 0.396274\tvalid_1's l2: 0.399943\n",
      "[29]\ttraining's l2: 0.39157\tvalid_1's l2: 0.39512\n",
      "[30]\ttraining's l2: 0.387299\tvalid_1's l2: 0.390757\n",
      "[31]\ttraining's l2: 0.383011\tvalid_1's l2: 0.386371\n",
      "[32]\ttraining's l2: 0.379035\tvalid_1's l2: 0.382333\n",
      "[33]\ttraining's l2: 0.375449\tvalid_1's l2: 0.378655\n",
      "[34]\ttraining's l2: 0.372171\tvalid_1's l2: 0.375366\n",
      "[35]\ttraining's l2: 0.369257\tvalid_1's l2: 0.372354\n",
      "[36]\ttraining's l2: 0.36654\tvalid_1's l2: 0.369568\n",
      "[37]\ttraining's l2: 0.364069\tvalid_1's l2: 0.367044\n",
      "[38]\ttraining's l2: 0.361795\tvalid_1's l2: 0.364722\n",
      "[39]\ttraining's l2: 0.359699\tvalid_1's l2: 0.362587\n",
      "[40]\ttraining's l2: 0.35776\tvalid_1's l2: 0.360652\n",
      "[41]\ttraining's l2: 0.356022\tvalid_1's l2: 0.358937\n",
      "[42]\ttraining's l2: 0.354415\tvalid_1's l2: 0.357288\n",
      "[43]\ttraining's l2: 0.353013\tvalid_1's l2: 0.355877\n",
      "[44]\ttraining's l2: 0.351601\tvalid_1's l2: 0.354467\n",
      "[45]\ttraining's l2: 0.350318\tvalid_1's l2: 0.353171\n",
      "[46]\ttraining's l2: 0.349118\tvalid_1's l2: 0.351928\n",
      "[47]\ttraining's l2: 0.348083\tvalid_1's l2: 0.350901\n",
      "[48]\ttraining's l2: 0.347119\tvalid_1's l2: 0.349957\n",
      "[49]\ttraining's l2: 0.346146\tvalid_1's l2: 0.348962\n",
      "[50]\ttraining's l2: 0.345173\tvalid_1's l2: 0.347957\n",
      "[51]\ttraining's l2: 0.344259\tvalid_1's l2: 0.347102\n",
      "[52]\ttraining's l2: 0.343394\tvalid_1's l2: 0.346243\n",
      "[53]\ttraining's l2: 0.342589\tvalid_1's l2: 0.345391\n",
      "[54]\ttraining's l2: 0.341948\tvalid_1's l2: 0.344768\n",
      "[55]\ttraining's l2: 0.341252\tvalid_1's l2: 0.344056\n",
      "[56]\ttraining's l2: 0.340664\tvalid_1's l2: 0.343463\n",
      "[57]\ttraining's l2: 0.339979\tvalid_1's l2: 0.342776\n",
      "[58]\ttraining's l2: 0.339364\tvalid_1's l2: 0.342205\n",
      "[59]\ttraining's l2: 0.338846\tvalid_1's l2: 0.341712\n",
      "[60]\ttraining's l2: 0.338403\tvalid_1's l2: 0.341311\n",
      "[61]\ttraining's l2: 0.337871\tvalid_1's l2: 0.340812\n",
      "[62]\ttraining's l2: 0.337364\tvalid_1's l2: 0.340413\n",
      "[63]\ttraining's l2: 0.336997\tvalid_1's l2: 0.340035\n",
      "[64]\ttraining's l2: 0.33663\tvalid_1's l2: 0.339629\n",
      "[65]\ttraining's l2: 0.336141\tvalid_1's l2: 0.339201\n",
      "[66]\ttraining's l2: 0.335738\tvalid_1's l2: 0.338819\n",
      "[67]\ttraining's l2: 0.335409\tvalid_1's l2: 0.338533\n",
      "[68]\ttraining's l2: 0.335097\tvalid_1's l2: 0.338274\n",
      "[69]\ttraining's l2: 0.334741\tvalid_1's l2: 0.338005\n",
      "[70]\ttraining's l2: 0.334398\tvalid_1's l2: 0.337692\n",
      "[71]\ttraining's l2: 0.334034\tvalid_1's l2: 0.337319\n",
      "[72]\ttraining's l2: 0.333661\tvalid_1's l2: 0.336953\n",
      "[73]\ttraining's l2: 0.333419\tvalid_1's l2: 0.336759\n",
      "[74]\ttraining's l2: 0.333176\tvalid_1's l2: 0.336579\n",
      "[75]\ttraining's l2: 0.332939\tvalid_1's l2: 0.336386\n",
      "[76]\ttraining's l2: 0.332614\tvalid_1's l2: 0.336074\n",
      "[77]\ttraining's l2: 0.33236\tvalid_1's l2: 0.335883\n",
      "[78]\ttraining's l2: 0.332107\tvalid_1's l2: 0.335732\n",
      "[79]\ttraining's l2: 0.331873\tvalid_1's l2: 0.335534\n",
      "[80]\ttraining's l2: 0.331639\tvalid_1's l2: 0.335339\n",
      "[81]\ttraining's l2: 0.331402\tvalid_1's l2: 0.335107\n",
      "[82]\ttraining's l2: 0.331208\tvalid_1's l2: 0.334943\n",
      "[83]\ttraining's l2: 0.330996\tvalid_1's l2: 0.334799\n",
      "[84]\ttraining's l2: 0.330807\tvalid_1's l2: 0.334657\n",
      "[85]\ttraining's l2: 0.330624\tvalid_1's l2: 0.33448\n",
      "[86]\ttraining's l2: 0.330427\tvalid_1's l2: 0.334327\n",
      "[87]\ttraining's l2: 0.330245\tvalid_1's l2: 0.334203\n",
      "[88]\ttraining's l2: 0.330101\tvalid_1's l2: 0.334049\n",
      "[89]\ttraining's l2: 0.329932\tvalid_1's l2: 0.333944\n",
      "[90]\ttraining's l2: 0.329685\tvalid_1's l2: 0.333719\n",
      "[91]\ttraining's l2: 0.329564\tvalid_1's l2: 0.333644\n",
      "[92]\ttraining's l2: 0.329356\tvalid_1's l2: 0.333385\n",
      "[93]\ttraining's l2: 0.329223\tvalid_1's l2: 0.333252\n",
      "[94]\ttraining's l2: 0.329081\tvalid_1's l2: 0.333173\n",
      "[95]\ttraining's l2: 0.328924\tvalid_1's l2: 0.332989\n",
      "[96]\ttraining's l2: 0.328737\tvalid_1's l2: 0.332872\n",
      "[97]\ttraining's l2: 0.328588\tvalid_1's l2: 0.332746\n",
      "[98]\ttraining's l2: 0.328457\tvalid_1's l2: 0.332675\n",
      "[99]\ttraining's l2: 0.328361\tvalid_1's l2: 0.332596\n",
      "[100]\ttraining's l2: 0.328221\tvalid_1's l2: 0.33252\n",
      "[101]\ttraining's l2: 0.328082\tvalid_1's l2: 0.332284\n",
      "[102]\ttraining's l2: 0.327947\tvalid_1's l2: 0.332193\n",
      "[103]\ttraining's l2: 0.327828\tvalid_1's l2: 0.33208\n",
      "[104]\ttraining's l2: 0.327722\tvalid_1's l2: 0.331987\n",
      "[105]\ttraining's l2: 0.327578\tvalid_1's l2: 0.331901\n",
      "[106]\ttraining's l2: 0.327473\tvalid_1's l2: 0.331819\n",
      "[107]\ttraining's l2: 0.327357\tvalid_1's l2: 0.331732\n",
      "[108]\ttraining's l2: 0.327237\tvalid_1's l2: 0.331647\n",
      "[109]\ttraining's l2: 0.327082\tvalid_1's l2: 0.331553\n",
      "[110]\ttraining's l2: 0.327\tvalid_1's l2: 0.331506\n",
      "[111]\ttraining's l2: 0.326883\tvalid_1's l2: 0.331382\n",
      "[112]\ttraining's l2: 0.326782\tvalid_1's l2: 0.331336\n",
      "[113]\ttraining's l2: 0.326695\tvalid_1's l2: 0.331286\n",
      "[114]\ttraining's l2: 0.32662\tvalid_1's l2: 0.331232\n",
      "[115]\ttraining's l2: 0.326539\tvalid_1's l2: 0.331164\n",
      "[116]\ttraining's l2: 0.326461\tvalid_1's l2: 0.331156\n",
      "[117]\ttraining's l2: 0.326366\tvalid_1's l2: 0.331075\n",
      "[118]\ttraining's l2: 0.326262\tvalid_1's l2: 0.331039\n",
      "[119]\ttraining's l2: 0.32618\tvalid_1's l2: 0.330989\n",
      "[120]\ttraining's l2: 0.326118\tvalid_1's l2: 0.330942\n",
      "[121]\ttraining's l2: 0.326045\tvalid_1's l2: 0.330901\n",
      "[122]\ttraining's l2: 0.325963\tvalid_1's l2: 0.330878\n",
      "[123]\ttraining's l2: 0.325882\tvalid_1's l2: 0.330802\n",
      "[124]\ttraining's l2: 0.325814\tvalid_1's l2: 0.330732\n",
      "[125]\ttraining's l2: 0.325702\tvalid_1's l2: 0.330674\n",
      "[126]\ttraining's l2: 0.325622\tvalid_1's l2: 0.330573\n",
      "[127]\ttraining's l2: 0.325564\tvalid_1's l2: 0.330534\n",
      "[128]\ttraining's l2: 0.325503\tvalid_1's l2: 0.330505\n",
      "[129]\ttraining's l2: 0.325422\tvalid_1's l2: 0.33045\n",
      "[130]\ttraining's l2: 0.325358\tvalid_1's l2: 0.330409\n",
      "[131]\ttraining's l2: 0.325297\tvalid_1's l2: 0.330343\n",
      "[132]\ttraining's l2: 0.32521\tvalid_1's l2: 0.330296\n",
      "[133]\ttraining's l2: 0.325162\tvalid_1's l2: 0.330282\n",
      "[134]\ttraining's l2: 0.325087\tvalid_1's l2: 0.330266\n",
      "[135]\ttraining's l2: 0.324991\tvalid_1's l2: 0.330234\n",
      "[136]\ttraining's l2: 0.324928\tvalid_1's l2: 0.330176\n",
      "[137]\ttraining's l2: 0.324843\tvalid_1's l2: 0.330167\n",
      "[138]\ttraining's l2: 0.324794\tvalid_1's l2: 0.330156\n",
      "[139]\ttraining's l2: 0.324751\tvalid_1's l2: 0.330132\n",
      "[140]\ttraining's l2: 0.324688\tvalid_1's l2: 0.330081\n",
      "[141]\ttraining's l2: 0.324629\tvalid_1's l2: 0.33007\n",
      "[142]\ttraining's l2: 0.324555\tvalid_1's l2: 0.330084\n",
      "[143]\ttraining's l2: 0.324514\tvalid_1's l2: 0.33006\n",
      "[144]\ttraining's l2: 0.324433\tvalid_1's l2: 0.330028\n",
      "[145]\ttraining's l2: 0.324392\tvalid_1's l2: 0.329998\n",
      "[146]\ttraining's l2: 0.324326\tvalid_1's l2: 0.329925\n",
      "[147]\ttraining's l2: 0.324259\tvalid_1's l2: 0.329896\n",
      "[148]\ttraining's l2: 0.324218\tvalid_1's l2: 0.32989\n",
      "[149]\ttraining's l2: 0.324169\tvalid_1's l2: 0.329888\n",
      "[150]\ttraining's l2: 0.324094\tvalid_1's l2: 0.329882\n",
      "[151]\ttraining's l2: 0.324032\tvalid_1's l2: 0.32975\n",
      "[152]\ttraining's l2: 0.323967\tvalid_1's l2: 0.329724\n",
      "[153]\ttraining's l2: 0.323922\tvalid_1's l2: 0.329716\n",
      "[154]\ttraining's l2: 0.323874\tvalid_1's l2: 0.329695\n",
      "[155]\ttraining's l2: 0.323828\tvalid_1's l2: 0.329674\n",
      "[156]\ttraining's l2: 0.3238\tvalid_1's l2: 0.329676\n",
      "[157]\ttraining's l2: 0.32373\tvalid_1's l2: 0.329648\n",
      "[158]\ttraining's l2: 0.323697\tvalid_1's l2: 0.329624\n",
      "[159]\ttraining's l2: 0.323662\tvalid_1's l2: 0.329596\n",
      "[160]\ttraining's l2: 0.323614\tvalid_1's l2: 0.329576\n",
      "[161]\ttraining's l2: 0.323563\tvalid_1's l2: 0.329523\n",
      "[162]\ttraining's l2: 0.323526\tvalid_1's l2: 0.329503\n",
      "[163]\ttraining's l2: 0.323468\tvalid_1's l2: 0.329456\n",
      "[164]\ttraining's l2: 0.323407\tvalid_1's l2: 0.329426\n",
      "[165]\ttraining's l2: 0.323349\tvalid_1's l2: 0.329389\n",
      "[166]\ttraining's l2: 0.323304\tvalid_1's l2: 0.329373\n",
      "[167]\ttraining's l2: 0.323239\tvalid_1's l2: 0.329369\n",
      "[168]\ttraining's l2: 0.323198\tvalid_1's l2: 0.329349\n",
      "[169]\ttraining's l2: 0.323158\tvalid_1's l2: 0.329333\n",
      "[170]\ttraining's l2: 0.323097\tvalid_1's l2: 0.32933\n",
      "[171]\ttraining's l2: 0.323036\tvalid_1's l2: 0.329262\n",
      "[172]\ttraining's l2: 0.323004\tvalid_1's l2: 0.329249\n",
      "[173]\ttraining's l2: 0.32297\tvalid_1's l2: 0.329146\n",
      "[174]\ttraining's l2: 0.322921\tvalid_1's l2: 0.329119\n",
      "[175]\ttraining's l2: 0.322897\tvalid_1's l2: 0.329106\n",
      "[176]\ttraining's l2: 0.322856\tvalid_1's l2: 0.329086\n",
      "[177]\ttraining's l2: 0.322793\tvalid_1's l2: 0.32905\n",
      "[178]\ttraining's l2: 0.322763\tvalid_1's l2: 0.329036\n",
      "[179]\ttraining's l2: 0.322714\tvalid_1's l2: 0.329036\n",
      "[180]\ttraining's l2: 0.32269\tvalid_1's l2: 0.329025\n",
      "[181]\ttraining's l2: 0.322639\tvalid_1's l2: 0.329001\n",
      "[182]\ttraining's l2: 0.322603\tvalid_1's l2: 0.328965\n",
      "[183]\ttraining's l2: 0.322567\tvalid_1's l2: 0.328961\n",
      "[184]\ttraining's l2: 0.322514\tvalid_1's l2: 0.329005\n",
      "[185]\ttraining's l2: 0.322475\tvalid_1's l2: 0.32896\n",
      "[186]\ttraining's l2: 0.322444\tvalid_1's l2: 0.328947\n",
      "[187]\ttraining's l2: 0.322392\tvalid_1's l2: 0.328938\n",
      "[188]\ttraining's l2: 0.322363\tvalid_1's l2: 0.328926\n",
      "[189]\ttraining's l2: 0.322325\tvalid_1's l2: 0.328906\n",
      "[190]\ttraining's l2: 0.322289\tvalid_1's l2: 0.328904\n",
      "[191]\ttraining's l2: 0.322243\tvalid_1's l2: 0.328922\n",
      "[192]\ttraining's l2: 0.322208\tvalid_1's l2: 0.32893\n",
      "[193]\ttraining's l2: 0.322168\tvalid_1's l2: 0.328942\n",
      "[194]\ttraining's l2: 0.322125\tvalid_1's l2: 0.328916\n",
      "[195]\ttraining's l2: 0.322093\tvalid_1's l2: 0.328881\n",
      "[196]\ttraining's l2: 0.322057\tvalid_1's l2: 0.328878\n",
      "[197]\ttraining's l2: 0.322034\tvalid_1's l2: 0.32887\n",
      "[198]\ttraining's l2: 0.322006\tvalid_1's l2: 0.32886\n",
      "[199]\ttraining's l2: 0.321974\tvalid_1's l2: 0.328844\n",
      "[200]\ttraining's l2: 0.321934\tvalid_1's l2: 0.328827\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.321934\tvalid_1's l2: 0.328827\n",
      "mean_14_sales: 6529810.85\n",
      "mean_7_sales: 5146704.48\n",
      "mean_6_sales: 957650.58\n",
      "mean_21_sales: 932963.68\n",
      "mean_20_dow2_2017: 923898.26\n",
      "mean_4_dow2_2017: 717276.14\n",
      "mean_30_sales: 681523.53\n",
      "mean_5_sales: 523540.54\n",
      "promo_2: 453584.25\n",
      "item_class_features: 249350.58\n",
      "sum_5_promo: 90985.76\n",
      "std_14_sales: 53402.40\n",
      "lag_1_sales: 47527.65\n",
      "mean_63_sales: 42730.07\n",
      "item_family_features: 41024.20\n",
      "std_21_sales: 40592.74\n",
      "store_cluster_features: 40209.83\n",
      "lag_5_sales: 37845.65\n",
      "std_30_sales: 25585.07\n",
      "promo_3: 24702.87\n",
      "std_7_sales: 23515.38\n",
      "mean_3_sales: 23347.72\n",
      "mean_20_dow1_2017: 18992.90\n",
      "std_63_sales: 17721.11\n",
      "sum_2_promo: 16617.46\n",
      "sum_4_promo: 16288.04\n",
      "promo_5: 14646.32\n",
      "promo_7: 14572.86\n",
      "store_city_features: 13479.68\n",
      "promo_4: 12110.21\n",
      "promo_0: 12034.19\n",
      "mean_4_sales: 11773.04\n",
      "std_6_sales: 11301.03\n",
      "lag_28_sales: 9801.43\n",
      "std_60_sales: 9573.84\n",
      "mean_60_sales: 8949.41\n",
      "store_type_features: 8362.05\n",
      "std_5_sales: 7863.74\n",
      "mean_20_dow0_2017: 6826.38\n",
      "sum_7_promo: 6079.49\n",
      "mean_4_dow3_2017: 5854.91\n",
      "mean_4_dow1_2017: 5778.43\n",
      "promo_9: 5565.99\n",
      "sum_3_promo: 5544.30\n",
      "mean_20_dow3_2017: 5528.48\n",
      "sum_14_promo: 5377.76\n",
      "promo_1: 5001.54\n",
      "promo_14: 4492.19\n",
      "lag_4_sales: 4473.91\n",
      "promo_6: 3722.59\n",
      "sum_21_promo: 3116.76\n",
      "mean_20_dow4_2017: 2461.33\n",
      "lag_6_sales: 2357.50\n",
      "sum_6_promo: 2125.51\n",
      "lag_56_sales: 1925.58\n",
      "mean_20_dow6_2017: 1881.22\n",
      "mean_4_dow0_2017: 1873.45\n",
      "lag_7_sales: 1718.82\n",
      "mean_20_dow5_2017: 1700.61\n",
      "std_4_sales: 1617.78\n",
      "lag_3_sales: 1376.99\n",
      "lag_21_sales: 1337.14\n",
      "lag_2_sales: 1190.53\n",
      "promo_12: 1146.71\n",
      "promo_8: 1122.44\n",
      "mean_4_dow6_2017: 1070.21\n",
      "std_3_sales: 812.16\n",
      "promo_13: 809.77\n",
      "mean_4_dow4_2017: 740.25\n",
      "store_state_features: 681.76\n",
      "lag_14_sales: 593.45\n",
      "lag_63_sales: 522.42\n",
      "promo_11: 345.55\n",
      "promo_10: 336.11\n",
      "lag_42_sales: 312.60\n",
      "mean_4_dow5_2017: 279.66\n",
      "promo_15: 267.59\n",
      "lag_35_sales: 122.78\n",
      "lag_49_sales: 39.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [03:24<15:03, 69.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.17381\tvalid_1's l2: 1.16028\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.09721\tvalid_1's l2: 1.08448\n",
      "[3]\ttraining's l2: 1.02873\tvalid_1's l2: 1.01673\n",
      "[4]\ttraining's l2: 0.965834\tvalid_1's l2: 0.954472\n",
      "[5]\ttraining's l2: 0.909126\tvalid_1's l2: 0.898394\n",
      "[6]\ttraining's l2: 0.857752\tvalid_1's l2: 0.847654\n",
      "[7]\ttraining's l2: 0.811711\tvalid_1's l2: 0.802138\n",
      "[8]\ttraining's l2: 0.770037\tvalid_1's l2: 0.761114\n",
      "[9]\ttraining's l2: 0.731893\tvalid_1's l2: 0.723452\n",
      "[10]\ttraining's l2: 0.697175\tvalid_1's l2: 0.689199\n",
      "[11]\ttraining's l2: 0.665888\tvalid_1's l2: 0.658405\n",
      "[12]\ttraining's l2: 0.637568\tvalid_1's l2: 0.630485\n",
      "[13]\ttraining's l2: 0.611825\tvalid_1's l2: 0.60498\n",
      "[14]\ttraining's l2: 0.588494\tvalid_1's l2: 0.581986\n",
      "[15]\ttraining's l2: 0.567411\tvalid_1's l2: 0.561115\n",
      "[16]\ttraining's l2: 0.548245\tvalid_1's l2: 0.542063\n",
      "[17]\ttraining's l2: 0.531084\tvalid_1's l2: 0.525276\n",
      "[18]\ttraining's l2: 0.515286\tvalid_1's l2: 0.509686\n",
      "[19]\ttraining's l2: 0.501042\tvalid_1's l2: 0.495628\n",
      "[20]\ttraining's l2: 0.488185\tvalid_1's l2: 0.482932\n",
      "[21]\ttraining's l2: 0.476577\tvalid_1's l2: 0.471598\n",
      "[22]\ttraining's l2: 0.466179\tvalid_1's l2: 0.461333\n",
      "[23]\ttraining's l2: 0.456346\tvalid_1's l2: 0.451646\n",
      "[24]\ttraining's l2: 0.447562\tvalid_1's l2: 0.442971\n",
      "[25]\ttraining's l2: 0.43944\tvalid_1's l2: 0.43484\n",
      "[26]\ttraining's l2: 0.432296\tvalid_1's l2: 0.427869\n",
      "[27]\ttraining's l2: 0.425592\tvalid_1's l2: 0.421195\n",
      "[28]\ttraining's l2: 0.419547\tvalid_1's l2: 0.415125\n",
      "[29]\ttraining's l2: 0.414214\tvalid_1's l2: 0.409934\n",
      "[30]\ttraining's l2: 0.409196\tvalid_1's l2: 0.405043\n",
      "[31]\ttraining's l2: 0.404672\tvalid_1's l2: 0.400515\n",
      "[32]\ttraining's l2: 0.400557\tvalid_1's l2: 0.396543\n",
      "[33]\ttraining's l2: 0.396699\tvalid_1's l2: 0.39272\n",
      "[34]\ttraining's l2: 0.393374\tvalid_1's l2: 0.389508\n",
      "[35]\ttraining's l2: 0.390149\tvalid_1's l2: 0.38628\n",
      "[36]\ttraining's l2: 0.387218\tvalid_1's l2: 0.383304\n",
      "[37]\ttraining's l2: 0.384652\tvalid_1's l2: 0.380799\n",
      "[38]\ttraining's l2: 0.382219\tvalid_1's l2: 0.378388\n",
      "[39]\ttraining's l2: 0.380096\tvalid_1's l2: 0.376371\n",
      "[40]\ttraining's l2: 0.378102\tvalid_1's l2: 0.374485\n",
      "[41]\ttraining's l2: 0.376217\tvalid_1's l2: 0.372606\n",
      "[42]\ttraining's l2: 0.374472\tvalid_1's l2: 0.37092\n",
      "[43]\ttraining's l2: 0.372951\tvalid_1's l2: 0.369502\n",
      "[44]\ttraining's l2: 0.371419\tvalid_1's l2: 0.367942\n",
      "[45]\ttraining's l2: 0.369996\tvalid_1's l2: 0.366467\n",
      "[46]\ttraining's l2: 0.368739\tvalid_1's l2: 0.365191\n",
      "[47]\ttraining's l2: 0.36758\tvalid_1's l2: 0.364045\n",
      "[48]\ttraining's l2: 0.366557\tvalid_1's l2: 0.363146\n",
      "[49]\ttraining's l2: 0.365517\tvalid_1's l2: 0.362137\n",
      "[50]\ttraining's l2: 0.364565\tvalid_1's l2: 0.361232\n",
      "[51]\ttraining's l2: 0.363669\tvalid_1's l2: 0.360311\n",
      "[52]\ttraining's l2: 0.362797\tvalid_1's l2: 0.359344\n",
      "[53]\ttraining's l2: 0.362028\tvalid_1's l2: 0.358587\n",
      "[54]\ttraining's l2: 0.361279\tvalid_1's l2: 0.35783\n",
      "[55]\ttraining's l2: 0.360676\tvalid_1's l2: 0.3573\n",
      "[56]\ttraining's l2: 0.360008\tvalid_1's l2: 0.356641\n",
      "[57]\ttraining's l2: 0.359436\tvalid_1's l2: 0.356096\n",
      "[58]\ttraining's l2: 0.358896\tvalid_1's l2: 0.355593\n",
      "[59]\ttraining's l2: 0.358413\tvalid_1's l2: 0.355124\n",
      "[60]\ttraining's l2: 0.357941\tvalid_1's l2: 0.354703\n",
      "[61]\ttraining's l2: 0.357477\tvalid_1's l2: 0.354258\n",
      "[62]\ttraining's l2: 0.357038\tvalid_1's l2: 0.353851\n",
      "[63]\ttraining's l2: 0.35665\tvalid_1's l2: 0.353478\n",
      "[64]\ttraining's l2: 0.356269\tvalid_1's l2: 0.353135\n",
      "[65]\ttraining's l2: 0.355908\tvalid_1's l2: 0.35282\n",
      "[66]\ttraining's l2: 0.355578\tvalid_1's l2: 0.352577\n",
      "[67]\ttraining's l2: 0.355245\tvalid_1's l2: 0.352314\n",
      "[68]\ttraining's l2: 0.354853\tvalid_1's l2: 0.351939\n",
      "[69]\ttraining's l2: 0.35455\tvalid_1's l2: 0.351704\n",
      "[70]\ttraining's l2: 0.354242\tvalid_1's l2: 0.351433\n",
      "[71]\ttraining's l2: 0.353968\tvalid_1's l2: 0.351203\n",
      "[72]\ttraining's l2: 0.35369\tvalid_1's l2: 0.350955\n",
      "[73]\ttraining's l2: 0.353391\tvalid_1's l2: 0.350645\n",
      "[74]\ttraining's l2: 0.353113\tvalid_1's l2: 0.350401\n",
      "[75]\ttraining's l2: 0.352866\tvalid_1's l2: 0.350249\n",
      "[76]\ttraining's l2: 0.352562\tvalid_1's l2: 0.34992\n",
      "[77]\ttraining's l2: 0.352348\tvalid_1's l2: 0.349714\n",
      "[78]\ttraining's l2: 0.352111\tvalid_1's l2: 0.349546\n",
      "[79]\ttraining's l2: 0.35185\tvalid_1's l2: 0.349345\n",
      "[80]\ttraining's l2: 0.351611\tvalid_1's l2: 0.349067\n",
      "[81]\ttraining's l2: 0.351399\tvalid_1's l2: 0.348815\n",
      "[82]\ttraining's l2: 0.351209\tvalid_1's l2: 0.348624\n",
      "[83]\ttraining's l2: 0.351007\tvalid_1's l2: 0.348475\n",
      "[84]\ttraining's l2: 0.350841\tvalid_1's l2: 0.348341\n",
      "[85]\ttraining's l2: 0.350649\tvalid_1's l2: 0.348198\n",
      "[86]\ttraining's l2: 0.350441\tvalid_1's l2: 0.34799\n",
      "[87]\ttraining's l2: 0.350223\tvalid_1's l2: 0.347789\n",
      "[88]\ttraining's l2: 0.350046\tvalid_1's l2: 0.347614\n",
      "[89]\ttraining's l2: 0.349891\tvalid_1's l2: 0.347519\n",
      "[90]\ttraining's l2: 0.349675\tvalid_1's l2: 0.347331\n",
      "[91]\ttraining's l2: 0.349543\tvalid_1's l2: 0.347245\n",
      "[92]\ttraining's l2: 0.349394\tvalid_1's l2: 0.347151\n",
      "[93]\ttraining's l2: 0.349247\tvalid_1's l2: 0.346957\n",
      "[94]\ttraining's l2: 0.349052\tvalid_1's l2: 0.346844\n",
      "[95]\ttraining's l2: 0.348884\tvalid_1's l2: 0.346682\n",
      "[96]\ttraining's l2: 0.348773\tvalid_1's l2: 0.346613\n",
      "[97]\ttraining's l2: 0.348558\tvalid_1's l2: 0.346392\n",
      "[98]\ttraining's l2: 0.348423\tvalid_1's l2: 0.346286\n",
      "[99]\ttraining's l2: 0.348278\tvalid_1's l2: 0.346179\n",
      "[100]\ttraining's l2: 0.348124\tvalid_1's l2: 0.346105\n",
      "[101]\ttraining's l2: 0.347981\tvalid_1's l2: 0.345934\n",
      "[102]\ttraining's l2: 0.34784\tvalid_1's l2: 0.345841\n",
      "[103]\ttraining's l2: 0.347741\tvalid_1's l2: 0.345787\n",
      "[104]\ttraining's l2: 0.347619\tvalid_1's l2: 0.345692\n",
      "[105]\ttraining's l2: 0.347476\tvalid_1's l2: 0.345613\n",
      "[106]\ttraining's l2: 0.347357\tvalid_1's l2: 0.345556\n",
      "[107]\ttraining's l2: 0.347261\tvalid_1's l2: 0.345467\n",
      "[108]\ttraining's l2: 0.347057\tvalid_1's l2: 0.345215\n",
      "[109]\ttraining's l2: 0.346956\tvalid_1's l2: 0.345154\n",
      "[110]\ttraining's l2: 0.346833\tvalid_1's l2: 0.345087\n",
      "[111]\ttraining's l2: 0.34674\tvalid_1's l2: 0.344996\n",
      "[112]\ttraining's l2: 0.346637\tvalid_1's l2: 0.344939\n",
      "[113]\ttraining's l2: 0.34653\tvalid_1's l2: 0.344889\n",
      "[114]\ttraining's l2: 0.346464\tvalid_1's l2: 0.344849\n",
      "[115]\ttraining's l2: 0.346391\tvalid_1's l2: 0.344811\n",
      "[116]\ttraining's l2: 0.346253\tvalid_1's l2: 0.34471\n",
      "[117]\ttraining's l2: 0.346103\tvalid_1's l2: 0.344553\n",
      "[118]\ttraining's l2: 0.346037\tvalid_1's l2: 0.344514\n",
      "[119]\ttraining's l2: 0.345925\tvalid_1's l2: 0.34444\n",
      "[120]\ttraining's l2: 0.345803\tvalid_1's l2: 0.344279\n",
      "[121]\ttraining's l2: 0.345717\tvalid_1's l2: 0.34422\n",
      "[122]\ttraining's l2: 0.345617\tvalid_1's l2: 0.34412\n",
      "[123]\ttraining's l2: 0.345557\tvalid_1's l2: 0.344055\n",
      "[124]\ttraining's l2: 0.345494\tvalid_1's l2: 0.344004\n",
      "[125]\ttraining's l2: 0.34544\tvalid_1's l2: 0.343968\n",
      "[126]\ttraining's l2: 0.345344\tvalid_1's l2: 0.343903\n",
      "[127]\ttraining's l2: 0.345233\tvalid_1's l2: 0.343754\n",
      "[128]\ttraining's l2: 0.345138\tvalid_1's l2: 0.343715\n",
      "[129]\ttraining's l2: 0.345078\tvalid_1's l2: 0.34366\n",
      "[130]\ttraining's l2: 0.34504\tvalid_1's l2: 0.34363\n",
      "[131]\ttraining's l2: 0.344935\tvalid_1's l2: 0.343582\n",
      "[132]\ttraining's l2: 0.344817\tvalid_1's l2: 0.343491\n",
      "[133]\ttraining's l2: 0.344761\tvalid_1's l2: 0.343455\n",
      "[134]\ttraining's l2: 0.344671\tvalid_1's l2: 0.343424\n",
      "[135]\ttraining's l2: 0.344629\tvalid_1's l2: 0.343395\n",
      "[136]\ttraining's l2: 0.344538\tvalid_1's l2: 0.34331\n",
      "[137]\ttraining's l2: 0.344425\tvalid_1's l2: 0.343225\n",
      "[138]\ttraining's l2: 0.344367\tvalid_1's l2: 0.343208\n",
      "[139]\ttraining's l2: 0.34432\tvalid_1's l2: 0.343195\n",
      "[140]\ttraining's l2: 0.344265\tvalid_1's l2: 0.343166\n",
      "[141]\ttraining's l2: 0.344218\tvalid_1's l2: 0.343138\n",
      "[142]\ttraining's l2: 0.344151\tvalid_1's l2: 0.343104\n",
      "[143]\ttraining's l2: 0.344097\tvalid_1's l2: 0.343092\n",
      "[144]\ttraining's l2: 0.344038\tvalid_1's l2: 0.343021\n",
      "[145]\ttraining's l2: 0.343981\tvalid_1's l2: 0.343002\n",
      "[146]\ttraining's l2: 0.343938\tvalid_1's l2: 0.342943\n",
      "[147]\ttraining's l2: 0.343899\tvalid_1's l2: 0.34292\n",
      "[148]\ttraining's l2: 0.343803\tvalid_1's l2: 0.342867\n",
      "[149]\ttraining's l2: 0.343753\tvalid_1's l2: 0.342856\n",
      "[150]\ttraining's l2: 0.343684\tvalid_1's l2: 0.34282\n",
      "[151]\ttraining's l2: 0.343637\tvalid_1's l2: 0.342806\n",
      "[152]\ttraining's l2: 0.343556\tvalid_1's l2: 0.342773\n",
      "[153]\ttraining's l2: 0.34343\tvalid_1's l2: 0.34266\n",
      "[154]\ttraining's l2: 0.343403\tvalid_1's l2: 0.342651\n",
      "[155]\ttraining's l2: 0.343326\tvalid_1's l2: 0.3426\n",
      "[156]\ttraining's l2: 0.343282\tvalid_1's l2: 0.342581\n",
      "[157]\ttraining's l2: 0.343244\tvalid_1's l2: 0.342558\n",
      "[158]\ttraining's l2: 0.343153\tvalid_1's l2: 0.342461\n",
      "[159]\ttraining's l2: 0.343113\tvalid_1's l2: 0.34243\n",
      "[160]\ttraining's l2: 0.343074\tvalid_1's l2: 0.342423\n",
      "[161]\ttraining's l2: 0.343032\tvalid_1's l2: 0.342415\n",
      "[162]\ttraining's l2: 0.342967\tvalid_1's l2: 0.34241\n",
      "[163]\ttraining's l2: 0.342932\tvalid_1's l2: 0.342395\n",
      "[164]\ttraining's l2: 0.342866\tvalid_1's l2: 0.342359\n",
      "[165]\ttraining's l2: 0.34277\tvalid_1's l2: 0.342248\n",
      "[166]\ttraining's l2: 0.342739\tvalid_1's l2: 0.342223\n",
      "[167]\ttraining's l2: 0.342698\tvalid_1's l2: 0.342196\n",
      "[168]\ttraining's l2: 0.342666\tvalid_1's l2: 0.34216\n",
      "[169]\ttraining's l2: 0.342622\tvalid_1's l2: 0.342136\n",
      "[170]\ttraining's l2: 0.342543\tvalid_1's l2: 0.342009\n",
      "[171]\ttraining's l2: 0.342468\tvalid_1's l2: 0.341977\n",
      "[172]\ttraining's l2: 0.342423\tvalid_1's l2: 0.34196\n",
      "[173]\ttraining's l2: 0.342397\tvalid_1's l2: 0.341954\n",
      "[174]\ttraining's l2: 0.342333\tvalid_1's l2: 0.341924\n",
      "[175]\ttraining's l2: 0.34228\tvalid_1's l2: 0.341857\n",
      "[176]\ttraining's l2: 0.342245\tvalid_1's l2: 0.341842\n",
      "[177]\ttraining's l2: 0.342193\tvalid_1's l2: 0.341793\n",
      "[178]\ttraining's l2: 0.342131\tvalid_1's l2: 0.34178\n",
      "[179]\ttraining's l2: 0.342057\tvalid_1's l2: 0.341734\n",
      "[180]\ttraining's l2: 0.342018\tvalid_1's l2: 0.341722\n",
      "[181]\ttraining's l2: 0.34197\tvalid_1's l2: 0.341703\n",
      "[182]\ttraining's l2: 0.341937\tvalid_1's l2: 0.34169\n",
      "[183]\ttraining's l2: 0.341908\tvalid_1's l2: 0.341676\n",
      "[184]\ttraining's l2: 0.341883\tvalid_1's l2: 0.34166\n",
      "[185]\ttraining's l2: 0.341829\tvalid_1's l2: 0.341635\n",
      "[186]\ttraining's l2: 0.341801\tvalid_1's l2: 0.341628\n",
      "[187]\ttraining's l2: 0.341762\tvalid_1's l2: 0.341602\n",
      "[188]\ttraining's l2: 0.341707\tvalid_1's l2: 0.341571\n",
      "[189]\ttraining's l2: 0.341663\tvalid_1's l2: 0.341551\n",
      "[190]\ttraining's l2: 0.341639\tvalid_1's l2: 0.341536\n",
      "[191]\ttraining's l2: 0.341552\tvalid_1's l2: 0.341393\n",
      "[192]\ttraining's l2: 0.341519\tvalid_1's l2: 0.341377\n",
      "[193]\ttraining's l2: 0.34149\tvalid_1's l2: 0.341362\n",
      "[194]\ttraining's l2: 0.341446\tvalid_1's l2: 0.341323\n",
      "[195]\ttraining's l2: 0.341414\tvalid_1's l2: 0.341305\n",
      "[196]\ttraining's l2: 0.341367\tvalid_1's l2: 0.341288\n",
      "[197]\ttraining's l2: 0.341338\tvalid_1's l2: 0.341263\n",
      "[198]\ttraining's l2: 0.341315\tvalid_1's l2: 0.341245\n",
      "[199]\ttraining's l2: 0.341273\tvalid_1's l2: 0.341242\n",
      "[200]\ttraining's l2: 0.341218\tvalid_1's l2: 0.341185\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.341218\tvalid_1's l2: 0.341185\n",
      "mean_14_sales: 8230760.77\n",
      "mean_5_sales: 2689785.35\n",
      "mean_6_sales: 2251074.99\n",
      "mean_21_sales: 1878110.67\n",
      "mean_7_sales: 1852970.03\n",
      "mean_20_dow3_2017: 793617.10\n",
      "mean_4_dow3_2017: 693063.79\n",
      "mean_30_sales: 632261.90\n",
      "promo_3: 322708.24\n",
      "mean_60_sales: 175064.85\n",
      "item_class_features: 166800.42\n",
      "mean_4_sales: 104613.32\n",
      "std_14_sales: 90816.44\n",
      "sum_4_promo: 54970.09\n",
      "mean_4_dow4_2017: 46151.98\n",
      "mean_3_sales: 30765.91\n",
      "promo_7: 28936.49\n",
      "store_cluster_features: 27714.84\n",
      "sum_2_promo: 26029.63\n",
      "mean_63_sales: 23338.86\n",
      "store_city_features: 22839.64\n",
      "lag_3_sales: 21886.42\n",
      "lag_1_sales: 19620.08\n",
      "promo_5: 18318.11\n",
      "promo_4: 17051.31\n",
      "std_21_sales: 16851.78\n",
      "item_family_features: 14795.92\n",
      "std_6_sales: 14102.48\n",
      "lag_4_sales: 13625.62\n",
      "std_30_sales: 13400.41\n",
      "std_7_sales: 11930.07\n",
      "promo_2: 11811.29\n",
      "promo_6: 9241.61\n",
      "std_63_sales: 9150.34\n",
      "mean_20_dow0_2017: 9031.46\n",
      "sum_3_promo: 8456.02\n",
      "std_5_sales: 7172.31\n",
      "std_60_sales: 6519.53\n",
      "promo_0: 6177.97\n",
      "std_4_sales: 6123.23\n",
      "store_type_features: 6043.83\n",
      "promo_1: 5641.07\n",
      "sum_14_promo: 5562.93\n",
      "promo_14: 5115.35\n",
      "sum_21_promo: 4982.93\n",
      "sum_7_promo: 4959.15\n",
      "sum_5_promo: 3454.81\n",
      "mean_20_dow4_2017: 3337.24\n",
      "lag_5_sales: 3041.84\n",
      "sum_6_promo: 2854.14\n",
      "promo_10: 2558.75\n",
      "mean_20_dow1_2017: 2520.53\n",
      "mean_4_dow1_2017: 2228.97\n",
      "mean_20_dow2_2017: 2060.73\n",
      "std_3_sales: 1950.70\n",
      "mean_20_dow5_2017: 1938.52\n",
      "store_state_features: 1568.35\n",
      "lag_28_sales: 1516.32\n",
      "mean_20_dow6_2017: 1482.42\n",
      "promo_8: 1481.70\n",
      "lag_56_sales: 1446.74\n",
      "mean_4_dow0_2017: 1234.34\n",
      "mean_4_dow2_2017: 1175.06\n",
      "lag_2_sales: 1107.28\n",
      "promo_13: 990.44\n",
      "lag_7_sales: 895.40\n",
      "mean_4_dow6_2017: 866.32\n",
      "promo_9: 836.28\n",
      "lag_63_sales: 772.63\n",
      "lag_6_sales: 734.45\n",
      "lag_14_sales: 635.25\n",
      "lag_21_sales: 396.12\n",
      "lag_42_sales: 267.04\n",
      "mean_4_dow5_2017: 235.65\n",
      "lag_35_sales: 229.72\n",
      "lag_49_sales: 213.85\n",
      "promo_11: 149.07\n",
      "promo_12: 96.53\n",
      "promo_15: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [04:23<13:18, 66.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.23857\tvalid_1's l2: 1.22177\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.15721\tvalid_1's l2: 1.14002\n",
      "[3]\ttraining's l2: 1.08353\tvalid_1's l2: 1.06609\n",
      "[4]\ttraining's l2: 1.01731\tvalid_1's l2: 0.999711\n",
      "[5]\ttraining's l2: 0.95697\tvalid_1's l2: 0.939207\n",
      "[6]\ttraining's l2: 0.902388\tvalid_1's l2: 0.884434\n",
      "[7]\ttraining's l2: 0.853559\tvalid_1's l2: 0.835648\n",
      "[8]\ttraining's l2: 0.808785\tvalid_1's l2: 0.790881\n",
      "[9]\ttraining's l2: 0.768088\tvalid_1's l2: 0.749986\n",
      "[10]\ttraining's l2: 0.731227\tvalid_1's l2: 0.713227\n",
      "[11]\ttraining's l2: 0.697834\tvalid_1's l2: 0.679826\n",
      "[12]\ttraining's l2: 0.668086\tvalid_1's l2: 0.650361\n",
      "[13]\ttraining's l2: 0.640708\tvalid_1's l2: 0.623323\n",
      "[14]\ttraining's l2: 0.615754\tvalid_1's l2: 0.598469\n",
      "[15]\ttraining's l2: 0.593481\tvalid_1's l2: 0.576305\n",
      "[16]\ttraining's l2: 0.57348\tvalid_1's l2: 0.556717\n",
      "[17]\ttraining's l2: 0.555189\tvalid_1's l2: 0.538653\n",
      "[18]\ttraining's l2: 0.538338\tvalid_1's l2: 0.522286\n",
      "[19]\ttraining's l2: 0.523131\tvalid_1's l2: 0.507419\n",
      "[20]\ttraining's l2: 0.509407\tvalid_1's l2: 0.49395\n",
      "[21]\ttraining's l2: 0.49718\tvalid_1's l2: 0.482089\n",
      "[22]\ttraining's l2: 0.485598\tvalid_1's l2: 0.470508\n",
      "[23]\ttraining's l2: 0.475069\tvalid_1's l2: 0.460196\n",
      "[24]\ttraining's l2: 0.465484\tvalid_1's l2: 0.450656\n",
      "[25]\ttraining's l2: 0.456987\tvalid_1's l2: 0.442388\n",
      "[26]\ttraining's l2: 0.449086\tvalid_1's l2: 0.434871\n",
      "[27]\ttraining's l2: 0.442056\tvalid_1's l2: 0.42813\n",
      "[28]\ttraining's l2: 0.435484\tvalid_1's l2: 0.421789\n",
      "[29]\ttraining's l2: 0.429596\tvalid_1's l2: 0.416073\n",
      "[30]\ttraining's l2: 0.424447\tvalid_1's l2: 0.411276\n",
      "[31]\ttraining's l2: 0.419519\tvalid_1's l2: 0.406546\n",
      "[32]\ttraining's l2: 0.414947\tvalid_1's l2: 0.402\n",
      "[33]\ttraining's l2: 0.410925\tvalid_1's l2: 0.398232\n",
      "[34]\ttraining's l2: 0.407121\tvalid_1's l2: 0.39447\n",
      "[35]\ttraining's l2: 0.403616\tvalid_1's l2: 0.391162\n",
      "[36]\ttraining's l2: 0.400407\tvalid_1's l2: 0.38804\n",
      "[37]\ttraining's l2: 0.397568\tvalid_1's l2: 0.385267\n",
      "[38]\ttraining's l2: 0.394971\tvalid_1's l2: 0.382833\n",
      "[39]\ttraining's l2: 0.392612\tvalid_1's l2: 0.380739\n",
      "[40]\ttraining's l2: 0.390323\tvalid_1's l2: 0.378596\n",
      "[41]\ttraining's l2: 0.388338\tvalid_1's l2: 0.376871\n",
      "[42]\ttraining's l2: 0.386382\tvalid_1's l2: 0.374965\n",
      "[43]\ttraining's l2: 0.384644\tvalid_1's l2: 0.373391\n",
      "[44]\ttraining's l2: 0.38301\tvalid_1's l2: 0.371859\n",
      "[45]\ttraining's l2: 0.381524\tvalid_1's l2: 0.37046\n",
      "[46]\ttraining's l2: 0.38024\tvalid_1's l2: 0.369375\n",
      "[47]\ttraining's l2: 0.379093\tvalid_1's l2: 0.368348\n",
      "[48]\ttraining's l2: 0.377902\tvalid_1's l2: 0.367337\n",
      "[49]\ttraining's l2: 0.376782\tvalid_1's l2: 0.366279\n",
      "[50]\ttraining's l2: 0.375823\tvalid_1's l2: 0.36549\n",
      "[51]\ttraining's l2: 0.374822\tvalid_1's l2: 0.364528\n",
      "[52]\ttraining's l2: 0.373895\tvalid_1's l2: 0.363666\n",
      "[53]\ttraining's l2: 0.373021\tvalid_1's l2: 0.362881\n",
      "[54]\ttraining's l2: 0.37231\tvalid_1's l2: 0.362258\n",
      "[55]\ttraining's l2: 0.371641\tvalid_1's l2: 0.361718\n",
      "[56]\ttraining's l2: 0.370968\tvalid_1's l2: 0.361095\n",
      "[57]\ttraining's l2: 0.370264\tvalid_1's l2: 0.360417\n",
      "[58]\ttraining's l2: 0.369677\tvalid_1's l2: 0.359903\n",
      "[59]\ttraining's l2: 0.369103\tvalid_1's l2: 0.359376\n",
      "[60]\ttraining's l2: 0.36859\tvalid_1's l2: 0.358922\n",
      "[61]\ttraining's l2: 0.36808\tvalid_1's l2: 0.35843\n",
      "[62]\ttraining's l2: 0.367625\tvalid_1's l2: 0.358096\n",
      "[63]\ttraining's l2: 0.367248\tvalid_1's l2: 0.357734\n",
      "[64]\ttraining's l2: 0.366874\tvalid_1's l2: 0.357442\n",
      "[65]\ttraining's l2: 0.366377\tvalid_1's l2: 0.356898\n",
      "[66]\ttraining's l2: 0.366014\tvalid_1's l2: 0.356615\n",
      "[67]\ttraining's l2: 0.365605\tvalid_1's l2: 0.356382\n",
      "[68]\ttraining's l2: 0.365269\tvalid_1's l2: 0.356182\n",
      "[69]\ttraining's l2: 0.364859\tvalid_1's l2: 0.355796\n",
      "[70]\ttraining's l2: 0.36455\tvalid_1's l2: 0.355618\n",
      "[71]\ttraining's l2: 0.36412\tvalid_1's l2: 0.355161\n",
      "[72]\ttraining's l2: 0.363678\tvalid_1's l2: 0.354742\n",
      "[73]\ttraining's l2: 0.363384\tvalid_1's l2: 0.35451\n",
      "[74]\ttraining's l2: 0.363068\tvalid_1's l2: 0.354287\n",
      "[75]\ttraining's l2: 0.362742\tvalid_1's l2: 0.35399\n",
      "[76]\ttraining's l2: 0.362396\tvalid_1's l2: 0.353684\n",
      "[77]\ttraining's l2: 0.362155\tvalid_1's l2: 0.35348\n",
      "[78]\ttraining's l2: 0.361895\tvalid_1's l2: 0.353201\n",
      "[79]\ttraining's l2: 0.361656\tvalid_1's l2: 0.35305\n",
      "[80]\ttraining's l2: 0.361434\tvalid_1's l2: 0.352893\n",
      "[81]\ttraining's l2: 0.361125\tvalid_1's l2: 0.352567\n",
      "[82]\ttraining's l2: 0.360909\tvalid_1's l2: 0.352362\n",
      "[83]\ttraining's l2: 0.360645\tvalid_1's l2: 0.35213\n",
      "[84]\ttraining's l2: 0.360471\tvalid_1's l2: 0.352008\n",
      "[85]\ttraining's l2: 0.360248\tvalid_1's l2: 0.351847\n",
      "[86]\ttraining's l2: 0.360063\tvalid_1's l2: 0.351734\n",
      "[87]\ttraining's l2: 0.359838\tvalid_1's l2: 0.351623\n",
      "[88]\ttraining's l2: 0.35964\tvalid_1's l2: 0.351451\n",
      "[89]\ttraining's l2: 0.359424\tvalid_1's l2: 0.351316\n",
      "[90]\ttraining's l2: 0.359163\tvalid_1's l2: 0.351154\n",
      "[91]\ttraining's l2: 0.359012\tvalid_1's l2: 0.351075\n",
      "[92]\ttraining's l2: 0.358864\tvalid_1's l2: 0.350992\n",
      "[93]\ttraining's l2: 0.358708\tvalid_1's l2: 0.350872\n",
      "[94]\ttraining's l2: 0.358562\tvalid_1's l2: 0.350781\n",
      "[95]\ttraining's l2: 0.358424\tvalid_1's l2: 0.350692\n",
      "[96]\ttraining's l2: 0.358274\tvalid_1's l2: 0.350608\n",
      "[97]\ttraining's l2: 0.358048\tvalid_1's l2: 0.350366\n",
      "[98]\ttraining's l2: 0.357918\tvalid_1's l2: 0.350256\n",
      "[99]\ttraining's l2: 0.357767\tvalid_1's l2: 0.350104\n",
      "[100]\ttraining's l2: 0.357497\tvalid_1's l2: 0.349835\n",
      "[101]\ttraining's l2: 0.357297\tvalid_1's l2: 0.349569\n",
      "[102]\ttraining's l2: 0.357172\tvalid_1's l2: 0.349471\n",
      "[103]\ttraining's l2: 0.357011\tvalid_1's l2: 0.349361\n",
      "[104]\ttraining's l2: 0.356888\tvalid_1's l2: 0.349236\n",
      "[105]\ttraining's l2: 0.356741\tvalid_1's l2: 0.349171\n",
      "[106]\ttraining's l2: 0.356605\tvalid_1's l2: 0.349096\n",
      "[107]\ttraining's l2: 0.356433\tvalid_1's l2: 0.348922\n",
      "[108]\ttraining's l2: 0.356268\tvalid_1's l2: 0.348743\n",
      "[109]\ttraining's l2: 0.356188\tvalid_1's l2: 0.348679\n",
      "[110]\ttraining's l2: 0.356097\tvalid_1's l2: 0.34862\n",
      "[111]\ttraining's l2: 0.356005\tvalid_1's l2: 0.34854\n",
      "[112]\ttraining's l2: 0.35582\tvalid_1's l2: 0.348328\n",
      "[113]\ttraining's l2: 0.355693\tvalid_1's l2: 0.348273\n",
      "[114]\ttraining's l2: 0.355491\tvalid_1's l2: 0.348072\n",
      "[115]\ttraining's l2: 0.355339\tvalid_1's l2: 0.347976\n",
      "[116]\ttraining's l2: 0.355258\tvalid_1's l2: 0.347931\n",
      "[117]\ttraining's l2: 0.355111\tvalid_1's l2: 0.34779\n",
      "[118]\ttraining's l2: 0.355015\tvalid_1's l2: 0.347721\n",
      "[119]\ttraining's l2: 0.354829\tvalid_1's l2: 0.347519\n",
      "[120]\ttraining's l2: 0.354684\tvalid_1's l2: 0.347339\n",
      "[121]\ttraining's l2: 0.35457\tvalid_1's l2: 0.347269\n",
      "[122]\ttraining's l2: 0.354453\tvalid_1's l2: 0.347181\n",
      "[123]\ttraining's l2: 0.354347\tvalid_1's l2: 0.347036\n",
      "[124]\ttraining's l2: 0.354276\tvalid_1's l2: 0.346965\n",
      "[125]\ttraining's l2: 0.354183\tvalid_1's l2: 0.346923\n",
      "[126]\ttraining's l2: 0.354023\tvalid_1's l2: 0.346744\n",
      "[127]\ttraining's l2: 0.353952\tvalid_1's l2: 0.346662\n",
      "[128]\ttraining's l2: 0.353899\tvalid_1's l2: 0.346629\n",
      "[129]\ttraining's l2: 0.353774\tvalid_1's l2: 0.346454\n",
      "[130]\ttraining's l2: 0.353716\tvalid_1's l2: 0.346402\n",
      "[131]\ttraining's l2: 0.353594\tvalid_1's l2: 0.34632\n",
      "[132]\ttraining's l2: 0.353516\tvalid_1's l2: 0.34628\n",
      "[133]\ttraining's l2: 0.353451\tvalid_1's l2: 0.346232\n",
      "[134]\ttraining's l2: 0.353398\tvalid_1's l2: 0.346185\n",
      "[135]\ttraining's l2: 0.353318\tvalid_1's l2: 0.346154\n",
      "[136]\ttraining's l2: 0.353248\tvalid_1's l2: 0.346122\n",
      "[137]\ttraining's l2: 0.353163\tvalid_1's l2: 0.346094\n",
      "[138]\ttraining's l2: 0.353064\tvalid_1's l2: 0.346056\n",
      "[139]\ttraining's l2: 0.352995\tvalid_1's l2: 0.346027\n",
      "[140]\ttraining's l2: 0.352923\tvalid_1's l2: 0.34598\n",
      "[141]\ttraining's l2: 0.352876\tvalid_1's l2: 0.345939\n",
      "[142]\ttraining's l2: 0.352828\tvalid_1's l2: 0.345894\n",
      "[143]\ttraining's l2: 0.352769\tvalid_1's l2: 0.345861\n",
      "[144]\ttraining's l2: 0.352669\tvalid_1's l2: 0.345739\n",
      "[145]\ttraining's l2: 0.352561\tvalid_1's l2: 0.345646\n",
      "[146]\ttraining's l2: 0.35249\tvalid_1's l2: 0.345609\n",
      "[147]\ttraining's l2: 0.352427\tvalid_1's l2: 0.345574\n",
      "[148]\ttraining's l2: 0.352362\tvalid_1's l2: 0.345538\n",
      "[149]\ttraining's l2: 0.352298\tvalid_1's l2: 0.345495\n",
      "[150]\ttraining's l2: 0.352232\tvalid_1's l2: 0.34547\n",
      "[151]\ttraining's l2: 0.352189\tvalid_1's l2: 0.345434\n",
      "[152]\ttraining's l2: 0.352087\tvalid_1's l2: 0.345379\n",
      "[153]\ttraining's l2: 0.352024\tvalid_1's l2: 0.34534\n",
      "[154]\ttraining's l2: 0.351967\tvalid_1's l2: 0.345316\n",
      "[155]\ttraining's l2: 0.351865\tvalid_1's l2: 0.345193\n",
      "[156]\ttraining's l2: 0.351828\tvalid_1's l2: 0.345171\n",
      "[157]\ttraining's l2: 0.351772\tvalid_1's l2: 0.345147\n",
      "[158]\ttraining's l2: 0.351732\tvalid_1's l2: 0.345124\n",
      "[159]\ttraining's l2: 0.351666\tvalid_1's l2: 0.345062\n",
      "[160]\ttraining's l2: 0.351616\tvalid_1's l2: 0.345047\n",
      "[161]\ttraining's l2: 0.351531\tvalid_1's l2: 0.34497\n",
      "[162]\ttraining's l2: 0.351475\tvalid_1's l2: 0.344956\n",
      "[163]\ttraining's l2: 0.351426\tvalid_1's l2: 0.344939\n",
      "[164]\ttraining's l2: 0.351358\tvalid_1's l2: 0.34492\n",
      "[165]\ttraining's l2: 0.351273\tvalid_1's l2: 0.344844\n",
      "[166]\ttraining's l2: 0.351237\tvalid_1's l2: 0.344809\n",
      "[167]\ttraining's l2: 0.35116\tvalid_1's l2: 0.344757\n",
      "[168]\ttraining's l2: 0.351112\tvalid_1's l2: 0.344727\n",
      "[169]\ttraining's l2: 0.351042\tvalid_1's l2: 0.344697\n",
      "[170]\ttraining's l2: 0.350961\tvalid_1's l2: 0.344652\n",
      "[171]\ttraining's l2: 0.35092\tvalid_1's l2: 0.344634\n",
      "[172]\ttraining's l2: 0.350878\tvalid_1's l2: 0.344616\n",
      "[173]\ttraining's l2: 0.350832\tvalid_1's l2: 0.344579\n",
      "[174]\ttraining's l2: 0.350739\tvalid_1's l2: 0.344485\n",
      "[175]\ttraining's l2: 0.350683\tvalid_1's l2: 0.344449\n",
      "[176]\ttraining's l2: 0.350628\tvalid_1's l2: 0.344393\n",
      "[177]\ttraining's l2: 0.350595\tvalid_1's l2: 0.344356\n",
      "[178]\ttraining's l2: 0.35056\tvalid_1's l2: 0.344329\n",
      "[179]\ttraining's l2: 0.35048\tvalid_1's l2: 0.344247\n",
      "[180]\ttraining's l2: 0.35043\tvalid_1's l2: 0.344211\n",
      "[181]\ttraining's l2: 0.350378\tvalid_1's l2: 0.344185\n",
      "[182]\ttraining's l2: 0.350324\tvalid_1's l2: 0.344144\n",
      "[183]\ttraining's l2: 0.350283\tvalid_1's l2: 0.344139\n",
      "[184]\ttraining's l2: 0.35022\tvalid_1's l2: 0.344099\n",
      "[185]\ttraining's l2: 0.350163\tvalid_1's l2: 0.344067\n",
      "[186]\ttraining's l2: 0.350128\tvalid_1's l2: 0.344049\n",
      "[187]\ttraining's l2: 0.350079\tvalid_1's l2: 0.34402\n",
      "[188]\ttraining's l2: 0.350026\tvalid_1's l2: 0.343997\n",
      "[189]\ttraining's l2: 0.34998\tvalid_1's l2: 0.343972\n",
      "[190]\ttraining's l2: 0.349939\tvalid_1's l2: 0.343929\n",
      "[191]\ttraining's l2: 0.349902\tvalid_1's l2: 0.343903\n",
      "[192]\ttraining's l2: 0.349875\tvalid_1's l2: 0.343888\n",
      "[193]\ttraining's l2: 0.349846\tvalid_1's l2: 0.343873\n",
      "[194]\ttraining's l2: 0.349801\tvalid_1's l2: 0.343823\n",
      "[195]\ttraining's l2: 0.349755\tvalid_1's l2: 0.343794\n",
      "[196]\ttraining's l2: 0.349698\tvalid_1's l2: 0.343772\n",
      "[197]\ttraining's l2: 0.349662\tvalid_1's l2: 0.343755\n",
      "[198]\ttraining's l2: 0.349626\tvalid_1's l2: 0.343722\n",
      "[199]\ttraining's l2: 0.349585\tvalid_1's l2: 0.343706\n",
      "[200]\ttraining's l2: 0.349551\tvalid_1's l2: 0.343693\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.349551\tvalid_1's l2: 0.343693\n",
      "mean_14_sales: 6729631.99\n",
      "mean_4_dow4_2017: 3503821.36\n",
      "mean_5_sales: 2654960.72\n",
      "mean_4_sales: 2277406.95\n",
      "mean_21_sales: 2092892.44\n",
      "mean_20_dow4_2017: 1159412.19\n",
      "mean_7_sales: 997883.34\n",
      "mean_6_sales: 729781.76\n",
      "mean_30_sales: 359623.19\n",
      "promo_4: 322724.21\n",
      "item_class_features: 174102.81\n",
      "std_14_sales: 103111.03\n",
      "sum_3_promo: 77999.71\n",
      "mean_3_sales: 68046.21\n",
      "mean_60_sales: 57016.35\n",
      "store_cluster_features: 55307.21\n",
      "promo_7: 38360.48\n",
      "store_city_features: 32044.68\n",
      "mean_4_dow3_2017: 31854.37\n",
      "lag_3_sales: 26231.80\n",
      "std_21_sales: 24412.79\n",
      "promo_3: 21268.46\n",
      "promo_5: 19366.36\n",
      "item_family_features: 17621.87\n",
      "sum_4_promo: 13397.47\n",
      "promo_6: 13352.42\n",
      "sum_2_promo: 13152.75\n",
      "std_30_sales: 11819.19\n",
      "mean_20_dow0_2017: 11554.25\n",
      "lag_1_sales: 11340.12\n",
      "promo_11: 11212.97\n",
      "mean_20_dow3_2017: 10941.61\n",
      "store_type_features: 10327.13\n",
      "promo_2: 10117.48\n",
      "promo_1: 7933.69\n",
      "sum_14_promo: 7780.82\n",
      "std_63_sales: 7600.95\n",
      "std_60_sales: 7306.28\n",
      "promo_14: 6906.98\n",
      "std_5_sales: 6822.30\n",
      "std_4_sales: 6553.62\n",
      "lag_2_sales: 6169.74\n",
      "std_7_sales: 4579.32\n",
      "sum_7_promo: 4514.84\n",
      "promo_0: 4472.24\n",
      "lag_4_sales: 4127.02\n",
      "std_6_sales: 4123.51\n",
      "mean_20_dow2_2017: 3674.46\n",
      "mean_63_sales: 3166.75\n",
      "mean_20_dow1_2017: 2987.06\n",
      "sum_21_promo: 2616.81\n",
      "promo_13: 2365.06\n",
      "store_state_features: 2157.66\n",
      "lag_5_sales: 1989.07\n",
      "mean_20_dow6_2017: 1815.49\n",
      "std_3_sales: 1531.49\n",
      "mean_4_dow0_2017: 1525.77\n",
      "mean_4_dow6_2017: 1520.01\n",
      "sum_5_promo: 1437.23\n",
      "promo_8: 1420.51\n",
      "mean_4_dow1_2017: 1302.66\n",
      "promo_10: 1268.25\n",
      "promo_9: 1086.28\n",
      "mean_4_dow5_2017: 1055.96\n",
      "lag_6_sales: 1000.26\n",
      "mean_4_dow2_2017: 949.94\n",
      "promo_12: 715.08\n",
      "mean_20_dow5_2017: 682.52\n",
      "lag_14_sales: 672.80\n",
      "lag_28_sales: 667.92\n",
      "lag_7_sales: 615.32\n",
      "lag_63_sales: 583.28\n",
      "sum_6_promo: 582.22\n",
      "lag_21_sales: 558.49\n",
      "lag_49_sales: 418.43\n",
      "lag_42_sales: 398.08\n",
      "lag_56_sales: 321.06\n",
      "lag_35_sales: 291.51\n",
      "promo_15: 214.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [05:23<11:48, 64.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.07025\tvalid_1's l2: 1.09676\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.00456\tvalid_1's l2: 1.02951\n",
      "[3]\ttraining's l2: 0.945237\tvalid_1's l2: 0.968399\n",
      "[4]\ttraining's l2: 0.891742\tvalid_1's l2: 0.9131\n",
      "[5]\ttraining's l2: 0.843253\tvalid_1's l2: 0.862931\n",
      "[6]\ttraining's l2: 0.799317\tvalid_1's l2: 0.817603\n",
      "[7]\ttraining's l2: 0.759429\tvalid_1's l2: 0.776347\n",
      "[8]\ttraining's l2: 0.723506\tvalid_1's l2: 0.73928\n",
      "[9]\ttraining's l2: 0.690956\tvalid_1's l2: 0.705473\n",
      "[10]\ttraining's l2: 0.661802\tvalid_1's l2: 0.675303\n",
      "[11]\ttraining's l2: 0.635516\tvalid_1's l2: 0.647999\n",
      "[12]\ttraining's l2: 0.611663\tvalid_1's l2: 0.62323\n",
      "[13]\ttraining's l2: 0.589542\tvalid_1's l2: 0.600123\n",
      "[14]\ttraining's l2: 0.569467\tvalid_1's l2: 0.57919\n",
      "[15]\ttraining's l2: 0.551322\tvalid_1's l2: 0.560196\n",
      "[16]\ttraining's l2: 0.53512\tvalid_1's l2: 0.54324\n",
      "[17]\ttraining's l2: 0.52056\tvalid_1's l2: 0.527981\n",
      "[18]\ttraining's l2: 0.506878\tvalid_1's l2: 0.513565\n",
      "[19]\ttraining's l2: 0.494451\tvalid_1's l2: 0.500408\n",
      "[20]\ttraining's l2: 0.483282\tvalid_1's l2: 0.488451\n",
      "[21]\ttraining's l2: 0.473142\tvalid_1's l2: 0.477557\n",
      "[22]\ttraining's l2: 0.463971\tvalid_1's l2: 0.467651\n",
      "[23]\ttraining's l2: 0.455725\tvalid_1's l2: 0.458939\n",
      "[24]\ttraining's l2: 0.448058\tvalid_1's l2: 0.450741\n",
      "[25]\ttraining's l2: 0.441077\tvalid_1's l2: 0.443212\n",
      "[26]\ttraining's l2: 0.434872\tvalid_1's l2: 0.436642\n",
      "[27]\ttraining's l2: 0.429093\tvalid_1's l2: 0.430435\n",
      "[28]\ttraining's l2: 0.423828\tvalid_1's l2: 0.424701\n",
      "[29]\ttraining's l2: 0.419214\tvalid_1's l2: 0.419714\n",
      "[30]\ttraining's l2: 0.414863\tvalid_1's l2: 0.414987\n",
      "[31]\ttraining's l2: 0.410937\tvalid_1's l2: 0.410668\n",
      "[32]\ttraining's l2: 0.407426\tvalid_1's l2: 0.406827\n",
      "[33]\ttraining's l2: 0.404202\tvalid_1's l2: 0.403291\n",
      "[34]\ttraining's l2: 0.401152\tvalid_1's l2: 0.399853\n",
      "[35]\ttraining's l2: 0.398485\tvalid_1's l2: 0.396894\n",
      "[36]\ttraining's l2: 0.395925\tvalid_1's l2: 0.39397\n",
      "[37]\ttraining's l2: 0.393586\tvalid_1's l2: 0.391276\n",
      "[38]\ttraining's l2: 0.391385\tvalid_1's l2: 0.388762\n",
      "[39]\ttraining's l2: 0.389416\tvalid_1's l2: 0.386479\n",
      "[40]\ttraining's l2: 0.387714\tvalid_1's l2: 0.384593\n",
      "[41]\ttraining's l2: 0.386157\tvalid_1's l2: 0.382842\n",
      "[42]\ttraining's l2: 0.384712\tvalid_1's l2: 0.381219\n",
      "[43]\ttraining's l2: 0.383248\tvalid_1's l2: 0.379427\n",
      "[44]\ttraining's l2: 0.382017\tvalid_1's l2: 0.37801\n",
      "[45]\ttraining's l2: 0.380872\tvalid_1's l2: 0.376701\n",
      "[46]\ttraining's l2: 0.379699\tvalid_1's l2: 0.375257\n",
      "[47]\ttraining's l2: 0.37865\tvalid_1's l2: 0.374033\n",
      "[48]\ttraining's l2: 0.377639\tvalid_1's l2: 0.372815\n",
      "[49]\ttraining's l2: 0.376656\tvalid_1's l2: 0.371603\n",
      "[50]\ttraining's l2: 0.37581\tvalid_1's l2: 0.370588\n",
      "[51]\ttraining's l2: 0.375009\tvalid_1's l2: 0.369631\n",
      "[52]\ttraining's l2: 0.374387\tvalid_1's l2: 0.368922\n",
      "[53]\ttraining's l2: 0.373613\tvalid_1's l2: 0.368074\n",
      "[54]\ttraining's l2: 0.372971\tvalid_1's l2: 0.367268\n",
      "[55]\ttraining's l2: 0.372347\tvalid_1's l2: 0.36645\n",
      "[56]\ttraining's l2: 0.371771\tvalid_1's l2: 0.365748\n",
      "[57]\ttraining's l2: 0.371286\tvalid_1's l2: 0.365133\n",
      "[58]\ttraining's l2: 0.370817\tvalid_1's l2: 0.364631\n",
      "[59]\ttraining's l2: 0.37035\tvalid_1's l2: 0.364152\n",
      "[60]\ttraining's l2: 0.369958\tvalid_1's l2: 0.363706\n",
      "[61]\ttraining's l2: 0.369582\tvalid_1's l2: 0.36328\n",
      "[62]\ttraining's l2: 0.36916\tvalid_1's l2: 0.362784\n",
      "[63]\ttraining's l2: 0.368817\tvalid_1's l2: 0.36236\n",
      "[64]\ttraining's l2: 0.368527\tvalid_1's l2: 0.362034\n",
      "[65]\ttraining's l2: 0.368148\tvalid_1's l2: 0.361539\n",
      "[66]\ttraining's l2: 0.367843\tvalid_1's l2: 0.361166\n",
      "[67]\ttraining's l2: 0.367509\tvalid_1's l2: 0.360799\n",
      "[68]\ttraining's l2: 0.367214\tvalid_1's l2: 0.360452\n",
      "[69]\ttraining's l2: 0.366967\tvalid_1's l2: 0.360198\n",
      "[70]\ttraining's l2: 0.366713\tvalid_1's l2: 0.359876\n",
      "[71]\ttraining's l2: 0.366406\tvalid_1's l2: 0.359562\n",
      "[72]\ttraining's l2: 0.366107\tvalid_1's l2: 0.359231\n",
      "[73]\ttraining's l2: 0.36586\tvalid_1's l2: 0.358941\n",
      "[74]\ttraining's l2: 0.365622\tvalid_1's l2: 0.358706\n",
      "[75]\ttraining's l2: 0.365364\tvalid_1's l2: 0.358471\n",
      "[76]\ttraining's l2: 0.365081\tvalid_1's l2: 0.358209\n",
      "[77]\ttraining's l2: 0.364878\tvalid_1's l2: 0.35802\n",
      "[78]\ttraining's l2: 0.364611\tvalid_1's l2: 0.35775\n",
      "[79]\ttraining's l2: 0.364436\tvalid_1's l2: 0.357572\n",
      "[80]\ttraining's l2: 0.364251\tvalid_1's l2: 0.357387\n",
      "[81]\ttraining's l2: 0.364077\tvalid_1's l2: 0.357228\n",
      "[82]\ttraining's l2: 0.363944\tvalid_1's l2: 0.357032\n",
      "[83]\ttraining's l2: 0.363736\tvalid_1's l2: 0.356838\n",
      "[84]\ttraining's l2: 0.36357\tvalid_1's l2: 0.356669\n",
      "[85]\ttraining's l2: 0.363371\tvalid_1's l2: 0.356448\n",
      "[86]\ttraining's l2: 0.363136\tvalid_1's l2: 0.356208\n",
      "[87]\ttraining's l2: 0.363014\tvalid_1's l2: 0.356117\n",
      "[88]\ttraining's l2: 0.362879\tvalid_1's l2: 0.355971\n",
      "[89]\ttraining's l2: 0.362707\tvalid_1's l2: 0.355816\n",
      "[90]\ttraining's l2: 0.362551\tvalid_1's l2: 0.35571\n",
      "[91]\ttraining's l2: 0.362384\tvalid_1's l2: 0.355545\n",
      "[92]\ttraining's l2: 0.36217\tvalid_1's l2: 0.355301\n",
      "[93]\ttraining's l2: 0.361978\tvalid_1's l2: 0.355113\n",
      "[94]\ttraining's l2: 0.361807\tvalid_1's l2: 0.354955\n",
      "[95]\ttraining's l2: 0.361645\tvalid_1's l2: 0.35483\n",
      "[96]\ttraining's l2: 0.361445\tvalid_1's l2: 0.354683\n",
      "[97]\ttraining's l2: 0.361335\tvalid_1's l2: 0.354582\n",
      "[98]\ttraining's l2: 0.361211\tvalid_1's l2: 0.354486\n",
      "[99]\ttraining's l2: 0.36112\tvalid_1's l2: 0.354431\n",
      "[100]\ttraining's l2: 0.360895\tvalid_1's l2: 0.354242\n",
      "[101]\ttraining's l2: 0.360735\tvalid_1's l2: 0.354093\n",
      "[102]\ttraining's l2: 0.360602\tvalid_1's l2: 0.353998\n",
      "[103]\ttraining's l2: 0.360437\tvalid_1's l2: 0.353845\n",
      "[104]\ttraining's l2: 0.360337\tvalid_1's l2: 0.353754\n",
      "[105]\ttraining's l2: 0.360241\tvalid_1's l2: 0.353662\n",
      "[106]\ttraining's l2: 0.3601\tvalid_1's l2: 0.353603\n",
      "[107]\ttraining's l2: 0.360033\tvalid_1's l2: 0.353565\n",
      "[108]\ttraining's l2: 0.359877\tvalid_1's l2: 0.353472\n",
      "[109]\ttraining's l2: 0.359732\tvalid_1's l2: 0.353329\n",
      "[110]\ttraining's l2: 0.359667\tvalid_1's l2: 0.353286\n",
      "[111]\ttraining's l2: 0.359562\tvalid_1's l2: 0.353216\n",
      "[112]\ttraining's l2: 0.3594\tvalid_1's l2: 0.353081\n",
      "[113]\ttraining's l2: 0.359256\tvalid_1's l2: 0.352972\n",
      "[114]\ttraining's l2: 0.359181\tvalid_1's l2: 0.352912\n",
      "[115]\ttraining's l2: 0.359114\tvalid_1's l2: 0.352887\n",
      "[116]\ttraining's l2: 0.359049\tvalid_1's l2: 0.352849\n",
      "[117]\ttraining's l2: 0.358963\tvalid_1's l2: 0.352795\n",
      "[118]\ttraining's l2: 0.358815\tvalid_1's l2: 0.352606\n",
      "[119]\ttraining's l2: 0.358755\tvalid_1's l2: 0.35256\n",
      "[120]\ttraining's l2: 0.358696\tvalid_1's l2: 0.352532\n",
      "[121]\ttraining's l2: 0.358647\tvalid_1's l2: 0.352519\n",
      "[122]\ttraining's l2: 0.358558\tvalid_1's l2: 0.352441\n",
      "[123]\ttraining's l2: 0.358413\tvalid_1's l2: 0.35234\n",
      "[124]\ttraining's l2: 0.358356\tvalid_1's l2: 0.352292\n",
      "[125]\ttraining's l2: 0.358298\tvalid_1's l2: 0.352255\n",
      "[126]\ttraining's l2: 0.358188\tvalid_1's l2: 0.352153\n",
      "[127]\ttraining's l2: 0.358086\tvalid_1's l2: 0.352018\n",
      "[128]\ttraining's l2: 0.358029\tvalid_1's l2: 0.351978\n",
      "[129]\ttraining's l2: 0.35792\tvalid_1's l2: 0.351856\n",
      "[130]\ttraining's l2: 0.357861\tvalid_1's l2: 0.351837\n",
      "[131]\ttraining's l2: 0.357775\tvalid_1's l2: 0.35182\n",
      "[132]\ttraining's l2: 0.357687\tvalid_1's l2: 0.351772\n",
      "[133]\ttraining's l2: 0.357623\tvalid_1's l2: 0.351733\n",
      "[134]\ttraining's l2: 0.357573\tvalid_1's l2: 0.351705\n",
      "[135]\ttraining's l2: 0.357505\tvalid_1's l2: 0.351686\n",
      "[136]\ttraining's l2: 0.357456\tvalid_1's l2: 0.351657\n",
      "[137]\ttraining's l2: 0.35736\tvalid_1's l2: 0.351572\n",
      "[138]\ttraining's l2: 0.35724\tvalid_1's l2: 0.351478\n",
      "[139]\ttraining's l2: 0.357142\tvalid_1's l2: 0.351419\n",
      "[140]\ttraining's l2: 0.35709\tvalid_1's l2: 0.351399\n",
      "[141]\ttraining's l2: 0.357042\tvalid_1's l2: 0.35137\n",
      "[142]\ttraining's l2: 0.357\tvalid_1's l2: 0.351343\n",
      "[143]\ttraining's l2: 0.35691\tvalid_1's l2: 0.351239\n",
      "[144]\ttraining's l2: 0.356853\tvalid_1's l2: 0.351204\n",
      "[145]\ttraining's l2: 0.356816\tvalid_1's l2: 0.351208\n",
      "[146]\ttraining's l2: 0.356762\tvalid_1's l2: 0.351169\n",
      "[147]\ttraining's l2: 0.35667\tvalid_1's l2: 0.351137\n",
      "[148]\ttraining's l2: 0.356622\tvalid_1's l2: 0.351102\n",
      "[149]\ttraining's l2: 0.356571\tvalid_1's l2: 0.351096\n",
      "[150]\ttraining's l2: 0.356526\tvalid_1's l2: 0.351074\n",
      "[151]\ttraining's l2: 0.356441\tvalid_1's l2: 0.351017\n",
      "[152]\ttraining's l2: 0.356347\tvalid_1's l2: 0.351001\n",
      "[153]\ttraining's l2: 0.356265\tvalid_1's l2: 0.35096\n",
      "[154]\ttraining's l2: 0.356225\tvalid_1's l2: 0.350948\n",
      "[155]\ttraining's l2: 0.356194\tvalid_1's l2: 0.350933\n",
      "[156]\ttraining's l2: 0.35615\tvalid_1's l2: 0.350906\n",
      "[157]\ttraining's l2: 0.356096\tvalid_1's l2: 0.350886\n",
      "[158]\ttraining's l2: 0.356061\tvalid_1's l2: 0.350872\n",
      "[159]\ttraining's l2: 0.356014\tvalid_1's l2: 0.350852\n",
      "[160]\ttraining's l2: 0.355962\tvalid_1's l2: 0.350821\n",
      "[161]\ttraining's l2: 0.355922\tvalid_1's l2: 0.350799\n",
      "[162]\ttraining's l2: 0.355848\tvalid_1's l2: 0.350778\n",
      "[163]\ttraining's l2: 0.355782\tvalid_1's l2: 0.350726\n",
      "[164]\ttraining's l2: 0.35571\tvalid_1's l2: 0.350665\n",
      "[165]\ttraining's l2: 0.355675\tvalid_1's l2: 0.350653\n",
      "[166]\ttraining's l2: 0.355643\tvalid_1's l2: 0.350646\n",
      "[167]\ttraining's l2: 0.355568\tvalid_1's l2: 0.350536\n",
      "[168]\ttraining's l2: 0.35552\tvalid_1's l2: 0.350517\n",
      "[169]\ttraining's l2: 0.355463\tvalid_1's l2: 0.35048\n",
      "[170]\ttraining's l2: 0.35543\tvalid_1's l2: 0.350465\n",
      "[171]\ttraining's l2: 0.355396\tvalid_1's l2: 0.350448\n",
      "[172]\ttraining's l2: 0.355352\tvalid_1's l2: 0.350423\n",
      "[173]\ttraining's l2: 0.355319\tvalid_1's l2: 0.350403\n",
      "[174]\ttraining's l2: 0.355271\tvalid_1's l2: 0.350399\n",
      "[175]\ttraining's l2: 0.355234\tvalid_1's l2: 0.35038\n",
      "[176]\ttraining's l2: 0.355191\tvalid_1's l2: 0.350383\n",
      "[177]\ttraining's l2: 0.355152\tvalid_1's l2: 0.350359\n",
      "[178]\ttraining's l2: 0.355108\tvalid_1's l2: 0.350328\n",
      "[179]\ttraining's l2: 0.355085\tvalid_1's l2: 0.350318\n",
      "[180]\ttraining's l2: 0.355044\tvalid_1's l2: 0.350287\n",
      "[181]\ttraining's l2: 0.354992\tvalid_1's l2: 0.35026\n",
      "[182]\ttraining's l2: 0.35495\tvalid_1's l2: 0.350249\n",
      "[183]\ttraining's l2: 0.354876\tvalid_1's l2: 0.350158\n",
      "[184]\ttraining's l2: 0.354846\tvalid_1's l2: 0.350144\n",
      "[185]\ttraining's l2: 0.354813\tvalid_1's l2: 0.350125\n",
      "[186]\ttraining's l2: 0.35478\tvalid_1's l2: 0.350105\n",
      "[187]\ttraining's l2: 0.354729\tvalid_1's l2: 0.350082\n",
      "[188]\ttraining's l2: 0.354684\tvalid_1's l2: 0.350063\n",
      "[189]\ttraining's l2: 0.354622\tvalid_1's l2: 0.350053\n",
      "[190]\ttraining's l2: 0.354587\tvalid_1's l2: 0.35003\n",
      "[191]\ttraining's l2: 0.354548\tvalid_1's l2: 0.350015\n",
      "[192]\ttraining's l2: 0.354511\tvalid_1's l2: 0.350004\n",
      "[193]\ttraining's l2: 0.354486\tvalid_1's l2: 0.349983\n",
      "[194]\ttraining's l2: 0.354458\tvalid_1's l2: 0.349959\n",
      "[195]\ttraining's l2: 0.354388\tvalid_1's l2: 0.349865\n",
      "[196]\ttraining's l2: 0.354348\tvalid_1's l2: 0.349841\n",
      "[197]\ttraining's l2: 0.354325\tvalid_1's l2: 0.349833\n",
      "[198]\ttraining's l2: 0.354291\tvalid_1's l2: 0.349805\n",
      "[199]\ttraining's l2: 0.354236\tvalid_1's l2: 0.349722\n",
      "[200]\ttraining's l2: 0.35421\tvalid_1's l2: 0.349714\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.35421\tvalid_1's l2: 0.349714\n",
      "mean_14_sales: 7507690.39\n",
      "mean_7_sales: 3036666.05\n",
      "mean_30_sales: 2087189.89\n",
      "mean_3_sales: 1096191.01\n",
      "mean_21_sales: 947573.65\n",
      "mean_4_sales: 505898.49\n",
      "mean_20_dow5_2017: 437209.55\n",
      "promo_5: 364975.57\n",
      "mean_60_sales: 242516.76\n",
      "item_class_features: 180317.73\n",
      "mean_4_dow5_2017: 179865.91\n",
      "mean_5_sales: 168238.60\n",
      "mean_6_sales: 121574.74\n",
      "mean_63_sales: 121393.90\n",
      "mean_4_dow6_2017: 75874.72\n",
      "sum_2_promo: 46713.79\n",
      "promo_7: 45366.34\n",
      "std_21_sales: 37935.64\n",
      "std_14_sales: 34678.41\n",
      "promo_3: 29561.51\n",
      "sum_4_promo: 28034.71\n",
      "lag_56_sales: 22493.38\n",
      "promo_6: 20511.51\n",
      "std_30_sales: 19812.30\n",
      "item_family_features: 19058.58\n",
      "mean_20_dow6_2017: 18358.84\n",
      "store_cluster_features: 16035.54\n",
      "mean_20_dow0_2017: 15362.01\n",
      "store_city_features: 9763.18\n",
      "std_60_sales: 8542.76\n",
      "lag_1_sales: 8473.08\n",
      "lag_3_sales: 7497.77\n",
      "sum_7_promo: 7165.56\n",
      "std_63_sales: 7032.08\n",
      "promo_14: 6686.70\n",
      "promo_2: 6491.29\n",
      "sum_3_promo: 5989.78\n",
      "sum_14_promo: 5967.83\n",
      "sum_21_promo: 5397.29\n",
      "promo_1: 5066.99\n",
      "mean_20_dow3_2017: 4958.36\n",
      "promo_4: 4740.89\n",
      "lag_2_sales: 4437.90\n",
      "promo_0: 3792.96\n",
      "promo_11: 3654.80\n",
      "std_3_sales: 3501.59\n",
      "lag_7_sales: 3142.76\n",
      "std_7_sales: 2932.41\n",
      "promo_8: 2451.18\n",
      "mean_4_dow1_2017: 2366.26\n",
      "mean_4_dow0_2017: 2341.58\n",
      "promo_10: 2207.98\n",
      "lag_42_sales: 2201.69\n",
      "sum_6_promo: 2144.87\n",
      "mean_20_dow2_2017: 2121.73\n",
      "lag_21_sales: 2057.29\n",
      "std_5_sales: 1937.66\n",
      "std_6_sales: 1798.22\n",
      "sum_5_promo: 1757.19\n",
      "std_4_sales: 1731.47\n",
      "promo_12: 1703.87\n",
      "mean_4_dow4_2017: 1635.23\n",
      "store_type_features: 1548.23\n",
      "lag_14_sales: 1338.82\n",
      "lag_6_sales: 1284.01\n",
      "store_state_features: 1277.73\n",
      "promo_13: 1228.65\n",
      "lag_28_sales: 1226.92\n",
      "mean_20_dow4_2017: 1093.43\n",
      "mean_20_dow1_2017: 1041.82\n",
      "lag_4_sales: 1035.78\n",
      "lag_63_sales: 929.07\n",
      "mean_4_dow2_2017: 853.84\n",
      "promo_9: 743.46\n",
      "lag_5_sales: 641.87\n",
      "mean_4_dow3_2017: 512.54\n",
      "lag_49_sales: 451.25\n",
      "lag_35_sales: 365.85\n",
      "promo_15: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [06:23<10:30, 63.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.01784\tvalid_1's l2: 1.18317\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.957183\tvalid_1's l2: 1.11738\n",
      "[3]\ttraining's l2: 0.900769\tvalid_1's l2: 1.05651\n",
      "[4]\ttraining's l2: 0.849756\tvalid_1's l2: 1.00097\n",
      "[5]\ttraining's l2: 0.805054\tvalid_1's l2: 0.951482\n",
      "[6]\ttraining's l2: 0.763213\tvalid_1's l2: 0.90572\n",
      "[7]\ttraining's l2: 0.726316\tvalid_1's l2: 0.864695\n",
      "[8]\ttraining's l2: 0.691834\tvalid_1's l2: 0.826712\n",
      "[9]\ttraining's l2: 0.66056\tvalid_1's l2: 0.791987\n",
      "[10]\ttraining's l2: 0.633202\tvalid_1's l2: 0.761268\n",
      "[11]\ttraining's l2: 0.608481\tvalid_1's l2: 0.733267\n",
      "[12]\ttraining's l2: 0.585124\tvalid_1's l2: 0.70691\n",
      "[13]\ttraining's l2: 0.564703\tvalid_1's l2: 0.683444\n",
      "[14]\ttraining's l2: 0.546241\tvalid_1's l2: 0.662191\n",
      "[15]\ttraining's l2: 0.52865\tvalid_1's l2: 0.641941\n",
      "[16]\ttraining's l2: 0.513463\tvalid_1's l2: 0.624115\n",
      "[17]\ttraining's l2: 0.499784\tvalid_1's l2: 0.607906\n",
      "[18]\ttraining's l2: 0.486471\tvalid_1's l2: 0.592415\n",
      "[19]\ttraining's l2: 0.474424\tvalid_1's l2: 0.578365\n",
      "[20]\ttraining's l2: 0.463491\tvalid_1's l2: 0.565484\n",
      "[21]\ttraining's l2: 0.453619\tvalid_1's l2: 0.553719\n",
      "[22]\ttraining's l2: 0.444675\tvalid_1's l2: 0.542901\n",
      "[23]\ttraining's l2: 0.436461\tvalid_1's l2: 0.533069\n",
      "[24]\ttraining's l2: 0.429007\tvalid_1's l2: 0.523967\n",
      "[25]\ttraining's l2: 0.422143\tvalid_1's l2: 0.515682\n",
      "[26]\ttraining's l2: 0.416039\tvalid_1's l2: 0.508021\n",
      "[27]\ttraining's l2: 0.41047\tvalid_1's l2: 0.501029\n",
      "[28]\ttraining's l2: 0.40539\tvalid_1's l2: 0.494517\n",
      "[29]\ttraining's l2: 0.400994\tvalid_1's l2: 0.488737\n",
      "[30]\ttraining's l2: 0.39698\tvalid_1's l2: 0.4834\n",
      "[31]\ttraining's l2: 0.393099\tvalid_1's l2: 0.478418\n",
      "[32]\ttraining's l2: 0.389511\tvalid_1's l2: 0.473791\n",
      "[33]\ttraining's l2: 0.386293\tvalid_1's l2: 0.469514\n",
      "[34]\ttraining's l2: 0.383528\tvalid_1's l2: 0.465654\n",
      "[35]\ttraining's l2: 0.38075\tvalid_1's l2: 0.46197\n",
      "[36]\ttraining's l2: 0.378219\tvalid_1's l2: 0.458542\n",
      "[37]\ttraining's l2: 0.376056\tvalid_1's l2: 0.455453\n",
      "[38]\ttraining's l2: 0.373934\tvalid_1's l2: 0.452616\n",
      "[39]\ttraining's l2: 0.372045\tvalid_1's l2: 0.449978\n",
      "[40]\ttraining's l2: 0.370392\tvalid_1's l2: 0.447558\n",
      "[41]\ttraining's l2: 0.368701\tvalid_1's l2: 0.445184\n",
      "[42]\ttraining's l2: 0.367162\tvalid_1's l2: 0.443073\n",
      "[43]\ttraining's l2: 0.365735\tvalid_1's l2: 0.441094\n",
      "[44]\ttraining's l2: 0.364397\tvalid_1's l2: 0.439214\n",
      "[45]\ttraining's l2: 0.363148\tvalid_1's l2: 0.437344\n",
      "[46]\ttraining's l2: 0.362114\tvalid_1's l2: 0.435729\n",
      "[47]\ttraining's l2: 0.361065\tvalid_1's l2: 0.434233\n",
      "[48]\ttraining's l2: 0.360207\tvalid_1's l2: 0.432849\n",
      "[49]\ttraining's l2: 0.359404\tvalid_1's l2: 0.431618\n",
      "[50]\ttraining's l2: 0.358662\tvalid_1's l2: 0.430439\n",
      "[51]\ttraining's l2: 0.357838\tvalid_1's l2: 0.429245\n",
      "[52]\ttraining's l2: 0.35714\tvalid_1's l2: 0.428234\n",
      "[53]\ttraining's l2: 0.356407\tvalid_1's l2: 0.427151\n",
      "[54]\ttraining's l2: 0.355602\tvalid_1's l2: 0.426204\n",
      "[55]\ttraining's l2: 0.354848\tvalid_1's l2: 0.425196\n",
      "[56]\ttraining's l2: 0.354156\tvalid_1's l2: 0.424301\n",
      "[57]\ttraining's l2: 0.353607\tvalid_1's l2: 0.423479\n",
      "[58]\ttraining's l2: 0.353006\tvalid_1's l2: 0.422593\n",
      "[59]\ttraining's l2: 0.352477\tvalid_1's l2: 0.421907\n",
      "[60]\ttraining's l2: 0.352056\tvalid_1's l2: 0.421262\n",
      "[61]\ttraining's l2: 0.351628\tvalid_1's l2: 0.420543\n",
      "[62]\ttraining's l2: 0.351163\tvalid_1's l2: 0.420006\n",
      "[63]\ttraining's l2: 0.350777\tvalid_1's l2: 0.419429\n",
      "[64]\ttraining's l2: 0.350492\tvalid_1's l2: 0.418927\n",
      "[65]\ttraining's l2: 0.350035\tvalid_1's l2: 0.41835\n",
      "[66]\ttraining's l2: 0.349675\tvalid_1's l2: 0.417925\n",
      "[67]\ttraining's l2: 0.34927\tvalid_1's l2: 0.417392\n",
      "[68]\ttraining's l2: 0.3489\tvalid_1's l2: 0.416978\n",
      "[69]\ttraining's l2: 0.348625\tvalid_1's l2: 0.416541\n",
      "[70]\ttraining's l2: 0.348381\tvalid_1's l2: 0.416256\n",
      "[71]\ttraining's l2: 0.347993\tvalid_1's l2: 0.415776\n",
      "[72]\ttraining's l2: 0.34773\tvalid_1's l2: 0.415447\n",
      "[73]\ttraining's l2: 0.347551\tvalid_1's l2: 0.415206\n",
      "[74]\ttraining's l2: 0.347336\tvalid_1's l2: 0.414877\n",
      "[75]\ttraining's l2: 0.347038\tvalid_1's l2: 0.414512\n",
      "[76]\ttraining's l2: 0.346693\tvalid_1's l2: 0.414189\n",
      "[77]\ttraining's l2: 0.346481\tvalid_1's l2: 0.413895\n",
      "[78]\ttraining's l2: 0.346177\tvalid_1's l2: 0.413634\n",
      "[79]\ttraining's l2: 0.345995\tvalid_1's l2: 0.413383\n",
      "[80]\ttraining's l2: 0.345819\tvalid_1's l2: 0.413127\n",
      "[81]\ttraining's l2: 0.345606\tvalid_1's l2: 0.412916\n",
      "[82]\ttraining's l2: 0.345398\tvalid_1's l2: 0.412724\n",
      "[83]\ttraining's l2: 0.345201\tvalid_1's l2: 0.412459\n",
      "[84]\ttraining's l2: 0.345016\tvalid_1's l2: 0.412279\n",
      "[85]\ttraining's l2: 0.344833\tvalid_1's l2: 0.412158\n",
      "[86]\ttraining's l2: 0.344666\tvalid_1's l2: 0.412045\n",
      "[87]\ttraining's l2: 0.344468\tvalid_1's l2: 0.411784\n",
      "[88]\ttraining's l2: 0.344285\tvalid_1's l2: 0.411586\n",
      "[89]\ttraining's l2: 0.344142\tvalid_1's l2: 0.411432\n",
      "[90]\ttraining's l2: 0.343996\tvalid_1's l2: 0.41128\n",
      "[91]\ttraining's l2: 0.343872\tvalid_1's l2: 0.411222\n",
      "[92]\ttraining's l2: 0.343758\tvalid_1's l2: 0.411103\n",
      "[93]\ttraining's l2: 0.343622\tvalid_1's l2: 0.410955\n",
      "[94]\ttraining's l2: 0.343517\tvalid_1's l2: 0.410821\n",
      "[95]\ttraining's l2: 0.343373\tvalid_1's l2: 0.410656\n",
      "[96]\ttraining's l2: 0.343238\tvalid_1's l2: 0.410531\n",
      "[97]\ttraining's l2: 0.343076\tvalid_1's l2: 0.410451\n",
      "[98]\ttraining's l2: 0.342908\tvalid_1's l2: 0.410356\n",
      "[99]\ttraining's l2: 0.342811\tvalid_1's l2: 0.410242\n",
      "[100]\ttraining's l2: 0.342545\tvalid_1's l2: 0.410168\n",
      "[101]\ttraining's l2: 0.342391\tvalid_1's l2: 0.409954\n",
      "[102]\ttraining's l2: 0.342214\tvalid_1's l2: 0.409879\n",
      "[103]\ttraining's l2: 0.34214\tvalid_1's l2: 0.409833\n",
      "[104]\ttraining's l2: 0.34199\tvalid_1's l2: 0.409794\n",
      "[105]\ttraining's l2: 0.341809\tvalid_1's l2: 0.409698\n",
      "[106]\ttraining's l2: 0.341652\tvalid_1's l2: 0.409634\n",
      "[107]\ttraining's l2: 0.341576\tvalid_1's l2: 0.409567\n",
      "[108]\ttraining's l2: 0.34137\tvalid_1's l2: 0.409504\n",
      "[109]\ttraining's l2: 0.341286\tvalid_1's l2: 0.409411\n",
      "[110]\ttraining's l2: 0.341198\tvalid_1's l2: 0.409376\n",
      "[111]\ttraining's l2: 0.341058\tvalid_1's l2: 0.409241\n",
      "[112]\ttraining's l2: 0.340984\tvalid_1's l2: 0.409204\n",
      "[113]\ttraining's l2: 0.340911\tvalid_1's l2: 0.40914\n",
      "[114]\ttraining's l2: 0.340815\tvalid_1's l2: 0.409053\n",
      "[115]\ttraining's l2: 0.34075\tvalid_1's l2: 0.409021\n",
      "[116]\ttraining's l2: 0.340665\tvalid_1's l2: 0.408956\n",
      "[117]\ttraining's l2: 0.340588\tvalid_1's l2: 0.408888\n",
      "[118]\ttraining's l2: 0.340404\tvalid_1's l2: 0.408828\n",
      "[119]\ttraining's l2: 0.340291\tvalid_1's l2: 0.408789\n",
      "[120]\ttraining's l2: 0.340216\tvalid_1's l2: 0.408749\n",
      "[121]\ttraining's l2: 0.340162\tvalid_1's l2: 0.408722\n",
      "[122]\ttraining's l2: 0.340117\tvalid_1's l2: 0.408688\n",
      "[123]\ttraining's l2: 0.34006\tvalid_1's l2: 0.408654\n",
      "[124]\ttraining's l2: 0.339975\tvalid_1's l2: 0.408593\n",
      "[125]\ttraining's l2: 0.339885\tvalid_1's l2: 0.408532\n",
      "[126]\ttraining's l2: 0.339791\tvalid_1's l2: 0.408476\n",
      "[127]\ttraining's l2: 0.33973\tvalid_1's l2: 0.408547\n",
      "[128]\ttraining's l2: 0.339651\tvalid_1's l2: 0.408486\n",
      "[129]\ttraining's l2: 0.339581\tvalid_1's l2: 0.408459\n",
      "[130]\ttraining's l2: 0.339528\tvalid_1's l2: 0.408446\n",
      "[131]\ttraining's l2: 0.339464\tvalid_1's l2: 0.408396\n",
      "[132]\ttraining's l2: 0.339372\tvalid_1's l2: 0.40831\n",
      "[133]\ttraining's l2: 0.339309\tvalid_1's l2: 0.408282\n",
      "[134]\ttraining's l2: 0.339191\tvalid_1's l2: 0.408332\n",
      "[135]\ttraining's l2: 0.339101\tvalid_1's l2: 0.408309\n",
      "[136]\ttraining's l2: 0.339011\tvalid_1's l2: 0.408315\n",
      "[137]\ttraining's l2: 0.338967\tvalid_1's l2: 0.408295\n",
      "[138]\ttraining's l2: 0.338926\tvalid_1's l2: 0.408279\n",
      "[139]\ttraining's l2: 0.338875\tvalid_1's l2: 0.408245\n",
      "[140]\ttraining's l2: 0.338823\tvalid_1's l2: 0.408225\n",
      "[141]\ttraining's l2: 0.338725\tvalid_1's l2: 0.408155\n",
      "[142]\ttraining's l2: 0.338683\tvalid_1's l2: 0.408126\n",
      "[143]\ttraining's l2: 0.338618\tvalid_1's l2: 0.408083\n",
      "[144]\ttraining's l2: 0.338562\tvalid_1's l2: 0.408159\n",
      "[145]\ttraining's l2: 0.338529\tvalid_1's l2: 0.408153\n",
      "[146]\ttraining's l2: 0.338468\tvalid_1's l2: 0.408127\n",
      "[147]\ttraining's l2: 0.338335\tvalid_1's l2: 0.408162\n",
      "[148]\ttraining's l2: 0.338293\tvalid_1's l2: 0.408149\n",
      "[149]\ttraining's l2: 0.338243\tvalid_1's l2: 0.40827\n",
      "[150]\ttraining's l2: 0.338185\tvalid_1's l2: 0.408233\n",
      "[151]\ttraining's l2: 0.338095\tvalid_1's l2: 0.408247\n",
      "[152]\ttraining's l2: 0.338039\tvalid_1's l2: 0.408247\n",
      "[153]\ttraining's l2: 0.337974\tvalid_1's l2: 0.408264\n",
      "[154]\ttraining's l2: 0.337902\tvalid_1's l2: 0.40834\n",
      "[155]\ttraining's l2: 0.337862\tvalid_1's l2: 0.408357\n",
      "[156]\ttraining's l2: 0.337819\tvalid_1's l2: 0.40835\n",
      "[157]\ttraining's l2: 0.337791\tvalid_1's l2: 0.408342\n",
      "[158]\ttraining's l2: 0.337756\tvalid_1's l2: 0.408326\n",
      "[159]\ttraining's l2: 0.337719\tvalid_1's l2: 0.408327\n",
      "[160]\ttraining's l2: 0.337676\tvalid_1's l2: 0.408291\n",
      "[161]\ttraining's l2: 0.337589\tvalid_1's l2: 0.408264\n",
      "[162]\ttraining's l2: 0.337554\tvalid_1's l2: 0.408229\n",
      "[163]\ttraining's l2: 0.33752\tvalid_1's l2: 0.40822\n",
      "[164]\ttraining's l2: 0.337436\tvalid_1's l2: 0.408235\n",
      "[165]\ttraining's l2: 0.337365\tvalid_1's l2: 0.408245\n",
      "[166]\ttraining's l2: 0.337333\tvalid_1's l2: 0.408232\n",
      "[167]\ttraining's l2: 0.337276\tvalid_1's l2: 0.408206\n",
      "[168]\ttraining's l2: 0.337232\tvalid_1's l2: 0.408211\n",
      "[169]\ttraining's l2: 0.337189\tvalid_1's l2: 0.408198\n",
      "[170]\ttraining's l2: 0.33714\tvalid_1's l2: 0.408194\n",
      "[171]\ttraining's l2: 0.337105\tvalid_1's l2: 0.408188\n",
      "[172]\ttraining's l2: 0.337067\tvalid_1's l2: 0.4082\n",
      "[173]\ttraining's l2: 0.337035\tvalid_1's l2: 0.408174\n",
      "[174]\ttraining's l2: 0.336996\tvalid_1's l2: 0.408161\n",
      "[175]\ttraining's l2: 0.336968\tvalid_1's l2: 0.408152\n",
      "[176]\ttraining's l2: 0.33694\tvalid_1's l2: 0.408134\n",
      "[177]\ttraining's l2: 0.336906\tvalid_1's l2: 0.408124\n",
      "[178]\ttraining's l2: 0.336873\tvalid_1's l2: 0.408132\n",
      "[179]\ttraining's l2: 0.336815\tvalid_1's l2: 0.408081\n",
      "[180]\ttraining's l2: 0.336783\tvalid_1's l2: 0.408066\n",
      "[181]\ttraining's l2: 0.336744\tvalid_1's l2: 0.408063\n",
      "[182]\ttraining's l2: 0.33671\tvalid_1's l2: 0.408054\n",
      "[183]\ttraining's l2: 0.336683\tvalid_1's l2: 0.40804\n",
      "[184]\ttraining's l2: 0.33666\tvalid_1's l2: 0.408039\n",
      "[185]\ttraining's l2: 0.336602\tvalid_1's l2: 0.408033\n",
      "[186]\ttraining's l2: 0.336574\tvalid_1's l2: 0.407999\n",
      "[187]\ttraining's l2: 0.336551\tvalid_1's l2: 0.407987\n",
      "[188]\ttraining's l2: 0.336525\tvalid_1's l2: 0.407991\n",
      "[189]\ttraining's l2: 0.336494\tvalid_1's l2: 0.407984\n",
      "[190]\ttraining's l2: 0.336413\tvalid_1's l2: 0.408016\n",
      "[191]\ttraining's l2: 0.336351\tvalid_1's l2: 0.408037\n",
      "[192]\ttraining's l2: 0.336323\tvalid_1's l2: 0.40803\n",
      "[193]\ttraining's l2: 0.336246\tvalid_1's l2: 0.408065\n",
      "[194]\ttraining's l2: 0.336218\tvalid_1's l2: 0.408046\n",
      "[195]\ttraining's l2: 0.336194\tvalid_1's l2: 0.40805\n",
      "[196]\ttraining's l2: 0.33613\tvalid_1's l2: 0.408082\n",
      "[197]\ttraining's l2: 0.336093\tvalid_1's l2: 0.408062\n",
      "[198]\ttraining's l2: 0.336062\tvalid_1's l2: 0.408048\n",
      "[199]\ttraining's l2: 0.336023\tvalid_1's l2: 0.408031\n",
      "[200]\ttraining's l2: 0.335978\tvalid_1's l2: 0.408007\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.335978\tvalid_1's l2: 0.408007\n",
      "mean_14_sales: 7103498.10\n",
      "mean_7_sales: 2952068.44\n",
      "mean_30_sales: 1773411.23\n",
      "mean_21_sales: 813818.52\n",
      "mean_20_dow6_2017: 732677.04\n",
      "mean_4_dow6_2017: 723287.38\n",
      "mean_3_sales: 655807.37\n",
      "promo_6: 531150.03\n",
      "mean_6_sales: 310386.69\n",
      "item_class_features: 179505.28\n",
      "mean_60_sales: 103048.68\n",
      "mean_4_sales: 102674.24\n",
      "promo_7: 66454.33\n",
      "mean_63_sales: 61686.49\n",
      "lag_1_sales: 50033.51\n",
      "mean_5_sales: 42491.29\n",
      "promo_3: 36028.93\n",
      "sum_4_promo: 35845.13\n",
      "std_30_sales: 34798.59\n",
      "std_21_sales: 34526.94\n",
      "item_family_features: 34388.80\n",
      "sum_2_promo: 26159.55\n",
      "promo_5: 24366.83\n",
      "mean_20_dow5_2017: 24156.22\n",
      "promo_13: 23945.95\n",
      "std_14_sales: 23104.87\n",
      "mean_4_dow5_2017: 22226.54\n",
      "lag_56_sales: 14689.75\n",
      "store_cluster_features: 14579.48\n",
      "std_63_sales: 13477.76\n",
      "mean_20_dow0_2017: 12420.66\n",
      "store_city_features: 10341.63\n",
      "mean_20_dow1_2017: 10205.01\n",
      "sum_14_promo: 10021.49\n",
      "std_60_sales: 9762.70\n",
      "sum_7_promo: 9106.72\n",
      "sum_3_promo: 9024.95\n",
      "promo_14: 7792.61\n",
      "store_type_features: 7698.32\n",
      "promo_4: 6818.89\n",
      "std_7_sales: 6749.41\n",
      "promo_1: 5150.90\n",
      "promo_0: 4951.84\n",
      "promo_2: 4716.74\n",
      "sum_21_promo: 4205.91\n",
      "mean_20_dow3_2017: 4133.45\n",
      "mean_4_dow1_2017: 3706.68\n",
      "lag_42_sales: 2895.04\n",
      "sum_5_promo: 2844.94\n",
      "lag_3_sales: 2807.00\n",
      "mean_20_dow4_2017: 2510.80\n",
      "promo_11: 2310.39\n",
      "std_3_sales: 2206.38\n",
      "lag_28_sales: 2131.43\n",
      "mean_4_dow0_2017: 2005.34\n",
      "lag_2_sales: 2003.54\n",
      "std_6_sales: 1920.84\n",
      "std_4_sales: 1740.22\n",
      "lag_6_sales: 1620.74\n",
      "sum_6_promo: 1497.07\n",
      "promo_8: 1478.14\n",
      "promo_10: 1423.52\n",
      "lag_5_sales: 1415.68\n",
      "lag_7_sales: 1375.20\n",
      "lag_4_sales: 1305.65\n",
      "store_state_features: 1268.76\n",
      "promo_9: 1248.13\n",
      "lag_21_sales: 1205.47\n",
      "mean_20_dow2_2017: 1063.15\n",
      "mean_4_dow2_2017: 987.06\n",
      "std_5_sales: 945.76\n",
      "mean_4_dow4_2017: 914.70\n",
      "mean_4_dow3_2017: 723.40\n",
      "lag_35_sales: 672.79\n",
      "lag_14_sales: 615.85\n",
      "lag_63_sales: 407.31\n",
      "lag_49_sales: 293.12\n",
      "promo_15: 215.51\n",
      "promo_12: 160.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [07:25<09:26, 62.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.04378\tvalid_1's l2: 1.16233\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.980812\tvalid_1's l2: 1.09579\n",
      "[3]\ttraining's l2: 0.92141\tvalid_1's l2: 1.03349\n",
      "[4]\ttraining's l2: 0.867666\tvalid_1's l2: 0.976639\n",
      "[5]\ttraining's l2: 0.818964\tvalid_1's l2: 0.925224\n",
      "[6]\ttraining's l2: 0.776933\tvalid_1's l2: 0.87967\n",
      "[7]\ttraining's l2: 0.736731\tvalid_1's l2: 0.837003\n",
      "[8]\ttraining's l2: 0.702363\tvalid_1's l2: 0.799586\n",
      "[9]\ttraining's l2: 0.669255\tvalid_1's l2: 0.764372\n",
      "[10]\ttraining's l2: 0.64078\tvalid_1's l2: 0.733313\n",
      "[11]\ttraining's l2: 0.615068\tvalid_1's l2: 0.705125\n",
      "[12]\ttraining's l2: 0.591915\tvalid_1's l2: 0.679664\n",
      "[13]\ttraining's l2: 0.569199\tvalid_1's l2: 0.655014\n",
      "[14]\ttraining's l2: 0.548351\tvalid_1's l2: 0.632466\n",
      "[15]\ttraining's l2: 0.53103\tvalid_1's l2: 0.613152\n",
      "[16]\ttraining's l2: 0.513788\tvalid_1's l2: 0.594527\n",
      "[17]\ttraining's l2: 0.498277\tvalid_1's l2: 0.577655\n",
      "[18]\ttraining's l2: 0.485415\tvalid_1's l2: 0.562823\n",
      "[19]\ttraining's l2: 0.472352\tvalid_1's l2: 0.548489\n",
      "[20]\ttraining's l2: 0.460518\tvalid_1's l2: 0.535533\n",
      "[21]\ttraining's l2: 0.449829\tvalid_1's l2: 0.523766\n",
      "[22]\ttraining's l2: 0.440109\tvalid_1's l2: 0.512745\n",
      "[23]\ttraining's l2: 0.431196\tvalid_1's l2: 0.502847\n",
      "[24]\ttraining's l2: 0.42393\tvalid_1's l2: 0.4942\n",
      "[25]\ttraining's l2: 0.416536\tvalid_1's l2: 0.485704\n",
      "[26]\ttraining's l2: 0.409714\tvalid_1's l2: 0.477879\n",
      "[27]\ttraining's l2: 0.403627\tvalid_1's l2: 0.470761\n",
      "[28]\ttraining's l2: 0.398675\tvalid_1's l2: 0.464779\n",
      "[29]\ttraining's l2: 0.393473\tvalid_1's l2: 0.458852\n",
      "[30]\ttraining's l2: 0.388825\tvalid_1's l2: 0.453322\n",
      "[31]\ttraining's l2: 0.385041\tvalid_1's l2: 0.448574\n",
      "[32]\ttraining's l2: 0.381007\tvalid_1's l2: 0.443862\n",
      "[33]\ttraining's l2: 0.377346\tvalid_1's l2: 0.439464\n",
      "[34]\ttraining's l2: 0.374035\tvalid_1's l2: 0.43531\n",
      "[35]\ttraining's l2: 0.370965\tvalid_1's l2: 0.431563\n",
      "[36]\ttraining's l2: 0.368176\tvalid_1's l2: 0.428185\n",
      "[37]\ttraining's l2: 0.365693\tvalid_1's l2: 0.425012\n",
      "[38]\ttraining's l2: 0.363689\tvalid_1's l2: 0.422392\n",
      "[39]\ttraining's l2: 0.361491\tvalid_1's l2: 0.419721\n",
      "[40]\ttraining's l2: 0.359511\tvalid_1's l2: 0.417224\n",
      "[41]\ttraining's l2: 0.357973\tvalid_1's l2: 0.415164\n",
      "[42]\ttraining's l2: 0.356183\tvalid_1's l2: 0.412931\n",
      "[43]\ttraining's l2: 0.354613\tvalid_1's l2: 0.410859\n",
      "[44]\ttraining's l2: 0.353172\tvalid_1's l2: 0.408932\n",
      "[45]\ttraining's l2: 0.351758\tvalid_1's l2: 0.407124\n",
      "[46]\ttraining's l2: 0.3505\tvalid_1's l2: 0.405434\n",
      "[47]\ttraining's l2: 0.349533\tvalid_1's l2: 0.404128\n",
      "[48]\ttraining's l2: 0.348374\tvalid_1's l2: 0.402585\n",
      "[49]\ttraining's l2: 0.347361\tvalid_1's l2: 0.401261\n",
      "[50]\ttraining's l2: 0.346333\tvalid_1's l2: 0.400011\n",
      "[51]\ttraining's l2: 0.345402\tvalid_1's l2: 0.39883\n",
      "[52]\ttraining's l2: 0.344576\tvalid_1's l2: 0.397683\n",
      "[53]\ttraining's l2: 0.343789\tvalid_1's l2: 0.396594\n",
      "[54]\ttraining's l2: 0.343025\tvalid_1's l2: 0.395635\n",
      "[55]\ttraining's l2: 0.342316\tvalid_1's l2: 0.39477\n",
      "[56]\ttraining's l2: 0.341713\tvalid_1's l2: 0.39396\n",
      "[57]\ttraining's l2: 0.341263\tvalid_1's l2: 0.393252\n",
      "[58]\ttraining's l2: 0.340701\tvalid_1's l2: 0.392563\n",
      "[59]\ttraining's l2: 0.340172\tvalid_1's l2: 0.391888\n",
      "[60]\ttraining's l2: 0.339752\tvalid_1's l2: 0.391365\n",
      "[61]\ttraining's l2: 0.339292\tvalid_1's l2: 0.39076\n",
      "[62]\ttraining's l2: 0.338851\tvalid_1's l2: 0.390189\n",
      "[63]\ttraining's l2: 0.338547\tvalid_1's l2: 0.389754\n",
      "[64]\ttraining's l2: 0.338257\tvalid_1's l2: 0.389327\n",
      "[65]\ttraining's l2: 0.33774\tvalid_1's l2: 0.388676\n",
      "[66]\ttraining's l2: 0.33746\tvalid_1's l2: 0.388332\n",
      "[67]\ttraining's l2: 0.337033\tvalid_1's l2: 0.387948\n",
      "[68]\ttraining's l2: 0.336598\tvalid_1's l2: 0.387699\n",
      "[69]\ttraining's l2: 0.336355\tvalid_1's l2: 0.387392\n",
      "[70]\ttraining's l2: 0.336077\tvalid_1's l2: 0.387091\n",
      "[71]\ttraining's l2: 0.335715\tvalid_1's l2: 0.386675\n",
      "[72]\ttraining's l2: 0.335492\tvalid_1's l2: 0.386396\n",
      "[73]\ttraining's l2: 0.335292\tvalid_1's l2: 0.386158\n",
      "[74]\ttraining's l2: 0.334901\tvalid_1's l2: 0.385717\n",
      "[75]\ttraining's l2: 0.334526\tvalid_1's l2: 0.385369\n",
      "[76]\ttraining's l2: 0.334187\tvalid_1's l2: 0.384958\n",
      "[77]\ttraining's l2: 0.333883\tvalid_1's l2: 0.384574\n",
      "[78]\ttraining's l2: 0.333622\tvalid_1's l2: 0.384325\n",
      "[79]\ttraining's l2: 0.333397\tvalid_1's l2: 0.384026\n",
      "[80]\ttraining's l2: 0.333178\tvalid_1's l2: 0.383761\n",
      "[81]\ttraining's l2: 0.333022\tvalid_1's l2: 0.383559\n",
      "[82]\ttraining's l2: 0.332801\tvalid_1's l2: 0.383267\n",
      "[83]\ttraining's l2: 0.33258\tvalid_1's l2: 0.383071\n",
      "[84]\ttraining's l2: 0.332432\tvalid_1's l2: 0.382912\n",
      "[85]\ttraining's l2: 0.332301\tvalid_1's l2: 0.382773\n",
      "[86]\ttraining's l2: 0.332043\tvalid_1's l2: 0.382559\n",
      "[87]\ttraining's l2: 0.331871\tvalid_1's l2: 0.382414\n",
      "[88]\ttraining's l2: 0.331683\tvalid_1's l2: 0.382147\n",
      "[89]\ttraining's l2: 0.331524\tvalid_1's l2: 0.38195\n",
      "[90]\ttraining's l2: 0.331321\tvalid_1's l2: 0.381739\n",
      "[91]\ttraining's l2: 0.331198\tvalid_1's l2: 0.381582\n",
      "[92]\ttraining's l2: 0.331083\tvalid_1's l2: 0.381445\n",
      "[93]\ttraining's l2: 0.330932\tvalid_1's l2: 0.381268\n",
      "[94]\ttraining's l2: 0.330731\tvalid_1's l2: 0.381158\n",
      "[95]\ttraining's l2: 0.330521\tvalid_1's l2: 0.380942\n",
      "[96]\ttraining's l2: 0.330376\tvalid_1's l2: 0.380803\n",
      "[97]\ttraining's l2: 0.330233\tvalid_1's l2: 0.380669\n",
      "[98]\ttraining's l2: 0.330127\tvalid_1's l2: 0.380552\n",
      "[99]\ttraining's l2: 0.33002\tvalid_1's l2: 0.380435\n",
      "[100]\ttraining's l2: 0.329925\tvalid_1's l2: 0.380342\n",
      "[101]\ttraining's l2: 0.329765\tvalid_1's l2: 0.38024\n",
      "[102]\ttraining's l2: 0.32965\tvalid_1's l2: 0.380127\n",
      "[103]\ttraining's l2: 0.32956\tvalid_1's l2: 0.380043\n",
      "[104]\ttraining's l2: 0.329464\tvalid_1's l2: 0.379959\n",
      "[105]\ttraining's l2: 0.329344\tvalid_1's l2: 0.379841\n",
      "[106]\ttraining's l2: 0.329197\tvalid_1's l2: 0.379806\n",
      "[107]\ttraining's l2: 0.329113\tvalid_1's l2: 0.379752\n",
      "[108]\ttraining's l2: 0.329021\tvalid_1's l2: 0.379672\n",
      "[109]\ttraining's l2: 0.328889\tvalid_1's l2: 0.379601\n",
      "[110]\ttraining's l2: 0.328815\tvalid_1's l2: 0.379558\n",
      "[111]\ttraining's l2: 0.328724\tvalid_1's l2: 0.379495\n",
      "[112]\ttraining's l2: 0.328609\tvalid_1's l2: 0.379405\n",
      "[113]\ttraining's l2: 0.328513\tvalid_1's l2: 0.37931\n",
      "[114]\ttraining's l2: 0.32841\tvalid_1's l2: 0.379221\n",
      "[115]\ttraining's l2: 0.328351\tvalid_1's l2: 0.37922\n",
      "[116]\ttraining's l2: 0.328287\tvalid_1's l2: 0.379208\n",
      "[117]\ttraining's l2: 0.328204\tvalid_1's l2: 0.379147\n",
      "[118]\ttraining's l2: 0.3281\tvalid_1's l2: 0.379053\n",
      "[119]\ttraining's l2: 0.328019\tvalid_1's l2: 0.379013\n",
      "[120]\ttraining's l2: 0.327938\tvalid_1's l2: 0.378969\n",
      "[121]\ttraining's l2: 0.327862\tvalid_1's l2: 0.37892\n",
      "[122]\ttraining's l2: 0.327815\tvalid_1's l2: 0.378884\n",
      "[123]\ttraining's l2: 0.327721\tvalid_1's l2: 0.378784\n",
      "[124]\ttraining's l2: 0.32763\tvalid_1's l2: 0.378665\n",
      "[125]\ttraining's l2: 0.327549\tvalid_1's l2: 0.378617\n",
      "[126]\ttraining's l2: 0.327478\tvalid_1's l2: 0.378544\n",
      "[127]\ttraining's l2: 0.327356\tvalid_1's l2: 0.378339\n",
      "[128]\ttraining's l2: 0.327295\tvalid_1's l2: 0.378315\n",
      "[129]\ttraining's l2: 0.327232\tvalid_1's l2: 0.378267\n",
      "[130]\ttraining's l2: 0.327168\tvalid_1's l2: 0.378229\n",
      "[131]\ttraining's l2: 0.32709\tvalid_1's l2: 0.378149\n",
      "[132]\ttraining's l2: 0.32704\tvalid_1's l2: 0.378141\n",
      "[133]\ttraining's l2: 0.326978\tvalid_1's l2: 0.378115\n",
      "[134]\ttraining's l2: 0.326927\tvalid_1's l2: 0.378132\n",
      "[135]\ttraining's l2: 0.326852\tvalid_1's l2: 0.378113\n",
      "[136]\ttraining's l2: 0.326805\tvalid_1's l2: 0.37806\n",
      "[137]\ttraining's l2: 0.32673\tvalid_1's l2: 0.378033\n",
      "[138]\ttraining's l2: 0.326689\tvalid_1's l2: 0.378013\n",
      "[139]\ttraining's l2: 0.32663\tvalid_1's l2: 0.377998\n",
      "[140]\ttraining's l2: 0.326569\tvalid_1's l2: 0.377961\n",
      "[141]\ttraining's l2: 0.326505\tvalid_1's l2: 0.377896\n",
      "[142]\ttraining's l2: 0.32645\tvalid_1's l2: 0.377885\n",
      "[143]\ttraining's l2: 0.326395\tvalid_1's l2: 0.377877\n",
      "[144]\ttraining's l2: 0.326314\tvalid_1's l2: 0.377788\n",
      "[145]\ttraining's l2: 0.326261\tvalid_1's l2: 0.377763\n",
      "[146]\ttraining's l2: 0.326206\tvalid_1's l2: 0.37775\n",
      "[147]\ttraining's l2: 0.326142\tvalid_1's l2: 0.377691\n",
      "[148]\ttraining's l2: 0.326086\tvalid_1's l2: 0.377665\n",
      "[149]\ttraining's l2: 0.326036\tvalid_1's l2: 0.377679\n",
      "[150]\ttraining's l2: 0.325972\tvalid_1's l2: 0.377671\n",
      "[151]\ttraining's l2: 0.325935\tvalid_1's l2: 0.37767\n",
      "[152]\ttraining's l2: 0.325892\tvalid_1's l2: 0.377652\n",
      "[153]\ttraining's l2: 0.325797\tvalid_1's l2: 0.377548\n",
      "[154]\ttraining's l2: 0.325757\tvalid_1's l2: 0.377535\n",
      "[155]\ttraining's l2: 0.325713\tvalid_1's l2: 0.37754\n",
      "[156]\ttraining's l2: 0.32565\tvalid_1's l2: 0.377485\n",
      "[157]\ttraining's l2: 0.325563\tvalid_1's l2: 0.377427\n",
      "[158]\ttraining's l2: 0.325485\tvalid_1's l2: 0.377368\n",
      "[159]\ttraining's l2: 0.32544\tvalid_1's l2: 0.377356\n",
      "[160]\ttraining's l2: 0.325387\tvalid_1's l2: 0.377345\n",
      "[161]\ttraining's l2: 0.325334\tvalid_1's l2: 0.377343\n",
      "[162]\ttraining's l2: 0.325273\tvalid_1's l2: 0.377308\n",
      "[163]\ttraining's l2: 0.325229\tvalid_1's l2: 0.377307\n",
      "[164]\ttraining's l2: 0.325179\tvalid_1's l2: 0.377282\n",
      "[165]\ttraining's l2: 0.32515\tvalid_1's l2: 0.377253\n",
      "[166]\ttraining's l2: 0.325098\tvalid_1's l2: 0.37724\n",
      "[167]\ttraining's l2: 0.325058\tvalid_1's l2: 0.377232\n",
      "[168]\ttraining's l2: 0.325025\tvalid_1's l2: 0.377222\n",
      "[169]\ttraining's l2: 0.324974\tvalid_1's l2: 0.377217\n",
      "[170]\ttraining's l2: 0.324932\tvalid_1's l2: 0.377204\n",
      "[171]\ttraining's l2: 0.324875\tvalid_1's l2: 0.377169\n",
      "[172]\ttraining's l2: 0.324836\tvalid_1's l2: 0.377155\n",
      "[173]\ttraining's l2: 0.32478\tvalid_1's l2: 0.377111\n",
      "[174]\ttraining's l2: 0.324729\tvalid_1's l2: 0.377051\n",
      "[175]\ttraining's l2: 0.324682\tvalid_1's l2: 0.377003\n",
      "[176]\ttraining's l2: 0.324608\tvalid_1's l2: 0.37697\n",
      "[177]\ttraining's l2: 0.324575\tvalid_1's l2: 0.376975\n",
      "[178]\ttraining's l2: 0.324524\tvalid_1's l2: 0.376969\n",
      "[179]\ttraining's l2: 0.324472\tvalid_1's l2: 0.376951\n",
      "[180]\ttraining's l2: 0.324431\tvalid_1's l2: 0.376955\n",
      "[181]\ttraining's l2: 0.324392\tvalid_1's l2: 0.376954\n",
      "[182]\ttraining's l2: 0.324356\tvalid_1's l2: 0.376937\n",
      "[183]\ttraining's l2: 0.324317\tvalid_1's l2: 0.376933\n",
      "[184]\ttraining's l2: 0.324275\tvalid_1's l2: 0.376903\n",
      "[185]\ttraining's l2: 0.324242\tvalid_1's l2: 0.376878\n",
      "[186]\ttraining's l2: 0.324212\tvalid_1's l2: 0.376881\n",
      "[187]\ttraining's l2: 0.324177\tvalid_1's l2: 0.376862\n",
      "[188]\ttraining's l2: 0.324142\tvalid_1's l2: 0.376842\n",
      "[189]\ttraining's l2: 0.324116\tvalid_1's l2: 0.37684\n",
      "[190]\ttraining's l2: 0.32409\tvalid_1's l2: 0.376829\n",
      "[191]\ttraining's l2: 0.324038\tvalid_1's l2: 0.376734\n",
      "[192]\ttraining's l2: 0.323998\tvalid_1's l2: 0.376708\n",
      "[193]\ttraining's l2: 0.323967\tvalid_1's l2: 0.376713\n",
      "[194]\ttraining's l2: 0.32394\tvalid_1's l2: 0.376696\n",
      "[195]\ttraining's l2: 0.323897\tvalid_1's l2: 0.37664\n",
      "[196]\ttraining's l2: 0.323869\tvalid_1's l2: 0.376641\n",
      "[197]\ttraining's l2: 0.323842\tvalid_1's l2: 0.376632\n",
      "[198]\ttraining's l2: 0.323764\tvalid_1's l2: 0.37648\n",
      "[199]\ttraining's l2: 0.323726\tvalid_1's l2: 0.376469\n",
      "[200]\ttraining's l2: 0.323688\tvalid_1's l2: 0.376462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.323688\tvalid_1's l2: 0.376462\n",
      "mean_14_sales: 6782020.75\n",
      "mean_7_sales: 4440248.20\n",
      "mean_30_sales: 1697808.15\n",
      "mean_21_sales: 1266671.34\n",
      "mean_20_dow0_2017: 992693.06\n",
      "promo_7: 777986.82\n",
      "mean_4_dow0_2017: 252900.92\n",
      "item_class_features: 210468.76\n",
      "mean_63_sales: 164209.23\n",
      "promo_0: 91141.62\n",
      "sum_7_promo: 78055.27\n",
      "mean_3_sales: 68703.63\n",
      "lag_1_sales: 65699.36\n",
      "promo_14: 55909.85\n",
      "item_family_features: 52393.55\n",
      "mean_5_sales: 50172.05\n",
      "store_cluster_features: 47811.50\n",
      "mean_6_sales: 43476.45\n",
      "std_21_sales: 38358.14\n",
      "std_14_sales: 35217.06\n",
      "mean_4_dow6_2017: 32931.39\n",
      "lag_56_sales: 30584.85\n",
      "std_30_sales: 30281.50\n",
      "sum_14_promo: 27084.59\n",
      "mean_60_sales: 26825.84\n",
      "std_63_sales: 24379.34\n",
      "promo_6: 19497.10\n",
      "std_60_sales: 18400.37\n",
      "store_type_features: 16022.82\n",
      "promo_3: 15658.71\n",
      "store_city_features: 15248.98\n",
      "promo_5: 14539.08\n",
      "sum_21_promo: 13723.89\n",
      "mean_4_sales: 13555.28\n",
      "mean_4_dow5_2017: 12859.01\n",
      "lag_21_sales: 12357.10\n",
      "std_7_sales: 12031.51\n",
      "promo_8: 11324.84\n",
      "mean_20_dow1_2017: 8169.13\n",
      "lag_7_sales: 8106.96\n",
      "promo_4: 6157.06\n",
      "mean_20_dow3_2017: 6116.43\n",
      "mean_20_dow2_2017: 5887.34\n",
      "promo_2: 5155.51\n",
      "mean_20_dow6_2017: 4929.41\n",
      "lag_42_sales: 4672.36\n",
      "promo_10: 4668.46\n",
      "promo_13: 4191.97\n",
      "sum_4_promo: 3591.66\n",
      "mean_20_dow4_2017: 3392.04\n",
      "sum_2_promo: 3350.41\n",
      "lag_35_sales: 2709.64\n",
      "lag_2_sales: 2674.69\n",
      "lag_5_sales: 2431.28\n",
      "promo_12: 2126.32\n",
      "lag_63_sales: 2057.52\n",
      "lag_4_sales: 1879.99\n",
      "promo_9: 1827.43\n",
      "promo_11: 1786.97\n",
      "mean_20_dow5_2017: 1675.17\n",
      "std_5_sales: 1499.36\n",
      "lag_28_sales: 1490.34\n",
      "std_4_sales: 1450.94\n",
      "lag_49_sales: 1305.66\n",
      "std_6_sales: 1291.49\n",
      "mean_4_dow2_2017: 1285.10\n",
      "sum_5_promo: 1198.93\n",
      "sum_6_promo: 1134.16\n",
      "promo_1: 1126.75\n",
      "mean_4_dow4_2017: 1103.63\n",
      "mean_4_dow3_2017: 1079.79\n",
      "store_state_features: 1055.34\n",
      "lag_14_sales: 834.19\n",
      "mean_4_dow1_2017: 826.19\n",
      "lag_3_sales: 729.49\n",
      "lag_6_sales: 633.17\n",
      "sum_3_promo: 556.09\n",
      "promo_15: 460.65\n",
      "std_3_sales: 428.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [08:26<08:18, 62.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.944491\tvalid_1's l2: 0.998089\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.889966\tvalid_1's l2: 0.94201\n",
      "[3]\ttraining's l2: 0.840568\tvalid_1's l2: 0.890789\n",
      "[4]\ttraining's l2: 0.796994\tvalid_1's l2: 0.845426\n",
      "[5]\ttraining's l2: 0.756408\tvalid_1's l2: 0.803319\n",
      "[6]\ttraining's l2: 0.719617\tvalid_1's l2: 0.76535\n",
      "[7]\ttraining's l2: 0.686478\tvalid_1's l2: 0.730685\n",
      "[8]\ttraining's l2: 0.656442\tvalid_1's l2: 0.699498\n",
      "[9]\ttraining's l2: 0.629206\tvalid_1's l2: 0.671118\n",
      "[10]\ttraining's l2: 0.604377\tvalid_1's l2: 0.645103\n",
      "[11]\ttraining's l2: 0.581902\tvalid_1's l2: 0.621541\n",
      "[12]\ttraining's l2: 0.561753\tvalid_1's l2: 0.600108\n",
      "[13]\ttraining's l2: 0.543386\tvalid_1's l2: 0.580641\n",
      "[14]\ttraining's l2: 0.526703\tvalid_1's l2: 0.562948\n",
      "[15]\ttraining's l2: 0.511548\tvalid_1's l2: 0.546906\n",
      "[16]\ttraining's l2: 0.497868\tvalid_1's l2: 0.532366\n",
      "[17]\ttraining's l2: 0.485492\tvalid_1's l2: 0.519221\n",
      "[18]\ttraining's l2: 0.474149\tvalid_1's l2: 0.507112\n",
      "[19]\ttraining's l2: 0.463849\tvalid_1's l2: 0.49607\n",
      "[20]\ttraining's l2: 0.45459\tvalid_1's l2: 0.486039\n",
      "[21]\ttraining's l2: 0.446293\tvalid_1's l2: 0.476982\n",
      "[22]\ttraining's l2: 0.438669\tvalid_1's l2: 0.468505\n",
      "[23]\ttraining's l2: 0.431673\tvalid_1's l2: 0.460808\n",
      "[24]\ttraining's l2: 0.425284\tvalid_1's l2: 0.453815\n",
      "[25]\ttraining's l2: 0.419523\tvalid_1's l2: 0.447469\n",
      "[26]\ttraining's l2: 0.41428\tvalid_1's l2: 0.441646\n",
      "[27]\ttraining's l2: 0.409524\tvalid_1's l2: 0.436301\n",
      "[28]\ttraining's l2: 0.40527\tvalid_1's l2: 0.431541\n",
      "[29]\ttraining's l2: 0.401265\tvalid_1's l2: 0.427067\n",
      "[30]\ttraining's l2: 0.397614\tvalid_1's l2: 0.422874\n",
      "[31]\ttraining's l2: 0.394306\tvalid_1's l2: 0.419117\n",
      "[32]\ttraining's l2: 0.391253\tvalid_1's l2: 0.415637\n",
      "[33]\ttraining's l2: 0.38845\tvalid_1's l2: 0.412444\n",
      "[34]\ttraining's l2: 0.385959\tvalid_1's l2: 0.409518\n",
      "[35]\ttraining's l2: 0.383662\tvalid_1's l2: 0.406892\n",
      "[36]\ttraining's l2: 0.381568\tvalid_1's l2: 0.4044\n",
      "[37]\ttraining's l2: 0.379653\tvalid_1's l2: 0.402118\n",
      "[38]\ttraining's l2: 0.377935\tvalid_1's l2: 0.400153\n",
      "[39]\ttraining's l2: 0.376264\tvalid_1's l2: 0.398153\n",
      "[40]\ttraining's l2: 0.374701\tvalid_1's l2: 0.396252\n",
      "[41]\ttraining's l2: 0.373344\tvalid_1's l2: 0.394611\n",
      "[42]\ttraining's l2: 0.372004\tvalid_1's l2: 0.393022\n",
      "[43]\ttraining's l2: 0.370787\tvalid_1's l2: 0.391618\n",
      "[44]\ttraining's l2: 0.369654\tvalid_1's l2: 0.390249\n",
      "[45]\ttraining's l2: 0.368635\tvalid_1's l2: 0.389031\n",
      "[46]\ttraining's l2: 0.367676\tvalid_1's l2: 0.387858\n",
      "[47]\ttraining's l2: 0.366806\tvalid_1's l2: 0.386852\n",
      "[48]\ttraining's l2: 0.365982\tvalid_1's l2: 0.385884\n",
      "[49]\ttraining's l2: 0.365106\tvalid_1's l2: 0.384813\n",
      "[50]\ttraining's l2: 0.364363\tvalid_1's l2: 0.383976\n",
      "[51]\ttraining's l2: 0.363691\tvalid_1's l2: 0.383214\n",
      "[52]\ttraining's l2: 0.363025\tvalid_1's l2: 0.382394\n",
      "[53]\ttraining's l2: 0.362385\tvalid_1's l2: 0.381693\n",
      "[54]\ttraining's l2: 0.361814\tvalid_1's l2: 0.380992\n",
      "[55]\ttraining's l2: 0.361228\tvalid_1's l2: 0.380311\n",
      "[56]\ttraining's l2: 0.360735\tvalid_1's l2: 0.379739\n",
      "[57]\ttraining's l2: 0.360293\tvalid_1's l2: 0.379164\n",
      "[58]\ttraining's l2: 0.359765\tvalid_1's l2: 0.378634\n",
      "[59]\ttraining's l2: 0.359353\tvalid_1's l2: 0.378054\n",
      "[60]\ttraining's l2: 0.358948\tvalid_1's l2: 0.377546\n",
      "[61]\ttraining's l2: 0.35849\tvalid_1's l2: 0.37703\n",
      "[62]\ttraining's l2: 0.358108\tvalid_1's l2: 0.376668\n",
      "[63]\ttraining's l2: 0.35779\tvalid_1's l2: 0.376282\n",
      "[64]\ttraining's l2: 0.3575\tvalid_1's l2: 0.37595\n",
      "[65]\ttraining's l2: 0.357126\tvalid_1's l2: 0.375586\n",
      "[66]\ttraining's l2: 0.356868\tvalid_1's l2: 0.375328\n",
      "[67]\ttraining's l2: 0.356555\tvalid_1's l2: 0.375063\n",
      "[68]\ttraining's l2: 0.356213\tvalid_1's l2: 0.374702\n",
      "[69]\ttraining's l2: 0.355955\tvalid_1's l2: 0.374396\n",
      "[70]\ttraining's l2: 0.355682\tvalid_1's l2: 0.374096\n",
      "[71]\ttraining's l2: 0.355377\tvalid_1's l2: 0.373775\n",
      "[72]\ttraining's l2: 0.355131\tvalid_1's l2: 0.373512\n",
      "[73]\ttraining's l2: 0.354909\tvalid_1's l2: 0.373281\n",
      "[74]\ttraining's l2: 0.354629\tvalid_1's l2: 0.373027\n",
      "[75]\ttraining's l2: 0.354304\tvalid_1's l2: 0.372749\n",
      "[76]\ttraining's l2: 0.354037\tvalid_1's l2: 0.372557\n",
      "[77]\ttraining's l2: 0.353759\tvalid_1's l2: 0.37223\n",
      "[78]\ttraining's l2: 0.353543\tvalid_1's l2: 0.37198\n",
      "[79]\ttraining's l2: 0.353346\tvalid_1's l2: 0.371825\n",
      "[80]\ttraining's l2: 0.353138\tvalid_1's l2: 0.371595\n",
      "[81]\ttraining's l2: 0.35294\tvalid_1's l2: 0.371387\n",
      "[82]\ttraining's l2: 0.352744\tvalid_1's l2: 0.371145\n",
      "[83]\ttraining's l2: 0.352551\tvalid_1's l2: 0.371022\n",
      "[84]\ttraining's l2: 0.352359\tvalid_1's l2: 0.370917\n",
      "[85]\ttraining's l2: 0.352173\tvalid_1's l2: 0.37078\n",
      "[86]\ttraining's l2: 0.351943\tvalid_1's l2: 0.370605\n",
      "[87]\ttraining's l2: 0.351744\tvalid_1's l2: 0.370447\n",
      "[88]\ttraining's l2: 0.3516\tvalid_1's l2: 0.370299\n",
      "[89]\ttraining's l2: 0.351467\tvalid_1's l2: 0.370184\n",
      "[90]\ttraining's l2: 0.351324\tvalid_1's l2: 0.370104\n",
      "[91]\ttraining's l2: 0.351166\tvalid_1's l2: 0.369945\n",
      "[92]\ttraining's l2: 0.351026\tvalid_1's l2: 0.369784\n",
      "[93]\ttraining's l2: 0.35091\tvalid_1's l2: 0.36968\n",
      "[94]\ttraining's l2: 0.350793\tvalid_1's l2: 0.369615\n",
      "[95]\ttraining's l2: 0.350649\tvalid_1's l2: 0.369527\n",
      "[96]\ttraining's l2: 0.350488\tvalid_1's l2: 0.369423\n",
      "[97]\ttraining's l2: 0.350342\tvalid_1's l2: 0.36929\n",
      "[98]\ttraining's l2: 0.350231\tvalid_1's l2: 0.369195\n",
      "[99]\ttraining's l2: 0.350086\tvalid_1's l2: 0.369069\n",
      "[100]\ttraining's l2: 0.349953\tvalid_1's l2: 0.36896\n",
      "[101]\ttraining's l2: 0.349787\tvalid_1's l2: 0.368795\n",
      "[102]\ttraining's l2: 0.349675\tvalid_1's l2: 0.368701\n",
      "[103]\ttraining's l2: 0.349566\tvalid_1's l2: 0.36856\n",
      "[104]\ttraining's l2: 0.349443\tvalid_1's l2: 0.368467\n",
      "[105]\ttraining's l2: 0.349304\tvalid_1's l2: 0.368394\n",
      "[106]\ttraining's l2: 0.349205\tvalid_1's l2: 0.368339\n",
      "[107]\ttraining's l2: 0.349121\tvalid_1's l2: 0.36824\n",
      "[108]\ttraining's l2: 0.349037\tvalid_1's l2: 0.368206\n",
      "[109]\ttraining's l2: 0.348941\tvalid_1's l2: 0.368141\n",
      "[110]\ttraining's l2: 0.348856\tvalid_1's l2: 0.368106\n",
      "[111]\ttraining's l2: 0.348779\tvalid_1's l2: 0.368041\n",
      "[112]\ttraining's l2: 0.348623\tvalid_1's l2: 0.36797\n",
      "[113]\ttraining's l2: 0.348531\tvalid_1's l2: 0.367874\n",
      "[114]\ttraining's l2: 0.348447\tvalid_1's l2: 0.367799\n",
      "[115]\ttraining's l2: 0.348365\tvalid_1's l2: 0.367742\n",
      "[116]\ttraining's l2: 0.348288\tvalid_1's l2: 0.367697\n",
      "[117]\ttraining's l2: 0.348203\tvalid_1's l2: 0.367603\n",
      "[118]\ttraining's l2: 0.348073\tvalid_1's l2: 0.367505\n",
      "[119]\ttraining's l2: 0.348001\tvalid_1's l2: 0.367481\n",
      "[120]\ttraining's l2: 0.347876\tvalid_1's l2: 0.367395\n",
      "[121]\ttraining's l2: 0.347798\tvalid_1's l2: 0.367362\n",
      "[122]\ttraining's l2: 0.347737\tvalid_1's l2: 0.367324\n",
      "[123]\ttraining's l2: 0.347627\tvalid_1's l2: 0.36726\n",
      "[124]\ttraining's l2: 0.347558\tvalid_1's l2: 0.367254\n",
      "[125]\ttraining's l2: 0.347498\tvalid_1's l2: 0.367231\n",
      "[126]\ttraining's l2: 0.347372\tvalid_1's l2: 0.36713\n",
      "[127]\ttraining's l2: 0.347291\tvalid_1's l2: 0.367077\n",
      "[128]\ttraining's l2: 0.347223\tvalid_1's l2: 0.367062\n",
      "[129]\ttraining's l2: 0.347171\tvalid_1's l2: 0.367043\n",
      "[130]\ttraining's l2: 0.34711\tvalid_1's l2: 0.367011\n",
      "[131]\ttraining's l2: 0.346999\tvalid_1's l2: 0.36693\n",
      "[132]\ttraining's l2: 0.346943\tvalid_1's l2: 0.366912\n",
      "[133]\ttraining's l2: 0.34688\tvalid_1's l2: 0.366887\n",
      "[134]\ttraining's l2: 0.346812\tvalid_1's l2: 0.36685\n",
      "[135]\ttraining's l2: 0.34677\tvalid_1's l2: 0.366835\n",
      "[136]\ttraining's l2: 0.346678\tvalid_1's l2: 0.366785\n",
      "[137]\ttraining's l2: 0.346634\tvalid_1's l2: 0.366776\n",
      "[138]\ttraining's l2: 0.346589\tvalid_1's l2: 0.366751\n",
      "[139]\ttraining's l2: 0.346494\tvalid_1's l2: 0.366717\n",
      "[140]\ttraining's l2: 0.346452\tvalid_1's l2: 0.366708\n",
      "[141]\ttraining's l2: 0.346366\tvalid_1's l2: 0.3667\n",
      "[142]\ttraining's l2: 0.346243\tvalid_1's l2: 0.366595\n",
      "[143]\ttraining's l2: 0.346151\tvalid_1's l2: 0.366505\n",
      "[144]\ttraining's l2: 0.346095\tvalid_1's l2: 0.366514\n",
      "[145]\ttraining's l2: 0.34605\tvalid_1's l2: 0.366502\n",
      "[146]\ttraining's l2: 0.346003\tvalid_1's l2: 0.366475\n",
      "[147]\ttraining's l2: 0.345945\tvalid_1's l2: 0.366467\n",
      "[148]\ttraining's l2: 0.345901\tvalid_1's l2: 0.366444\n",
      "[149]\ttraining's l2: 0.345845\tvalid_1's l2: 0.366436\n",
      "[150]\ttraining's l2: 0.345797\tvalid_1's l2: 0.366403\n",
      "[151]\ttraining's l2: 0.345759\tvalid_1's l2: 0.366388\n",
      "[152]\ttraining's l2: 0.345677\tvalid_1's l2: 0.366378\n",
      "[153]\ttraining's l2: 0.345641\tvalid_1's l2: 0.366374\n",
      "[154]\ttraining's l2: 0.3456\tvalid_1's l2: 0.366353\n",
      "[155]\ttraining's l2: 0.345538\tvalid_1's l2: 0.36635\n",
      "[156]\ttraining's l2: 0.345446\tvalid_1's l2: 0.366236\n",
      "[157]\ttraining's l2: 0.345413\tvalid_1's l2: 0.36623\n",
      "[158]\ttraining's l2: 0.345375\tvalid_1's l2: 0.366227\n",
      "[159]\ttraining's l2: 0.345339\tvalid_1's l2: 0.366215\n",
      "[160]\ttraining's l2: 0.345264\tvalid_1's l2: 0.366167\n",
      "[161]\ttraining's l2: 0.345221\tvalid_1's l2: 0.36615\n",
      "[162]\ttraining's l2: 0.345187\tvalid_1's l2: 0.366125\n",
      "[163]\ttraining's l2: 0.345153\tvalid_1's l2: 0.366103\n",
      "[164]\ttraining's l2: 0.345083\tvalid_1's l2: 0.366027\n",
      "[165]\ttraining's l2: 0.345017\tvalid_1's l2: 0.365973\n",
      "[166]\ttraining's l2: 0.344973\tvalid_1's l2: 0.365968\n",
      "[167]\ttraining's l2: 0.344905\tvalid_1's l2: 0.365849\n",
      "[168]\ttraining's l2: 0.344863\tvalid_1's l2: 0.365831\n",
      "[169]\ttraining's l2: 0.344818\tvalid_1's l2: 0.365838\n",
      "[170]\ttraining's l2: 0.34478\tvalid_1's l2: 0.365826\n",
      "[171]\ttraining's l2: 0.344753\tvalid_1's l2: 0.365824\n",
      "[172]\ttraining's l2: 0.344715\tvalid_1's l2: 0.365804\n",
      "[173]\ttraining's l2: 0.34468\tvalid_1's l2: 0.36579\n",
      "[174]\ttraining's l2: 0.344635\tvalid_1's l2: 0.365774\n",
      "[175]\ttraining's l2: 0.344605\tvalid_1's l2: 0.36576\n",
      "[176]\ttraining's l2: 0.344564\tvalid_1's l2: 0.365747\n",
      "[177]\ttraining's l2: 0.344491\tvalid_1's l2: 0.365675\n",
      "[178]\ttraining's l2: 0.344432\tvalid_1's l2: 0.365635\n",
      "[179]\ttraining's l2: 0.344382\tvalid_1's l2: 0.365645\n",
      "[180]\ttraining's l2: 0.344343\tvalid_1's l2: 0.365651\n",
      "[181]\ttraining's l2: 0.344293\tvalid_1's l2: 0.365637\n",
      "[182]\ttraining's l2: 0.344264\tvalid_1's l2: 0.365633\n",
      "[183]\ttraining's l2: 0.34417\tvalid_1's l2: 0.365557\n",
      "[184]\ttraining's l2: 0.344128\tvalid_1's l2: 0.365545\n",
      "[185]\ttraining's l2: 0.344089\tvalid_1's l2: 0.365529\n",
      "[186]\ttraining's l2: 0.344061\tvalid_1's l2: 0.365501\n",
      "[187]\ttraining's l2: 0.343981\tvalid_1's l2: 0.365395\n",
      "[188]\ttraining's l2: 0.343941\tvalid_1's l2: 0.365392\n",
      "[189]\ttraining's l2: 0.343877\tvalid_1's l2: 0.365338\n",
      "[190]\ttraining's l2: 0.343832\tvalid_1's l2: 0.365334\n",
      "[191]\ttraining's l2: 0.343786\tvalid_1's l2: 0.365286\n",
      "[192]\ttraining's l2: 0.343761\tvalid_1's l2: 0.365294\n",
      "[193]\ttraining's l2: 0.343726\tvalid_1's l2: 0.36529\n",
      "[194]\ttraining's l2: 0.34369\tvalid_1's l2: 0.36526\n",
      "[195]\ttraining's l2: 0.343659\tvalid_1's l2: 0.365245\n",
      "[196]\ttraining's l2: 0.343589\tvalid_1's l2: 0.365177\n",
      "[197]\ttraining's l2: 0.343556\tvalid_1's l2: 0.365161\n",
      "[198]\ttraining's l2: 0.343482\tvalid_1's l2: 0.365121\n",
      "[199]\ttraining's l2: 0.343461\tvalid_1's l2: 0.365111\n",
      "[200]\ttraining's l2: 0.343405\tvalid_1's l2: 0.365095\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.343405\tvalid_1's l2: 0.365095\n",
      "mean_14_sales: 3604353.70\n",
      "mean_7_sales: 3295192.54\n",
      "mean_21_sales: 2521987.01\n",
      "mean_30_sales: 2408679.33\n",
      "mean_20_dow1_2017: 562552.95\n",
      "mean_63_sales: 532959.85\n",
      "promo_8: 499132.51\n",
      "mean_6_sales: 297395.55\n",
      "item_class_features: 202115.53\n",
      "mean_60_sales: 106030.11\n",
      "lag_1_sales: 61480.38\n",
      "mean_4_dow1_2017: 46247.07\n",
      "mean_4_dow6_2017: 39295.45\n",
      "promo_7: 39182.28\n",
      "sum_4_promo: 38259.05\n",
      "mean_20_dow2_2017: 35060.75\n",
      "mean_5_sales: 34458.10\n",
      "std_14_sales: 26040.50\n",
      "std_21_sales: 24613.33\n",
      "store_city_features: 23588.11\n",
      "promo_10: 22582.53\n",
      "std_63_sales: 19663.43\n",
      "sum_6_promo: 18801.65\n",
      "sum_2_promo: 17787.72\n",
      "item_family_features: 17690.08\n",
      "store_cluster_features: 16256.25\n",
      "promo_14: 15818.13\n",
      "std_30_sales: 13751.47\n",
      "std_60_sales: 11334.37\n",
      "mean_3_sales: 11326.85\n",
      "mean_4_sales: 11287.34\n",
      "sum_7_promo: 11127.43\n",
      "promo_9: 10124.77\n",
      "mean_20_dow0_2017: 9301.41\n",
      "lag_21_sales: 9091.44\n",
      "promo_12: 8593.22\n",
      "std_7_sales: 8459.93\n",
      "lag_6_sales: 8199.71\n",
      "promo_11: 8016.17\n",
      "store_type_features: 6894.23\n",
      "sum_14_promo: 6802.08\n",
      "mean_20_dow3_2017: 6426.85\n",
      "sum_21_promo: 6395.26\n",
      "std_6_sales: 5936.00\n",
      "promo_3: 5670.57\n",
      "lag_56_sales: 5273.29\n",
      "promo_13: 5116.77\n",
      "promo_1: 4887.80\n",
      "lag_5_sales: 4818.68\n",
      "promo_6: 4585.09\n",
      "sum_5_promo: 4494.66\n",
      "promo_4: 3488.36\n",
      "sum_3_promo: 3408.49\n",
      "mean_4_dow2_2017: 3007.45\n",
      "promo_5: 2645.12\n",
      "lag_4_sales: 2382.73\n",
      "mean_20_dow4_2017: 2163.61\n",
      "std_5_sales: 1796.31\n",
      "mean_4_dow0_2017: 1769.44\n",
      "promo_15: 1539.30\n",
      "mean_20_dow6_2017: 1478.93\n",
      "lag_3_sales: 1332.09\n",
      "promo_0: 1298.13\n",
      "std_4_sales: 1255.39\n",
      "lag_7_sales: 1236.99\n",
      "lag_2_sales: 1090.21\n",
      "lag_35_sales: 964.15\n",
      "mean_4_dow4_2017: 851.69\n",
      "lag_49_sales: 812.56\n",
      "mean_4_dow3_2017: 778.07\n",
      "mean_4_dow5_2017: 671.94\n",
      "store_state_features: 594.85\n",
      "lag_63_sales: 532.74\n",
      "promo_2: 528.59\n",
      "lag_42_sales: 512.47\n",
      "lag_14_sales: 510.29\n",
      "std_3_sales: 442.38\n",
      "mean_20_dow5_2017: 421.46\n",
      "lag_28_sales: 405.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [09:26<07:12, 61.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05826\tvalid_1's l2: 1.07297\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.994598\tvalid_1's l2: 1.00898\n",
      "[3]\ttraining's l2: 0.93664\tvalid_1's l2: 0.950378\n",
      "[4]\ttraining's l2: 0.884376\tvalid_1's l2: 0.89724\n",
      "[5]\ttraining's l2: 0.836913\tvalid_1's l2: 0.849147\n",
      "[6]\ttraining's l2: 0.793761\tvalid_1's l2: 0.80556\n",
      "[7]\ttraining's l2: 0.754937\tvalid_1's l2: 0.76621\n",
      "[8]\ttraining's l2: 0.719654\tvalid_1's l2: 0.730453\n",
      "[9]\ttraining's l2: 0.687467\tvalid_1's l2: 0.698021\n",
      "[10]\ttraining's l2: 0.659015\tvalid_1's l2: 0.668964\n",
      "[11]\ttraining's l2: 0.632459\tvalid_1's l2: 0.64217\n",
      "[12]\ttraining's l2: 0.609275\tvalid_1's l2: 0.618576\n",
      "[13]\ttraining's l2: 0.587437\tvalid_1's l2: 0.596172\n",
      "[14]\ttraining's l2: 0.567487\tvalid_1's l2: 0.575844\n",
      "[15]\ttraining's l2: 0.54949\tvalid_1's l2: 0.557436\n",
      "[16]\ttraining's l2: 0.533057\tvalid_1's l2: 0.540653\n",
      "[17]\ttraining's l2: 0.518239\tvalid_1's l2: 0.525644\n",
      "[18]\ttraining's l2: 0.504661\tvalid_1's l2: 0.511842\n",
      "[19]\ttraining's l2: 0.492758\tvalid_1's l2: 0.499571\n",
      "[20]\ttraining's l2: 0.481568\tvalid_1's l2: 0.488015\n",
      "[21]\ttraining's l2: 0.471391\tvalid_1's l2: 0.477533\n",
      "[22]\ttraining's l2: 0.462296\tvalid_1's l2: 0.468006\n",
      "[23]\ttraining's l2: 0.454217\tvalid_1's l2: 0.459784\n",
      "[24]\ttraining's l2: 0.446429\tvalid_1's l2: 0.451826\n",
      "[25]\ttraining's l2: 0.43944\tvalid_1's l2: 0.444542\n",
      "[26]\ttraining's l2: 0.433286\tvalid_1's l2: 0.438189\n",
      "[27]\ttraining's l2: 0.427728\tvalid_1's l2: 0.432555\n",
      "[28]\ttraining's l2: 0.422371\tvalid_1's l2: 0.426966\n",
      "[29]\ttraining's l2: 0.417425\tvalid_1's l2: 0.421905\n",
      "[30]\ttraining's l2: 0.413173\tvalid_1's l2: 0.417536\n",
      "[31]\ttraining's l2: 0.40903\tvalid_1's l2: 0.413243\n",
      "[32]\ttraining's l2: 0.405231\tvalid_1's l2: 0.409178\n",
      "[33]\ttraining's l2: 0.401737\tvalid_1's l2: 0.40548\n",
      "[34]\ttraining's l2: 0.39859\tvalid_1's l2: 0.402062\n",
      "[35]\ttraining's l2: 0.395682\tvalid_1's l2: 0.399034\n",
      "[36]\ttraining's l2: 0.392949\tvalid_1's l2: 0.396218\n",
      "[37]\ttraining's l2: 0.39055\tvalid_1's l2: 0.393757\n",
      "[38]\ttraining's l2: 0.388367\tvalid_1's l2: 0.391568\n",
      "[39]\ttraining's l2: 0.386313\tvalid_1's l2: 0.38936\n",
      "[40]\ttraining's l2: 0.384413\tvalid_1's l2: 0.387327\n",
      "[41]\ttraining's l2: 0.382583\tvalid_1's l2: 0.385436\n",
      "[42]\ttraining's l2: 0.380971\tvalid_1's l2: 0.383751\n",
      "[43]\ttraining's l2: 0.379375\tvalid_1's l2: 0.382046\n",
      "[44]\ttraining's l2: 0.377963\tvalid_1's l2: 0.380548\n",
      "[45]\ttraining's l2: 0.376651\tvalid_1's l2: 0.379249\n",
      "[46]\ttraining's l2: 0.375432\tvalid_1's l2: 0.377974\n",
      "[47]\ttraining's l2: 0.374329\tvalid_1's l2: 0.3769\n",
      "[48]\ttraining's l2: 0.373347\tvalid_1's l2: 0.375906\n",
      "[49]\ttraining's l2: 0.372429\tvalid_1's l2: 0.375048\n",
      "[50]\ttraining's l2: 0.371551\tvalid_1's l2: 0.374228\n",
      "[51]\ttraining's l2: 0.370572\tvalid_1's l2: 0.3732\n",
      "[52]\ttraining's l2: 0.36966\tvalid_1's l2: 0.372215\n",
      "[53]\ttraining's l2: 0.368823\tvalid_1's l2: 0.371349\n",
      "[54]\ttraining's l2: 0.368076\tvalid_1's l2: 0.37059\n",
      "[55]\ttraining's l2: 0.367369\tvalid_1's l2: 0.3699\n",
      "[56]\ttraining's l2: 0.366692\tvalid_1's l2: 0.369257\n",
      "[57]\ttraining's l2: 0.366161\tvalid_1's l2: 0.368692\n",
      "[58]\ttraining's l2: 0.365576\tvalid_1's l2: 0.36821\n",
      "[59]\ttraining's l2: 0.365048\tvalid_1's l2: 0.367756\n",
      "[60]\ttraining's l2: 0.364478\tvalid_1's l2: 0.36725\n",
      "[61]\ttraining's l2: 0.363913\tvalid_1's l2: 0.36675\n",
      "[62]\ttraining's l2: 0.363329\tvalid_1's l2: 0.366206\n",
      "[63]\ttraining's l2: 0.362858\tvalid_1's l2: 0.365737\n",
      "[64]\ttraining's l2: 0.36242\tvalid_1's l2: 0.365291\n",
      "[65]\ttraining's l2: 0.361992\tvalid_1's l2: 0.364839\n",
      "[66]\ttraining's l2: 0.36168\tvalid_1's l2: 0.364553\n",
      "[67]\ttraining's l2: 0.361277\tvalid_1's l2: 0.36426\n",
      "[68]\ttraining's l2: 0.360845\tvalid_1's l2: 0.36387\n",
      "[69]\ttraining's l2: 0.360474\tvalid_1's l2: 0.363501\n",
      "[70]\ttraining's l2: 0.360124\tvalid_1's l2: 0.363304\n",
      "[71]\ttraining's l2: 0.359814\tvalid_1's l2: 0.363082\n",
      "[72]\ttraining's l2: 0.359479\tvalid_1's l2: 0.362741\n",
      "[73]\ttraining's l2: 0.359122\tvalid_1's l2: 0.362389\n",
      "[74]\ttraining's l2: 0.358754\tvalid_1's l2: 0.362043\n",
      "[75]\ttraining's l2: 0.358398\tvalid_1's l2: 0.361738\n",
      "[76]\ttraining's l2: 0.358093\tvalid_1's l2: 0.361428\n",
      "[77]\ttraining's l2: 0.357837\tvalid_1's l2: 0.361237\n",
      "[78]\ttraining's l2: 0.35756\tvalid_1's l2: 0.361031\n",
      "[79]\ttraining's l2: 0.357313\tvalid_1's l2: 0.360846\n",
      "[80]\ttraining's l2: 0.357041\tvalid_1's l2: 0.360578\n",
      "[81]\ttraining's l2: 0.356804\tvalid_1's l2: 0.360448\n",
      "[82]\ttraining's l2: 0.356631\tvalid_1's l2: 0.360294\n",
      "[83]\ttraining's l2: 0.356384\tvalid_1's l2: 0.3602\n",
      "[84]\ttraining's l2: 0.356147\tvalid_1's l2: 0.359972\n",
      "[85]\ttraining's l2: 0.355896\tvalid_1's l2: 0.359775\n",
      "[86]\ttraining's l2: 0.355646\tvalid_1's l2: 0.35953\n",
      "[87]\ttraining's l2: 0.35546\tvalid_1's l2: 0.359407\n",
      "[88]\ttraining's l2: 0.355278\tvalid_1's l2: 0.359288\n",
      "[89]\ttraining's l2: 0.354944\tvalid_1's l2: 0.359089\n",
      "[90]\ttraining's l2: 0.354789\tvalid_1's l2: 0.359016\n",
      "[91]\ttraining's l2: 0.354516\tvalid_1's l2: 0.358755\n",
      "[92]\ttraining's l2: 0.354311\tvalid_1's l2: 0.358539\n",
      "[93]\ttraining's l2: 0.354153\tvalid_1's l2: 0.35842\n",
      "[94]\ttraining's l2: 0.354006\tvalid_1's l2: 0.358355\n",
      "[95]\ttraining's l2: 0.353811\tvalid_1's l2: 0.3583\n",
      "[96]\ttraining's l2: 0.353545\tvalid_1's l2: 0.358074\n",
      "[97]\ttraining's l2: 0.353391\tvalid_1's l2: 0.357913\n",
      "[98]\ttraining's l2: 0.353215\tvalid_1's l2: 0.357762\n",
      "[99]\ttraining's l2: 0.353066\tvalid_1's l2: 0.357709\n",
      "[100]\ttraining's l2: 0.352938\tvalid_1's l2: 0.357611\n",
      "[101]\ttraining's l2: 0.352721\tvalid_1's l2: 0.357424\n",
      "[102]\ttraining's l2: 0.352589\tvalid_1's l2: 0.357401\n",
      "[103]\ttraining's l2: 0.352362\tvalid_1's l2: 0.357212\n",
      "[104]\ttraining's l2: 0.352231\tvalid_1's l2: 0.3571\n",
      "[105]\ttraining's l2: 0.352074\tvalid_1's l2: 0.357044\n",
      "[106]\ttraining's l2: 0.351927\tvalid_1's l2: 0.356965\n",
      "[107]\ttraining's l2: 0.351811\tvalid_1's l2: 0.356897\n",
      "[108]\ttraining's l2: 0.351664\tvalid_1's l2: 0.356771\n",
      "[109]\ttraining's l2: 0.351514\tvalid_1's l2: 0.356687\n",
      "[110]\ttraining's l2: 0.351376\tvalid_1's l2: 0.356628\n",
      "[111]\ttraining's l2: 0.351265\tvalid_1's l2: 0.356526\n",
      "[112]\ttraining's l2: 0.351174\tvalid_1's l2: 0.35649\n",
      "[113]\ttraining's l2: 0.351037\tvalid_1's l2: 0.356392\n",
      "[114]\ttraining's l2: 0.350914\tvalid_1's l2: 0.356305\n",
      "[115]\ttraining's l2: 0.35079\tvalid_1's l2: 0.356241\n",
      "[116]\ttraining's l2: 0.350684\tvalid_1's l2: 0.356176\n",
      "[117]\ttraining's l2: 0.350582\tvalid_1's l2: 0.356071\n",
      "[118]\ttraining's l2: 0.350497\tvalid_1's l2: 0.355995\n",
      "[119]\ttraining's l2: 0.35041\tvalid_1's l2: 0.355927\n",
      "[120]\ttraining's l2: 0.350329\tvalid_1's l2: 0.355885\n",
      "[121]\ttraining's l2: 0.350263\tvalid_1's l2: 0.355842\n",
      "[122]\ttraining's l2: 0.350171\tvalid_1's l2: 0.355769\n",
      "[123]\ttraining's l2: 0.350068\tvalid_1's l2: 0.355756\n",
      "[124]\ttraining's l2: 0.349967\tvalid_1's l2: 0.355649\n",
      "[125]\ttraining's l2: 0.349889\tvalid_1's l2: 0.355605\n",
      "[126]\ttraining's l2: 0.34981\tvalid_1's l2: 0.355581\n",
      "[127]\ttraining's l2: 0.349736\tvalid_1's l2: 0.355535\n",
      "[128]\ttraining's l2: 0.349668\tvalid_1's l2: 0.355513\n",
      "[129]\ttraining's l2: 0.34961\tvalid_1's l2: 0.35544\n",
      "[130]\ttraining's l2: 0.349504\tvalid_1's l2: 0.355329\n",
      "[131]\ttraining's l2: 0.349446\tvalid_1's l2: 0.355312\n",
      "[132]\ttraining's l2: 0.349356\tvalid_1's l2: 0.355307\n",
      "[133]\ttraining's l2: 0.349264\tvalid_1's l2: 0.355297\n",
      "[134]\ttraining's l2: 0.349209\tvalid_1's l2: 0.355277\n",
      "[135]\ttraining's l2: 0.349163\tvalid_1's l2: 0.355233\n",
      "[136]\ttraining's l2: 0.349089\tvalid_1's l2: 0.355186\n",
      "[137]\ttraining's l2: 0.348992\tvalid_1's l2: 0.355132\n",
      "[138]\ttraining's l2: 0.34894\tvalid_1's l2: 0.355112\n",
      "[139]\ttraining's l2: 0.34884\tvalid_1's l2: 0.355121\n",
      "[140]\ttraining's l2: 0.348787\tvalid_1's l2: 0.355106\n",
      "[141]\ttraining's l2: 0.348735\tvalid_1's l2: 0.355092\n",
      "[142]\ttraining's l2: 0.348679\tvalid_1's l2: 0.355075\n",
      "[143]\ttraining's l2: 0.348578\tvalid_1's l2: 0.354989\n",
      "[144]\ttraining's l2: 0.34848\tvalid_1's l2: 0.354927\n",
      "[145]\ttraining's l2: 0.348429\tvalid_1's l2: 0.354885\n",
      "[146]\ttraining's l2: 0.348372\tvalid_1's l2: 0.354861\n",
      "[147]\ttraining's l2: 0.348331\tvalid_1's l2: 0.354849\n",
      "[148]\ttraining's l2: 0.34826\tvalid_1's l2: 0.35487\n",
      "[149]\ttraining's l2: 0.348192\tvalid_1's l2: 0.354859\n",
      "[150]\ttraining's l2: 0.348143\tvalid_1's l2: 0.354838\n",
      "[151]\ttraining's l2: 0.348105\tvalid_1's l2: 0.354794\n",
      "[152]\ttraining's l2: 0.348055\tvalid_1's l2: 0.354791\n",
      "[153]\ttraining's l2: 0.348004\tvalid_1's l2: 0.354785\n",
      "[154]\ttraining's l2: 0.34796\tvalid_1's l2: 0.354753\n",
      "[155]\ttraining's l2: 0.347829\tvalid_1's l2: 0.354679\n",
      "[156]\ttraining's l2: 0.347772\tvalid_1's l2: 0.354632\n",
      "[157]\ttraining's l2: 0.347713\tvalid_1's l2: 0.354585\n",
      "[158]\ttraining's l2: 0.347674\tvalid_1's l2: 0.35458\n",
      "[159]\ttraining's l2: 0.347643\tvalid_1's l2: 0.354561\n",
      "[160]\ttraining's l2: 0.347569\tvalid_1's l2: 0.354568\n",
      "[161]\ttraining's l2: 0.347497\tvalid_1's l2: 0.354561\n",
      "[162]\ttraining's l2: 0.34741\tvalid_1's l2: 0.354526\n",
      "[163]\ttraining's l2: 0.347336\tvalid_1's l2: 0.354438\n",
      "[164]\ttraining's l2: 0.347292\tvalid_1's l2: 0.354422\n",
      "[165]\ttraining's l2: 0.347211\tvalid_1's l2: 0.354383\n",
      "[166]\ttraining's l2: 0.347167\tvalid_1's l2: 0.354367\n",
      "[167]\ttraining's l2: 0.347118\tvalid_1's l2: 0.354351\n",
      "[168]\ttraining's l2: 0.347072\tvalid_1's l2: 0.354338\n",
      "[169]\ttraining's l2: 0.347027\tvalid_1's l2: 0.354331\n",
      "[170]\ttraining's l2: 0.346981\tvalid_1's l2: 0.354309\n",
      "[171]\ttraining's l2: 0.346946\tvalid_1's l2: 0.354304\n",
      "[172]\ttraining's l2: 0.346901\tvalid_1's l2: 0.354282\n",
      "[173]\ttraining's l2: 0.346874\tvalid_1's l2: 0.354259\n",
      "[174]\ttraining's l2: 0.346825\tvalid_1's l2: 0.354241\n",
      "[175]\ttraining's l2: 0.346794\tvalid_1's l2: 0.354213\n",
      "[176]\ttraining's l2: 0.346738\tvalid_1's l2: 0.354197\n",
      "[177]\ttraining's l2: 0.346705\tvalid_1's l2: 0.354188\n",
      "[178]\ttraining's l2: 0.346655\tvalid_1's l2: 0.354175\n",
      "[179]\ttraining's l2: 0.346572\tvalid_1's l2: 0.354118\n",
      "[180]\ttraining's l2: 0.346539\tvalid_1's l2: 0.354113\n",
      "[181]\ttraining's l2: 0.346483\tvalid_1's l2: 0.354088\n",
      "[182]\ttraining's l2: 0.346446\tvalid_1's l2: 0.354086\n",
      "[183]\ttraining's l2: 0.346406\tvalid_1's l2: 0.354066\n",
      "[184]\ttraining's l2: 0.346365\tvalid_1's l2: 0.354027\n",
      "[185]\ttraining's l2: 0.346334\tvalid_1's l2: 0.354019\n",
      "[186]\ttraining's l2: 0.34631\tvalid_1's l2: 0.354007\n",
      "[187]\ttraining's l2: 0.346268\tvalid_1's l2: 0.353994\n",
      "[188]\ttraining's l2: 0.346234\tvalid_1's l2: 0.353995\n",
      "[189]\ttraining's l2: 0.346194\tvalid_1's l2: 0.353972\n",
      "[190]\ttraining's l2: 0.34615\tvalid_1's l2: 0.353964\n",
      "[191]\ttraining's l2: 0.346118\tvalid_1's l2: 0.353946\n",
      "[192]\ttraining's l2: 0.346075\tvalid_1's l2: 0.353941\n",
      "[193]\ttraining's l2: 0.346029\tvalid_1's l2: 0.353924\n",
      "[194]\ttraining's l2: 0.345965\tvalid_1's l2: 0.353898\n",
      "[195]\ttraining's l2: 0.345904\tvalid_1's l2: 0.353861\n",
      "[196]\ttraining's l2: 0.345823\tvalid_1's l2: 0.353801\n",
      "[197]\ttraining's l2: 0.345768\tvalid_1's l2: 0.353782\n",
      "[198]\ttraining's l2: 0.345737\tvalid_1's l2: 0.353771\n",
      "[199]\ttraining's l2: 0.345709\tvalid_1's l2: 0.353768\n",
      "[200]\ttraining's l2: 0.345676\tvalid_1's l2: 0.353757\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.345676\tvalid_1's l2: 0.353757\n",
      "mean_21_sales: 5541037.23\n",
      "mean_14_sales: 2915404.73\n",
      "mean_7_sales: 2670304.07\n",
      "mean_20_dow2_2017: 1828755.99\n",
      "mean_30_sales: 1211260.28\n",
      "promo_9: 635875.60\n",
      "mean_4_dow2_2017: 623915.24\n",
      "mean_6_sales: 590815.87\n",
      "item_class_features: 332230.03\n",
      "mean_5_sales: 128607.86\n",
      "mean_63_sales: 98532.88\n",
      "sum_5_promo: 71199.96\n",
      "store_cluster_features: 55281.57\n",
      "promo_10: 53327.66\n",
      "item_family_features: 50560.40\n",
      "std_21_sales: 47784.26\n",
      "std_30_sales: 40764.55\n",
      "lag_1_sales: 40237.15\n",
      "std_63_sales: 33254.80\n",
      "promo_14: 33111.98\n",
      "promo_7: 30814.03\n",
      "mean_20_dow1_2017: 30716.70\n",
      "lag_5_sales: 27694.92\n",
      "store_city_features: 27085.52\n",
      "mean_60_sales: 18651.27\n",
      "std_14_sales: 18177.53\n",
      "promo_2: 17667.31\n",
      "std_60_sales: 17403.92\n",
      "promo_12: 16814.75\n",
      "sum_4_promo: 14859.70\n",
      "lag_4_sales: 14723.34\n",
      "store_type_features: 13647.57\n",
      "promo_11: 11737.11\n",
      "mean_4_sales: 11225.64\n",
      "mean_3_sales: 10955.16\n",
      "mean_20_dow3_2017: 10926.23\n",
      "sum_2_promo: 9899.60\n",
      "std_6_sales: 9663.67\n",
      "mean_20_dow0_2017: 9328.54\n",
      "sum_7_promo: 8686.21\n",
      "std_7_sales: 7942.17\n",
      "sum_14_promo: 7922.05\n",
      "promo_8: 7642.47\n",
      "sum_3_promo: 7492.90\n",
      "promo_13: 6844.51\n",
      "lag_21_sales: 5208.71\n",
      "std_5_sales: 4552.32\n",
      "mean_4_dow3_2017: 4397.55\n",
      "mean_4_dow1_2017: 4109.40\n",
      "sum_21_promo: 3073.04\n",
      "lag_49_sales: 3068.67\n",
      "promo_15: 2697.33\n",
      "store_state_features: 2308.34\n",
      "sum_6_promo: 2228.73\n",
      "mean_4_dow0_2017: 1972.70\n",
      "mean_20_dow4_2017: 1926.82\n",
      "std_4_sales: 1862.25\n",
      "lag_14_sales: 1748.07\n",
      "lag_63_sales: 1722.96\n",
      "lag_7_sales: 1632.69\n",
      "mean_20_dow5_2017: 1538.74\n",
      "mean_4_dow6_2017: 1458.81\n",
      "mean_20_dow6_2017: 1446.58\n",
      "promo_6: 1428.41\n",
      "lag_6_sales: 1283.57\n",
      "lag_56_sales: 885.88\n",
      "mean_4_dow5_2017: 859.11\n",
      "lag_3_sales: 843.81\n",
      "promo_0: 771.37\n",
      "std_3_sales: 735.46\n",
      "lag_2_sales: 692.95\n",
      "lag_42_sales: 540.12\n",
      "mean_4_dow4_2017: 519.94\n",
      "promo_3: 447.93\n",
      "promo_1: 388.92\n",
      "lag_28_sales: 276.79\n",
      "promo_5: 246.37\n",
      "lag_35_sales: 149.83\n",
      "promo_4: 30.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [10:25<06:04, 60.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.17691\tvalid_1's l2: 1.14473\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.10341\tvalid_1's l2: 1.07205\n",
      "[3]\ttraining's l2: 1.03706\tvalid_1's l2: 1.0065\n",
      "[4]\ttraining's l2: 0.977066\tvalid_1's l2: 0.947053\n",
      "[5]\ttraining's l2: 0.923253\tvalid_1's l2: 0.894017\n",
      "[6]\ttraining's l2: 0.873547\tvalid_1's l2: 0.845275\n",
      "[7]\ttraining's l2: 0.829546\tvalid_1's l2: 0.801837\n",
      "[8]\ttraining's l2: 0.788944\tvalid_1's l2: 0.761933\n",
      "[9]\ttraining's l2: 0.752146\tvalid_1's l2: 0.72596\n",
      "[10]\ttraining's l2: 0.71864\tvalid_1's l2: 0.693226\n",
      "[11]\ttraining's l2: 0.688346\tvalid_1's l2: 0.663493\n",
      "[12]\ttraining's l2: 0.660949\tvalid_1's l2: 0.636759\n",
      "[13]\ttraining's l2: 0.636206\tvalid_1's l2: 0.612669\n",
      "[14]\ttraining's l2: 0.613669\tvalid_1's l2: 0.590814\n",
      "[15]\ttraining's l2: 0.593651\tvalid_1's l2: 0.571347\n",
      "[16]\ttraining's l2: 0.575185\tvalid_1's l2: 0.553525\n",
      "[17]\ttraining's l2: 0.558424\tvalid_1's l2: 0.537087\n",
      "[18]\ttraining's l2: 0.543072\tvalid_1's l2: 0.522379\n",
      "[19]\ttraining's l2: 0.529373\tvalid_1's l2: 0.509125\n",
      "[20]\ttraining's l2: 0.516833\tvalid_1's l2: 0.496984\n",
      "[21]\ttraining's l2: 0.505415\tvalid_1's l2: 0.485959\n",
      "[22]\ttraining's l2: 0.495281\tvalid_1's l2: 0.476179\n",
      "[23]\ttraining's l2: 0.485767\tvalid_1's l2: 0.466994\n",
      "[24]\ttraining's l2: 0.477304\tvalid_1's l2: 0.458871\n",
      "[25]\ttraining's l2: 0.469444\tvalid_1's l2: 0.451346\n",
      "[26]\ttraining's l2: 0.462287\tvalid_1's l2: 0.444529\n",
      "[27]\ttraining's l2: 0.45579\tvalid_1's l2: 0.438269\n",
      "[28]\ttraining's l2: 0.449908\tvalid_1's l2: 0.432699\n",
      "[29]\ttraining's l2: 0.444545\tvalid_1's l2: 0.427568\n",
      "[30]\ttraining's l2: 0.439592\tvalid_1's l2: 0.422924\n",
      "[31]\ttraining's l2: 0.435115\tvalid_1's l2: 0.418679\n",
      "[32]\ttraining's l2: 0.431031\tvalid_1's l2: 0.414723\n",
      "[33]\ttraining's l2: 0.427237\tvalid_1's l2: 0.411188\n",
      "[34]\ttraining's l2: 0.423832\tvalid_1's l2: 0.407963\n",
      "[35]\ttraining's l2: 0.420695\tvalid_1's l2: 0.405024\n",
      "[36]\ttraining's l2: 0.417822\tvalid_1's l2: 0.402262\n",
      "[37]\ttraining's l2: 0.415238\tvalid_1's l2: 0.399781\n",
      "[38]\ttraining's l2: 0.412841\tvalid_1's l2: 0.397551\n",
      "[39]\ttraining's l2: 0.410663\tvalid_1's l2: 0.395561\n",
      "[40]\ttraining's l2: 0.408649\tvalid_1's l2: 0.393604\n",
      "[41]\ttraining's l2: 0.406764\tvalid_1's l2: 0.391941\n",
      "[42]\ttraining's l2: 0.404987\tvalid_1's l2: 0.390274\n",
      "[43]\ttraining's l2: 0.403325\tvalid_1's l2: 0.388744\n",
      "[44]\ttraining's l2: 0.401869\tvalid_1's l2: 0.387432\n",
      "[45]\ttraining's l2: 0.40052\tvalid_1's l2: 0.386259\n",
      "[46]\ttraining's l2: 0.399202\tvalid_1's l2: 0.385001\n",
      "[47]\ttraining's l2: 0.397991\tvalid_1's l2: 0.383911\n",
      "[48]\ttraining's l2: 0.396897\tvalid_1's l2: 0.382953\n",
      "[49]\ttraining's l2: 0.395903\tvalid_1's l2: 0.382093\n",
      "[50]\ttraining's l2: 0.395004\tvalid_1's l2: 0.381368\n",
      "[51]\ttraining's l2: 0.394064\tvalid_1's l2: 0.380479\n",
      "[52]\ttraining's l2: 0.393131\tvalid_1's l2: 0.379687\n",
      "[53]\ttraining's l2: 0.392304\tvalid_1's l2: 0.37901\n",
      "[54]\ttraining's l2: 0.391533\tvalid_1's l2: 0.378316\n",
      "[55]\ttraining's l2: 0.390799\tvalid_1's l2: 0.377653\n",
      "[56]\ttraining's l2: 0.3901\tvalid_1's l2: 0.377012\n",
      "[57]\ttraining's l2: 0.389582\tvalid_1's l2: 0.376612\n",
      "[58]\ttraining's l2: 0.389046\tvalid_1's l2: 0.376142\n",
      "[59]\ttraining's l2: 0.388471\tvalid_1's l2: 0.375542\n",
      "[60]\ttraining's l2: 0.387961\tvalid_1's l2: 0.375078\n",
      "[61]\ttraining's l2: 0.387388\tvalid_1's l2: 0.374614\n",
      "[62]\ttraining's l2: 0.386885\tvalid_1's l2: 0.374165\n",
      "[63]\ttraining's l2: 0.386459\tvalid_1's l2: 0.373796\n",
      "[64]\ttraining's l2: 0.386022\tvalid_1's l2: 0.373388\n",
      "[65]\ttraining's l2: 0.385593\tvalid_1's l2: 0.373062\n",
      "[66]\ttraining's l2: 0.385275\tvalid_1's l2: 0.372818\n",
      "[67]\ttraining's l2: 0.38485\tvalid_1's l2: 0.372528\n",
      "[68]\ttraining's l2: 0.384456\tvalid_1's l2: 0.372198\n",
      "[69]\ttraining's l2: 0.384098\tvalid_1's l2: 0.371955\n",
      "[70]\ttraining's l2: 0.383734\tvalid_1's l2: 0.37171\n",
      "[71]\ttraining's l2: 0.38338\tvalid_1's l2: 0.371462\n",
      "[72]\ttraining's l2: 0.383068\tvalid_1's l2: 0.371249\n",
      "[73]\ttraining's l2: 0.382749\tvalid_1's l2: 0.370992\n",
      "[74]\ttraining's l2: 0.382408\tvalid_1's l2: 0.370752\n",
      "[75]\ttraining's l2: 0.382079\tvalid_1's l2: 0.370524\n",
      "[76]\ttraining's l2: 0.381783\tvalid_1's l2: 0.37029\n",
      "[77]\ttraining's l2: 0.381475\tvalid_1's l2: 0.370023\n",
      "[78]\ttraining's l2: 0.38121\tvalid_1's l2: 0.369824\n",
      "[79]\ttraining's l2: 0.380945\tvalid_1's l2: 0.369636\n",
      "[80]\ttraining's l2: 0.380714\tvalid_1's l2: 0.369412\n",
      "[81]\ttraining's l2: 0.380464\tvalid_1's l2: 0.369238\n",
      "[82]\ttraining's l2: 0.380285\tvalid_1's l2: 0.369079\n",
      "[83]\ttraining's l2: 0.380045\tvalid_1's l2: 0.368918\n",
      "[84]\ttraining's l2: 0.379824\tvalid_1's l2: 0.368771\n",
      "[85]\ttraining's l2: 0.379607\tvalid_1's l2: 0.368582\n",
      "[86]\ttraining's l2: 0.379398\tvalid_1's l2: 0.368433\n",
      "[87]\ttraining's l2: 0.379129\tvalid_1's l2: 0.36824\n",
      "[88]\ttraining's l2: 0.378942\tvalid_1's l2: 0.368073\n",
      "[89]\ttraining's l2: 0.378745\tvalid_1's l2: 0.367981\n",
      "[90]\ttraining's l2: 0.378563\tvalid_1's l2: 0.367918\n",
      "[91]\ttraining's l2: 0.378367\tvalid_1's l2: 0.367767\n",
      "[92]\ttraining's l2: 0.378206\tvalid_1's l2: 0.367637\n",
      "[93]\ttraining's l2: 0.378061\tvalid_1's l2: 0.367536\n",
      "[94]\ttraining's l2: 0.377862\tvalid_1's l2: 0.367429\n",
      "[95]\ttraining's l2: 0.377673\tvalid_1's l2: 0.367305\n",
      "[96]\ttraining's l2: 0.377523\tvalid_1's l2: 0.367204\n",
      "[97]\ttraining's l2: 0.37736\tvalid_1's l2: 0.367065\n",
      "[98]\ttraining's l2: 0.377124\tvalid_1's l2: 0.366847\n",
      "[99]\ttraining's l2: 0.376972\tvalid_1's l2: 0.366808\n",
      "[100]\ttraining's l2: 0.376739\tvalid_1's l2: 0.366676\n",
      "[101]\ttraining's l2: 0.376599\tvalid_1's l2: 0.366541\n",
      "[102]\ttraining's l2: 0.376348\tvalid_1's l2: 0.366372\n",
      "[103]\ttraining's l2: 0.376137\tvalid_1's l2: 0.366242\n",
      "[104]\ttraining's l2: 0.376045\tvalid_1's l2: 0.366185\n",
      "[105]\ttraining's l2: 0.375923\tvalid_1's l2: 0.36612\n",
      "[106]\ttraining's l2: 0.375708\tvalid_1's l2: 0.365999\n",
      "[107]\ttraining's l2: 0.375578\tvalid_1's l2: 0.365918\n",
      "[108]\ttraining's l2: 0.375451\tvalid_1's l2: 0.365842\n",
      "[109]\ttraining's l2: 0.375246\tvalid_1's l2: 0.365744\n",
      "[110]\ttraining's l2: 0.375123\tvalid_1's l2: 0.36567\n",
      "[111]\ttraining's l2: 0.375048\tvalid_1's l2: 0.365604\n",
      "[112]\ttraining's l2: 0.374938\tvalid_1's l2: 0.365554\n",
      "[113]\ttraining's l2: 0.374734\tvalid_1's l2: 0.365442\n",
      "[114]\ttraining's l2: 0.374553\tvalid_1's l2: 0.36531\n",
      "[115]\ttraining's l2: 0.37449\tvalid_1's l2: 0.365284\n",
      "[116]\ttraining's l2: 0.374399\tvalid_1's l2: 0.365242\n",
      "[117]\ttraining's l2: 0.374213\tvalid_1's l2: 0.365104\n",
      "[118]\ttraining's l2: 0.374037\tvalid_1's l2: 0.365059\n",
      "[119]\ttraining's l2: 0.373964\tvalid_1's l2: 0.365013\n",
      "[120]\ttraining's l2: 0.3738\tvalid_1's l2: 0.364934\n",
      "[121]\ttraining's l2: 0.373705\tvalid_1's l2: 0.364945\n",
      "[122]\ttraining's l2: 0.373573\tvalid_1's l2: 0.364834\n",
      "[123]\ttraining's l2: 0.373504\tvalid_1's l2: 0.364794\n",
      "[124]\ttraining's l2: 0.373417\tvalid_1's l2: 0.364778\n",
      "[125]\ttraining's l2: 0.373289\tvalid_1's l2: 0.36471\n",
      "[126]\ttraining's l2: 0.373146\tvalid_1's l2: 0.364571\n",
      "[127]\ttraining's l2: 0.373057\tvalid_1's l2: 0.364513\n",
      "[128]\ttraining's l2: 0.372968\tvalid_1's l2: 0.36448\n",
      "[129]\ttraining's l2: 0.372832\tvalid_1's l2: 0.364397\n",
      "[130]\ttraining's l2: 0.372776\tvalid_1's l2: 0.364372\n",
      "[131]\ttraining's l2: 0.372725\tvalid_1's l2: 0.364345\n",
      "[132]\ttraining's l2: 0.372659\tvalid_1's l2: 0.36433\n",
      "[133]\ttraining's l2: 0.372607\tvalid_1's l2: 0.364317\n",
      "[134]\ttraining's l2: 0.37252\tvalid_1's l2: 0.364289\n",
      "[135]\ttraining's l2: 0.372433\tvalid_1's l2: 0.364257\n",
      "[136]\ttraining's l2: 0.372298\tvalid_1's l2: 0.36413\n",
      "[137]\ttraining's l2: 0.37223\tvalid_1's l2: 0.364104\n",
      "[138]\ttraining's l2: 0.372158\tvalid_1's l2: 0.364077\n",
      "[139]\ttraining's l2: 0.372117\tvalid_1's l2: 0.364067\n",
      "[140]\ttraining's l2: 0.372049\tvalid_1's l2: 0.364061\n",
      "[141]\ttraining's l2: 0.371892\tvalid_1's l2: 0.363919\n",
      "[142]\ttraining's l2: 0.37184\tvalid_1's l2: 0.363912\n",
      "[143]\ttraining's l2: 0.371781\tvalid_1's l2: 0.363893\n",
      "[144]\ttraining's l2: 0.371694\tvalid_1's l2: 0.363907\n",
      "[145]\ttraining's l2: 0.37165\tvalid_1's l2: 0.363859\n",
      "[146]\ttraining's l2: 0.371586\tvalid_1's l2: 0.363809\n",
      "[147]\ttraining's l2: 0.371541\tvalid_1's l2: 0.3638\n",
      "[148]\ttraining's l2: 0.371424\tvalid_1's l2: 0.363734\n",
      "[149]\ttraining's l2: 0.371346\tvalid_1's l2: 0.363706\n",
      "[150]\ttraining's l2: 0.371305\tvalid_1's l2: 0.363692\n",
      "[151]\ttraining's l2: 0.371214\tvalid_1's l2: 0.363602\n",
      "[152]\ttraining's l2: 0.371166\tvalid_1's l2: 0.363597\n",
      "[153]\ttraining's l2: 0.371104\tvalid_1's l2: 0.363597\n",
      "[154]\ttraining's l2: 0.371016\tvalid_1's l2: 0.363536\n",
      "[155]\ttraining's l2: 0.370966\tvalid_1's l2: 0.36351\n",
      "[156]\ttraining's l2: 0.370906\tvalid_1's l2: 0.363497\n",
      "[157]\ttraining's l2: 0.370799\tvalid_1's l2: 0.363467\n",
      "[158]\ttraining's l2: 0.370754\tvalid_1's l2: 0.363444\n",
      "[159]\ttraining's l2: 0.370697\tvalid_1's l2: 0.363405\n",
      "[160]\ttraining's l2: 0.37059\tvalid_1's l2: 0.363341\n",
      "[161]\ttraining's l2: 0.370539\tvalid_1's l2: 0.363317\n",
      "[162]\ttraining's l2: 0.370472\tvalid_1's l2: 0.36329\n",
      "[163]\ttraining's l2: 0.370415\tvalid_1's l2: 0.36328\n",
      "[164]\ttraining's l2: 0.370333\tvalid_1's l2: 0.363273\n",
      "[165]\ttraining's l2: 0.370303\tvalid_1's l2: 0.363265\n",
      "[166]\ttraining's l2: 0.370268\tvalid_1's l2: 0.363234\n",
      "[167]\ttraining's l2: 0.370178\tvalid_1's l2: 0.363176\n",
      "[168]\ttraining's l2: 0.370134\tvalid_1's l2: 0.363173\n",
      "[169]\ttraining's l2: 0.370076\tvalid_1's l2: 0.363152\n",
      "[170]\ttraining's l2: 0.370037\tvalid_1's l2: 0.363143\n",
      "[171]\ttraining's l2: 0.369985\tvalid_1's l2: 0.363109\n",
      "[172]\ttraining's l2: 0.369945\tvalid_1's l2: 0.363104\n",
      "[173]\ttraining's l2: 0.369909\tvalid_1's l2: 0.363066\n",
      "[174]\ttraining's l2: 0.36986\tvalid_1's l2: 0.363029\n",
      "[175]\ttraining's l2: 0.369815\tvalid_1's l2: 0.362992\n",
      "[176]\ttraining's l2: 0.369761\tvalid_1's l2: 0.363013\n",
      "[177]\ttraining's l2: 0.369714\tvalid_1's l2: 0.362964\n",
      "[178]\ttraining's l2: 0.369672\tvalid_1's l2: 0.362932\n",
      "[179]\ttraining's l2: 0.369568\tvalid_1's l2: 0.362835\n",
      "[180]\ttraining's l2: 0.369514\tvalid_1's l2: 0.362797\n",
      "[181]\ttraining's l2: 0.369469\tvalid_1's l2: 0.362794\n",
      "[182]\ttraining's l2: 0.369416\tvalid_1's l2: 0.362772\n",
      "[183]\ttraining's l2: 0.369354\tvalid_1's l2: 0.362771\n",
      "[184]\ttraining's l2: 0.36929\tvalid_1's l2: 0.362695\n",
      "[185]\ttraining's l2: 0.369216\tvalid_1's l2: 0.362654\n",
      "[186]\ttraining's l2: 0.369157\tvalid_1's l2: 0.362623\n",
      "[187]\ttraining's l2: 0.369069\tvalid_1's l2: 0.362571\n",
      "[188]\ttraining's l2: 0.369034\tvalid_1's l2: 0.362557\n",
      "[189]\ttraining's l2: 0.368986\tvalid_1's l2: 0.362542\n",
      "[190]\ttraining's l2: 0.368926\tvalid_1's l2: 0.362507\n",
      "[191]\ttraining's l2: 0.368827\tvalid_1's l2: 0.362434\n",
      "[192]\ttraining's l2: 0.368783\tvalid_1's l2: 0.362437\n",
      "[193]\ttraining's l2: 0.368741\tvalid_1's l2: 0.362428\n",
      "[194]\ttraining's l2: 0.368697\tvalid_1's l2: 0.362396\n",
      "[195]\ttraining's l2: 0.368646\tvalid_1's l2: 0.362354\n",
      "[196]\ttraining's l2: 0.368599\tvalid_1's l2: 0.362353\n",
      "[197]\ttraining's l2: 0.368552\tvalid_1's l2: 0.362352\n",
      "[198]\ttraining's l2: 0.36852\tvalid_1's l2: 0.362342\n",
      "[199]\ttraining's l2: 0.368483\tvalid_1's l2: 0.36233\n",
      "[200]\ttraining's l2: 0.368431\tvalid_1's l2: 0.362318\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.368431\tvalid_1's l2: 0.362318\n",
      "mean_21_sales: 6674610.76\n",
      "mean_14_sales: 2650800.88\n",
      "mean_6_sales: 2224672.42\n",
      "mean_30_sales: 1610108.88\n",
      "mean_5_sales: 1510233.73\n",
      "mean_7_sales: 1117912.33\n",
      "mean_20_dow3_2017: 1103875.93\n",
      "mean_4_dow3_2017: 654590.11\n",
      "mean_60_sales: 581502.53\n",
      "promo_10: 500909.32\n",
      "item_class_features: 257762.12\n",
      "mean_4_sales: 185561.09\n",
      "std_21_sales: 62377.90\n",
      "promo_14: 46493.78\n",
      "mean_4_dow4_2017: 41352.83\n",
      "mean_63_sales: 41271.79\n",
      "store_cluster_features: 41084.12\n",
      "sum_4_promo: 40565.44\n",
      "store_city_features: 40439.45\n",
      "lag_3_sales: 37867.03\n",
      "std_14_sales: 35609.40\n",
      "std_30_sales: 34811.57\n",
      "promo_7: 28886.67\n",
      "item_family_features: 24466.91\n",
      "promo_9: 19964.13\n",
      "promo_12: 18926.24\n",
      "promo_11: 18643.11\n",
      "std_63_sales: 17070.88\n",
      "promo_13: 16548.80\n",
      "sum_2_promo: 16236.52\n",
      "mean_3_sales: 15111.54\n",
      "store_type_features: 13116.04\n",
      "mean_20_dow0_2017: 12927.11\n",
      "std_60_sales: 11057.74\n",
      "mean_20_dow4_2017: 9051.73\n",
      "promo_3: 8630.53\n",
      "sum_14_promo: 7833.93\n",
      "sum_3_promo: 7720.25\n",
      "lag_1_sales: 7069.69\n",
      "sum_7_promo: 6656.72\n",
      "lag_4_sales: 6250.15\n",
      "std_5_sales: 5712.76\n",
      "mean_20_dow2_2017: 5638.28\n",
      "sum_21_promo: 5633.55\n",
      "store_state_features: 5546.12\n",
      "promo_8: 5259.70\n",
      "sum_5_promo: 4570.10\n",
      "std_6_sales: 4086.45\n",
      "sum_6_promo: 3562.00\n",
      "mean_4_dow0_2017: 3290.23\n",
      "std_7_sales: 3277.33\n",
      "mean_4_dow1_2017: 2982.57\n",
      "promo_6: 2789.47\n",
      "promo_15: 2723.85\n",
      "lag_5_sales: 2719.53\n",
      "mean_4_dow2_2017: 2501.79\n",
      "mean_20_dow1_2017: 2317.92\n",
      "std_4_sales: 1979.20\n",
      "lag_14_sales: 1922.76\n",
      "mean_20_dow5_2017: 1853.73\n",
      "lag_49_sales: 1696.61\n",
      "mean_20_dow6_2017: 1420.14\n",
      "lag_56_sales: 1085.71\n",
      "promo_2: 977.59\n",
      "lag_2_sales: 941.43\n",
      "std_3_sales: 812.44\n",
      "lag_21_sales: 770.22\n",
      "lag_6_sales: 737.00\n",
      "lag_63_sales: 696.94\n",
      "mean_4_dow6_2017: 695.70\n",
      "lag_35_sales: 552.35\n",
      "lag_7_sales: 456.70\n",
      "lag_42_sales: 349.87\n",
      "mean_4_dow5_2017: 264.17\n",
      "promo_1: 185.83\n",
      "lag_28_sales: 180.63\n",
      "promo_0: 178.28\n",
      "promo_5: 149.55\n",
      "promo_4: 101.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [11:24<05:01, 60.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.24003\tvalid_1's l2: 1.20977\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.16189\tvalid_1's l2: 1.13079\n",
      "[3]\ttraining's l2: 1.09103\tvalid_1's l2: 1.05954\n",
      "[4]\ttraining's l2: 1.02711\tvalid_1's l2: 0.994986\n",
      "[5]\ttraining's l2: 0.969416\tvalid_1's l2: 0.937096\n",
      "[6]\ttraining's l2: 0.917003\tvalid_1's l2: 0.88445\n",
      "[7]\ttraining's l2: 0.870138\tvalid_1's l2: 0.837959\n",
      "[8]\ttraining's l2: 0.827047\tvalid_1's l2: 0.795167\n",
      "[9]\ttraining's l2: 0.788495\tvalid_1's l2: 0.756952\n",
      "[10]\ttraining's l2: 0.753573\tvalid_1's l2: 0.722103\n",
      "[11]\ttraining's l2: 0.72144\tvalid_1's l2: 0.690352\n",
      "[12]\ttraining's l2: 0.692712\tvalid_1's l2: 0.662321\n",
      "[13]\ttraining's l2: 0.666268\tvalid_1's l2: 0.636687\n",
      "[14]\ttraining's l2: 0.642048\tvalid_1's l2: 0.613084\n",
      "[15]\ttraining's l2: 0.620226\tvalid_1's l2: 0.59183\n",
      "[16]\ttraining's l2: 0.600437\tvalid_1's l2: 0.572698\n",
      "[17]\ttraining's l2: 0.582409\tvalid_1's l2: 0.555012\n",
      "[18]\ttraining's l2: 0.566437\tvalid_1's l2: 0.540203\n",
      "[19]\ttraining's l2: 0.551758\tvalid_1's l2: 0.526153\n",
      "[20]\ttraining's l2: 0.538253\tvalid_1's l2: 0.513115\n",
      "[21]\ttraining's l2: 0.526405\tvalid_1's l2: 0.501892\n",
      "[22]\ttraining's l2: 0.515416\tvalid_1's l2: 0.491428\n",
      "[23]\ttraining's l2: 0.505198\tvalid_1's l2: 0.481718\n",
      "[24]\ttraining's l2: 0.495885\tvalid_1's l2: 0.47286\n",
      "[25]\ttraining's l2: 0.487415\tvalid_1's l2: 0.46493\n",
      "[26]\ttraining's l2: 0.479649\tvalid_1's l2: 0.457523\n",
      "[27]\ttraining's l2: 0.472697\tvalid_1's l2: 0.451154\n",
      "[28]\ttraining's l2: 0.466437\tvalid_1's l2: 0.445506\n",
      "[29]\ttraining's l2: 0.460613\tvalid_1's l2: 0.440121\n",
      "[30]\ttraining's l2: 0.455359\tvalid_1's l2: 0.435341\n",
      "[31]\ttraining's l2: 0.450731\tvalid_1's l2: 0.431188\n",
      "[32]\ttraining's l2: 0.446344\tvalid_1's l2: 0.427231\n",
      "[33]\ttraining's l2: 0.442259\tvalid_1's l2: 0.423595\n",
      "[34]\ttraining's l2: 0.438535\tvalid_1's l2: 0.420222\n",
      "[35]\ttraining's l2: 0.435057\tvalid_1's l2: 0.41705\n",
      "[36]\ttraining's l2: 0.43183\tvalid_1's l2: 0.414196\n",
      "[37]\ttraining's l2: 0.429066\tvalid_1's l2: 0.411737\n",
      "[38]\ttraining's l2: 0.426392\tvalid_1's l2: 0.409366\n",
      "[39]\ttraining's l2: 0.42403\tvalid_1's l2: 0.407309\n",
      "[40]\ttraining's l2: 0.421733\tvalid_1's l2: 0.405463\n",
      "[41]\ttraining's l2: 0.419595\tvalid_1's l2: 0.403685\n",
      "[42]\ttraining's l2: 0.4177\tvalid_1's l2: 0.402084\n",
      "[43]\ttraining's l2: 0.415869\tvalid_1's l2: 0.400558\n",
      "[44]\ttraining's l2: 0.414245\tvalid_1's l2: 0.399128\n",
      "[45]\ttraining's l2: 0.412724\tvalid_1's l2: 0.397759\n",
      "[46]\ttraining's l2: 0.411329\tvalid_1's l2: 0.396558\n",
      "[47]\ttraining's l2: 0.409994\tvalid_1's l2: 0.395592\n",
      "[48]\ttraining's l2: 0.408684\tvalid_1's l2: 0.394577\n",
      "[49]\ttraining's l2: 0.407543\tvalid_1's l2: 0.393804\n",
      "[50]\ttraining's l2: 0.40652\tvalid_1's l2: 0.393028\n",
      "[51]\ttraining's l2: 0.405494\tvalid_1's l2: 0.39212\n",
      "[52]\ttraining's l2: 0.404504\tvalid_1's l2: 0.391351\n",
      "[53]\ttraining's l2: 0.403609\tvalid_1's l2: 0.390664\n",
      "[54]\ttraining's l2: 0.402811\tvalid_1's l2: 0.39001\n",
      "[55]\ttraining's l2: 0.402095\tvalid_1's l2: 0.389552\n",
      "[56]\ttraining's l2: 0.401364\tvalid_1's l2: 0.388967\n",
      "[57]\ttraining's l2: 0.40065\tvalid_1's l2: 0.388306\n",
      "[58]\ttraining's l2: 0.400075\tvalid_1's l2: 0.387811\n",
      "[59]\ttraining's l2: 0.39947\tvalid_1's l2: 0.387308\n",
      "[60]\ttraining's l2: 0.398854\tvalid_1's l2: 0.38691\n",
      "[61]\ttraining's l2: 0.398272\tvalid_1's l2: 0.386434\n",
      "[62]\ttraining's l2: 0.3977\tvalid_1's l2: 0.386063\n",
      "[63]\ttraining's l2: 0.397183\tvalid_1's l2: 0.385621\n",
      "[64]\ttraining's l2: 0.396717\tvalid_1's l2: 0.385268\n",
      "[65]\ttraining's l2: 0.396137\tvalid_1's l2: 0.384773\n",
      "[66]\ttraining's l2: 0.395759\tvalid_1's l2: 0.384471\n",
      "[67]\ttraining's l2: 0.395344\tvalid_1's l2: 0.384207\n",
      "[68]\ttraining's l2: 0.394959\tvalid_1's l2: 0.38394\n",
      "[69]\ttraining's l2: 0.394452\tvalid_1's l2: 0.383482\n",
      "[70]\ttraining's l2: 0.394048\tvalid_1's l2: 0.38318\n",
      "[71]\ttraining's l2: 0.393654\tvalid_1's l2: 0.382956\n",
      "[72]\ttraining's l2: 0.39323\tvalid_1's l2: 0.382648\n",
      "[73]\ttraining's l2: 0.392868\tvalid_1's l2: 0.382405\n",
      "[74]\ttraining's l2: 0.39253\tvalid_1's l2: 0.382166\n",
      "[75]\ttraining's l2: 0.392194\tvalid_1's l2: 0.381949\n",
      "[76]\ttraining's l2: 0.391827\tvalid_1's l2: 0.381714\n",
      "[77]\ttraining's l2: 0.391566\tvalid_1's l2: 0.38148\n",
      "[78]\ttraining's l2: 0.391297\tvalid_1's l2: 0.381325\n",
      "[79]\ttraining's l2: 0.390954\tvalid_1's l2: 0.381134\n",
      "[80]\ttraining's l2: 0.390587\tvalid_1's l2: 0.380833\n",
      "[81]\ttraining's l2: 0.390311\tvalid_1's l2: 0.380602\n",
      "[82]\ttraining's l2: 0.390025\tvalid_1's l2: 0.380349\n",
      "[83]\ttraining's l2: 0.389763\tvalid_1's l2: 0.380205\n",
      "[84]\ttraining's l2: 0.389534\tvalid_1's l2: 0.380033\n",
      "[85]\ttraining's l2: 0.38928\tvalid_1's l2: 0.379914\n",
      "[86]\ttraining's l2: 0.389027\tvalid_1's l2: 0.379675\n",
      "[87]\ttraining's l2: 0.388825\tvalid_1's l2: 0.37954\n",
      "[88]\ttraining's l2: 0.388554\tvalid_1's l2: 0.379253\n",
      "[89]\ttraining's l2: 0.388248\tvalid_1's l2: 0.379073\n",
      "[90]\ttraining's l2: 0.387955\tvalid_1's l2: 0.378871\n",
      "[91]\ttraining's l2: 0.38775\tvalid_1's l2: 0.378717\n",
      "[92]\ttraining's l2: 0.387588\tvalid_1's l2: 0.37859\n",
      "[93]\ttraining's l2: 0.387371\tvalid_1's l2: 0.378403\n",
      "[94]\ttraining's l2: 0.387071\tvalid_1's l2: 0.378184\n",
      "[95]\ttraining's l2: 0.386789\tvalid_1's l2: 0.378015\n",
      "[96]\ttraining's l2: 0.386619\tvalid_1's l2: 0.377918\n",
      "[97]\ttraining's l2: 0.386453\tvalid_1's l2: 0.377821\n",
      "[98]\ttraining's l2: 0.386301\tvalid_1's l2: 0.377711\n",
      "[99]\ttraining's l2: 0.38607\tvalid_1's l2: 0.377587\n",
      "[100]\ttraining's l2: 0.385905\tvalid_1's l2: 0.377461\n",
      "[101]\ttraining's l2: 0.38578\tvalid_1's l2: 0.377394\n",
      "[102]\ttraining's l2: 0.385641\tvalid_1's l2: 0.377299\n",
      "[103]\ttraining's l2: 0.385447\tvalid_1's l2: 0.377127\n",
      "[104]\ttraining's l2: 0.385338\tvalid_1's l2: 0.377055\n",
      "[105]\ttraining's l2: 0.385117\tvalid_1's l2: 0.376854\n",
      "[106]\ttraining's l2: 0.384868\tvalid_1's l2: 0.376739\n",
      "[107]\ttraining's l2: 0.384741\tvalid_1's l2: 0.376663\n",
      "[108]\ttraining's l2: 0.384599\tvalid_1's l2: 0.376621\n",
      "[109]\ttraining's l2: 0.384441\tvalid_1's l2: 0.376513\n",
      "[110]\ttraining's l2: 0.38419\tvalid_1's l2: 0.376305\n",
      "[111]\ttraining's l2: 0.38401\tvalid_1's l2: 0.376173\n",
      "[112]\ttraining's l2: 0.38391\tvalid_1's l2: 0.376101\n",
      "[113]\ttraining's l2: 0.383697\tvalid_1's l2: 0.375994\n",
      "[114]\ttraining's l2: 0.383593\tvalid_1's l2: 0.375919\n",
      "[115]\ttraining's l2: 0.383479\tvalid_1's l2: 0.375834\n",
      "[116]\ttraining's l2: 0.383315\tvalid_1's l2: 0.375783\n",
      "[117]\ttraining's l2: 0.383133\tvalid_1's l2: 0.37568\n",
      "[118]\ttraining's l2: 0.383037\tvalid_1's l2: 0.375609\n",
      "[119]\ttraining's l2: 0.382936\tvalid_1's l2: 0.375565\n",
      "[120]\ttraining's l2: 0.38277\tvalid_1's l2: 0.375486\n",
      "[121]\ttraining's l2: 0.382684\tvalid_1's l2: 0.37542\n",
      "[122]\ttraining's l2: 0.382601\tvalid_1's l2: 0.375348\n",
      "[123]\ttraining's l2: 0.382462\tvalid_1's l2: 0.375331\n",
      "[124]\ttraining's l2: 0.382348\tvalid_1's l2: 0.375276\n",
      "[125]\ttraining's l2: 0.382286\tvalid_1's l2: 0.375242\n",
      "[126]\ttraining's l2: 0.382112\tvalid_1's l2: 0.375092\n",
      "[127]\ttraining's l2: 0.381941\tvalid_1's l2: 0.374937\n",
      "[128]\ttraining's l2: 0.381808\tvalid_1's l2: 0.374835\n",
      "[129]\ttraining's l2: 0.381728\tvalid_1's l2: 0.374779\n",
      "[130]\ttraining's l2: 0.381622\tvalid_1's l2: 0.374757\n",
      "[131]\ttraining's l2: 0.381554\tvalid_1's l2: 0.374697\n",
      "[132]\ttraining's l2: 0.38138\tvalid_1's l2: 0.374615\n",
      "[133]\ttraining's l2: 0.3812\tvalid_1's l2: 0.374544\n",
      "[134]\ttraining's l2: 0.381117\tvalid_1's l2: 0.374508\n",
      "[135]\ttraining's l2: 0.38105\tvalid_1's l2: 0.374481\n",
      "[136]\ttraining's l2: 0.380904\tvalid_1's l2: 0.374378\n",
      "[137]\ttraining's l2: 0.380824\tvalid_1's l2: 0.374344\n",
      "[138]\ttraining's l2: 0.380704\tvalid_1's l2: 0.374251\n",
      "[139]\ttraining's l2: 0.380613\tvalid_1's l2: 0.374214\n",
      "[140]\ttraining's l2: 0.380562\tvalid_1's l2: 0.37417\n",
      "[141]\ttraining's l2: 0.380452\tvalid_1's l2: 0.374129\n",
      "[142]\ttraining's l2: 0.380334\tvalid_1's l2: 0.374059\n",
      "[143]\ttraining's l2: 0.380242\tvalid_1's l2: 0.374043\n",
      "[144]\ttraining's l2: 0.38014\tvalid_1's l2: 0.374019\n",
      "[145]\ttraining's l2: 0.380078\tvalid_1's l2: 0.373963\n",
      "[146]\ttraining's l2: 0.380005\tvalid_1's l2: 0.373925\n",
      "[147]\ttraining's l2: 0.379936\tvalid_1's l2: 0.373885\n",
      "[148]\ttraining's l2: 0.37988\tvalid_1's l2: 0.373858\n",
      "[149]\ttraining's l2: 0.379805\tvalid_1's l2: 0.373841\n",
      "[150]\ttraining's l2: 0.379739\tvalid_1's l2: 0.373818\n",
      "[151]\ttraining's l2: 0.379676\tvalid_1's l2: 0.373762\n",
      "[152]\ttraining's l2: 0.379574\tvalid_1's l2: 0.373739\n",
      "[153]\ttraining's l2: 0.379513\tvalid_1's l2: 0.373722\n",
      "[154]\ttraining's l2: 0.379455\tvalid_1's l2: 0.373683\n",
      "[155]\ttraining's l2: 0.379365\tvalid_1's l2: 0.3737\n",
      "[156]\ttraining's l2: 0.37931\tvalid_1's l2: 0.373646\n",
      "[157]\ttraining's l2: 0.379236\tvalid_1's l2: 0.373663\n",
      "[158]\ttraining's l2: 0.379181\tvalid_1's l2: 0.373617\n",
      "[159]\ttraining's l2: 0.379077\tvalid_1's l2: 0.373552\n",
      "[160]\ttraining's l2: 0.378997\tvalid_1's l2: 0.373545\n",
      "[161]\ttraining's l2: 0.378935\tvalid_1's l2: 0.373527\n",
      "[162]\ttraining's l2: 0.378816\tvalid_1's l2: 0.373404\n",
      "[163]\ttraining's l2: 0.378706\tvalid_1's l2: 0.37331\n",
      "[164]\ttraining's l2: 0.378663\tvalid_1's l2: 0.373295\n",
      "[165]\ttraining's l2: 0.378608\tvalid_1's l2: 0.373295\n",
      "[166]\ttraining's l2: 0.378541\tvalid_1's l2: 0.373289\n",
      "[167]\ttraining's l2: 0.37849\tvalid_1's l2: 0.373259\n",
      "[168]\ttraining's l2: 0.378396\tvalid_1's l2: 0.373235\n",
      "[169]\ttraining's l2: 0.378306\tvalid_1's l2: 0.373204\n",
      "[170]\ttraining's l2: 0.378268\tvalid_1's l2: 0.373179\n",
      "[171]\ttraining's l2: 0.37823\tvalid_1's l2: 0.373147\n",
      "[172]\ttraining's l2: 0.378181\tvalid_1's l2: 0.373135\n",
      "[173]\ttraining's l2: 0.378141\tvalid_1's l2: 0.373103\n",
      "[174]\ttraining's l2: 0.378056\tvalid_1's l2: 0.37305\n",
      "[175]\ttraining's l2: 0.378012\tvalid_1's l2: 0.373041\n",
      "[176]\ttraining's l2: 0.377921\tvalid_1's l2: 0.373016\n",
      "[177]\ttraining's l2: 0.377872\tvalid_1's l2: 0.372988\n",
      "[178]\ttraining's l2: 0.377806\tvalid_1's l2: 0.372973\n",
      "[179]\ttraining's l2: 0.377715\tvalid_1's l2: 0.372913\n",
      "[180]\ttraining's l2: 0.377663\tvalid_1's l2: 0.372913\n",
      "[181]\ttraining's l2: 0.377583\tvalid_1's l2: 0.372857\n",
      "[182]\ttraining's l2: 0.377533\tvalid_1's l2: 0.372853\n",
      "[183]\ttraining's l2: 0.377473\tvalid_1's l2: 0.372851\n",
      "[184]\ttraining's l2: 0.37741\tvalid_1's l2: 0.37283\n",
      "[185]\ttraining's l2: 0.377369\tvalid_1's l2: 0.372781\n",
      "[186]\ttraining's l2: 0.377322\tvalid_1's l2: 0.372777\n",
      "[187]\ttraining's l2: 0.377252\tvalid_1's l2: 0.372816\n",
      "[188]\ttraining's l2: 0.377184\tvalid_1's l2: 0.3728\n",
      "[189]\ttraining's l2: 0.377123\tvalid_1's l2: 0.372793\n",
      "[190]\ttraining's l2: 0.377069\tvalid_1's l2: 0.37275\n",
      "[191]\ttraining's l2: 0.377008\tvalid_1's l2: 0.372716\n",
      "[192]\ttraining's l2: 0.376946\tvalid_1's l2: 0.372706\n",
      "[193]\ttraining's l2: 0.376909\tvalid_1's l2: 0.372687\n",
      "[194]\ttraining's l2: 0.376855\tvalid_1's l2: 0.372637\n",
      "[195]\ttraining's l2: 0.376814\tvalid_1's l2: 0.372593\n",
      "[196]\ttraining's l2: 0.37675\tvalid_1's l2: 0.372598\n",
      "[197]\ttraining's l2: 0.37671\tvalid_1's l2: 0.372564\n",
      "[198]\ttraining's l2: 0.376655\tvalid_1's l2: 0.372557\n",
      "[199]\ttraining's l2: 0.376622\tvalid_1's l2: 0.37253\n",
      "[200]\ttraining's l2: 0.376546\tvalid_1's l2: 0.372527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.376546\tvalid_1's l2: 0.372527\n",
      "mean_21_sales: 5887138.37\n",
      "mean_4_dow4_2017: 5101686.38\n",
      "mean_14_sales: 2968543.32\n",
      "mean_20_dow4_2017: 1678179.07\n",
      "mean_4_sales: 1386274.76\n",
      "mean_5_sales: 868024.87\n",
      "promo_11: 485484.76\n",
      "mean_6_sales: 441318.83\n",
      "mean_7_sales: 414226.48\n",
      "mean_30_sales: 368054.38\n",
      "mean_60_sales: 342265.96\n",
      "item_class_features: 275850.55\n",
      "lag_3_sales: 163512.77\n",
      "store_cluster_features: 70263.05\n",
      "promo_14: 59588.22\n",
      "sum_3_promo: 53073.70\n",
      "std_21_sales: 52483.03\n",
      "store_city_features: 49901.89\n",
      "mean_4_dow3_2017: 43885.81\n",
      "std_14_sales: 41375.98\n",
      "promo_12: 40165.17\n",
      "item_family_features: 31113.19\n",
      "promo_13: 26933.41\n",
      "std_30_sales: 23797.06\n",
      "promo_10: 23355.77\n",
      "mean_20_dow3_2017: 20392.70\n",
      "promo_7: 19867.83\n",
      "store_type_features: 19355.28\n",
      "promo_9: 16360.00\n",
      "mean_3_sales: 15238.44\n",
      "std_63_sales: 14598.39\n",
      "mean_20_dow0_2017: 14210.16\n",
      "mean_63_sales: 13171.84\n",
      "sum_4_promo: 11699.75\n",
      "std_60_sales: 11492.16\n",
      "promo_4: 11107.49\n",
      "promo_8: 10029.88\n",
      "sum_2_promo: 8515.68\n",
      "sum_7_promo: 8440.80\n",
      "lag_1_sales: 7617.78\n",
      "sum_21_promo: 6094.42\n",
      "sum_14_promo: 5871.71\n",
      "std_6_sales: 5224.31\n",
      "store_state_features: 4809.15\n",
      "mean_20_dow2_2017: 4364.70\n",
      "mean_20_dow1_2017: 4046.42\n",
      "std_5_sales: 4044.59\n",
      "std_4_sales: 3942.33\n",
      "lag_4_sales: 3779.44\n",
      "lag_63_sales: 3623.66\n",
      "mean_4_dow5_2017: 3293.46\n",
      "mean_20_dow6_2017: 2794.10\n",
      "promo_6: 2650.57\n",
      "promo_15: 2407.82\n",
      "mean_4_dow0_2017: 1558.84\n",
      "std_7_sales: 1491.64\n",
      "lag_56_sales: 1480.87\n",
      "lag_7_sales: 1253.96\n",
      "lag_14_sales: 1194.51\n",
      "sum_5_promo: 1125.32\n",
      "lag_6_sales: 1084.36\n",
      "mean_4_dow2_2017: 1072.38\n",
      "lag_42_sales: 1035.06\n",
      "mean_4_dow1_2017: 1029.57\n",
      "mean_4_dow6_2017: 952.57\n",
      "mean_20_dow5_2017: 861.94\n",
      "std_3_sales: 847.23\n",
      "lag_2_sales: 748.99\n",
      "lag_49_sales: 731.31\n",
      "lag_21_sales: 707.46\n",
      "sum_6_promo: 703.39\n",
      "promo_0: 518.75\n",
      "lag_5_sales: 508.41\n",
      "promo_3: 448.24\n",
      "promo_2: 376.77\n",
      "promo_5: 212.07\n",
      "promo_1: 188.34\n",
      "lag_28_sales: 172.21\n",
      "lag_35_sales: 67.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [12:24<04:00, 60.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.07777\tvalid_1's l2: 1.0496\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.01393\tvalid_1's l2: 0.986254\n",
      "[3]\ttraining's l2: 0.957328\tvalid_1's l2: 0.929677\n",
      "[4]\ttraining's l2: 0.906105\tvalid_1's l2: 0.878364\n",
      "[5]\ttraining's l2: 0.859742\tvalid_1's l2: 0.832136\n",
      "[6]\ttraining's l2: 0.816597\tvalid_1's l2: 0.789246\n",
      "[7]\ttraining's l2: 0.778627\tvalid_1's l2: 0.751509\n",
      "[8]\ttraining's l2: 0.743196\tvalid_1's l2: 0.716491\n",
      "[9]\ttraining's l2: 0.711108\tvalid_1's l2: 0.684702\n",
      "[10]\ttraining's l2: 0.682738\tvalid_1's l2: 0.656633\n",
      "[11]\ttraining's l2: 0.656305\tvalid_1's l2: 0.630655\n",
      "[12]\ttraining's l2: 0.632324\tvalid_1's l2: 0.607142\n",
      "[13]\ttraining's l2: 0.610536\tvalid_1's l2: 0.585803\n",
      "[14]\ttraining's l2: 0.590752\tvalid_1's l2: 0.566279\n",
      "[15]\ttraining's l2: 0.572849\tvalid_1's l2: 0.548717\n",
      "[16]\ttraining's l2: 0.556692\tvalid_1's l2: 0.532769\n",
      "[17]\ttraining's l2: 0.542356\tvalid_1's l2: 0.518759\n",
      "[18]\ttraining's l2: 0.528945\tvalid_1's l2: 0.505667\n",
      "[19]\ttraining's l2: 0.516843\tvalid_1's l2: 0.493842\n",
      "[20]\ttraining's l2: 0.505785\tvalid_1's l2: 0.483092\n",
      "[21]\ttraining's l2: 0.495733\tvalid_1's l2: 0.473336\n",
      "[22]\ttraining's l2: 0.486724\tvalid_1's l2: 0.464404\n",
      "[23]\ttraining's l2: 0.478468\tvalid_1's l2: 0.456383\n",
      "[24]\ttraining's l2: 0.470872\tvalid_1's l2: 0.449195\n",
      "[25]\ttraining's l2: 0.46402\tvalid_1's l2: 0.442542\n",
      "[26]\ttraining's l2: 0.457866\tvalid_1's l2: 0.436748\n",
      "[27]\ttraining's l2: 0.452162\tvalid_1's l2: 0.431219\n",
      "[28]\ttraining's l2: 0.447129\tvalid_1's l2: 0.426495\n",
      "[29]\ttraining's l2: 0.442563\tvalid_1's l2: 0.422097\n",
      "[30]\ttraining's l2: 0.438198\tvalid_1's l2: 0.417922\n",
      "[31]\ttraining's l2: 0.434369\tvalid_1's l2: 0.414293\n",
      "[32]\ttraining's l2: 0.430738\tvalid_1's l2: 0.410817\n",
      "[33]\ttraining's l2: 0.427399\tvalid_1's l2: 0.407606\n",
      "[34]\ttraining's l2: 0.424341\tvalid_1's l2: 0.404618\n",
      "[35]\ttraining's l2: 0.421528\tvalid_1's l2: 0.401939\n",
      "[36]\ttraining's l2: 0.418953\tvalid_1's l2: 0.399431\n",
      "[37]\ttraining's l2: 0.416601\tvalid_1's l2: 0.397173\n",
      "[38]\ttraining's l2: 0.414516\tvalid_1's l2: 0.395279\n",
      "[39]\ttraining's l2: 0.41254\tvalid_1's l2: 0.393464\n",
      "[40]\ttraining's l2: 0.410821\tvalid_1's l2: 0.391897\n",
      "[41]\ttraining's l2: 0.409136\tvalid_1's l2: 0.390354\n",
      "[42]\ttraining's l2: 0.407581\tvalid_1's l2: 0.388904\n",
      "[43]\ttraining's l2: 0.406184\tvalid_1's l2: 0.387624\n",
      "[44]\ttraining's l2: 0.40488\tvalid_1's l2: 0.386396\n",
      "[45]\ttraining's l2: 0.403651\tvalid_1's l2: 0.385241\n",
      "[46]\ttraining's l2: 0.402543\tvalid_1's l2: 0.384186\n",
      "[47]\ttraining's l2: 0.401546\tvalid_1's l2: 0.383387\n",
      "[48]\ttraining's l2: 0.400527\tvalid_1's l2: 0.38248\n",
      "[49]\ttraining's l2: 0.39957\tvalid_1's l2: 0.381634\n",
      "[50]\ttraining's l2: 0.398727\tvalid_1's l2: 0.380892\n",
      "[51]\ttraining's l2: 0.39788\tvalid_1's l2: 0.380142\n",
      "[52]\ttraining's l2: 0.397175\tvalid_1's l2: 0.379548\n",
      "[53]\ttraining's l2: 0.396464\tvalid_1's l2: 0.378943\n",
      "[54]\ttraining's l2: 0.395744\tvalid_1's l2: 0.378342\n",
      "[55]\ttraining's l2: 0.395089\tvalid_1's l2: 0.377777\n",
      "[56]\ttraining's l2: 0.394487\tvalid_1's l2: 0.377271\n",
      "[57]\ttraining's l2: 0.39398\tvalid_1's l2: 0.376797\n",
      "[58]\ttraining's l2: 0.393484\tvalid_1's l2: 0.376401\n",
      "[59]\ttraining's l2: 0.392997\tvalid_1's l2: 0.375983\n",
      "[60]\ttraining's l2: 0.392545\tvalid_1's l2: 0.375675\n",
      "[61]\ttraining's l2: 0.39212\tvalid_1's l2: 0.375407\n",
      "[62]\ttraining's l2: 0.391662\tvalid_1's l2: 0.375106\n",
      "[63]\ttraining's l2: 0.391276\tvalid_1's l2: 0.374758\n",
      "[64]\ttraining's l2: 0.390833\tvalid_1's l2: 0.374389\n",
      "[65]\ttraining's l2: 0.390511\tvalid_1's l2: 0.374071\n",
      "[66]\ttraining's l2: 0.390216\tvalid_1's l2: 0.373838\n",
      "[67]\ttraining's l2: 0.389864\tvalid_1's l2: 0.373651\n",
      "[68]\ttraining's l2: 0.389575\tvalid_1's l2: 0.373504\n",
      "[69]\ttraining's l2: 0.389233\tvalid_1's l2: 0.373231\n",
      "[70]\ttraining's l2: 0.388881\tvalid_1's l2: 0.373061\n",
      "[71]\ttraining's l2: 0.38843\tvalid_1's l2: 0.372751\n",
      "[72]\ttraining's l2: 0.388038\tvalid_1's l2: 0.372484\n",
      "[73]\ttraining's l2: 0.387734\tvalid_1's l2: 0.372251\n",
      "[74]\ttraining's l2: 0.387329\tvalid_1's l2: 0.371991\n",
      "[75]\ttraining's l2: 0.38695\tvalid_1's l2: 0.371799\n",
      "[76]\ttraining's l2: 0.386618\tvalid_1's l2: 0.37163\n",
      "[77]\ttraining's l2: 0.386362\tvalid_1's l2: 0.371446\n",
      "[78]\ttraining's l2: 0.386133\tvalid_1's l2: 0.371339\n",
      "[79]\ttraining's l2: 0.385869\tvalid_1's l2: 0.371196\n",
      "[80]\ttraining's l2: 0.385665\tvalid_1's l2: 0.371048\n",
      "[81]\ttraining's l2: 0.38543\tvalid_1's l2: 0.370894\n",
      "[82]\ttraining's l2: 0.385283\tvalid_1's l2: 0.370775\n",
      "[83]\ttraining's l2: 0.385093\tvalid_1's l2: 0.370682\n",
      "[84]\ttraining's l2: 0.384876\tvalid_1's l2: 0.370618\n",
      "[85]\ttraining's l2: 0.384674\tvalid_1's l2: 0.3705\n",
      "[86]\ttraining's l2: 0.384467\tvalid_1's l2: 0.370373\n",
      "[87]\ttraining's l2: 0.38434\tvalid_1's l2: 0.370331\n",
      "[88]\ttraining's l2: 0.384144\tvalid_1's l2: 0.370167\n",
      "[89]\ttraining's l2: 0.383961\tvalid_1's l2: 0.370075\n",
      "[90]\ttraining's l2: 0.383735\tvalid_1's l2: 0.369911\n",
      "[91]\ttraining's l2: 0.383512\tvalid_1's l2: 0.369813\n",
      "[92]\ttraining's l2: 0.38339\tvalid_1's l2: 0.369708\n",
      "[93]\ttraining's l2: 0.383157\tvalid_1's l2: 0.369532\n",
      "[94]\ttraining's l2: 0.383009\tvalid_1's l2: 0.369471\n",
      "[95]\ttraining's l2: 0.382877\tvalid_1's l2: 0.369422\n",
      "[96]\ttraining's l2: 0.382693\tvalid_1's l2: 0.369332\n",
      "[97]\ttraining's l2: 0.382469\tvalid_1's l2: 0.369191\n",
      "[98]\ttraining's l2: 0.382358\tvalid_1's l2: 0.369135\n",
      "[99]\ttraining's l2: 0.382262\tvalid_1's l2: 0.369115\n",
      "[100]\ttraining's l2: 0.38205\tvalid_1's l2: 0.368956\n",
      "[101]\ttraining's l2: 0.381862\tvalid_1's l2: 0.368829\n",
      "[102]\ttraining's l2: 0.381758\tvalid_1's l2: 0.368782\n",
      "[103]\ttraining's l2: 0.381628\tvalid_1's l2: 0.368669\n",
      "[104]\ttraining's l2: 0.381552\tvalid_1's l2: 0.368598\n",
      "[105]\ttraining's l2: 0.381344\tvalid_1's l2: 0.368475\n",
      "[106]\ttraining's l2: 0.381137\tvalid_1's l2: 0.368368\n",
      "[107]\ttraining's l2: 0.38096\tvalid_1's l2: 0.36825\n",
      "[108]\ttraining's l2: 0.380822\tvalid_1's l2: 0.368201\n",
      "[109]\ttraining's l2: 0.380723\tvalid_1's l2: 0.368165\n",
      "[110]\ttraining's l2: 0.380519\tvalid_1's l2: 0.368016\n",
      "[111]\ttraining's l2: 0.380434\tvalid_1's l2: 0.367948\n",
      "[112]\ttraining's l2: 0.380341\tvalid_1's l2: 0.367914\n",
      "[113]\ttraining's l2: 0.380232\tvalid_1's l2: 0.367863\n",
      "[114]\ttraining's l2: 0.380134\tvalid_1's l2: 0.367826\n",
      "[115]\ttraining's l2: 0.380011\tvalid_1's l2: 0.367769\n",
      "[116]\ttraining's l2: 0.379877\tvalid_1's l2: 0.367735\n",
      "[117]\ttraining's l2: 0.379812\tvalid_1's l2: 0.367681\n",
      "[118]\ttraining's l2: 0.37974\tvalid_1's l2: 0.367636\n",
      "[119]\ttraining's l2: 0.379657\tvalid_1's l2: 0.367616\n",
      "[120]\ttraining's l2: 0.379539\tvalid_1's l2: 0.367595\n",
      "[121]\ttraining's l2: 0.379435\tvalid_1's l2: 0.367526\n",
      "[122]\ttraining's l2: 0.3793\tvalid_1's l2: 0.367414\n",
      "[123]\ttraining's l2: 0.379235\tvalid_1's l2: 0.367406\n",
      "[124]\ttraining's l2: 0.379096\tvalid_1's l2: 0.367345\n",
      "[125]\ttraining's l2: 0.379026\tvalid_1's l2: 0.367317\n",
      "[126]\ttraining's l2: 0.378941\tvalid_1's l2: 0.367263\n",
      "[127]\ttraining's l2: 0.378783\tvalid_1's l2: 0.367134\n",
      "[128]\ttraining's l2: 0.378668\tvalid_1's l2: 0.367073\n",
      "[129]\ttraining's l2: 0.378579\tvalid_1's l2: 0.367053\n",
      "[130]\ttraining's l2: 0.378468\tvalid_1's l2: 0.367005\n",
      "[131]\ttraining's l2: 0.378418\tvalid_1's l2: 0.366993\n",
      "[132]\ttraining's l2: 0.378319\tvalid_1's l2: 0.366952\n",
      "[133]\ttraining's l2: 0.378267\tvalid_1's l2: 0.366943\n",
      "[134]\ttraining's l2: 0.378169\tvalid_1's l2: 0.366917\n",
      "[135]\ttraining's l2: 0.378081\tvalid_1's l2: 0.366888\n",
      "[136]\ttraining's l2: 0.377939\tvalid_1's l2: 0.366802\n",
      "[137]\ttraining's l2: 0.377894\tvalid_1's l2: 0.366794\n",
      "[138]\ttraining's l2: 0.377808\tvalid_1's l2: 0.366785\n",
      "[139]\ttraining's l2: 0.377721\tvalid_1's l2: 0.366777\n",
      "[140]\ttraining's l2: 0.377643\tvalid_1's l2: 0.366746\n",
      "[141]\ttraining's l2: 0.377577\tvalid_1's l2: 0.366727\n",
      "[142]\ttraining's l2: 0.377415\tvalid_1's l2: 0.366653\n",
      "[143]\ttraining's l2: 0.377344\tvalid_1's l2: 0.366611\n",
      "[144]\ttraining's l2: 0.377265\tvalid_1's l2: 0.366593\n",
      "[145]\ttraining's l2: 0.37723\tvalid_1's l2: 0.366585\n",
      "[146]\ttraining's l2: 0.377176\tvalid_1's l2: 0.366565\n",
      "[147]\ttraining's l2: 0.377118\tvalid_1's l2: 0.366549\n",
      "[148]\ttraining's l2: 0.377052\tvalid_1's l2: 0.366548\n",
      "[149]\ttraining's l2: 0.376985\tvalid_1's l2: 0.366519\n",
      "[150]\ttraining's l2: 0.376941\tvalid_1's l2: 0.366501\n",
      "[151]\ttraining's l2: 0.376887\tvalid_1's l2: 0.366462\n",
      "[152]\ttraining's l2: 0.376845\tvalid_1's l2: 0.366448\n",
      "[153]\ttraining's l2: 0.376779\tvalid_1's l2: 0.366446\n",
      "[154]\ttraining's l2: 0.376678\tvalid_1's l2: 0.366386\n",
      "[155]\ttraining's l2: 0.376574\tvalid_1's l2: 0.366348\n",
      "[156]\ttraining's l2: 0.376475\tvalid_1's l2: 0.366278\n",
      "[157]\ttraining's l2: 0.376441\tvalid_1's l2: 0.366279\n",
      "[158]\ttraining's l2: 0.376407\tvalid_1's l2: 0.366279\n",
      "[159]\ttraining's l2: 0.376296\tvalid_1's l2: 0.366263\n",
      "[160]\ttraining's l2: 0.376248\tvalid_1's l2: 0.366248\n",
      "[161]\ttraining's l2: 0.376208\tvalid_1's l2: 0.36623\n",
      "[162]\ttraining's l2: 0.376158\tvalid_1's l2: 0.366221\n",
      "[163]\ttraining's l2: 0.376108\tvalid_1's l2: 0.366211\n",
      "[164]\ttraining's l2: 0.376015\tvalid_1's l2: 0.366181\n",
      "[165]\ttraining's l2: 0.375975\tvalid_1's l2: 0.366178\n",
      "[166]\ttraining's l2: 0.375925\tvalid_1's l2: 0.366166\n",
      "[167]\ttraining's l2: 0.375887\tvalid_1's l2: 0.366145\n",
      "[168]\ttraining's l2: 0.375838\tvalid_1's l2: 0.366147\n",
      "[169]\ttraining's l2: 0.37579\tvalid_1's l2: 0.366145\n",
      "[170]\ttraining's l2: 0.375744\tvalid_1's l2: 0.366138\n",
      "[171]\ttraining's l2: 0.375673\tvalid_1's l2: 0.3661\n",
      "[172]\ttraining's l2: 0.375629\tvalid_1's l2: 0.366068\n",
      "[173]\ttraining's l2: 0.375595\tvalid_1's l2: 0.366034\n",
      "[174]\ttraining's l2: 0.375545\tvalid_1's l2: 0.366017\n",
      "[175]\ttraining's l2: 0.375495\tvalid_1's l2: 0.365971\n",
      "[176]\ttraining's l2: 0.375381\tvalid_1's l2: 0.365896\n",
      "[177]\ttraining's l2: 0.375325\tvalid_1's l2: 0.36585\n",
      "[178]\ttraining's l2: 0.375287\tvalid_1's l2: 0.365862\n",
      "[179]\ttraining's l2: 0.37524\tvalid_1's l2: 0.365855\n",
      "[180]\ttraining's l2: 0.375199\tvalid_1's l2: 0.365873\n",
      "[181]\ttraining's l2: 0.375164\tvalid_1's l2: 0.365865\n",
      "[182]\ttraining's l2: 0.375096\tvalid_1's l2: 0.365849\n",
      "[183]\ttraining's l2: 0.375068\tvalid_1's l2: 0.365849\n",
      "[184]\ttraining's l2: 0.375024\tvalid_1's l2: 0.36583\n",
      "[185]\ttraining's l2: 0.374968\tvalid_1's l2: 0.365795\n",
      "[186]\ttraining's l2: 0.374936\tvalid_1's l2: 0.365796\n",
      "[187]\ttraining's l2: 0.374861\tvalid_1's l2: 0.365795\n",
      "[188]\ttraining's l2: 0.374787\tvalid_1's l2: 0.365751\n",
      "[189]\ttraining's l2: 0.374724\tvalid_1's l2: 0.365737\n",
      "[190]\ttraining's l2: 0.374693\tvalid_1's l2: 0.365725\n",
      "[191]\ttraining's l2: 0.374631\tvalid_1's l2: 0.365713\n",
      "[192]\ttraining's l2: 0.374571\tvalid_1's l2: 0.365631\n",
      "[193]\ttraining's l2: 0.374536\tvalid_1's l2: 0.365614\n",
      "[194]\ttraining's l2: 0.374497\tvalid_1's l2: 0.365596\n",
      "[195]\ttraining's l2: 0.374462\tvalid_1's l2: 0.365581\n",
      "[196]\ttraining's l2: 0.37442\tvalid_1's l2: 0.365565\n",
      "[197]\ttraining's l2: 0.374385\tvalid_1's l2: 0.365551\n",
      "[198]\ttraining's l2: 0.374346\tvalid_1's l2: 0.36554\n",
      "[199]\ttraining's l2: 0.374316\tvalid_1's l2: 0.365529\n",
      "[200]\ttraining's l2: 0.374238\tvalid_1's l2: 0.365501\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.374238\tvalid_1's l2: 0.365501\n",
      "mean_21_sales: 6462607.00\n",
      "mean_14_sales: 2227659.71\n",
      "mean_30_sales: 2001647.19\n",
      "mean_7_sales: 1612684.05\n",
      "mean_3_sales: 886066.53\n",
      "mean_60_sales: 676993.34\n",
      "mean_20_dow5_2017: 659156.77\n",
      "promo_12: 483325.82\n",
      "mean_6_sales: 451223.81\n",
      "mean_4_sales: 366744.83\n",
      "mean_63_sales: 266825.49\n",
      "item_class_features: 258402.44\n",
      "mean_4_dow5_2017: 157985.85\n",
      "mean_5_sales: 81925.16\n",
      "promo_14: 73007.24\n",
      "promo_13: 63794.71\n",
      "std_21_sales: 46776.27\n",
      "promo_10: 38394.51\n",
      "sum_2_promo: 38146.41\n",
      "store_cluster_features: 28334.82\n",
      "lag_49_sales: 27875.66\n",
      "item_family_features: 25490.42\n",
      "lag_1_sales: 22762.74\n",
      "store_city_features: 22686.71\n",
      "mean_20_dow6_2017: 21623.36\n",
      "sum_4_promo: 21073.43\n",
      "std_63_sales: 17633.38\n",
      "std_30_sales: 17631.02\n",
      "promo_11: 13154.61\n",
      "lag_2_sales: 12763.04\n",
      "mean_4_dow6_2017: 12161.18\n",
      "promo_7: 10768.79\n",
      "std_14_sales: 10423.72\n",
      "std_60_sales: 9888.63\n",
      "mean_20_dow0_2017: 9650.85\n",
      "promo_9: 9011.24\n",
      "sum_14_promo: 8966.29\n",
      "store_type_features: 7752.78\n",
      "sum_7_promo: 7017.06\n",
      "promo_8: 6836.38\n",
      "promo_15: 5832.68\n",
      "sum_21_promo: 5728.53\n",
      "promo_0: 5103.64\n",
      "mean_20_dow3_2017: 4876.60\n",
      "lag_6_sales: 4540.76\n",
      "std_7_sales: 4265.11\n",
      "sum_3_promo: 4018.03\n",
      "store_state_features: 3965.21\n",
      "mean_20_dow1_2017: 3588.28\n",
      "promo_5: 3587.64\n",
      "mean_4_dow0_2017: 3046.61\n",
      "mean_20_dow4_2017: 2943.34\n",
      "promo_6: 2527.87\n",
      "lag_3_sales: 2355.73\n",
      "sum_5_promo: 2258.18\n",
      "lag_7_sales: 2210.97\n",
      "mean_4_dow1_2017: 2187.65\n",
      "lag_14_sales: 2093.07\n",
      "mean_4_dow3_2017: 2047.84\n",
      "mean_20_dow2_2017: 2027.53\n",
      "std_5_sales: 1978.29\n",
      "std_4_sales: 1838.40\n",
      "lag_4_sales: 1640.86\n",
      "lag_42_sales: 1577.18\n",
      "lag_56_sales: 1404.34\n",
      "lag_63_sales: 1376.91\n",
      "lag_21_sales: 1265.25\n",
      "promo_2: 1221.96\n",
      "std_6_sales: 1206.12\n",
      "std_3_sales: 1184.29\n",
      "mean_4_dow4_2017: 1169.07\n",
      "mean_4_dow2_2017: 969.24\n",
      "sum_6_promo: 476.60\n",
      "lag_28_sales: 414.98\n",
      "lag_5_sales: 387.66\n",
      "lag_35_sales: 360.79\n",
      "promo_4: 186.45\n",
      "promo_3: 99.86\n",
      "promo_1: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [13:23<02:59, 59.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.03072\tvalid_1's l2: 0.994269\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.971451\tvalid_1's l2: 0.935965\n",
      "[3]\ttraining's l2: 0.917924\tvalid_1's l2: 0.883168\n",
      "[4]\ttraining's l2: 0.867699\tvalid_1's l2: 0.833807\n",
      "[5]\ttraining's l2: 0.822218\tvalid_1's l2: 0.789002\n",
      "[6]\ttraining's l2: 0.781032\tvalid_1's l2: 0.74853\n",
      "[7]\ttraining's l2: 0.745071\tvalid_1's l2: 0.713186\n",
      "[8]\ttraining's l2: 0.711243\tvalid_1's l2: 0.680126\n",
      "[9]\ttraining's l2: 0.681886\tvalid_1's l2: 0.651453\n",
      "[10]\ttraining's l2: 0.654031\tvalid_1's l2: 0.624447\n",
      "[11]\ttraining's l2: 0.628748\tvalid_1's l2: 0.600058\n",
      "[12]\ttraining's l2: 0.605849\tvalid_1's l2: 0.577736\n",
      "[13]\ttraining's l2: 0.584998\tvalid_1's l2: 0.557459\n",
      "[14]\ttraining's l2: 0.566136\tvalid_1's l2: 0.539198\n",
      "[15]\ttraining's l2: 0.549074\tvalid_1's l2: 0.522583\n",
      "[16]\ttraining's l2: 0.533404\tvalid_1's l2: 0.507565\n",
      "[17]\ttraining's l2: 0.519311\tvalid_1's l2: 0.493899\n",
      "[18]\ttraining's l2: 0.506444\tvalid_1's l2: 0.481608\n",
      "[19]\ttraining's l2: 0.494786\tvalid_1's l2: 0.47049\n",
      "[20]\ttraining's l2: 0.484618\tvalid_1's l2: 0.46084\n",
      "[21]\ttraining's l2: 0.474962\tvalid_1's l2: 0.451727\n",
      "[22]\ttraining's l2: 0.466652\tvalid_1's l2: 0.443728\n",
      "[23]\ttraining's l2: 0.458593\tvalid_1's l2: 0.436116\n",
      "[24]\ttraining's l2: 0.451593\tvalid_1's l2: 0.429587\n",
      "[25]\ttraining's l2: 0.444922\tvalid_1's l2: 0.423277\n",
      "[26]\ttraining's l2: 0.438871\tvalid_1's l2: 0.417599\n",
      "[27]\ttraining's l2: 0.433576\tvalid_1's l2: 0.412662\n",
      "[28]\ttraining's l2: 0.428779\tvalid_1's l2: 0.408302\n",
      "[29]\ttraining's l2: 0.424127\tvalid_1's l2: 0.403928\n",
      "[30]\ttraining's l2: 0.419915\tvalid_1's l2: 0.400105\n",
      "[31]\ttraining's l2: 0.416221\tvalid_1's l2: 0.39672\n",
      "[32]\ttraining's l2: 0.412617\tvalid_1's l2: 0.39344\n",
      "[33]\ttraining's l2: 0.409382\tvalid_1's l2: 0.39042\n",
      "[34]\ttraining's l2: 0.406383\tvalid_1's l2: 0.387696\n",
      "[35]\ttraining's l2: 0.403618\tvalid_1's l2: 0.385224\n",
      "[36]\ttraining's l2: 0.401122\tvalid_1's l2: 0.382898\n",
      "[37]\ttraining's l2: 0.398825\tvalid_1's l2: 0.380772\n",
      "[38]\ttraining's l2: 0.396709\tvalid_1's l2: 0.378837\n",
      "[39]\ttraining's l2: 0.394771\tvalid_1's l2: 0.377133\n",
      "[40]\ttraining's l2: 0.392956\tvalid_1's l2: 0.375586\n",
      "[41]\ttraining's l2: 0.391235\tvalid_1's l2: 0.374143\n",
      "[42]\ttraining's l2: 0.389707\tvalid_1's l2: 0.372796\n",
      "[43]\ttraining's l2: 0.388306\tvalid_1's l2: 0.371588\n",
      "[44]\ttraining's l2: 0.38696\tvalid_1's l2: 0.370426\n",
      "[45]\ttraining's l2: 0.38576\tvalid_1's l2: 0.369377\n",
      "[46]\ttraining's l2: 0.384503\tvalid_1's l2: 0.368344\n",
      "[47]\ttraining's l2: 0.383367\tvalid_1's l2: 0.367475\n",
      "[48]\ttraining's l2: 0.382346\tvalid_1's l2: 0.366659\n",
      "[49]\ttraining's l2: 0.381449\tvalid_1's l2: 0.365962\n",
      "[50]\ttraining's l2: 0.38063\tvalid_1's l2: 0.365339\n",
      "[51]\ttraining's l2: 0.379817\tvalid_1's l2: 0.364736\n",
      "[52]\ttraining's l2: 0.379004\tvalid_1's l2: 0.36414\n",
      "[53]\ttraining's l2: 0.378292\tvalid_1's l2: 0.363579\n",
      "[54]\ttraining's l2: 0.377526\tvalid_1's l2: 0.362985\n",
      "[55]\ttraining's l2: 0.376845\tvalid_1's l2: 0.362456\n",
      "[56]\ttraining's l2: 0.376252\tvalid_1's l2: 0.361998\n",
      "[57]\ttraining's l2: 0.375695\tvalid_1's l2: 0.361521\n",
      "[58]\ttraining's l2: 0.375258\tvalid_1's l2: 0.361234\n",
      "[59]\ttraining's l2: 0.374801\tvalid_1's l2: 0.360852\n",
      "[60]\ttraining's l2: 0.374341\tvalid_1's l2: 0.360505\n",
      "[61]\ttraining's l2: 0.373915\tvalid_1's l2: 0.360229\n",
      "[62]\ttraining's l2: 0.373451\tvalid_1's l2: 0.359931\n",
      "[63]\ttraining's l2: 0.37306\tvalid_1's l2: 0.3596\n",
      "[64]\ttraining's l2: 0.372662\tvalid_1's l2: 0.359293\n",
      "[65]\ttraining's l2: 0.372378\tvalid_1's l2: 0.359107\n",
      "[66]\ttraining's l2: 0.372039\tvalid_1's l2: 0.358854\n",
      "[67]\ttraining's l2: 0.371727\tvalid_1's l2: 0.358729\n",
      "[68]\ttraining's l2: 0.37142\tvalid_1's l2: 0.358574\n",
      "[69]\ttraining's l2: 0.371048\tvalid_1's l2: 0.358355\n",
      "[70]\ttraining's l2: 0.37074\tvalid_1's l2: 0.358125\n",
      "[71]\ttraining's l2: 0.370257\tvalid_1's l2: 0.357827\n",
      "[72]\ttraining's l2: 0.369764\tvalid_1's l2: 0.357588\n",
      "[73]\ttraining's l2: 0.369312\tvalid_1's l2: 0.357287\n",
      "[74]\ttraining's l2: 0.36905\tvalid_1's l2: 0.357167\n",
      "[75]\ttraining's l2: 0.368753\tvalid_1's l2: 0.35703\n",
      "[76]\ttraining's l2: 0.368453\tvalid_1's l2: 0.356807\n",
      "[77]\ttraining's l2: 0.368251\tvalid_1's l2: 0.356675\n",
      "[78]\ttraining's l2: 0.367994\tvalid_1's l2: 0.356521\n",
      "[79]\ttraining's l2: 0.367757\tvalid_1's l2: 0.356383\n",
      "[80]\ttraining's l2: 0.367545\tvalid_1's l2: 0.356212\n",
      "[81]\ttraining's l2: 0.367281\tvalid_1's l2: 0.356054\n",
      "[82]\ttraining's l2: 0.367129\tvalid_1's l2: 0.355953\n",
      "[83]\ttraining's l2: 0.366803\tvalid_1's l2: 0.35581\n",
      "[84]\ttraining's l2: 0.366628\tvalid_1's l2: 0.355732\n",
      "[85]\ttraining's l2: 0.366428\tvalid_1's l2: 0.355617\n",
      "[86]\ttraining's l2: 0.366218\tvalid_1's l2: 0.355483\n",
      "[87]\ttraining's l2: 0.366062\tvalid_1's l2: 0.355413\n",
      "[88]\ttraining's l2: 0.365929\tvalid_1's l2: 0.35533\n",
      "[89]\ttraining's l2: 0.365654\tvalid_1's l2: 0.355136\n",
      "[90]\ttraining's l2: 0.365443\tvalid_1's l2: 0.355003\n",
      "[91]\ttraining's l2: 0.36531\tvalid_1's l2: 0.354925\n",
      "[92]\ttraining's l2: 0.365152\tvalid_1's l2: 0.354834\n",
      "[93]\ttraining's l2: 0.365038\tvalid_1's l2: 0.354775\n",
      "[94]\ttraining's l2: 0.364651\tvalid_1's l2: 0.354518\n",
      "[95]\ttraining's l2: 0.364508\tvalid_1's l2: 0.354469\n",
      "[96]\ttraining's l2: 0.364389\tvalid_1's l2: 0.354435\n",
      "[97]\ttraining's l2: 0.364172\tvalid_1's l2: 0.354261\n",
      "[98]\ttraining's l2: 0.364039\tvalid_1's l2: 0.35419\n",
      "[99]\ttraining's l2: 0.363888\tvalid_1's l2: 0.35412\n",
      "[100]\ttraining's l2: 0.363681\tvalid_1's l2: 0.354044\n",
      "[101]\ttraining's l2: 0.363441\tvalid_1's l2: 0.353903\n",
      "[102]\ttraining's l2: 0.363324\tvalid_1's l2: 0.35388\n",
      "[103]\ttraining's l2: 0.363207\tvalid_1's l2: 0.353815\n",
      "[104]\ttraining's l2: 0.363105\tvalid_1's l2: 0.353755\n",
      "[105]\ttraining's l2: 0.362974\tvalid_1's l2: 0.353714\n",
      "[106]\ttraining's l2: 0.3628\tvalid_1's l2: 0.353645\n",
      "[107]\ttraining's l2: 0.36266\tvalid_1's l2: 0.353543\n",
      "[108]\ttraining's l2: 0.362533\tvalid_1's l2: 0.353489\n",
      "[109]\ttraining's l2: 0.362404\tvalid_1's l2: 0.353415\n",
      "[110]\ttraining's l2: 0.362247\tvalid_1's l2: 0.353334\n",
      "[111]\ttraining's l2: 0.362152\tvalid_1's l2: 0.353285\n",
      "[112]\ttraining's l2: 0.362058\tvalid_1's l2: 0.353251\n",
      "[113]\ttraining's l2: 0.361927\tvalid_1's l2: 0.353199\n",
      "[114]\ttraining's l2: 0.361776\tvalid_1's l2: 0.353082\n",
      "[115]\ttraining's l2: 0.361681\tvalid_1's l2: 0.353024\n",
      "[116]\ttraining's l2: 0.361599\tvalid_1's l2: 0.353017\n",
      "[117]\ttraining's l2: 0.361469\tvalid_1's l2: 0.352942\n",
      "[118]\ttraining's l2: 0.361396\tvalid_1's l2: 0.35292\n",
      "[119]\ttraining's l2: 0.361309\tvalid_1's l2: 0.35291\n",
      "[120]\ttraining's l2: 0.361182\tvalid_1's l2: 0.352854\n",
      "[121]\ttraining's l2: 0.361108\tvalid_1's l2: 0.352816\n",
      "[122]\ttraining's l2: 0.361043\tvalid_1's l2: 0.352783\n",
      "[123]\ttraining's l2: 0.360978\tvalid_1's l2: 0.35279\n",
      "[124]\ttraining's l2: 0.360891\tvalid_1's l2: 0.352765\n",
      "[125]\ttraining's l2: 0.360792\tvalid_1's l2: 0.352723\n",
      "[126]\ttraining's l2: 0.36073\tvalid_1's l2: 0.352687\n",
      "[127]\ttraining's l2: 0.360538\tvalid_1's l2: 0.352575\n",
      "[128]\ttraining's l2: 0.360454\tvalid_1's l2: 0.352548\n",
      "[129]\ttraining's l2: 0.36039\tvalid_1's l2: 0.35251\n",
      "[130]\ttraining's l2: 0.36033\tvalid_1's l2: 0.352487\n",
      "[131]\ttraining's l2: 0.360274\tvalid_1's l2: 0.352477\n",
      "[132]\ttraining's l2: 0.360206\tvalid_1's l2: 0.352477\n",
      "[133]\ttraining's l2: 0.360141\tvalid_1's l2: 0.352447\n",
      "[134]\ttraining's l2: 0.359958\tvalid_1's l2: 0.352325\n",
      "[135]\ttraining's l2: 0.359907\tvalid_1's l2: 0.352323\n",
      "[136]\ttraining's l2: 0.359825\tvalid_1's l2: 0.352275\n",
      "[137]\ttraining's l2: 0.359769\tvalid_1's l2: 0.352264\n",
      "[138]\ttraining's l2: 0.359695\tvalid_1's l2: 0.352255\n",
      "[139]\ttraining's l2: 0.359577\tvalid_1's l2: 0.352197\n",
      "[140]\ttraining's l2: 0.35953\tvalid_1's l2: 0.352184\n",
      "[141]\ttraining's l2: 0.359398\tvalid_1's l2: 0.352105\n",
      "[142]\ttraining's l2: 0.359256\tvalid_1's l2: 0.352021\n",
      "[143]\ttraining's l2: 0.359182\tvalid_1's l2: 0.352003\n",
      "[144]\ttraining's l2: 0.359076\tvalid_1's l2: 0.351949\n",
      "[145]\ttraining's l2: 0.358987\tvalid_1's l2: 0.351906\n",
      "[146]\ttraining's l2: 0.35892\tvalid_1's l2: 0.351869\n",
      "[147]\ttraining's l2: 0.358873\tvalid_1's l2: 0.351862\n",
      "[148]\ttraining's l2: 0.35882\tvalid_1's l2: 0.351856\n",
      "[149]\ttraining's l2: 0.358742\tvalid_1's l2: 0.351845\n",
      "[150]\ttraining's l2: 0.358691\tvalid_1's l2: 0.351834\n",
      "[151]\ttraining's l2: 0.358641\tvalid_1's l2: 0.351809\n",
      "[152]\ttraining's l2: 0.358576\tvalid_1's l2: 0.351797\n",
      "[153]\ttraining's l2: 0.358524\tvalid_1's l2: 0.351792\n",
      "[154]\ttraining's l2: 0.358469\tvalid_1's l2: 0.35177\n",
      "[155]\ttraining's l2: 0.358378\tvalid_1's l2: 0.351756\n",
      "[156]\ttraining's l2: 0.358334\tvalid_1's l2: 0.351744\n",
      "[157]\ttraining's l2: 0.358276\tvalid_1's l2: 0.351736\n",
      "[158]\ttraining's l2: 0.358237\tvalid_1's l2: 0.351737\n",
      "[159]\ttraining's l2: 0.358199\tvalid_1's l2: 0.351729\n",
      "[160]\ttraining's l2: 0.358158\tvalid_1's l2: 0.351717\n",
      "[161]\ttraining's l2: 0.358104\tvalid_1's l2: 0.351703\n",
      "[162]\ttraining's l2: 0.358078\tvalid_1's l2: 0.351699\n",
      "[163]\ttraining's l2: 0.357989\tvalid_1's l2: 0.35162\n",
      "[164]\ttraining's l2: 0.357922\tvalid_1's l2: 0.351616\n",
      "[165]\ttraining's l2: 0.357882\tvalid_1's l2: 0.351614\n",
      "[166]\ttraining's l2: 0.357838\tvalid_1's l2: 0.351611\n",
      "[167]\ttraining's l2: 0.357792\tvalid_1's l2: 0.351589\n",
      "[168]\ttraining's l2: 0.35771\tvalid_1's l2: 0.351527\n",
      "[169]\ttraining's l2: 0.35766\tvalid_1's l2: 0.351501\n",
      "[170]\ttraining's l2: 0.357608\tvalid_1's l2: 0.351507\n",
      "[171]\ttraining's l2: 0.357553\tvalid_1's l2: 0.351505\n",
      "[172]\ttraining's l2: 0.357498\tvalid_1's l2: 0.351497\n",
      "[173]\ttraining's l2: 0.35747\tvalid_1's l2: 0.351478\n",
      "[174]\ttraining's l2: 0.357413\tvalid_1's l2: 0.351476\n",
      "[175]\ttraining's l2: 0.357356\tvalid_1's l2: 0.351427\n",
      "[176]\ttraining's l2: 0.357328\tvalid_1's l2: 0.351421\n",
      "[177]\ttraining's l2: 0.357298\tvalid_1's l2: 0.351405\n",
      "[178]\ttraining's l2: 0.357272\tvalid_1's l2: 0.3514\n",
      "[179]\ttraining's l2: 0.35719\tvalid_1's l2: 0.35136\n",
      "[180]\ttraining's l2: 0.357145\tvalid_1's l2: 0.351352\n",
      "[181]\ttraining's l2: 0.35709\tvalid_1's l2: 0.351338\n",
      "[182]\ttraining's l2: 0.357056\tvalid_1's l2: 0.351354\n",
      "[183]\ttraining's l2: 0.357022\tvalid_1's l2: 0.351351\n",
      "[184]\ttraining's l2: 0.356996\tvalid_1's l2: 0.351356\n",
      "[185]\ttraining's l2: 0.356921\tvalid_1's l2: 0.351317\n",
      "[186]\ttraining's l2: 0.356878\tvalid_1's l2: 0.351329\n",
      "[187]\ttraining's l2: 0.356846\tvalid_1's l2: 0.351317\n",
      "[188]\ttraining's l2: 0.356807\tvalid_1's l2: 0.351311\n",
      "[189]\ttraining's l2: 0.356761\tvalid_1's l2: 0.351312\n",
      "[190]\ttraining's l2: 0.356733\tvalid_1's l2: 0.3513\n",
      "[191]\ttraining's l2: 0.356677\tvalid_1's l2: 0.35126\n",
      "[192]\ttraining's l2: 0.356636\tvalid_1's l2: 0.351257\n",
      "[193]\ttraining's l2: 0.356604\tvalid_1's l2: 0.351235\n",
      "[194]\ttraining's l2: 0.356579\tvalid_1's l2: 0.351213\n",
      "[195]\ttraining's l2: 0.356547\tvalid_1's l2: 0.35119\n",
      "[196]\ttraining's l2: 0.356486\tvalid_1's l2: 0.351139\n",
      "[197]\ttraining's l2: 0.356448\tvalid_1's l2: 0.351144\n",
      "[198]\ttraining's l2: 0.35642\tvalid_1's l2: 0.351126\n",
      "[199]\ttraining's l2: 0.356393\tvalid_1's l2: 0.351109\n",
      "[200]\ttraining's l2: 0.356339\tvalid_1's l2: 0.351098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.356339\tvalid_1's l2: 0.351098\n",
      "mean_21_sales: 5223448.23\n",
      "mean_30_sales: 2451285.85\n",
      "mean_14_sales: 2069923.70\n",
      "mean_7_sales: 1500803.09\n",
      "mean_20_dow6_2017: 1460696.10\n",
      "mean_3_sales: 782065.91\n",
      "promo_13: 675559.13\n",
      "mean_6_sales: 469358.40\n",
      "mean_4_dow6_2017: 383283.66\n",
      "item_class_features: 257143.54\n",
      "mean_63_sales: 197051.82\n",
      "mean_60_sales: 182743.42\n",
      "promo_14: 99337.28\n",
      "mean_4_sales: 96723.60\n",
      "lag_1_sales: 80377.43\n",
      "mean_20_dow5_2017: 55487.45\n",
      "item_family_features: 43607.71\n",
      "promo_12: 37473.72\n",
      "mean_5_sales: 33003.44\n",
      "promo_10: 32985.52\n",
      "std_30_sales: 30032.63\n",
      "std_21_sales: 25485.23\n",
      "std_63_sales: 25165.98\n",
      "sum_2_promo: 22934.78\n",
      "sum_4_promo: 22399.57\n",
      "store_city_features: 22058.31\n",
      "store_cluster_features: 21945.56\n",
      "promo_6: 19600.02\n",
      "lag_2_sales: 19467.24\n",
      "lag_49_sales: 17614.03\n",
      "mean_20_dow1_2017: 14902.09\n",
      "mean_4_dow5_2017: 14756.84\n",
      "std_60_sales: 13370.33\n",
      "sum_7_promo: 11483.81\n",
      "mean_20_dow0_2017: 11140.64\n",
      "store_type_features: 9881.97\n",
      "sum_21_promo: 7935.41\n",
      "promo_11: 7474.29\n",
      "promo_9: 6726.02\n",
      "mean_20_dow3_2017: 6503.70\n",
      "promo_0: 6005.24\n",
      "promo_7: 5814.68\n",
      "std_14_sales: 5121.87\n",
      "sum_3_promo: 5105.09\n",
      "promo_15: 5060.09\n",
      "sum_14_promo: 4925.17\n",
      "std_6_sales: 4524.90\n",
      "lag_6_sales: 4251.39\n",
      "std_7_sales: 3911.83\n",
      "mean_4_dow1_2017: 3400.50\n",
      "sum_5_promo: 3131.60\n",
      "mean_20_dow4_2017: 2963.65\n",
      "std_5_sales: 2764.23\n",
      "lag_3_sales: 2403.97\n",
      "promo_8: 2280.15\n",
      "std_4_sales: 2224.60\n",
      "lag_14_sales: 2037.18\n",
      "mean_4_dow0_2017: 2008.96\n",
      "lag_63_sales: 1884.02\n",
      "lag_7_sales: 1867.96\n",
      "sum_6_promo: 1821.17\n",
      "lag_4_sales: 1305.73\n",
      "store_state_features: 1267.79\n",
      "mean_20_dow2_2017: 1250.69\n",
      "mean_4_dow4_2017: 939.69\n",
      "lag_21_sales: 873.13\n",
      "lag_56_sales: 784.99\n",
      "lag_28_sales: 760.65\n",
      "std_3_sales: 626.00\n",
      "lag_35_sales: 621.99\n",
      "mean_4_dow2_2017: 607.48\n",
      "promo_2: 567.88\n",
      "lag_5_sales: 451.89\n",
      "mean_4_dow3_2017: 429.63\n",
      "lag_42_sales: 301.99\n",
      "promo_1: 163.12\n",
      "promo_3: 108.07\n",
      "promo_4: 77.96\n",
      "promo_5: 32.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [14:23<01:59, 59.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.05389\tvalid_1's l2: 1.00847\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.989743\tvalid_1's l2: 0.946425\n",
      "[3]\ttraining's l2: 0.93163\tvalid_1's l2: 0.890158\n",
      "[4]\ttraining's l2: 0.881542\tvalid_1's l2: 0.841019\n",
      "[5]\ttraining's l2: 0.836168\tvalid_1's l2: 0.796772\n",
      "[6]\ttraining's l2: 0.792457\tvalid_1's l2: 0.754546\n",
      "[7]\ttraining's l2: 0.753063\tvalid_1's l2: 0.716597\n",
      "[8]\ttraining's l2: 0.717177\tvalid_1's l2: 0.681957\n",
      "[9]\ttraining's l2: 0.686633\tvalid_1's l2: 0.652303\n",
      "[10]\ttraining's l2: 0.65701\tvalid_1's l2: 0.623893\n",
      "[11]\ttraining's l2: 0.631831\tvalid_1's l2: 0.599705\n",
      "[12]\ttraining's l2: 0.609073\tvalid_1's l2: 0.577735\n",
      "[13]\ttraining's l2: 0.58851\tvalid_1's l2: 0.55787\n",
      "[14]\ttraining's l2: 0.567943\tvalid_1's l2: 0.538382\n",
      "[15]\ttraining's l2: 0.549325\tvalid_1's l2: 0.520888\n",
      "[16]\ttraining's l2: 0.53242\tvalid_1's l2: 0.50505\n",
      "[17]\ttraining's l2: 0.517157\tvalid_1's l2: 0.490712\n",
      "[18]\ttraining's l2: 0.504471\tvalid_1's l2: 0.478642\n",
      "[19]\ttraining's l2: 0.491689\tvalid_1's l2: 0.466548\n",
      "[20]\ttraining's l2: 0.480028\tvalid_1's l2: 0.455678\n",
      "[21]\ttraining's l2: 0.470519\tvalid_1's l2: 0.446649\n",
      "[22]\ttraining's l2: 0.460839\tvalid_1's l2: 0.437665\n",
      "[23]\ttraining's l2: 0.452001\tvalid_1's l2: 0.42948\n",
      "[24]\ttraining's l2: 0.443863\tvalid_1's l2: 0.422002\n",
      "[25]\ttraining's l2: 0.437272\tvalid_1's l2: 0.415874\n",
      "[26]\ttraining's l2: 0.43048\tvalid_1's l2: 0.409712\n",
      "[27]\ttraining's l2: 0.424233\tvalid_1's l2: 0.404043\n",
      "[28]\ttraining's l2: 0.418662\tvalid_1's l2: 0.399017\n",
      "[29]\ttraining's l2: 0.413454\tvalid_1's l2: 0.394311\n",
      "[30]\ttraining's l2: 0.408817\tvalid_1's l2: 0.39009\n",
      "[31]\ttraining's l2: 0.404431\tvalid_1's l2: 0.386153\n",
      "[32]\ttraining's l2: 0.400523\tvalid_1's l2: 0.382615\n",
      "[33]\ttraining's l2: 0.397369\tvalid_1's l2: 0.379788\n",
      "[34]\ttraining's l2: 0.394066\tvalid_1's l2: 0.376809\n",
      "[35]\ttraining's l2: 0.391406\tvalid_1's l2: 0.374445\n",
      "[36]\ttraining's l2: 0.388524\tvalid_1's l2: 0.371936\n",
      "[37]\ttraining's l2: 0.385942\tvalid_1's l2: 0.369621\n",
      "[38]\ttraining's l2: 0.383522\tvalid_1's l2: 0.367534\n",
      "[39]\ttraining's l2: 0.381242\tvalid_1's l2: 0.36562\n",
      "[40]\ttraining's l2: 0.379177\tvalid_1's l2: 0.363889\n",
      "[41]\ttraining's l2: 0.377296\tvalid_1's l2: 0.36225\n",
      "[42]\ttraining's l2: 0.375786\tvalid_1's l2: 0.36096\n",
      "[43]\ttraining's l2: 0.37414\tvalid_1's l2: 0.359652\n",
      "[44]\ttraining's l2: 0.372688\tvalid_1's l2: 0.358415\n",
      "[45]\ttraining's l2: 0.371507\tvalid_1's l2: 0.357443\n",
      "[46]\ttraining's l2: 0.370107\tvalid_1's l2: 0.356182\n",
      "[47]\ttraining's l2: 0.368807\tvalid_1's l2: 0.355163\n",
      "[48]\ttraining's l2: 0.367581\tvalid_1's l2: 0.35416\n",
      "[49]\ttraining's l2: 0.366463\tvalid_1's l2: 0.353283\n",
      "[50]\ttraining's l2: 0.365433\tvalid_1's l2: 0.352472\n",
      "[51]\ttraining's l2: 0.364516\tvalid_1's l2: 0.351706\n",
      "[52]\ttraining's l2: 0.363637\tvalid_1's l2: 0.351056\n",
      "[53]\ttraining's l2: 0.362852\tvalid_1's l2: 0.350384\n",
      "[54]\ttraining's l2: 0.362052\tvalid_1's l2: 0.349783\n",
      "[55]\ttraining's l2: 0.361408\tvalid_1's l2: 0.349354\n",
      "[56]\ttraining's l2: 0.360846\tvalid_1's l2: 0.348996\n",
      "[57]\ttraining's l2: 0.360356\tvalid_1's l2: 0.348642\n",
      "[58]\ttraining's l2: 0.359861\tvalid_1's l2: 0.348336\n",
      "[59]\ttraining's l2: 0.359417\tvalid_1's l2: 0.348021\n",
      "[60]\ttraining's l2: 0.35896\tvalid_1's l2: 0.347762\n",
      "[61]\ttraining's l2: 0.358265\tvalid_1's l2: 0.347201\n",
      "[62]\ttraining's l2: 0.357718\tvalid_1's l2: 0.346827\n",
      "[63]\ttraining's l2: 0.357174\tvalid_1's l2: 0.346352\n",
      "[64]\ttraining's l2: 0.356615\tvalid_1's l2: 0.345864\n",
      "[65]\ttraining's l2: 0.356298\tvalid_1's l2: 0.345663\n",
      "[66]\ttraining's l2: 0.356001\tvalid_1's l2: 0.345482\n",
      "[67]\ttraining's l2: 0.355514\tvalid_1's l2: 0.345178\n",
      "[68]\ttraining's l2: 0.355203\tvalid_1's l2: 0.345053\n",
      "[69]\ttraining's l2: 0.354822\tvalid_1's l2: 0.344775\n",
      "[70]\ttraining's l2: 0.3543\tvalid_1's l2: 0.344418\n",
      "[71]\ttraining's l2: 0.353959\tvalid_1's l2: 0.344165\n",
      "[72]\ttraining's l2: 0.353574\tvalid_1's l2: 0.343891\n",
      "[73]\ttraining's l2: 0.353251\tvalid_1's l2: 0.343626\n",
      "[74]\ttraining's l2: 0.352876\tvalid_1's l2: 0.343332\n",
      "[75]\ttraining's l2: 0.352538\tvalid_1's l2: 0.343149\n",
      "[76]\ttraining's l2: 0.35224\tvalid_1's l2: 0.342919\n",
      "[77]\ttraining's l2: 0.351996\tvalid_1's l2: 0.342746\n",
      "[78]\ttraining's l2: 0.351766\tvalid_1's l2: 0.342589\n",
      "[79]\ttraining's l2: 0.351504\tvalid_1's l2: 0.342439\n",
      "[80]\ttraining's l2: 0.351223\tvalid_1's l2: 0.34225\n",
      "[81]\ttraining's l2: 0.350935\tvalid_1's l2: 0.342055\n",
      "[82]\ttraining's l2: 0.350788\tvalid_1's l2: 0.341959\n",
      "[83]\ttraining's l2: 0.350594\tvalid_1's l2: 0.341872\n",
      "[84]\ttraining's l2: 0.350391\tvalid_1's l2: 0.341784\n",
      "[85]\ttraining's l2: 0.3502\tvalid_1's l2: 0.341662\n",
      "[86]\ttraining's l2: 0.350028\tvalid_1's l2: 0.341566\n",
      "[87]\ttraining's l2: 0.349887\tvalid_1's l2: 0.341528\n",
      "[88]\ttraining's l2: 0.349756\tvalid_1's l2: 0.341451\n",
      "[89]\ttraining's l2: 0.349436\tvalid_1's l2: 0.341249\n",
      "[90]\ttraining's l2: 0.349267\tvalid_1's l2: 0.341154\n",
      "[91]\ttraining's l2: 0.349129\tvalid_1's l2: 0.341098\n",
      "[92]\ttraining's l2: 0.348897\tvalid_1's l2: 0.340901\n",
      "[93]\ttraining's l2: 0.348793\tvalid_1's l2: 0.34088\n",
      "[94]\ttraining's l2: 0.348554\tvalid_1's l2: 0.340701\n",
      "[95]\ttraining's l2: 0.348431\tvalid_1's l2: 0.340631\n",
      "[96]\ttraining's l2: 0.348324\tvalid_1's l2: 0.340612\n",
      "[97]\ttraining's l2: 0.34813\tvalid_1's l2: 0.340451\n",
      "[98]\ttraining's l2: 0.348008\tvalid_1's l2: 0.340382\n",
      "[99]\ttraining's l2: 0.347915\tvalid_1's l2: 0.340337\n",
      "[100]\ttraining's l2: 0.347703\tvalid_1's l2: 0.340171\n",
      "[101]\ttraining's l2: 0.347575\tvalid_1's l2: 0.340099\n",
      "[102]\ttraining's l2: 0.347466\tvalid_1's l2: 0.340027\n",
      "[103]\ttraining's l2: 0.34727\tvalid_1's l2: 0.33985\n",
      "[104]\ttraining's l2: 0.347177\tvalid_1's l2: 0.33979\n",
      "[105]\ttraining's l2: 0.346978\tvalid_1's l2: 0.339659\n",
      "[106]\ttraining's l2: 0.346817\tvalid_1's l2: 0.339569\n",
      "[107]\ttraining's l2: 0.346659\tvalid_1's l2: 0.339435\n",
      "[108]\ttraining's l2: 0.346492\tvalid_1's l2: 0.339339\n",
      "[109]\ttraining's l2: 0.346378\tvalid_1's l2: 0.339267\n",
      "[110]\ttraining's l2: 0.346215\tvalid_1's l2: 0.33916\n",
      "[111]\ttraining's l2: 0.346126\tvalid_1's l2: 0.339111\n",
      "[112]\ttraining's l2: 0.345992\tvalid_1's l2: 0.339041\n",
      "[113]\ttraining's l2: 0.345901\tvalid_1's l2: 0.339006\n",
      "[114]\ttraining's l2: 0.345786\tvalid_1's l2: 0.338875\n",
      "[115]\ttraining's l2: 0.345666\tvalid_1's l2: 0.338809\n",
      "[116]\ttraining's l2: 0.345586\tvalid_1's l2: 0.338766\n",
      "[117]\ttraining's l2: 0.345503\tvalid_1's l2: 0.338715\n",
      "[118]\ttraining's l2: 0.345428\tvalid_1's l2: 0.338694\n",
      "[119]\ttraining's l2: 0.345351\tvalid_1's l2: 0.338696\n",
      "[120]\ttraining's l2: 0.345239\tvalid_1's l2: 0.338609\n",
      "[121]\ttraining's l2: 0.345173\tvalid_1's l2: 0.338569\n",
      "[122]\ttraining's l2: 0.345084\tvalid_1's l2: 0.338528\n",
      "[123]\ttraining's l2: 0.34501\tvalid_1's l2: 0.338501\n",
      "[124]\ttraining's l2: 0.34494\tvalid_1's l2: 0.33849\n",
      "[125]\ttraining's l2: 0.344871\tvalid_1's l2: 0.338459\n",
      "[126]\ttraining's l2: 0.344798\tvalid_1's l2: 0.338398\n",
      "[127]\ttraining's l2: 0.344687\tvalid_1's l2: 0.338334\n",
      "[128]\ttraining's l2: 0.344627\tvalid_1's l2: 0.338323\n",
      "[129]\ttraining's l2: 0.344545\tvalid_1's l2: 0.338247\n",
      "[130]\ttraining's l2: 0.344492\tvalid_1's l2: 0.338245\n",
      "[131]\ttraining's l2: 0.344428\tvalid_1's l2: 0.338247\n",
      "[132]\ttraining's l2: 0.344319\tvalid_1's l2: 0.338225\n",
      "[133]\ttraining's l2: 0.344234\tvalid_1's l2: 0.338191\n",
      "[134]\ttraining's l2: 0.344139\tvalid_1's l2: 0.338145\n",
      "[135]\ttraining's l2: 0.344084\tvalid_1's l2: 0.338133\n",
      "[136]\ttraining's l2: 0.344036\tvalid_1's l2: 0.338103\n",
      "[137]\ttraining's l2: 0.343962\tvalid_1's l2: 0.338061\n",
      "[138]\ttraining's l2: 0.343855\tvalid_1's l2: 0.337979\n",
      "[139]\ttraining's l2: 0.343766\tvalid_1's l2: 0.337933\n",
      "[140]\ttraining's l2: 0.343685\tvalid_1's l2: 0.337902\n",
      "[141]\ttraining's l2: 0.343633\tvalid_1's l2: 0.337901\n",
      "[142]\ttraining's l2: 0.343564\tvalid_1's l2: 0.33791\n",
      "[143]\ttraining's l2: 0.343506\tvalid_1's l2: 0.337882\n",
      "[144]\ttraining's l2: 0.343428\tvalid_1's l2: 0.337845\n",
      "[145]\ttraining's l2: 0.343363\tvalid_1's l2: 0.337799\n",
      "[146]\ttraining's l2: 0.343316\tvalid_1's l2: 0.337774\n",
      "[147]\ttraining's l2: 0.343246\tvalid_1's l2: 0.337753\n",
      "[148]\ttraining's l2: 0.343165\tvalid_1's l2: 0.337694\n",
      "[149]\ttraining's l2: 0.343092\tvalid_1's l2: 0.337672\n",
      "[150]\ttraining's l2: 0.343013\tvalid_1's l2: 0.337657\n",
      "[151]\ttraining's l2: 0.342957\tvalid_1's l2: 0.337613\n",
      "[152]\ttraining's l2: 0.342886\tvalid_1's l2: 0.337603\n",
      "[153]\ttraining's l2: 0.342823\tvalid_1's l2: 0.337583\n",
      "[154]\ttraining's l2: 0.342764\tvalid_1's l2: 0.337535\n",
      "[155]\ttraining's l2: 0.342686\tvalid_1's l2: 0.337479\n",
      "[156]\ttraining's l2: 0.342614\tvalid_1's l2: 0.337427\n",
      "[157]\ttraining's l2: 0.342539\tvalid_1's l2: 0.337413\n",
      "[158]\ttraining's l2: 0.342467\tvalid_1's l2: 0.337377\n",
      "[159]\ttraining's l2: 0.342424\tvalid_1's l2: 0.33735\n",
      "[160]\ttraining's l2: 0.342389\tvalid_1's l2: 0.337345\n",
      "[161]\ttraining's l2: 0.342343\tvalid_1's l2: 0.337331\n",
      "[162]\ttraining's l2: 0.342271\tvalid_1's l2: 0.337256\n",
      "[163]\ttraining's l2: 0.342214\tvalid_1's l2: 0.337244\n",
      "[164]\ttraining's l2: 0.342164\tvalid_1's l2: 0.337254\n",
      "[165]\ttraining's l2: 0.342099\tvalid_1's l2: 0.337184\n",
      "[166]\ttraining's l2: 0.342041\tvalid_1's l2: 0.337171\n",
      "[167]\ttraining's l2: 0.342005\tvalid_1's l2: 0.337144\n",
      "[168]\ttraining's l2: 0.341959\tvalid_1's l2: 0.337113\n",
      "[169]\ttraining's l2: 0.341925\tvalid_1's l2: 0.337109\n",
      "[170]\ttraining's l2: 0.341857\tvalid_1's l2: 0.337062\n",
      "[171]\ttraining's l2: 0.341816\tvalid_1's l2: 0.337048\n",
      "[172]\ttraining's l2: 0.341778\tvalid_1's l2: 0.337051\n",
      "[173]\ttraining's l2: 0.341726\tvalid_1's l2: 0.337009\n",
      "[174]\ttraining's l2: 0.341694\tvalid_1's l2: 0.337008\n",
      "[175]\ttraining's l2: 0.341655\tvalid_1's l2: 0.336971\n",
      "[176]\ttraining's l2: 0.34162\tvalid_1's l2: 0.336966\n",
      "[177]\ttraining's l2: 0.341572\tvalid_1's l2: 0.336943\n",
      "[178]\ttraining's l2: 0.341523\tvalid_1's l2: 0.336932\n",
      "[179]\ttraining's l2: 0.341463\tvalid_1's l2: 0.336893\n",
      "[180]\ttraining's l2: 0.341407\tvalid_1's l2: 0.336873\n",
      "[181]\ttraining's l2: 0.341353\tvalid_1's l2: 0.336835\n",
      "[182]\ttraining's l2: 0.3413\tvalid_1's l2: 0.33684\n",
      "[183]\ttraining's l2: 0.341246\tvalid_1's l2: 0.336826\n",
      "[184]\ttraining's l2: 0.341205\tvalid_1's l2: 0.336837\n",
      "[185]\ttraining's l2: 0.34117\tvalid_1's l2: 0.336819\n",
      "[186]\ttraining's l2: 0.341123\tvalid_1's l2: 0.336803\n",
      "[187]\ttraining's l2: 0.341084\tvalid_1's l2: 0.336794\n",
      "[188]\ttraining's l2: 0.341029\tvalid_1's l2: 0.336784\n",
      "[189]\ttraining's l2: 0.340984\tvalid_1's l2: 0.336778\n",
      "[190]\ttraining's l2: 0.340947\tvalid_1's l2: 0.336752\n",
      "[191]\ttraining's l2: 0.340896\tvalid_1's l2: 0.336717\n",
      "[192]\ttraining's l2: 0.340839\tvalid_1's l2: 0.336685\n",
      "[193]\ttraining's l2: 0.340796\tvalid_1's l2: 0.336663\n",
      "[194]\ttraining's l2: 0.340748\tvalid_1's l2: 0.336638\n",
      "[195]\ttraining's l2: 0.340709\tvalid_1's l2: 0.336615\n",
      "[196]\ttraining's l2: 0.34066\tvalid_1's l2: 0.336607\n",
      "[197]\ttraining's l2: 0.340602\tvalid_1's l2: 0.336612\n",
      "[198]\ttraining's l2: 0.340551\tvalid_1's l2: 0.336553\n",
      "[199]\ttraining's l2: 0.340511\tvalid_1's l2: 0.336545\n",
      "[200]\ttraining's l2: 0.340467\tvalid_1's l2: 0.336542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.340467\tvalid_1's l2: 0.336542\n",
      "mean_21_sales: 6681458.67\n",
      "mean_14_sales: 2435312.10\n",
      "mean_7_sales: 1988293.27\n",
      "mean_30_sales: 1645813.54\n",
      "mean_20_dow0_2017: 1534491.91\n",
      "promo_14: 943755.13\n",
      "mean_63_sales: 570830.74\n",
      "item_class_features: 279945.18\n",
      "mean_4_dow0_2017: 136517.31\n",
      "mean_60_sales: 112911.19\n",
      "mean_3_sales: 105387.83\n",
      "item_family_features: 75436.78\n",
      "promo_13: 63087.60\n",
      "lag_1_sales: 62055.18\n",
      "store_cluster_features: 60558.87\n",
      "sum_7_promo: 59866.03\n",
      "std_30_sales: 54334.78\n",
      "mean_6_sales: 49753.55\n",
      "promo_0: 49104.10\n",
      "std_63_sales: 40636.62\n",
      "mean_5_sales: 40139.88\n",
      "lag_2_sales: 34445.52\n",
      "std_21_sales: 33086.58\n",
      "lag_49_sales: 32341.71\n",
      "promo_7: 31428.88\n",
      "sum_21_promo: 31317.26\n",
      "store_city_features: 27927.11\n",
      "sum_14_promo: 27288.87\n",
      "promo_12: 23451.75\n",
      "promo_10: 22567.60\n",
      "store_type_features: 22159.57\n",
      "promo_15: 19298.64\n",
      "std_60_sales: 19070.91\n",
      "mean_4_sales: 18824.97\n",
      "lag_14_sales: 14970.01\n",
      "std_14_sales: 14245.38\n",
      "mean_20_dow1_2017: 13711.95\n",
      "mean_20_dow2_2017: 10998.52\n",
      "std_7_sales: 9688.48\n",
      "mean_20_dow3_2017: 9502.76\n",
      "promo_9: 9254.03\n",
      "sum_2_promo: 6417.81\n",
      "sum_5_promo: 5133.31\n",
      "lag_63_sales: 4693.55\n",
      "mean_20_dow5_2017: 4359.85\n",
      "mean_4_dow6_2017: 4157.51\n",
      "mean_20_dow6_2017: 4145.51\n",
      "promo_11: 4125.56\n",
      "lag_42_sales: 4022.36\n",
      "lag_56_sales: 3381.16\n",
      "promo_6: 2708.80\n",
      "sum_4_promo: 2674.82\n",
      "sum_3_promo: 2673.37\n",
      "mean_20_dow4_2017: 2330.31\n",
      "lag_7_sales: 2101.68\n",
      "store_state_features: 1966.89\n",
      "mean_4_dow3_2017: 1643.27\n",
      "mean_4_dow5_2017: 1479.49\n",
      "lag_35_sales: 1453.68\n",
      "mean_4_dow4_2017: 1369.41\n",
      "mean_4_dow2_2017: 1305.74\n",
      "std_6_sales: 1183.22\n",
      "std_4_sales: 1161.64\n",
      "lag_21_sales: 1132.18\n",
      "promo_2: 1121.98\n",
      "lag_4_sales: 975.72\n",
      "mean_4_dow1_2017: 871.16\n",
      "std_5_sales: 716.67\n",
      "promo_8: 689.57\n",
      "lag_3_sales: 663.22\n",
      "std_3_sales: 623.00\n",
      "lag_28_sales: 618.15\n",
      "lag_5_sales: 517.12\n",
      "lag_6_sales: 437.61\n",
      "sum_6_promo: 213.23\n",
      "promo_1: 110.25\n",
      "promo_4: 103.97\n",
      "promo_5: 46.13\n",
      "promo_3: 21.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [15:26<01:00, 60.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.946809\tvalid_1's l2: 0.938802\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.89314\tvalid_1's l2: 0.885753\n",
      "[3]\ttraining's l2: 0.84468\tvalid_1's l2: 0.837507\n",
      "[4]\ttraining's l2: 0.800844\tvalid_1's l2: 0.793835\n",
      "[5]\ttraining's l2: 0.761128\tvalid_1's l2: 0.754249\n",
      "[6]\ttraining's l2: 0.725177\tvalid_1's l2: 0.718492\n",
      "[7]\ttraining's l2: 0.692724\tvalid_1's l2: 0.686148\n",
      "[8]\ttraining's l2: 0.663482\tvalid_1's l2: 0.657051\n",
      "[9]\ttraining's l2: 0.637764\tvalid_1's l2: 0.631341\n",
      "[10]\ttraining's l2: 0.613623\tvalid_1's l2: 0.607376\n",
      "[11]\ttraining's l2: 0.591662\tvalid_1's l2: 0.585676\n",
      "[12]\ttraining's l2: 0.571836\tvalid_1's l2: 0.565907\n",
      "[13]\ttraining's l2: 0.553897\tvalid_1's l2: 0.548055\n",
      "[14]\ttraining's l2: 0.537691\tvalid_1's l2: 0.531899\n",
      "[15]\ttraining's l2: 0.5229\tvalid_1's l2: 0.517251\n",
      "[16]\ttraining's l2: 0.509462\tvalid_1's l2: 0.503944\n",
      "[17]\ttraining's l2: 0.497286\tvalid_1's l2: 0.491953\n",
      "[18]\ttraining's l2: 0.486204\tvalid_1's l2: 0.481017\n",
      "[19]\ttraining's l2: 0.476171\tvalid_1's l2: 0.471129\n",
      "[20]\ttraining's l2: 0.467271\tvalid_1's l2: 0.462362\n",
      "[21]\ttraining's l2: 0.458946\tvalid_1's l2: 0.454125\n",
      "[22]\ttraining's l2: 0.451502\tvalid_1's l2: 0.446759\n",
      "[23]\ttraining's l2: 0.444598\tvalid_1's l2: 0.439897\n",
      "[24]\ttraining's l2: 0.438385\tvalid_1's l2: 0.433755\n",
      "[25]\ttraining's l2: 0.43271\tvalid_1's l2: 0.428172\n",
      "[26]\ttraining's l2: 0.427512\tvalid_1's l2: 0.423037\n",
      "[27]\ttraining's l2: 0.422792\tvalid_1's l2: 0.418457\n",
      "[28]\ttraining's l2: 0.418513\tvalid_1's l2: 0.414301\n",
      "[29]\ttraining's l2: 0.414623\tvalid_1's l2: 0.410486\n",
      "[30]\ttraining's l2: 0.411035\tvalid_1's l2: 0.406988\n",
      "[31]\ttraining's l2: 0.407732\tvalid_1's l2: 0.403744\n",
      "[32]\ttraining's l2: 0.404709\tvalid_1's l2: 0.400798\n",
      "[33]\ttraining's l2: 0.401988\tvalid_1's l2: 0.398094\n",
      "[34]\ttraining's l2: 0.399403\tvalid_1's l2: 0.39558\n",
      "[35]\ttraining's l2: 0.397099\tvalid_1's l2: 0.393298\n",
      "[36]\ttraining's l2: 0.394958\tvalid_1's l2: 0.391185\n",
      "[37]\ttraining's l2: 0.393027\tvalid_1's l2: 0.389287\n",
      "[38]\ttraining's l2: 0.391248\tvalid_1's l2: 0.38753\n",
      "[39]\ttraining's l2: 0.3896\tvalid_1's l2: 0.386001\n",
      "[40]\ttraining's l2: 0.388051\tvalid_1's l2: 0.384508\n",
      "[41]\ttraining's l2: 0.386592\tvalid_1's l2: 0.38323\n",
      "[42]\ttraining's l2: 0.385312\tvalid_1's l2: 0.382031\n",
      "[43]\ttraining's l2: 0.384106\tvalid_1's l2: 0.380945\n",
      "[44]\ttraining's l2: 0.383009\tvalid_1's l2: 0.37988\n",
      "[45]\ttraining's l2: 0.381992\tvalid_1's l2: 0.378973\n",
      "[46]\ttraining's l2: 0.380944\tvalid_1's l2: 0.378013\n",
      "[47]\ttraining's l2: 0.380018\tvalid_1's l2: 0.377108\n",
      "[48]\ttraining's l2: 0.379171\tvalid_1's l2: 0.376353\n",
      "[49]\ttraining's l2: 0.378347\tvalid_1's l2: 0.375629\n",
      "[50]\ttraining's l2: 0.377578\tvalid_1's l2: 0.374934\n",
      "[51]\ttraining's l2: 0.376836\tvalid_1's l2: 0.374251\n",
      "[52]\ttraining's l2: 0.376197\tvalid_1's l2: 0.373715\n",
      "[53]\ttraining's l2: 0.375552\tvalid_1's l2: 0.37319\n",
      "[54]\ttraining's l2: 0.374918\tvalid_1's l2: 0.372679\n",
      "[55]\ttraining's l2: 0.374387\tvalid_1's l2: 0.372212\n",
      "[56]\ttraining's l2: 0.373876\tvalid_1's l2: 0.371753\n",
      "[57]\ttraining's l2: 0.373475\tvalid_1's l2: 0.371407\n",
      "[58]\ttraining's l2: 0.373024\tvalid_1's l2: 0.370997\n",
      "[59]\ttraining's l2: 0.372601\tvalid_1's l2: 0.370621\n",
      "[60]\ttraining's l2: 0.372205\tvalid_1's l2: 0.370332\n",
      "[61]\ttraining's l2: 0.371722\tvalid_1's l2: 0.369941\n",
      "[62]\ttraining's l2: 0.371282\tvalid_1's l2: 0.369626\n",
      "[63]\ttraining's l2: 0.370924\tvalid_1's l2: 0.369297\n",
      "[64]\ttraining's l2: 0.370531\tvalid_1's l2: 0.368966\n",
      "[65]\ttraining's l2: 0.370248\tvalid_1's l2: 0.36874\n",
      "[66]\ttraining's l2: 0.369991\tvalid_1's l2: 0.368535\n",
      "[67]\ttraining's l2: 0.369652\tvalid_1's l2: 0.368314\n",
      "[68]\ttraining's l2: 0.369388\tvalid_1's l2: 0.368135\n",
      "[69]\ttraining's l2: 0.36907\tvalid_1's l2: 0.367874\n",
      "[70]\ttraining's l2: 0.368746\tvalid_1's l2: 0.367616\n",
      "[71]\ttraining's l2: 0.368425\tvalid_1's l2: 0.367369\n",
      "[72]\ttraining's l2: 0.368199\tvalid_1's l2: 0.36718\n",
      "[73]\ttraining's l2: 0.367864\tvalid_1's l2: 0.366937\n",
      "[74]\ttraining's l2: 0.367626\tvalid_1's l2: 0.366808\n",
      "[75]\ttraining's l2: 0.367323\tvalid_1's l2: 0.366607\n",
      "[76]\ttraining's l2: 0.367115\tvalid_1's l2: 0.36645\n",
      "[77]\ttraining's l2: 0.366886\tvalid_1's l2: 0.366255\n",
      "[78]\ttraining's l2: 0.366651\tvalid_1's l2: 0.366096\n",
      "[79]\ttraining's l2: 0.36642\tvalid_1's l2: 0.365897\n",
      "[80]\ttraining's l2: 0.366203\tvalid_1's l2: 0.365729\n",
      "[81]\ttraining's l2: 0.366014\tvalid_1's l2: 0.36557\n",
      "[82]\ttraining's l2: 0.365873\tvalid_1's l2: 0.365456\n",
      "[83]\ttraining's l2: 0.36568\tvalid_1's l2: 0.365313\n",
      "[84]\ttraining's l2: 0.36545\tvalid_1's l2: 0.365168\n",
      "[85]\ttraining's l2: 0.365231\tvalid_1's l2: 0.364999\n",
      "[86]\ttraining's l2: 0.365063\tvalid_1's l2: 0.364858\n",
      "[87]\ttraining's l2: 0.364914\tvalid_1's l2: 0.364762\n",
      "[88]\ttraining's l2: 0.364778\tvalid_1's l2: 0.364647\n",
      "[89]\ttraining's l2: 0.364598\tvalid_1's l2: 0.364515\n",
      "[90]\ttraining's l2: 0.364445\tvalid_1's l2: 0.364386\n",
      "[91]\ttraining's l2: 0.364331\tvalid_1's l2: 0.364316\n",
      "[92]\ttraining's l2: 0.364202\tvalid_1's l2: 0.364214\n",
      "[93]\ttraining's l2: 0.36409\tvalid_1's l2: 0.36414\n",
      "[94]\ttraining's l2: 0.363945\tvalid_1's l2: 0.364061\n",
      "[95]\ttraining's l2: 0.363793\tvalid_1's l2: 0.363955\n",
      "[96]\ttraining's l2: 0.363692\tvalid_1's l2: 0.363901\n",
      "[97]\ttraining's l2: 0.363528\tvalid_1's l2: 0.363793\n",
      "[98]\ttraining's l2: 0.363426\tvalid_1's l2: 0.363698\n",
      "[99]\ttraining's l2: 0.363326\tvalid_1's l2: 0.363644\n",
      "[100]\ttraining's l2: 0.363115\tvalid_1's l2: 0.363493\n",
      "[101]\ttraining's l2: 0.363023\tvalid_1's l2: 0.363413\n",
      "[102]\ttraining's l2: 0.362906\tvalid_1's l2: 0.363355\n",
      "[103]\ttraining's l2: 0.362763\tvalid_1's l2: 0.363261\n",
      "[104]\ttraining's l2: 0.362687\tvalid_1's l2: 0.363203\n",
      "[105]\ttraining's l2: 0.362495\tvalid_1's l2: 0.363096\n",
      "[106]\ttraining's l2: 0.362358\tvalid_1's l2: 0.363004\n",
      "[107]\ttraining's l2: 0.362241\tvalid_1's l2: 0.362913\n",
      "[108]\ttraining's l2: 0.362094\tvalid_1's l2: 0.362825\n",
      "[109]\ttraining's l2: 0.361991\tvalid_1's l2: 0.362765\n",
      "[110]\ttraining's l2: 0.361896\tvalid_1's l2: 0.362723\n",
      "[111]\ttraining's l2: 0.36182\tvalid_1's l2: 0.362683\n",
      "[112]\ttraining's l2: 0.361724\tvalid_1's l2: 0.362625\n",
      "[113]\ttraining's l2: 0.361606\tvalid_1's l2: 0.36255\n",
      "[114]\ttraining's l2: 0.361456\tvalid_1's l2: 0.362447\n",
      "[115]\ttraining's l2: 0.361391\tvalid_1's l2: 0.362426\n",
      "[116]\ttraining's l2: 0.361226\tvalid_1's l2: 0.362297\n",
      "[117]\ttraining's l2: 0.361134\tvalid_1's l2: 0.362225\n",
      "[118]\ttraining's l2: 0.36105\tvalid_1's l2: 0.362169\n",
      "[119]\ttraining's l2: 0.360976\tvalid_1's l2: 0.362137\n",
      "[120]\ttraining's l2: 0.36086\tvalid_1's l2: 0.362058\n",
      "[121]\ttraining's l2: 0.360793\tvalid_1's l2: 0.362024\n",
      "[122]\ttraining's l2: 0.360714\tvalid_1's l2: 0.361976\n",
      "[123]\ttraining's l2: 0.360636\tvalid_1's l2: 0.361953\n",
      "[124]\ttraining's l2: 0.36057\tvalid_1's l2: 0.361915\n",
      "[125]\ttraining's l2: 0.360462\tvalid_1's l2: 0.361851\n",
      "[126]\ttraining's l2: 0.360406\tvalid_1's l2: 0.361804\n",
      "[127]\ttraining's l2: 0.360359\tvalid_1's l2: 0.361789\n",
      "[128]\ttraining's l2: 0.360308\tvalid_1's l2: 0.36177\n",
      "[129]\ttraining's l2: 0.360171\tvalid_1's l2: 0.361681\n",
      "[130]\ttraining's l2: 0.360064\tvalid_1's l2: 0.361625\n",
      "[131]\ttraining's l2: 0.360004\tvalid_1's l2: 0.361622\n",
      "[132]\ttraining's l2: 0.359956\tvalid_1's l2: 0.361625\n",
      "[133]\ttraining's l2: 0.359901\tvalid_1's l2: 0.361616\n",
      "[134]\ttraining's l2: 0.359844\tvalid_1's l2: 0.361601\n",
      "[135]\ttraining's l2: 0.359754\tvalid_1's l2: 0.361549\n",
      "[136]\ttraining's l2: 0.359684\tvalid_1's l2: 0.36149\n",
      "[137]\ttraining's l2: 0.359574\tvalid_1's l2: 0.361442\n",
      "[138]\ttraining's l2: 0.359494\tvalid_1's l2: 0.36139\n",
      "[139]\ttraining's l2: 0.359402\tvalid_1's l2: 0.361351\n",
      "[140]\ttraining's l2: 0.359319\tvalid_1's l2: 0.361289\n",
      "[141]\ttraining's l2: 0.359232\tvalid_1's l2: 0.361248\n",
      "[142]\ttraining's l2: 0.359159\tvalid_1's l2: 0.361235\n",
      "[143]\ttraining's l2: 0.359099\tvalid_1's l2: 0.361212\n",
      "[144]\ttraining's l2: 0.359044\tvalid_1's l2: 0.3612\n",
      "[145]\ttraining's l2: 0.359006\tvalid_1's l2: 0.361181\n",
      "[146]\ttraining's l2: 0.358963\tvalid_1's l2: 0.361159\n",
      "[147]\ttraining's l2: 0.358889\tvalid_1's l2: 0.361111\n",
      "[148]\ttraining's l2: 0.358833\tvalid_1's l2: 0.36111\n",
      "[149]\ttraining's l2: 0.358762\tvalid_1's l2: 0.361068\n",
      "[150]\ttraining's l2: 0.358703\tvalid_1's l2: 0.361046\n",
      "[151]\ttraining's l2: 0.358658\tvalid_1's l2: 0.361047\n",
      "[152]\ttraining's l2: 0.358611\tvalid_1's l2: 0.361038\n",
      "[153]\ttraining's l2: 0.358573\tvalid_1's l2: 0.36104\n",
      "[154]\ttraining's l2: 0.358517\tvalid_1's l2: 0.360976\n",
      "[155]\ttraining's l2: 0.358449\tvalid_1's l2: 0.360952\n",
      "[156]\ttraining's l2: 0.35838\tvalid_1's l2: 0.360931\n",
      "[157]\ttraining's l2: 0.358257\tvalid_1's l2: 0.360849\n",
      "[158]\ttraining's l2: 0.358207\tvalid_1's l2: 0.360828\n",
      "[159]\ttraining's l2: 0.358174\tvalid_1's l2: 0.360814\n",
      "[160]\ttraining's l2: 0.35812\tvalid_1's l2: 0.360794\n",
      "[161]\ttraining's l2: 0.358062\tvalid_1's l2: 0.360781\n",
      "[162]\ttraining's l2: 0.358032\tvalid_1's l2: 0.360774\n",
      "[163]\ttraining's l2: 0.357987\tvalid_1's l2: 0.360772\n",
      "[164]\ttraining's l2: 0.357954\tvalid_1's l2: 0.360765\n",
      "[165]\ttraining's l2: 0.357896\tvalid_1's l2: 0.360733\n",
      "[166]\ttraining's l2: 0.357847\tvalid_1's l2: 0.360732\n",
      "[167]\ttraining's l2: 0.357806\tvalid_1's l2: 0.360702\n",
      "[168]\ttraining's l2: 0.357769\tvalid_1's l2: 0.360697\n",
      "[169]\ttraining's l2: 0.357724\tvalid_1's l2: 0.360686\n",
      "[170]\ttraining's l2: 0.357625\tvalid_1's l2: 0.360621\n",
      "[171]\ttraining's l2: 0.357584\tvalid_1's l2: 0.360586\n",
      "[172]\ttraining's l2: 0.357555\tvalid_1's l2: 0.360589\n",
      "[173]\ttraining's l2: 0.357528\tvalid_1's l2: 0.360585\n",
      "[174]\ttraining's l2: 0.357475\tvalid_1's l2: 0.360578\n",
      "[175]\ttraining's l2: 0.357391\tvalid_1's l2: 0.360553\n",
      "[176]\ttraining's l2: 0.357351\tvalid_1's l2: 0.360536\n",
      "[177]\ttraining's l2: 0.357319\tvalid_1's l2: 0.360522\n",
      "[178]\ttraining's l2: 0.357289\tvalid_1's l2: 0.360525\n",
      "[179]\ttraining's l2: 0.357235\tvalid_1's l2: 0.360509\n",
      "[180]\ttraining's l2: 0.357185\tvalid_1's l2: 0.360496\n",
      "[181]\ttraining's l2: 0.357139\tvalid_1's l2: 0.360505\n",
      "[182]\ttraining's l2: 0.357044\tvalid_1's l2: 0.360411\n",
      "[183]\ttraining's l2: 0.357004\tvalid_1's l2: 0.360395\n",
      "[184]\ttraining's l2: 0.356974\tvalid_1's l2: 0.360399\n",
      "[185]\ttraining's l2: 0.356943\tvalid_1's l2: 0.360392\n",
      "[186]\ttraining's l2: 0.356898\tvalid_1's l2: 0.360379\n",
      "[187]\ttraining's l2: 0.356823\tvalid_1's l2: 0.360314\n",
      "[188]\ttraining's l2: 0.356788\tvalid_1's l2: 0.360306\n",
      "[189]\ttraining's l2: 0.356694\tvalid_1's l2: 0.360233\n",
      "[190]\ttraining's l2: 0.356664\tvalid_1's l2: 0.36021\n",
      "[191]\ttraining's l2: 0.35663\tvalid_1's l2: 0.360195\n",
      "[192]\ttraining's l2: 0.356588\tvalid_1's l2: 0.360181\n",
      "[193]\ttraining's l2: 0.356562\tvalid_1's l2: 0.360176\n",
      "[194]\ttraining's l2: 0.356534\tvalid_1's l2: 0.360163\n",
      "[195]\ttraining's l2: 0.356508\tvalid_1's l2: 0.360177\n",
      "[196]\ttraining's l2: 0.356483\tvalid_1's l2: 0.360186\n",
      "[197]\ttraining's l2: 0.356415\tvalid_1's l2: 0.360137\n",
      "[198]\ttraining's l2: 0.356376\tvalid_1's l2: 0.360102\n",
      "[199]\ttraining's l2: 0.356341\tvalid_1's l2: 0.360081\n",
      "[200]\ttraining's l2: 0.35631\tvalid_1's l2: 0.360084\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.35631\tvalid_1's l2: 0.360084\n",
      "mean_21_sales: 6008705.99\n",
      "mean_30_sales: 2197410.04\n",
      "mean_14_sales: 1491473.72\n",
      "mean_7_sales: 840259.70\n",
      "mean_20_dow1_2017: 833598.31\n",
      "mean_63_sales: 719810.15\n",
      "promo_15: 582213.42\n",
      "mean_60_sales: 400560.94\n",
      "mean_6_sales: 390093.65\n",
      "item_class_features: 259378.95\n",
      "lag_1_sales: 110914.51\n",
      "promo_14: 56883.63\n",
      "mean_20_dow2_2017: 39965.58\n",
      "store_city_features: 38007.62\n",
      "std_63_sales: 36865.59\n",
      "mean_4_dow1_2017: 35702.82\n",
      "std_30_sales: 27009.90\n",
      "std_21_sales: 26932.34\n",
      "store_cluster_features: 26237.82\n",
      "item_family_features: 25111.09\n",
      "mean_5_sales: 24235.03\n",
      "sum_4_promo: 24137.18\n",
      "store_type_features: 15672.24\n",
      "mean_3_sales: 15605.39\n",
      "std_60_sales: 14330.01\n",
      "sum_2_promo: 13813.91\n",
      "mean_4_sales: 12161.48\n",
      "promo_13: 11533.71\n",
      "promo_10: 10674.68\n",
      "sum_6_promo: 10352.90\n",
      "sum_7_promo: 9488.36\n",
      "lag_14_sales: 8792.21\n",
      "mean_20_dow0_2017: 8585.12\n",
      "sum_14_promo: 7708.76\n",
      "sum_21_promo: 7445.51\n",
      "lag_2_sales: 7062.51\n",
      "promo_12: 6439.37\n",
      "lag_49_sales: 5924.49\n",
      "std_7_sales: 5911.53\n",
      "mean_20_dow6_2017: 5777.66\n",
      "promo_8: 5092.23\n",
      "mean_20_dow4_2017: 4890.20\n",
      "mean_20_dow3_2017: 4748.84\n",
      "store_state_features: 4486.44\n",
      "std_6_sales: 4277.91\n",
      "lag_5_sales: 4028.56\n",
      "mean_4_dow6_2017: 3931.77\n",
      "promo_7: 3907.09\n",
      "std_14_sales: 3884.57\n",
      "mean_4_dow0_2017: 3515.55\n",
      "mean_4_dow2_2017: 2971.90\n",
      "promo_0: 2751.36\n",
      "lag_6_sales: 2690.77\n",
      "lag_4_sales: 2118.32\n",
      "mean_4_dow5_2017: 2004.97\n",
      "sum_3_promo: 1926.70\n",
      "sum_5_promo: 1914.71\n",
      "lag_42_sales: 1836.34\n",
      "std_4_sales: 1611.46\n",
      "promo_6: 1500.37\n",
      "lag_3_sales: 1493.44\n",
      "std_5_sales: 1242.53\n",
      "mean_4_dow3_2017: 1172.29\n",
      "promo_11: 1146.73\n",
      "lag_56_sales: 1097.65\n",
      "lag_63_sales: 963.69\n",
      "mean_20_dow5_2017: 866.44\n",
      "mean_4_dow4_2017: 834.09\n",
      "lag_21_sales: 790.41\n",
      "promo_9: 762.06\n",
      "lag_28_sales: 723.17\n",
      "lag_35_sales: 647.97\n",
      "std_3_sales: 600.15\n",
      "lag_7_sales: 442.69\n",
      "promo_2: 390.86\n",
      "promo_1: 390.45\n",
      "promo_5: 266.72\n",
      "promo_3: 158.55\n",
      "promo_4: 82.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [16:32<00:00, 62.28s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(16)):\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * nbr_weeks) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "\n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=MAX_ROUNDS,\n",
    "#         verbose_eval = False,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50)\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3511710550491811"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1507177033492823"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "252/1672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 0.3511710550491811\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "\n",
    "mlflow.set_experiment('grocery forecasting')\n",
    "with mlflow.start_run(run_name='lgbm'):\n",
    "    mlflow.log_param('model', 'lgbm')\n",
    "    mlflow.log_param('train starts', train_start)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param('lagging', LAG_DICT.values())\n",
    "    mlflow.log_param('slidingWindows', SLIDING_DICT.values())\n",
    "    mlflow.log_param('item_info', 'Yes')\n",
    "    mlflow.log_param('store_info', 'Yes')\n",
    "    mlflow.log_param('private score', 0.52207)\n",
    "    mlflow.log_param('private rank', '15%')\n",
    "    mlflow.log_param('public score', 0.51485)\n",
    "\n",
    "    mlflow.log_metric('mse', mse)\n",
    "    \n",
    "print(\"Validation mse:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_train.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
