{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from config import (\n",
    "    RAW_DATA_DIR,\n",
    "    FEATURE_DIR,\n",
    "    LAG_DICT,\n",
    "    SLIDING_DICT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve lightgbm error on MAC\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv(\n",
    "    RAW_DATA_DIR+'train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    RAW_DATA_DIR+'test.csv', usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    RAW_DATA_DIR+'items.csv',\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    RAW_DATA_DIR+'stores.csv',\n",
    ").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Period\n",
    "\n",
    "2017-08-16 to 2017-08-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = date(2017, 8, 16)\n",
    "test_end = date(2017,8, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid starts from 2017-07-26 to 2017-08-10\n"
     ]
    }
   ],
   "source": [
    "valid_start = test_start - timedelta(16)\n",
    "while(1):\n",
    "    if valid_start.weekday() == test_start.weekday():\n",
    "        break\n",
    "    valid_start = valid_start-timedelta(days=1)\n",
    "valid_end = valid_start + timedelta(15)\n",
    "print('valid starts from {} to {}'.format(valid_start, valid_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Period\n",
    "\n",
    "Considering the more nearer peiods of sales data may have more in common, it would be better to find the nearest period as valid period.\n",
    "\n",
    "Based on the analysis before, we assume the sales data is periodically with the frequency of 7 days, so we want to keep that feature same\n",
    "in the train, valid and test period.\n",
    "\n",
    "So finally, we choose valid period:\n",
    "\n",
    "2017-07-26 to 2017-08-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_start = date(2017, 7, 26)\n",
    "valid_end = date(2017, 8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Period\n",
    "\n",
    "#### Earthquake happended on April 16, 2016. It may affect for the next several weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train datasets starts from 2016-10-05\n"
     ]
    }
   ],
   "source": [
    "filter_date = date(2016,4,16) + timedelta(7*4)\n",
    "lag_max = 140\n",
    "train_start=  filter_date+timedelta(days=lag_max)\n",
    "\n",
    "while(1):\n",
    "    train_start = train_start + timedelta(1)\n",
    "    if train_start.weekday() == valid_start.weekday():\n",
    "        break\n",
    "print('train datasets starts from {}'.format(train_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and a TypeError will be raised. To retain the current\n",
      "behavior, convert the 'datetime.date' to a datetime with\n",
      "'pd.Timestamp'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train[df_train['date']>=filter_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Promo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_train = df_train.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]]\n",
    "\n",
    "# missing onpromotions filling\n",
    "promo_train = promo_train.unstack(level=-1).fillna(False)\n",
    "promo_train.columns = promo_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing test onpromotions filling\n",
    "promo_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_test.columns = promo_test.columns.get_level_values(1)\n",
    "# filter those items/stores in promo_test but not in promo_train\n",
    "promo_test = promo_test.reindex(promo_train.index).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_features = pd.concat([promo_train, promo_test], axis=1)\n",
    "del promo_test, promo_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "df_train = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_train.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['family'] = items['family'].astype('category')\n",
    "item_family_features = items.family.cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['class'] = items['class'].astype('category')\n",
    "item_class_features = items['class'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = stores.reindex(df_train.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['city'] = stores['city'].astype('category')\n",
    "store_city_features = stores['city'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['state'] = stores['state'].astype('category')\n",
    "store_state_features = stores['state'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['type'] = stores['type'].astype('category')\n",
    "store_type_features = stores['type'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store's cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['cluster'] = stores['cluster'].astype('category')\n",
    "store_cluster_features = stores['cluster'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = df_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = df_train.columns\n",
    "obj_list = pd.date_range(filter_date, test_start-timedelta(1))\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    df_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_list = promo_features.columns\n",
    "obj_list = pd.date_range(filter_date, test_end)\n",
    "diff_list = list(set(obj_list) - set(date_list)) \n",
    "for i in diff_list:\n",
    "    print(i)\n",
    "    promo_features[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagging and sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG_DICT = {'unit_sales': [1,2,3,4,5,6,7,14,21,28,35,42,49,56,63],\n",
    "            'onpromotion': [2, 3,4,5,6, 7, 14, 21]}\n",
    "\n",
    "SLIDING_DICT = {'unit_sales': [3, 4, 5, 6, 7, 14, 21, 30, 60, 63]}\n",
    "\n",
    "# initialise dirs\n",
    "RAW_DATA_DIR = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, \n",
    "                 start_time,\n",
    "                 minus,\n",
    "                 periods,\n",
    "                 freq='D'):\n",
    "    return df[pd.date_range(start_time - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def gen_dataset(df, \n",
    "                promo_features,\n",
    "                item_family_features,\n",
    "                item_class_features,\n",
    "                store_city_features,\n",
    "                store_state_features,\n",
    "                store_type_features,\n",
    "                store_cluster_features,\n",
    "                start_time,\n",
    "                is_train=True):\n",
    "    # init\n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    for i in LAG_DICT['unit_sales']:\n",
    "        X['lag_{}_sales'.format(i)] = get_timespan(df, start_time, i, 1).values.ravel()\n",
    "    \n",
    "    for i in LAG_DICT['onpromotion']:\n",
    "        X['sum_{}_promo'.format(i)] = get_timespan(promo_features, start_time, i, 1).sum(axis=1).ravel()\n",
    "\n",
    "    for i in SLIDING_DICT['unit_sales']:\n",
    "        X[\"mean_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).mean(axis=1).values\n",
    "        X[\"std_{}_sales\".format(i)] = get_timespan(df, start_time, i, i).std(axis=1).values\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, start_time, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, start_time, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "        \n",
    "    # for the next to-predict 16 days \n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_features[start_time + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X['item_family_features'] = item_family_features\n",
    "\n",
    "    X['item_class_features'] = item_class_features\n",
    "\n",
    "    X['store_city_features'] = store_city_features\n",
    "\n",
    "    X['store_state_features'] = store_state_features\n",
    "\n",
    "    X['store_type_features'] = store_type_features\n",
    "\n",
    "    X['store_cluster_features'] = store_cluster_features\n",
    "        \n",
    "    if is_train:\n",
    "        y = df[pd.date_range(start_time, periods=16)].values\n",
    "        return X, y\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train, valid and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of week:   0%|          | 0/42 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of week:   2%|▏         | 1/42 [00:01<00:48,  1.19s/it]\u001b[A\n",
      "No. of week:   5%|▍         | 2/42 [00:01<00:42,  1.07s/it]\u001b[A\n",
      "No. of week:   7%|▋         | 3/42 [00:02<00:37,  1.03it/s]\u001b[A\n",
      "No. of week:  10%|▉         | 4/42 [00:03<00:34,  1.12it/s]\u001b[A\n",
      "No. of week:  12%|█▏        | 5/42 [00:04<00:31,  1.18it/s]\u001b[A\n",
      "No. of week:  14%|█▍        | 6/42 [00:04<00:29,  1.24it/s]\u001b[A\n",
      "No. of week:  17%|█▋        | 7/42 [00:05<00:27,  1.27it/s]\u001b[A\n",
      "No. of week:  19%|█▉        | 8/42 [00:06<00:26,  1.29it/s]\u001b[A\n",
      "No. of week:  21%|██▏       | 9/42 [00:07<00:25,  1.30it/s]\u001b[A\n",
      "No. of week:  24%|██▍       | 10/42 [00:07<00:24,  1.31it/s]\u001b[A\n",
      "No. of week:  26%|██▌       | 11/42 [00:08<00:23,  1.31it/s]\u001b[A\n",
      "No. of week:  29%|██▊       | 12/42 [00:09<00:22,  1.31it/s]\u001b[A\n",
      "No. of week:  31%|███       | 13/42 [00:10<00:24,  1.21it/s]\u001b[A\n",
      "No. of week:  33%|███▎      | 14/42 [00:11<00:24,  1.13it/s]\u001b[A\n",
      "No. of week:  36%|███▌      | 15/42 [00:12<00:24,  1.09it/s]\u001b[A\n",
      "No. of week:  38%|███▊      | 16/42 [00:13<00:24,  1.07it/s]\u001b[A\n",
      "No. of week:  40%|████      | 17/42 [00:14<00:23,  1.07it/s]\u001b[A\n",
      "No. of week:  43%|████▎     | 18/42 [00:15<00:22,  1.07it/s]\u001b[A\n",
      "No. of week:  45%|████▌     | 19/42 [00:16<00:21,  1.07it/s]\u001b[A\n",
      "No. of week:  48%|████▊     | 20/42 [00:17<00:20,  1.06it/s]\u001b[A\n",
      "No. of week:  50%|█████     | 21/42 [00:18<00:19,  1.05it/s]\u001b[A\n",
      "No. of week:  52%|█████▏    | 22/42 [00:18<00:17,  1.11it/s]\u001b[A\n",
      "No. of week:  55%|█████▍    | 23/42 [00:19<00:16,  1.17it/s]\u001b[A\n",
      "No. of week:  57%|█████▋    | 24/42 [00:20<00:14,  1.20it/s]\u001b[A\n",
      "No. of week:  60%|█████▉    | 25/42 [00:21<00:13,  1.23it/s]\u001b[A\n",
      "No. of week:  62%|██████▏   | 26/42 [00:21<00:12,  1.24it/s]\u001b[A\n",
      "No. of week:  64%|██████▍   | 27/42 [00:22<00:11,  1.26it/s]\u001b[A\n",
      "No. of week:  67%|██████▋   | 28/42 [00:23<00:11,  1.25it/s]\u001b[A\n",
      "No. of week:  69%|██████▉   | 29/42 [00:24<00:10,  1.25it/s]\u001b[A\n",
      "No. of week:  71%|███████▏  | 30/42 [00:25<00:09,  1.26it/s]\u001b[A\n",
      "No. of week:  74%|███████▍  | 31/42 [00:25<00:08,  1.27it/s]\u001b[A\n",
      "No. of week:  76%|███████▌  | 32/42 [00:26<00:07,  1.28it/s]\u001b[A\n",
      "No. of week:  79%|███████▊  | 33/42 [00:27<00:06,  1.29it/s]\u001b[A\n",
      "No. of week:  81%|████████  | 34/42 [00:28<00:06,  1.27it/s]\u001b[A\n",
      "No. of week:  83%|████████▎ | 35/42 [00:29<00:05,  1.28it/s]\u001b[A\n",
      "No. of week:  86%|████████▌ | 36/42 [00:29<00:04,  1.28it/s]\u001b[A\n",
      "No. of week:  88%|████████▊ | 37/42 [00:30<00:03,  1.29it/s]\u001b[A\n",
      "No. of week:  90%|█████████ | 38/42 [00:31<00:03,  1.29it/s]\u001b[A\n",
      "No. of week:  93%|█████████▎| 39/42 [00:32<00:02,  1.30it/s]\u001b[A\n",
      "No. of week:  95%|█████████▌| 40/42 [00:32<00:01,  1.30it/s]\u001b[A\n",
      "No. of week:  98%|█████████▊| 41/42 [00:33<00:00,  1.29it/s]\u001b[A\n",
      "No. of week: 100%|██████████| 42/42 [00:34<00:00,  1.30it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "\n",
    "nbr_weeks = int((valid_start - train_start).days/7)\n",
    "\n",
    "X_l, y_l = [], []\n",
    "\n",
    "for i in tqdm(range(nbr_weeks), desc = 'No. of week'):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = gen_dataset(\n",
    "        df_train,\n",
    "        promo_features,\n",
    "        item_family_features,\n",
    "        item_class_features,\n",
    "        store_city_features,\n",
    "        store_state_features,\n",
    "        store_type_features,\n",
    "        store_cluster_features,\n",
    "        train_start + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_val, y_val = gen_dataset(df_train,\n",
    "                           promo_features,\n",
    "                           item_family_features,\n",
    "                           item_class_features,\n",
    "                           store_city_features,\n",
    "                           store_state_features,\n",
    "                           store_type_features,\n",
    "                           store_cluster_features,\n",
    "                           valid_start)\n",
    "X_test = gen_dataset(df_train, \n",
    "                    promo_features,\n",
    "                    item_family_features,\n",
    "                    item_class_features,\n",
    "                    store_city_features,\n",
    "                    store_state_features,\n",
    "                    store_type_features,\n",
    "                    store_cluster_features,\n",
    "                    test_start, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 200\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = ['item_family_features',\n",
    "            'item_class_features',\n",
    "            'store_city_features',\n",
    "            'store_state_features',\n",
    "            'store_type_features',\n",
    "            'store_cluster_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A/Users/liuyu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.0669\tvalid_1's l2: 1.00319\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.997115\tvalid_1's l2: 0.936875\n",
      "[3]\ttraining's l2: 0.93291\tvalid_1's l2: 0.8756\n",
      "[4]\ttraining's l2: 0.875641\tvalid_1's l2: 0.821276\n",
      "[5]\ttraining's l2: 0.82264\tvalid_1's l2: 0.77096\n",
      "[6]\ttraining's l2: 0.774825\tvalid_1's l2: 0.725402\n",
      "[7]\ttraining's l2: 0.731454\tvalid_1's l2: 0.684427\n",
      "[8]\ttraining's l2: 0.692291\tvalid_1's l2: 0.647398\n",
      "[9]\ttraining's l2: 0.656942\tvalid_1's l2: 0.614013\n",
      "[10]\ttraining's l2: 0.624789\tvalid_1's l2: 0.58376\n",
      "[11]\ttraining's l2: 0.595655\tvalid_1's l2: 0.55643\n",
      "[12]\ttraining's l2: 0.569987\tvalid_1's l2: 0.532496\n",
      "[13]\ttraining's l2: 0.546698\tvalid_1's l2: 0.510864\n",
      "[14]\ttraining's l2: 0.524965\tvalid_1's l2: 0.49061\n",
      "[15]\ttraining's l2: 0.505157\tvalid_1's l2: 0.472122\n",
      "[16]\ttraining's l2: 0.487249\tvalid_1's l2: 0.455509\n",
      "[17]\ttraining's l2: 0.471025\tvalid_1's l2: 0.440529\n",
      "[18]\ttraining's l2: 0.45627\tvalid_1's l2: 0.426768\n",
      "[19]\ttraining's l2: 0.44289\tvalid_1's l2: 0.414437\n",
      "[20]\ttraining's l2: 0.430698\tvalid_1's l2: 0.403226\n",
      "[21]\ttraining's l2: 0.419676\tvalid_1's l2: 0.393144\n",
      "[22]\ttraining's l2: 0.409646\tvalid_1's l2: 0.384057\n",
      "[23]\ttraining's l2: 0.400875\tvalid_1's l2: 0.3761\n",
      "[24]\ttraining's l2: 0.392462\tvalid_1's l2: 0.368477\n",
      "[25]\ttraining's l2: 0.384837\tvalid_1's l2: 0.36166\n",
      "[26]\ttraining's l2: 0.377978\tvalid_1's l2: 0.355429\n",
      "[27]\ttraining's l2: 0.371988\tvalid_1's l2: 0.350148\n",
      "[28]\ttraining's l2: 0.366536\tvalid_1's l2: 0.345378\n",
      "[29]\ttraining's l2: 0.361232\tvalid_1's l2: 0.34059\n",
      "[30]\ttraining's l2: 0.356219\tvalid_1's l2: 0.336185\n",
      "[31]\ttraining's l2: 0.351822\tvalid_1's l2: 0.332169\n",
      "[32]\ttraining's l2: 0.347627\tvalid_1's l2: 0.328525\n",
      "[33]\ttraining's l2: 0.344239\tvalid_1's l2: 0.325595\n",
      "[34]\ttraining's l2: 0.341011\tvalid_1's l2: 0.322924\n",
      "[35]\ttraining's l2: 0.337903\tvalid_1's l2: 0.320174\n",
      "[36]\ttraining's l2: 0.334926\tvalid_1's l2: 0.317564\n",
      "[37]\ttraining's l2: 0.332216\tvalid_1's l2: 0.31521\n",
      "[38]\ttraining's l2: 0.329848\tvalid_1's l2: 0.313128\n",
      "[39]\ttraining's l2: 0.327545\tvalid_1's l2: 0.311188\n",
      "[40]\ttraining's l2: 0.325451\tvalid_1's l2: 0.309403\n",
      "[41]\ttraining's l2: 0.323719\tvalid_1's l2: 0.308012\n",
      "[42]\ttraining's l2: 0.321949\tvalid_1's l2: 0.306492\n",
      "[43]\ttraining's l2: 0.320493\tvalid_1's l2: 0.305349\n",
      "[44]\ttraining's l2: 0.319182\tvalid_1's l2: 0.30432\n",
      "[45]\ttraining's l2: 0.317748\tvalid_1's l2: 0.303095\n",
      "[46]\ttraining's l2: 0.316449\tvalid_1's l2: 0.301938\n",
      "[47]\ttraining's l2: 0.315238\tvalid_1's l2: 0.300862\n",
      "[48]\ttraining's l2: 0.31415\tvalid_1's l2: 0.299955\n",
      "[49]\ttraining's l2: 0.313182\tvalid_1's l2: 0.2992\n",
      "[50]\ttraining's l2: 0.312405\tvalid_1's l2: 0.298611\n",
      "[51]\ttraining's l2: 0.311635\tvalid_1's l2: 0.298042\n",
      "[52]\ttraining's l2: 0.310779\tvalid_1's l2: 0.297349\n",
      "[53]\ttraining's l2: 0.310025\tvalid_1's l2: 0.296779\n",
      "[54]\ttraining's l2: 0.309484\tvalid_1's l2: 0.296389\n",
      "[55]\ttraining's l2: 0.308785\tvalid_1's l2: 0.295763\n",
      "[56]\ttraining's l2: 0.308154\tvalid_1's l2: 0.295259\n",
      "[57]\ttraining's l2: 0.307544\tvalid_1's l2: 0.294717\n",
      "[58]\ttraining's l2: 0.306995\tvalid_1's l2: 0.294229\n",
      "[59]\ttraining's l2: 0.306569\tvalid_1's l2: 0.29393\n",
      "[60]\ttraining's l2: 0.306084\tvalid_1's l2: 0.293561\n",
      "[61]\ttraining's l2: 0.305699\tvalid_1's l2: 0.29329\n",
      "[62]\ttraining's l2: 0.305258\tvalid_1's l2: 0.292944\n",
      "[63]\ttraining's l2: 0.304832\tvalid_1's l2: 0.292553\n",
      "[64]\ttraining's l2: 0.304347\tvalid_1's l2: 0.292086\n",
      "[65]\ttraining's l2: 0.303981\tvalid_1's l2: 0.291746\n",
      "[66]\ttraining's l2: 0.303633\tvalid_1's l2: 0.291468\n",
      "[67]\ttraining's l2: 0.303312\tvalid_1's l2: 0.291218\n",
      "[68]\ttraining's l2: 0.303034\tvalid_1's l2: 0.291026\n",
      "[69]\ttraining's l2: 0.302733\tvalid_1's l2: 0.290757\n",
      "[70]\ttraining's l2: 0.302513\tvalid_1's l2: 0.290615\n",
      "[71]\ttraining's l2: 0.3023\tvalid_1's l2: 0.290486\n",
      "[72]\ttraining's l2: 0.30198\tvalid_1's l2: 0.290204\n",
      "[73]\ttraining's l2: 0.301747\tvalid_1's l2: 0.290015\n",
      "[74]\ttraining's l2: 0.301563\tvalid_1's l2: 0.289898\n",
      "[75]\ttraining's l2: 0.3014\tvalid_1's l2: 0.289793\n",
      "[76]\ttraining's l2: 0.301127\tvalid_1's l2: 0.289522\n",
      "[77]\ttraining's l2: 0.30093\tvalid_1's l2: 0.289368\n",
      "[78]\ttraining's l2: 0.300739\tvalid_1's l2: 0.289244\n",
      "[79]\ttraining's l2: 0.300486\tvalid_1's l2: 0.288988\n",
      "[80]\ttraining's l2: 0.300271\tvalid_1's l2: 0.288769\n",
      "[81]\ttraining's l2: 0.300069\tvalid_1's l2: 0.288577\n",
      "[82]\ttraining's l2: 0.299915\tvalid_1's l2: 0.288407\n",
      "[83]\ttraining's l2: 0.299755\tvalid_1's l2: 0.288271\n",
      "[84]\ttraining's l2: 0.29963\tvalid_1's l2: 0.288187\n",
      "[85]\ttraining's l2: 0.299525\tvalid_1's l2: 0.2881\n",
      "[86]\ttraining's l2: 0.299361\tvalid_1's l2: 0.287925\n",
      "[87]\ttraining's l2: 0.299219\tvalid_1's l2: 0.287799\n",
      "[88]\ttraining's l2: 0.299114\tvalid_1's l2: 0.287718\n",
      "[89]\ttraining's l2: 0.298976\tvalid_1's l2: 0.287597\n",
      "[90]\ttraining's l2: 0.298879\tvalid_1's l2: 0.28752\n",
      "[91]\ttraining's l2: 0.298706\tvalid_1's l2: 0.287366\n",
      "[92]\ttraining's l2: 0.298571\tvalid_1's l2: 0.287218\n",
      "[93]\ttraining's l2: 0.298448\tvalid_1's l2: 0.287102\n",
      "[94]\ttraining's l2: 0.298369\tvalid_1's l2: 0.287054\n",
      "[95]\ttraining's l2: 0.29825\tvalid_1's l2: 0.286934\n",
      "[96]\ttraining's l2: 0.298107\tvalid_1's l2: 0.28681\n",
      "[97]\ttraining's l2: 0.298033\tvalid_1's l2: 0.286759\n",
      "[98]\ttraining's l2: 0.297904\tvalid_1's l2: 0.286622\n",
      "[99]\ttraining's l2: 0.297827\tvalid_1's l2: 0.28658\n",
      "[100]\ttraining's l2: 0.297742\tvalid_1's l2: 0.286497\n",
      "[101]\ttraining's l2: 0.297605\tvalid_1's l2: 0.286365\n",
      "[102]\ttraining's l2: 0.297514\tvalid_1's l2: 0.286304\n",
      "[103]\ttraining's l2: 0.297456\tvalid_1's l2: 0.286258\n",
      "[104]\ttraining's l2: 0.297397\tvalid_1's l2: 0.286196\n",
      "[105]\ttraining's l2: 0.297293\tvalid_1's l2: 0.286088\n",
      "[106]\ttraining's l2: 0.297187\tvalid_1's l2: 0.286001\n",
      "[107]\ttraining's l2: 0.297114\tvalid_1's l2: 0.285925\n",
      "[108]\ttraining's l2: 0.297051\tvalid_1's l2: 0.285881\n",
      "[109]\ttraining's l2: 0.296992\tvalid_1's l2: 0.285853\n",
      "[110]\ttraining's l2: 0.296944\tvalid_1's l2: 0.285815\n",
      "[111]\ttraining's l2: 0.296849\tvalid_1's l2: 0.285724\n",
      "[112]\ttraining's l2: 0.296803\tvalid_1's l2: 0.285684\n",
      "[113]\ttraining's l2: 0.296707\tvalid_1's l2: 0.285587\n",
      "[114]\ttraining's l2: 0.29666\tvalid_1's l2: 0.285552\n",
      "[115]\ttraining's l2: 0.29661\tvalid_1's l2: 0.285511\n",
      "[116]\ttraining's l2: 0.296531\tvalid_1's l2: 0.285443\n",
      "[117]\ttraining's l2: 0.296484\tvalid_1's l2: 0.285408\n",
      "[118]\ttraining's l2: 0.296414\tvalid_1's l2: 0.28536\n",
      "[119]\ttraining's l2: 0.29634\tvalid_1's l2: 0.285307\n",
      "[120]\ttraining's l2: 0.296283\tvalid_1's l2: 0.285259\n",
      "[121]\ttraining's l2: 0.296226\tvalid_1's l2: 0.285222\n",
      "[122]\ttraining's l2: 0.296171\tvalid_1's l2: 0.285179\n",
      "[123]\ttraining's l2: 0.296093\tvalid_1's l2: 0.285103\n",
      "[124]\ttraining's l2: 0.296049\tvalid_1's l2: 0.285069\n",
      "[125]\ttraining's l2: 0.295992\tvalid_1's l2: 0.285039\n",
      "[126]\ttraining's l2: 0.295939\tvalid_1's l2: 0.285\n",
      "[127]\ttraining's l2: 0.295889\tvalid_1's l2: 0.284938\n",
      "[128]\ttraining's l2: 0.295816\tvalid_1's l2: 0.284868\n",
      "[129]\ttraining's l2: 0.295732\tvalid_1's l2: 0.284791\n",
      "[130]\ttraining's l2: 0.295673\tvalid_1's l2: 0.284742\n",
      "[131]\ttraining's l2: 0.295596\tvalid_1's l2: 0.284668\n",
      "[132]\ttraining's l2: 0.29554\tvalid_1's l2: 0.284624\n",
      "[133]\ttraining's l2: 0.295497\tvalid_1's l2: 0.284597\n",
      "[134]\ttraining's l2: 0.295455\tvalid_1's l2: 0.284569\n",
      "[135]\ttraining's l2: 0.295409\tvalid_1's l2: 0.284545\n",
      "[136]\ttraining's l2: 0.295367\tvalid_1's l2: 0.284527\n",
      "[137]\ttraining's l2: 0.295316\tvalid_1's l2: 0.284513\n",
      "[138]\ttraining's l2: 0.29527\tvalid_1's l2: 0.284488\n",
      "[139]\ttraining's l2: 0.295233\tvalid_1's l2: 0.284462\n",
      "[140]\ttraining's l2: 0.295202\tvalid_1's l2: 0.284424\n",
      "[141]\ttraining's l2: 0.295137\tvalid_1's l2: 0.284374\n",
      "[142]\ttraining's l2: 0.295095\tvalid_1's l2: 0.284344\n",
      "[143]\ttraining's l2: 0.295044\tvalid_1's l2: 0.284323\n",
      "[144]\ttraining's l2: 0.294978\tvalid_1's l2: 0.28427\n",
      "[145]\ttraining's l2: 0.294937\tvalid_1's l2: 0.28424\n",
      "[146]\ttraining's l2: 0.294901\tvalid_1's l2: 0.284219\n",
      "[147]\ttraining's l2: 0.294864\tvalid_1's l2: 0.284193\n",
      "[148]\ttraining's l2: 0.294826\tvalid_1's l2: 0.284174\n",
      "[149]\ttraining's l2: 0.29479\tvalid_1's l2: 0.284146\n",
      "[150]\ttraining's l2: 0.294738\tvalid_1's l2: 0.28411\n",
      "[151]\ttraining's l2: 0.294686\tvalid_1's l2: 0.28407\n",
      "[152]\ttraining's l2: 0.294647\tvalid_1's l2: 0.284051\n",
      "[153]\ttraining's l2: 0.294609\tvalid_1's l2: 0.284024\n",
      "[154]\ttraining's l2: 0.294586\tvalid_1's l2: 0.283997\n",
      "[155]\ttraining's l2: 0.294535\tvalid_1's l2: 0.283947\n",
      "[156]\ttraining's l2: 0.2945\tvalid_1's l2: 0.283933\n",
      "[157]\ttraining's l2: 0.294458\tvalid_1's l2: 0.283924\n",
      "[158]\ttraining's l2: 0.294423\tvalid_1's l2: 0.283899\n",
      "[159]\ttraining's l2: 0.294378\tvalid_1's l2: 0.283884\n",
      "[160]\ttraining's l2: 0.294346\tvalid_1's l2: 0.283856\n",
      "[161]\ttraining's l2: 0.294312\tvalid_1's l2: 0.283832\n",
      "[162]\ttraining's l2: 0.294286\tvalid_1's l2: 0.283813\n",
      "[163]\ttraining's l2: 0.294248\tvalid_1's l2: 0.283786\n",
      "[164]\ttraining's l2: 0.294205\tvalid_1's l2: 0.283757\n",
      "[165]\ttraining's l2: 0.294182\tvalid_1's l2: 0.283731\n",
      "[166]\ttraining's l2: 0.294158\tvalid_1's l2: 0.283709\n",
      "[167]\ttraining's l2: 0.294123\tvalid_1's l2: 0.283676\n",
      "[168]\ttraining's l2: 0.294088\tvalid_1's l2: 0.283654\n",
      "[169]\ttraining's l2: 0.29405\tvalid_1's l2: 0.283613\n",
      "[170]\ttraining's l2: 0.294007\tvalid_1's l2: 0.283572\n",
      "[171]\ttraining's l2: 0.293978\tvalid_1's l2: 0.283554\n",
      "[172]\ttraining's l2: 0.293947\tvalid_1's l2: 0.283536\n",
      "[173]\ttraining's l2: 0.293912\tvalid_1's l2: 0.283512\n",
      "[174]\ttraining's l2: 0.293884\tvalid_1's l2: 0.283491\n",
      "[175]\ttraining's l2: 0.293864\tvalid_1's l2: 0.28347\n",
      "[176]\ttraining's l2: 0.293834\tvalid_1's l2: 0.283445\n",
      "[177]\ttraining's l2: 0.293803\tvalid_1's l2: 0.283419\n",
      "[178]\ttraining's l2: 0.29376\tvalid_1's l2: 0.283396\n",
      "[179]\ttraining's l2: 0.293734\tvalid_1's l2: 0.283387\n",
      "[180]\ttraining's l2: 0.293711\tvalid_1's l2: 0.28337\n",
      "[181]\ttraining's l2: 0.293683\tvalid_1's l2: 0.283353\n",
      "[182]\ttraining's l2: 0.293641\tvalid_1's l2: 0.283336\n",
      "[183]\ttraining's l2: 0.293618\tvalid_1's l2: 0.283322\n",
      "[184]\ttraining's l2: 0.293591\tvalid_1's l2: 0.283301\n",
      "[185]\ttraining's l2: 0.293551\tvalid_1's l2: 0.283281\n",
      "[186]\ttraining's l2: 0.293527\tvalid_1's l2: 0.283266\n",
      "[187]\ttraining's l2: 0.293502\tvalid_1's l2: 0.283247\n",
      "[188]\ttraining's l2: 0.293474\tvalid_1's l2: 0.283233\n",
      "[189]\ttraining's l2: 0.293452\tvalid_1's l2: 0.283226\n",
      "[190]\ttraining's l2: 0.293427\tvalid_1's l2: 0.283207\n",
      "[191]\ttraining's l2: 0.293395\tvalid_1's l2: 0.283183\n",
      "[192]\ttraining's l2: 0.293363\tvalid_1's l2: 0.283167\n",
      "[193]\ttraining's l2: 0.293336\tvalid_1's l2: 0.283151\n",
      "[194]\ttraining's l2: 0.293306\tvalid_1's l2: 0.28313\n",
      "[195]\ttraining's l2: 0.293282\tvalid_1's l2: 0.283114\n",
      "[196]\ttraining's l2: 0.293265\tvalid_1's l2: 0.283106\n",
      "[197]\ttraining's l2: 0.293243\tvalid_1's l2: 0.283092\n",
      "[198]\ttraining's l2: 0.293219\tvalid_1's l2: 0.283063\n",
      "[199]\ttraining's l2: 0.293196\tvalid_1's l2: 0.283051\n",
      "[200]\ttraining's l2: 0.293163\tvalid_1's l2: 0.283037\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.293163\tvalid_1's l2: 0.283037\n",
      "mean_7_sales: 25854726.64\n",
      "mean_14_sales: 14214487.90\n",
      "lag_1_sales: 1718508.70\n",
      "promo_0: 1255941.93\n",
      "mean_20_dow0_2017: 1188856.67\n",
      "mean_30_sales: 944124.25\n",
      "mean_5_sales: 866843.60\n",
      "mean_4_dow0_2017: 454618.41\n",
      "mean_3_sales: 409206.85\n",
      "mean_63_sales: 340933.26\n",
      "mean_21_sales: 317979.88\n",
      "mean_6_sales: 257874.10\n",
      "sum_7_promo: 243800.79\n",
      "item_class_features: 218261.56\n",
      "lag_2_sales: 209665.89\n",
      "std_14_sales: 139973.16\n",
      "std_7_sales: 132683.88\n",
      "store_cluster_features: 90128.42\n",
      "item_family_features: 85310.65\n",
      "sum_2_promo: 75820.21\n",
      "promo_7: 70065.05\n",
      "sum_4_promo: 60419.25\n",
      "sum_14_promo: 54631.27\n",
      "mean_4_sales: 50900.98\n",
      "mean_4_dow6_2017: 43115.62\n",
      "std_6_sales: 42249.27\n",
      "lag_3_sales: 38524.79\n",
      "lag_28_sales: 36895.04\n",
      "std_21_sales: 29969.34\n",
      "mean_60_sales: 28150.69\n",
      "std_63_sales: 27741.91\n",
      "store_type_features: 26898.99\n",
      "lag_14_sales: 25654.99\n",
      "std_30_sales: 24253.88\n",
      "lag_56_sales: 19564.09\n",
      "std_60_sales: 18723.75\n",
      "sum_21_promo: 16896.78\n",
      "sum_3_promo: 16129.18\n",
      "lag_7_sales: 15083.13\n",
      "std_5_sales: 14097.91\n",
      "std_3_sales: 13927.70\n",
      "store_city_features: 13520.10\n",
      "promo_3: 12210.82\n",
      "mean_4_dow5_2017: 11238.37\n",
      "promo_14: 8036.37\n",
      "std_4_sales: 6679.50\n",
      "sum_5_promo: 6465.48\n",
      "mean_20_dow2_2017: 6375.90\n",
      "promo_1: 6278.70\n",
      "lag_42_sales: 6035.49\n",
      "sum_6_promo: 6016.53\n",
      "mean_20_dow3_2017: 5761.29\n",
      "mean_20_dow1_2017: 5699.25\n",
      "lag_4_sales: 4886.14\n",
      "mean_20_dow4_2017: 4820.72\n",
      "mean_20_dow6_2017: 4815.13\n",
      "lag_6_sales: 4431.02\n",
      "lag_35_sales: 4419.21\n",
      "lag_5_sales: 4376.39\n",
      "mean_4_dow2_2017: 3628.53\n",
      "promo_6: 3608.75\n",
      "promo_5: 3117.61\n",
      "lag_63_sales: 2942.04\n",
      "promo_2: 2677.27\n",
      "promo_15: 1990.87\n",
      "store_state_features: 1937.18\n",
      "promo_4: 1725.62\n",
      "mean_4_dow3_2017: 1513.54\n",
      "promo_13: 1386.80\n",
      "mean_20_dow5_2017: 914.40\n",
      "mean_4_dow1_2017: 910.67\n",
      "promo_10: 861.86\n",
      "promo_8: 846.52\n",
      "promo_9: 815.95\n",
      "mean_4_dow4_2017: 717.01\n",
      "lag_49_sales: 558.97\n",
      "lag_21_sales: 0.00\n",
      "promo_11: 0.00\n",
      "promo_12: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▋         | 1/16 [03:01<45:21, 181.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.963985\tvalid_1's l2: 0.924324\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.904899\tvalid_1's l2: 0.867583\n",
      "[3]\ttraining's l2: 0.851413\tvalid_1's l2: 0.816018\n",
      "[4]\ttraining's l2: 0.802821\tvalid_1's l2: 0.769379\n",
      "[5]\ttraining's l2: 0.758868\tvalid_1's l2: 0.727085\n",
      "[6]\ttraining's l2: 0.719869\tvalid_1's l2: 0.689843\n",
      "[7]\ttraining's l2: 0.683853\tvalid_1's l2: 0.655212\n",
      "[8]\ttraining's l2: 0.651996\tvalid_1's l2: 0.62482\n",
      "[9]\ttraining's l2: 0.622609\tvalid_1's l2: 0.596642\n",
      "[10]\ttraining's l2: 0.595832\tvalid_1's l2: 0.571112\n",
      "[11]\ttraining's l2: 0.571984\tvalid_1's l2: 0.548512\n",
      "[12]\ttraining's l2: 0.550006\tvalid_1's l2: 0.52748\n",
      "[13]\ttraining's l2: 0.530099\tvalid_1's l2: 0.508501\n",
      "[14]\ttraining's l2: 0.512468\tvalid_1's l2: 0.49201\n",
      "[15]\ttraining's l2: 0.496054\tvalid_1's l2: 0.476464\n",
      "[16]\ttraining's l2: 0.481223\tvalid_1's l2: 0.462484\n",
      "[17]\ttraining's l2: 0.467852\tvalid_1's l2: 0.449908\n",
      "[18]\ttraining's l2: 0.455661\tvalid_1's l2: 0.438444\n",
      "[19]\ttraining's l2: 0.444567\tvalid_1's l2: 0.427967\n",
      "[20]\ttraining's l2: 0.434779\tvalid_1's l2: 0.418901\n",
      "[21]\ttraining's l2: 0.425623\tvalid_1's l2: 0.410305\n",
      "[22]\ttraining's l2: 0.417335\tvalid_1's l2: 0.402595\n",
      "[23]\ttraining's l2: 0.410073\tvalid_1's l2: 0.395933\n",
      "[24]\ttraining's l2: 0.403176\tvalid_1's l2: 0.389471\n",
      "[25]\ttraining's l2: 0.396957\tvalid_1's l2: 0.383725\n",
      "[26]\ttraining's l2: 0.391323\tvalid_1's l2: 0.37845\n",
      "[27]\ttraining's l2: 0.386146\tvalid_1's l2: 0.373643\n",
      "[28]\ttraining's l2: 0.381442\tvalid_1's l2: 0.36933\n",
      "[29]\ttraining's l2: 0.377173\tvalid_1's l2: 0.365317\n",
      "[30]\ttraining's l2: 0.373248\tvalid_1's l2: 0.361757\n",
      "[31]\ttraining's l2: 0.369694\tvalid_1's l2: 0.358486\n",
      "[32]\ttraining's l2: 0.366453\tvalid_1's l2: 0.355561\n",
      "[33]\ttraining's l2: 0.363525\tvalid_1's l2: 0.35285\n",
      "[34]\ttraining's l2: 0.360873\tvalid_1's l2: 0.350601\n",
      "[35]\ttraining's l2: 0.358408\tvalid_1's l2: 0.348415\n",
      "[36]\ttraining's l2: 0.356091\tvalid_1's l2: 0.346333\n",
      "[37]\ttraining's l2: 0.354003\tvalid_1's l2: 0.344511\n",
      "[38]\ttraining's l2: 0.35223\tvalid_1's l2: 0.343022\n",
      "[39]\ttraining's l2: 0.350474\tvalid_1's l2: 0.341475\n",
      "[40]\ttraining's l2: 0.34884\tvalid_1's l2: 0.340109\n",
      "[41]\ttraining's l2: 0.347364\tvalid_1's l2: 0.338841\n",
      "[42]\ttraining's l2: 0.346004\tvalid_1's l2: 0.337632\n",
      "[43]\ttraining's l2: 0.344754\tvalid_1's l2: 0.336543\n",
      "[44]\ttraining's l2: 0.343582\tvalid_1's l2: 0.335508\n",
      "[45]\ttraining's l2: 0.342538\tvalid_1's l2: 0.334624\n",
      "[46]\ttraining's l2: 0.341618\tvalid_1's l2: 0.333877\n",
      "[47]\ttraining's l2: 0.340761\tvalid_1's l2: 0.333194\n",
      "[48]\ttraining's l2: 0.339927\tvalid_1's l2: 0.332482\n",
      "[49]\ttraining's l2: 0.339116\tvalid_1's l2: 0.331765\n",
      "[50]\ttraining's l2: 0.338408\tvalid_1's l2: 0.331103\n",
      "[51]\ttraining's l2: 0.337771\tvalid_1's l2: 0.330639\n",
      "[52]\ttraining's l2: 0.337083\tvalid_1's l2: 0.330064\n",
      "[53]\ttraining's l2: 0.336457\tvalid_1's l2: 0.329507\n",
      "[54]\ttraining's l2: 0.335882\tvalid_1's l2: 0.328941\n",
      "[55]\ttraining's l2: 0.335357\tvalid_1's l2: 0.328454\n",
      "[56]\ttraining's l2: 0.334838\tvalid_1's l2: 0.328025\n",
      "[57]\ttraining's l2: 0.334376\tvalid_1's l2: 0.327588\n",
      "[58]\ttraining's l2: 0.333916\tvalid_1's l2: 0.32717\n",
      "[59]\ttraining's l2: 0.333528\tvalid_1's l2: 0.326853\n",
      "[60]\ttraining's l2: 0.333139\tvalid_1's l2: 0.326513\n",
      "[61]\ttraining's l2: 0.332782\tvalid_1's l2: 0.326217\n",
      "[62]\ttraining's l2: 0.332412\tvalid_1's l2: 0.325917\n",
      "[63]\ttraining's l2: 0.332074\tvalid_1's l2: 0.325582\n",
      "[64]\ttraining's l2: 0.331783\tvalid_1's l2: 0.325291\n",
      "[65]\ttraining's l2: 0.331527\tvalid_1's l2: 0.32506\n",
      "[66]\ttraining's l2: 0.331254\tvalid_1's l2: 0.324856\n",
      "[67]\ttraining's l2: 0.331006\tvalid_1's l2: 0.324671\n",
      "[68]\ttraining's l2: 0.330708\tvalid_1's l2: 0.324394\n",
      "[69]\ttraining's l2: 0.330474\tvalid_1's l2: 0.324228\n",
      "[70]\ttraining's l2: 0.330253\tvalid_1's l2: 0.324021\n",
      "[71]\ttraining's l2: 0.33005\tvalid_1's l2: 0.323879\n",
      "[72]\ttraining's l2: 0.329818\tvalid_1's l2: 0.323631\n",
      "[73]\ttraining's l2: 0.329616\tvalid_1's l2: 0.323432\n",
      "[74]\ttraining's l2: 0.329433\tvalid_1's l2: 0.323357\n",
      "[75]\ttraining's l2: 0.32924\tvalid_1's l2: 0.32314\n",
      "[76]\ttraining's l2: 0.32907\tvalid_1's l2: 0.323038\n",
      "[77]\ttraining's l2: 0.328895\tvalid_1's l2: 0.322829\n",
      "[78]\ttraining's l2: 0.328709\tvalid_1's l2: 0.322667\n",
      "[79]\ttraining's l2: 0.328546\tvalid_1's l2: 0.322489\n",
      "[80]\ttraining's l2: 0.328382\tvalid_1's l2: 0.32232\n",
      "[81]\ttraining's l2: 0.328208\tvalid_1's l2: 0.322106\n",
      "[82]\ttraining's l2: 0.32804\tvalid_1's l2: 0.321934\n",
      "[83]\ttraining's l2: 0.327879\tvalid_1's l2: 0.321789\n",
      "[84]\ttraining's l2: 0.327746\tvalid_1's l2: 0.321671\n",
      "[85]\ttraining's l2: 0.327607\tvalid_1's l2: 0.321527\n",
      "[86]\ttraining's l2: 0.327471\tvalid_1's l2: 0.321403\n",
      "[87]\ttraining's l2: 0.32732\tvalid_1's l2: 0.32129\n",
      "[88]\ttraining's l2: 0.327205\tvalid_1's l2: 0.321235\n",
      "[89]\ttraining's l2: 0.32709\tvalid_1's l2: 0.321129\n",
      "[90]\ttraining's l2: 0.326966\tvalid_1's l2: 0.321021\n",
      "[91]\ttraining's l2: 0.326853\tvalid_1's l2: 0.32091\n",
      "[92]\ttraining's l2: 0.326728\tvalid_1's l2: 0.320789\n",
      "[93]\ttraining's l2: 0.32663\tvalid_1's l2: 0.320729\n",
      "[94]\ttraining's l2: 0.326518\tvalid_1's l2: 0.320636\n",
      "[95]\ttraining's l2: 0.326416\tvalid_1's l2: 0.320551\n",
      "[96]\ttraining's l2: 0.326302\tvalid_1's l2: 0.320456\n",
      "[97]\ttraining's l2: 0.326215\tvalid_1's l2: 0.320372\n",
      "[98]\ttraining's l2: 0.32611\tvalid_1's l2: 0.320297\n",
      "[99]\ttraining's l2: 0.326041\tvalid_1's l2: 0.320264\n",
      "[100]\ttraining's l2: 0.325931\tvalid_1's l2: 0.320168\n",
      "[101]\ttraining's l2: 0.325844\tvalid_1's l2: 0.320072\n",
      "[102]\ttraining's l2: 0.325743\tvalid_1's l2: 0.319985\n",
      "[103]\ttraining's l2: 0.325664\tvalid_1's l2: 0.319929\n",
      "[104]\ttraining's l2: 0.325593\tvalid_1's l2: 0.319873\n",
      "[105]\ttraining's l2: 0.325514\tvalid_1's l2: 0.31983\n",
      "[106]\ttraining's l2: 0.325444\tvalid_1's l2: 0.319765\n",
      "[107]\ttraining's l2: 0.325366\tvalid_1's l2: 0.319695\n",
      "[108]\ttraining's l2: 0.325279\tvalid_1's l2: 0.319647\n",
      "[109]\ttraining's l2: 0.325206\tvalid_1's l2: 0.319604\n",
      "[110]\ttraining's l2: 0.325115\tvalid_1's l2: 0.319494\n",
      "[111]\ttraining's l2: 0.32505\tvalid_1's l2: 0.31947\n",
      "[112]\ttraining's l2: 0.324983\tvalid_1's l2: 0.319409\n",
      "[113]\ttraining's l2: 0.324927\tvalid_1's l2: 0.319373\n",
      "[114]\ttraining's l2: 0.324875\tvalid_1's l2: 0.319344\n",
      "[115]\ttraining's l2: 0.324811\tvalid_1's l2: 0.319329\n",
      "[116]\ttraining's l2: 0.324746\tvalid_1's l2: 0.319313\n",
      "[117]\ttraining's l2: 0.324684\tvalid_1's l2: 0.319268\n",
      "[118]\ttraining's l2: 0.324631\tvalid_1's l2: 0.319235\n",
      "[119]\ttraining's l2: 0.324591\tvalid_1's l2: 0.319221\n",
      "[120]\ttraining's l2: 0.324514\tvalid_1's l2: 0.319178\n",
      "[121]\ttraining's l2: 0.324432\tvalid_1's l2: 0.319076\n",
      "[122]\ttraining's l2: 0.324355\tvalid_1's l2: 0.318992\n",
      "[123]\ttraining's l2: 0.32431\tvalid_1's l2: 0.318963\n",
      "[124]\ttraining's l2: 0.324236\tvalid_1's l2: 0.318903\n",
      "[125]\ttraining's l2: 0.324202\tvalid_1's l2: 0.318884\n",
      "[126]\ttraining's l2: 0.324147\tvalid_1's l2: 0.318819\n",
      "[127]\ttraining's l2: 0.324056\tvalid_1's l2: 0.318691\n",
      "[128]\ttraining's l2: 0.323983\tvalid_1's l2: 0.318641\n",
      "[129]\ttraining's l2: 0.323944\tvalid_1's l2: 0.318617\n",
      "[130]\ttraining's l2: 0.323897\tvalid_1's l2: 0.318582\n",
      "[131]\ttraining's l2: 0.323849\tvalid_1's l2: 0.318558\n",
      "[132]\ttraining's l2: 0.323806\tvalid_1's l2: 0.31854\n",
      "[133]\ttraining's l2: 0.323747\tvalid_1's l2: 0.318502\n",
      "[134]\ttraining's l2: 0.323693\tvalid_1's l2: 0.318479\n",
      "[135]\ttraining's l2: 0.323628\tvalid_1's l2: 0.318406\n",
      "[136]\ttraining's l2: 0.323591\tvalid_1's l2: 0.318386\n",
      "[137]\ttraining's l2: 0.323509\tvalid_1's l2: 0.318306\n",
      "[138]\ttraining's l2: 0.323468\tvalid_1's l2: 0.318262\n",
      "[139]\ttraining's l2: 0.323404\tvalid_1's l2: 0.318185\n",
      "[140]\ttraining's l2: 0.323344\tvalid_1's l2: 0.318134\n",
      "[141]\ttraining's l2: 0.32331\tvalid_1's l2: 0.318124\n",
      "[142]\ttraining's l2: 0.323279\tvalid_1's l2: 0.318117\n",
      "[143]\ttraining's l2: 0.32323\tvalid_1's l2: 0.318105\n",
      "[144]\ttraining's l2: 0.323184\tvalid_1's l2: 0.318087\n",
      "[145]\ttraining's l2: 0.32313\tvalid_1's l2: 0.318047\n",
      "[146]\ttraining's l2: 0.3231\tvalid_1's l2: 0.318021\n",
      "[147]\ttraining's l2: 0.323045\tvalid_1's l2: 0.317977\n",
      "[148]\ttraining's l2: 0.323004\tvalid_1's l2: 0.317946\n",
      "[149]\ttraining's l2: 0.322962\tvalid_1's l2: 0.317924\n",
      "[150]\ttraining's l2: 0.322915\tvalid_1's l2: 0.317872\n",
      "[151]\ttraining's l2: 0.322885\tvalid_1's l2: 0.317856\n",
      "[152]\ttraining's l2: 0.322832\tvalid_1's l2: 0.317806\n",
      "[153]\ttraining's l2: 0.322778\tvalid_1's l2: 0.317761\n",
      "[154]\ttraining's l2: 0.32273\tvalid_1's l2: 0.317753\n",
      "[155]\ttraining's l2: 0.322678\tvalid_1's l2: 0.317707\n",
      "[156]\ttraining's l2: 0.322635\tvalid_1's l2: 0.317675\n",
      "[157]\ttraining's l2: 0.322597\tvalid_1's l2: 0.317655\n",
      "[158]\ttraining's l2: 0.32257\tvalid_1's l2: 0.317639\n",
      "[159]\ttraining's l2: 0.322535\tvalid_1's l2: 0.317626\n",
      "[160]\ttraining's l2: 0.322486\tvalid_1's l2: 0.317588\n",
      "[161]\ttraining's l2: 0.322449\tvalid_1's l2: 0.317553\n",
      "[162]\ttraining's l2: 0.32241\tvalid_1's l2: 0.317547\n",
      "[163]\ttraining's l2: 0.322372\tvalid_1's l2: 0.317532\n",
      "[164]\ttraining's l2: 0.322332\tvalid_1's l2: 0.317488\n",
      "[165]\ttraining's l2: 0.322312\tvalid_1's l2: 0.31748\n",
      "[166]\ttraining's l2: 0.322289\tvalid_1's l2: 0.317473\n",
      "[167]\ttraining's l2: 0.322227\tvalid_1's l2: 0.317426\n",
      "[168]\ttraining's l2: 0.322192\tvalid_1's l2: 0.317403\n",
      "[169]\ttraining's l2: 0.322147\tvalid_1's l2: 0.317358\n",
      "[170]\ttraining's l2: 0.3221\tvalid_1's l2: 0.317328\n",
      "[171]\ttraining's l2: 0.322064\tvalid_1's l2: 0.317312\n",
      "[172]\ttraining's l2: 0.322022\tvalid_1's l2: 0.317271\n",
      "[173]\ttraining's l2: 0.321977\tvalid_1's l2: 0.31726\n",
      "[174]\ttraining's l2: 0.321943\tvalid_1's l2: 0.317229\n",
      "[175]\ttraining's l2: 0.321913\tvalid_1's l2: 0.317216\n",
      "[176]\ttraining's l2: 0.321872\tvalid_1's l2: 0.317183\n",
      "[177]\ttraining's l2: 0.321845\tvalid_1's l2: 0.317172\n",
      "[178]\ttraining's l2: 0.321811\tvalid_1's l2: 0.317153\n",
      "[179]\ttraining's l2: 0.321773\tvalid_1's l2: 0.317138\n",
      "[180]\ttraining's l2: 0.321745\tvalid_1's l2: 0.317124\n",
      "[181]\ttraining's l2: 0.321718\tvalid_1's l2: 0.317111\n",
      "[182]\ttraining's l2: 0.321684\tvalid_1's l2: 0.317086\n",
      "[183]\ttraining's l2: 0.321655\tvalid_1's l2: 0.317083\n",
      "[184]\ttraining's l2: 0.321626\tvalid_1's l2: 0.317071\n",
      "[185]\ttraining's l2: 0.321596\tvalid_1's l2: 0.317055\n",
      "[186]\ttraining's l2: 0.321556\tvalid_1's l2: 0.317006\n",
      "[187]\ttraining's l2: 0.321521\tvalid_1's l2: 0.316966\n",
      "[188]\ttraining's l2: 0.321494\tvalid_1's l2: 0.316964\n",
      "[189]\ttraining's l2: 0.32147\tvalid_1's l2: 0.316951\n",
      "[190]\ttraining's l2: 0.321437\tvalid_1's l2: 0.316944\n",
      "[191]\ttraining's l2: 0.321404\tvalid_1's l2: 0.316913\n",
      "[192]\ttraining's l2: 0.321371\tvalid_1's l2: 0.316891\n",
      "[193]\ttraining's l2: 0.32134\tvalid_1's l2: 0.316866\n",
      "[194]\ttraining's l2: 0.321314\tvalid_1's l2: 0.316849\n",
      "[195]\ttraining's l2: 0.321283\tvalid_1's l2: 0.31683\n",
      "[196]\ttraining's l2: 0.321244\tvalid_1's l2: 0.316807\n",
      "[197]\ttraining's l2: 0.321212\tvalid_1's l2: 0.316805\n",
      "[198]\ttraining's l2: 0.321179\tvalid_1's l2: 0.316795\n",
      "[199]\ttraining's l2: 0.321153\tvalid_1's l2: 0.316783\n",
      "[200]\ttraining's l2: 0.321123\tvalid_1's l2: 0.316772\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.321123\tvalid_1's l2: 0.316772\n",
      "mean_7_sales: 14955107.40\n",
      "mean_14_sales: 14670407.71\n",
      "mean_6_sales: 5020484.14\n",
      "mean_30_sales: 1465538.69\n",
      "lag_1_sales: 904779.67\n",
      "mean_20_dow1_2017: 855143.31\n",
      "promo_1: 842800.20\n",
      "mean_63_sales: 558368.30\n",
      "item_class_features: 238337.19\n",
      "std_14_sales: 206738.23\n",
      "mean_21_sales: 172661.19\n",
      "mean_5_sales: 163822.85\n",
      "mean_4_dow1_2017: 128753.15\n",
      "mean_60_sales: 89616.09\n",
      "sum_2_promo: 85313.44\n",
      "sum_4_promo: 81835.26\n",
      "sum_6_promo: 81115.52\n",
      "lag_2_sales: 78927.94\n",
      "mean_3_sales: 70542.77\n",
      "mean_20_dow2_2017: 64910.45\n",
      "promo_0: 53627.03\n",
      "mean_4_sales: 47637.81\n",
      "promo_3: 47633.60\n",
      "lag_3_sales: 45230.36\n",
      "std_6_sales: 37001.68\n",
      "std_7_sales: 33505.77\n",
      "promo_5: 26118.45\n",
      "promo_2: 24973.48\n",
      "std_21_sales: 24262.15\n",
      "sum_7_promo: 22352.63\n",
      "lag_5_sales: 22141.94\n",
      "lag_28_sales: 21934.62\n",
      "std_63_sales: 21858.14\n",
      "store_city_features: 20967.85\n",
      "sum_3_promo: 17893.29\n",
      "std_60_sales: 15989.43\n",
      "std_30_sales: 15475.58\n",
      "item_family_features: 14886.95\n",
      "promo_4: 12209.57\n",
      "store_cluster_features: 11719.99\n",
      "sum_5_promo: 10575.42\n",
      "promo_7: 9526.87\n",
      "sum_14_promo: 9437.67\n",
      "lag_6_sales: 9295.15\n",
      "lag_56_sales: 9079.95\n",
      "std_5_sales: 8842.46\n",
      "promo_6: 8687.97\n",
      "mean_20_dow6_2017: 8192.10\n",
      "mean_20_dow3_2017: 7950.77\n",
      "mean_20_dow4_2017: 7740.18\n",
      "mean_4_dow6_2017: 7689.46\n",
      "mean_20_dow0_2017: 7222.30\n",
      "std_3_sales: 5609.55\n",
      "sum_21_promo: 5031.99\n",
      "mean_4_dow5_2017: 3839.79\n",
      "mean_4_dow2_2017: 3324.96\n",
      "promo_8: 3270.69\n",
      "std_4_sales: 3086.12\n",
      "lag_42_sales: 2862.04\n",
      "promo_14: 2741.35\n",
      "store_state_features: 2465.99\n",
      "mean_4_dow4_2017: 2410.74\n",
      "lag_4_sales: 2097.15\n",
      "mean_4_dow0_2017: 2062.20\n",
      "lag_14_sales: 2057.74\n",
      "store_type_features: 1483.64\n",
      "lag_7_sales: 1398.62\n",
      "mean_20_dow5_2017: 1352.58\n",
      "lag_63_sales: 1217.72\n",
      "promo_9: 817.70\n",
      "mean_4_dow3_2017: 553.00\n",
      "promo_12: 521.95\n",
      "lag_49_sales: 445.17\n",
      "promo_13: 414.35\n",
      "promo_11: 207.57\n",
      "lag_35_sales: 142.36\n",
      "lag_21_sales: 100.01\n",
      "promo_15: 65.93\n",
      "promo_10: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 2/16 [05:56<41:52, 179.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.06495\tvalid_1's l2: 1.05922\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.997637\tvalid_1's l2: 0.992963\n",
      "[3]\ttraining's l2: 0.937403\tvalid_1's l2: 0.933416\n",
      "[4]\ttraining's l2: 0.881598\tvalid_1's l2: 0.87809\n",
      "[5]\ttraining's l2: 0.831347\tvalid_1's l2: 0.8284\n",
      "[6]\ttraining's l2: 0.786764\tvalid_1's l2: 0.78441\n",
      "[7]\ttraining's l2: 0.745374\tvalid_1's l2: 0.743603\n",
      "[8]\ttraining's l2: 0.708008\tvalid_1's l2: 0.70664\n",
      "[9]\ttraining's l2: 0.674084\tvalid_1's l2: 0.673201\n",
      "[10]\ttraining's l2: 0.64388\tvalid_1's l2: 0.643344\n",
      "[11]\ttraining's l2: 0.615754\tvalid_1's l2: 0.615628\n",
      "[12]\ttraining's l2: 0.59038\tvalid_1's l2: 0.590531\n",
      "[13]\ttraining's l2: 0.567346\tvalid_1's l2: 0.56767\n",
      "[14]\ttraining's l2: 0.546358\tvalid_1's l2: 0.546993\n",
      "[15]\ttraining's l2: 0.528005\tvalid_1's l2: 0.528818\n",
      "[16]\ttraining's l2: 0.511419\tvalid_1's l2: 0.512387\n",
      "[17]\ttraining's l2: 0.495879\tvalid_1's l2: 0.496945\n",
      "[18]\ttraining's l2: 0.481621\tvalid_1's l2: 0.482842\n",
      "[19]\ttraining's l2: 0.468631\tvalid_1's l2: 0.469979\n",
      "[20]\ttraining's l2: 0.456916\tvalid_1's l2: 0.458378\n",
      "[21]\ttraining's l2: 0.446748\tvalid_1's l2: 0.448292\n",
      "[22]\ttraining's l2: 0.437156\tvalid_1's l2: 0.43869\n",
      "[23]\ttraining's l2: 0.428405\tvalid_1's l2: 0.430015\n",
      "[24]\ttraining's l2: 0.420342\tvalid_1's l2: 0.422059\n",
      "[25]\ttraining's l2: 0.413411\tvalid_1's l2: 0.415229\n",
      "[26]\ttraining's l2: 0.406766\tvalid_1's l2: 0.408597\n",
      "[27]\ttraining's l2: 0.401035\tvalid_1's l2: 0.402947\n",
      "[28]\ttraining's l2: 0.395481\tvalid_1's l2: 0.397419\n",
      "[29]\ttraining's l2: 0.390799\tvalid_1's l2: 0.392791\n",
      "[30]\ttraining's l2: 0.38646\tvalid_1's l2: 0.388532\n",
      "[31]\ttraining's l2: 0.382157\tvalid_1's l2: 0.38431\n",
      "[32]\ttraining's l2: 0.378244\tvalid_1's l2: 0.38039\n",
      "[33]\ttraining's l2: 0.374652\tvalid_1's l2: 0.37678\n",
      "[34]\ttraining's l2: 0.371408\tvalid_1's l2: 0.373563\n",
      "[35]\ttraining's l2: 0.36847\tvalid_1's l2: 0.370653\n",
      "[36]\ttraining's l2: 0.365774\tvalid_1's l2: 0.367972\n",
      "[37]\ttraining's l2: 0.363267\tvalid_1's l2: 0.365484\n",
      "[38]\ttraining's l2: 0.360965\tvalid_1's l2: 0.363256\n",
      "[39]\ttraining's l2: 0.358867\tvalid_1's l2: 0.361234\n",
      "[40]\ttraining's l2: 0.356958\tvalid_1's l2: 0.359399\n",
      "[41]\ttraining's l2: 0.355183\tvalid_1's l2: 0.357682\n",
      "[42]\ttraining's l2: 0.353577\tvalid_1's l2: 0.35611\n",
      "[43]\ttraining's l2: 0.352184\tvalid_1's l2: 0.354748\n",
      "[44]\ttraining's l2: 0.350776\tvalid_1's l2: 0.353384\n",
      "[45]\ttraining's l2: 0.349402\tvalid_1's l2: 0.35201\n",
      "[46]\ttraining's l2: 0.348152\tvalid_1's l2: 0.350789\n",
      "[47]\ttraining's l2: 0.347146\tvalid_1's l2: 0.349844\n",
      "[48]\ttraining's l2: 0.346175\tvalid_1's l2: 0.348934\n",
      "[49]\ttraining's l2: 0.345176\tvalid_1's l2: 0.347969\n",
      "[50]\ttraining's l2: 0.344225\tvalid_1's l2: 0.347062\n",
      "[51]\ttraining's l2: 0.343372\tvalid_1's l2: 0.346205\n",
      "[52]\ttraining's l2: 0.342519\tvalid_1's l2: 0.345382\n",
      "[53]\ttraining's l2: 0.341733\tvalid_1's l2: 0.344588\n",
      "[54]\ttraining's l2: 0.341117\tvalid_1's l2: 0.343949\n",
      "[55]\ttraining's l2: 0.340493\tvalid_1's l2: 0.343355\n",
      "[56]\ttraining's l2: 0.339933\tvalid_1's l2: 0.342845\n",
      "[57]\ttraining's l2: 0.339378\tvalid_1's l2: 0.342353\n",
      "[58]\ttraining's l2: 0.338881\tvalid_1's l2: 0.34183\n",
      "[59]\ttraining's l2: 0.338367\tvalid_1's l2: 0.341368\n",
      "[60]\ttraining's l2: 0.33795\tvalid_1's l2: 0.341027\n",
      "[61]\ttraining's l2: 0.337462\tvalid_1's l2: 0.34057\n",
      "[62]\ttraining's l2: 0.337018\tvalid_1's l2: 0.340165\n",
      "[63]\ttraining's l2: 0.336683\tvalid_1's l2: 0.339846\n",
      "[64]\ttraining's l2: 0.336365\tvalid_1's l2: 0.339535\n",
      "[65]\ttraining's l2: 0.33589\tvalid_1's l2: 0.339075\n",
      "[66]\ttraining's l2: 0.335504\tvalid_1's l2: 0.338776\n",
      "[67]\ttraining's l2: 0.335161\tvalid_1's l2: 0.338493\n",
      "[68]\ttraining's l2: 0.334855\tvalid_1's l2: 0.338212\n",
      "[69]\ttraining's l2: 0.334479\tvalid_1's l2: 0.337848\n",
      "[70]\ttraining's l2: 0.334143\tvalid_1's l2: 0.337578\n",
      "[71]\ttraining's l2: 0.333808\tvalid_1's l2: 0.337247\n",
      "[72]\ttraining's l2: 0.333503\tvalid_1's l2: 0.33696\n",
      "[73]\ttraining's l2: 0.333282\tvalid_1's l2: 0.336805\n",
      "[74]\ttraining's l2: 0.332976\tvalid_1's l2: 0.336497\n",
      "[75]\ttraining's l2: 0.332736\tvalid_1's l2: 0.336332\n",
      "[76]\ttraining's l2: 0.332433\tvalid_1's l2: 0.336028\n",
      "[77]\ttraining's l2: 0.332177\tvalid_1's l2: 0.335739\n",
      "[78]\ttraining's l2: 0.331913\tvalid_1's l2: 0.335434\n",
      "[79]\ttraining's l2: 0.331684\tvalid_1's l2: 0.335213\n",
      "[80]\ttraining's l2: 0.331492\tvalid_1's l2: 0.335101\n",
      "[81]\ttraining's l2: 0.331288\tvalid_1's l2: 0.334984\n",
      "[82]\ttraining's l2: 0.331108\tvalid_1's l2: 0.334821\n",
      "[83]\ttraining's l2: 0.330919\tvalid_1's l2: 0.334709\n",
      "[84]\ttraining's l2: 0.330768\tvalid_1's l2: 0.334617\n",
      "[85]\ttraining's l2: 0.330565\tvalid_1's l2: 0.334428\n",
      "[86]\ttraining's l2: 0.33039\tvalid_1's l2: 0.334286\n",
      "[87]\ttraining's l2: 0.330246\tvalid_1's l2: 0.334209\n",
      "[88]\ttraining's l2: 0.330111\tvalid_1's l2: 0.334136\n",
      "[89]\ttraining's l2: 0.329938\tvalid_1's l2: 0.33395\n",
      "[90]\ttraining's l2: 0.329775\tvalid_1's l2: 0.333846\n",
      "[91]\ttraining's l2: 0.329661\tvalid_1's l2: 0.333783\n",
      "[92]\ttraining's l2: 0.329515\tvalid_1's l2: 0.333636\n",
      "[93]\ttraining's l2: 0.329351\tvalid_1's l2: 0.333496\n",
      "[94]\ttraining's l2: 0.329213\tvalid_1's l2: 0.333395\n",
      "[95]\ttraining's l2: 0.329105\tvalid_1's l2: 0.333325\n",
      "[96]\ttraining's l2: 0.328967\tvalid_1's l2: 0.333203\n",
      "[97]\ttraining's l2: 0.328842\tvalid_1's l2: 0.333165\n",
      "[98]\ttraining's l2: 0.328727\tvalid_1's l2: 0.333131\n",
      "[99]\ttraining's l2: 0.328625\tvalid_1's l2: 0.333079\n",
      "[100]\ttraining's l2: 0.328456\tvalid_1's l2: 0.33296\n",
      "[101]\ttraining's l2: 0.328359\tvalid_1's l2: 0.332877\n",
      "[102]\ttraining's l2: 0.328214\tvalid_1's l2: 0.332786\n",
      "[103]\ttraining's l2: 0.328098\tvalid_1's l2: 0.332729\n",
      "[104]\ttraining's l2: 0.328016\tvalid_1's l2: 0.332637\n",
      "[105]\ttraining's l2: 0.327875\tvalid_1's l2: 0.33256\n",
      "[106]\ttraining's l2: 0.327782\tvalid_1's l2: 0.332498\n",
      "[107]\ttraining's l2: 0.327686\tvalid_1's l2: 0.332438\n",
      "[108]\ttraining's l2: 0.327591\tvalid_1's l2: 0.332375\n",
      "[109]\ttraining's l2: 0.327511\tvalid_1's l2: 0.332326\n",
      "[110]\ttraining's l2: 0.327419\tvalid_1's l2: 0.332287\n",
      "[111]\ttraining's l2: 0.327322\tvalid_1's l2: 0.332203\n",
      "[112]\ttraining's l2: 0.327228\tvalid_1's l2: 0.332171\n",
      "[113]\ttraining's l2: 0.327143\tvalid_1's l2: 0.332134\n",
      "[114]\ttraining's l2: 0.327071\tvalid_1's l2: 0.332105\n",
      "[115]\ttraining's l2: 0.326995\tvalid_1's l2: 0.332088\n",
      "[116]\ttraining's l2: 0.326905\tvalid_1's l2: 0.332007\n",
      "[117]\ttraining's l2: 0.326804\tvalid_1's l2: 0.331949\n",
      "[118]\ttraining's l2: 0.326691\tvalid_1's l2: 0.331836\n",
      "[119]\ttraining's l2: 0.326626\tvalid_1's l2: 0.331788\n",
      "[120]\ttraining's l2: 0.32653\tvalid_1's l2: 0.331739\n",
      "[121]\ttraining's l2: 0.326457\tvalid_1's l2: 0.331702\n",
      "[122]\ttraining's l2: 0.326387\tvalid_1's l2: 0.331636\n",
      "[123]\ttraining's l2: 0.326307\tvalid_1's l2: 0.331604\n",
      "[124]\ttraining's l2: 0.326221\tvalid_1's l2: 0.331573\n",
      "[125]\ttraining's l2: 0.326143\tvalid_1's l2: 0.331532\n",
      "[126]\ttraining's l2: 0.326082\tvalid_1's l2: 0.331488\n",
      "[127]\ttraining's l2: 0.326026\tvalid_1's l2: 0.331465\n",
      "[128]\ttraining's l2: 0.325967\tvalid_1's l2: 0.331422\n",
      "[129]\ttraining's l2: 0.325901\tvalid_1's l2: 0.331368\n",
      "[130]\ttraining's l2: 0.325841\tvalid_1's l2: 0.331343\n",
      "[131]\ttraining's l2: 0.325799\tvalid_1's l2: 0.3313\n",
      "[132]\ttraining's l2: 0.325747\tvalid_1's l2: 0.33128\n",
      "[133]\ttraining's l2: 0.325696\tvalid_1's l2: 0.331249\n",
      "[134]\ttraining's l2: 0.325641\tvalid_1's l2: 0.331198\n",
      "[135]\ttraining's l2: 0.325574\tvalid_1's l2: 0.331168\n",
      "[136]\ttraining's l2: 0.325524\tvalid_1's l2: 0.331131\n",
      "[137]\ttraining's l2: 0.325464\tvalid_1's l2: 0.331084\n",
      "[138]\ttraining's l2: 0.32541\tvalid_1's l2: 0.331072\n",
      "[139]\ttraining's l2: 0.325364\tvalid_1's l2: 0.331049\n",
      "[140]\ttraining's l2: 0.325298\tvalid_1's l2: 0.330955\n",
      "[141]\ttraining's l2: 0.325233\tvalid_1's l2: 0.330914\n",
      "[142]\ttraining's l2: 0.325163\tvalid_1's l2: 0.330858\n",
      "[143]\ttraining's l2: 0.325117\tvalid_1's l2: 0.330848\n",
      "[144]\ttraining's l2: 0.325049\tvalid_1's l2: 0.330788\n",
      "[145]\ttraining's l2: 0.32499\tvalid_1's l2: 0.33073\n",
      "[146]\ttraining's l2: 0.324953\tvalid_1's l2: 0.330714\n",
      "[147]\ttraining's l2: 0.324898\tvalid_1's l2: 0.330673\n",
      "[148]\ttraining's l2: 0.324858\tvalid_1's l2: 0.330648\n",
      "[149]\ttraining's l2: 0.324792\tvalid_1's l2: 0.330613\n",
      "[150]\ttraining's l2: 0.324729\tvalid_1's l2: 0.330557\n",
      "[151]\ttraining's l2: 0.324685\tvalid_1's l2: 0.330542\n",
      "[152]\ttraining's l2: 0.32465\tvalid_1's l2: 0.330514\n",
      "[153]\ttraining's l2: 0.324605\tvalid_1's l2: 0.3305\n",
      "[154]\ttraining's l2: 0.324559\tvalid_1's l2: 0.33047\n",
      "[155]\ttraining's l2: 0.32452\tvalid_1's l2: 0.330457\n",
      "[156]\ttraining's l2: 0.32448\tvalid_1's l2: 0.330407\n",
      "[157]\ttraining's l2: 0.32443\tvalid_1's l2: 0.330353\n",
      "[158]\ttraining's l2: 0.324402\tvalid_1's l2: 0.330331\n",
      "[159]\ttraining's l2: 0.324346\tvalid_1's l2: 0.330313\n",
      "[160]\ttraining's l2: 0.32431\tvalid_1's l2: 0.330302\n",
      "[161]\ttraining's l2: 0.324276\tvalid_1's l2: 0.330291\n",
      "[162]\ttraining's l2: 0.324246\tvalid_1's l2: 0.330268\n",
      "[163]\ttraining's l2: 0.324207\tvalid_1's l2: 0.330243\n",
      "[164]\ttraining's l2: 0.324168\tvalid_1's l2: 0.330225\n",
      "[165]\ttraining's l2: 0.32413\tvalid_1's l2: 0.330221\n",
      "[166]\ttraining's l2: 0.324101\tvalid_1's l2: 0.330217\n",
      "[167]\ttraining's l2: 0.324054\tvalid_1's l2: 0.330229\n",
      "[168]\ttraining's l2: 0.324024\tvalid_1's l2: 0.330217\n",
      "[169]\ttraining's l2: 0.323979\tvalid_1's l2: 0.330184\n",
      "[170]\ttraining's l2: 0.323924\tvalid_1's l2: 0.330173\n",
      "[171]\ttraining's l2: 0.32388\tvalid_1's l2: 0.330134\n",
      "[172]\ttraining's l2: 0.323829\tvalid_1's l2: 0.330071\n",
      "[173]\ttraining's l2: 0.323793\tvalid_1's l2: 0.330039\n",
      "[174]\ttraining's l2: 0.323749\tvalid_1's l2: 0.330013\n",
      "[175]\ttraining's l2: 0.323719\tvalid_1's l2: 0.329995\n",
      "[176]\ttraining's l2: 0.323683\tvalid_1's l2: 0.329981\n",
      "[177]\ttraining's l2: 0.323647\tvalid_1's l2: 0.329964\n",
      "[178]\ttraining's l2: 0.323615\tvalid_1's l2: 0.329956\n",
      "[179]\ttraining's l2: 0.323577\tvalid_1's l2: 0.329947\n",
      "[180]\ttraining's l2: 0.323549\tvalid_1's l2: 0.329941\n",
      "[181]\ttraining's l2: 0.323509\tvalid_1's l2: 0.329912\n",
      "[182]\ttraining's l2: 0.323462\tvalid_1's l2: 0.32988\n",
      "[183]\ttraining's l2: 0.323422\tvalid_1's l2: 0.329835\n",
      "[184]\ttraining's l2: 0.323387\tvalid_1's l2: 0.329826\n",
      "[185]\ttraining's l2: 0.323353\tvalid_1's l2: 0.329806\n",
      "[186]\ttraining's l2: 0.323316\tvalid_1's l2: 0.329789\n",
      "[187]\ttraining's l2: 0.323281\tvalid_1's l2: 0.329763\n",
      "[188]\ttraining's l2: 0.323247\tvalid_1's l2: 0.329741\n",
      "[189]\ttraining's l2: 0.323221\tvalid_1's l2: 0.329715\n",
      "[190]\ttraining's l2: 0.323183\tvalid_1's l2: 0.329658\n",
      "[191]\ttraining's l2: 0.323156\tvalid_1's l2: 0.329633\n",
      "[192]\ttraining's l2: 0.323114\tvalid_1's l2: 0.329621\n",
      "[193]\ttraining's l2: 0.323068\tvalid_1's l2: 0.329598\n",
      "[194]\ttraining's l2: 0.323036\tvalid_1's l2: 0.329571\n",
      "[195]\ttraining's l2: 0.323007\tvalid_1's l2: 0.329547\n",
      "[196]\ttraining's l2: 0.322969\tvalid_1's l2: 0.329516\n",
      "[197]\ttraining's l2: 0.322932\tvalid_1's l2: 0.329504\n",
      "[198]\ttraining's l2: 0.322887\tvalid_1's l2: 0.329469\n",
      "[199]\ttraining's l2: 0.322855\tvalid_1's l2: 0.329452\n",
      "[200]\ttraining's l2: 0.322825\tvalid_1's l2: 0.32944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.322825\tvalid_1's l2: 0.32944\n",
      "mean_14_sales: 17840082.22\n",
      "mean_7_sales: 15380078.45\n",
      "mean_20_dow2_2017: 2879252.16\n",
      "mean_21_sales: 2423489.76\n",
      "mean_6_sales: 1852297.24\n",
      "mean_30_sales: 1439314.75\n",
      "mean_4_dow2_2017: 1286648.45\n",
      "promo_2: 1203337.79\n",
      "mean_5_sales: 658358.93\n",
      "item_class_features: 501347.14\n",
      "lag_1_sales: 324705.47\n",
      "sum_5_promo: 274219.07\n",
      "std_14_sales: 211327.98\n",
      "lag_5_sales: 169212.86\n",
      "std_21_sales: 112467.59\n",
      "mean_63_sales: 97806.37\n",
      "store_cluster_features: 75312.94\n",
      "item_family_features: 62540.71\n",
      "promo_3: 62310.77\n",
      "mean_3_sales: 54353.34\n",
      "std_7_sales: 51928.61\n",
      "std_63_sales: 50343.96\n",
      "mean_20_dow1_2017: 49499.20\n",
      "mean_4_sales: 48667.44\n",
      "std_6_sales: 38690.27\n",
      "sum_4_promo: 36599.19\n",
      "lag_4_sales: 36019.65\n",
      "lag_3_sales: 34545.35\n",
      "promo_5: 34121.52\n",
      "mean_60_sales: 33706.80\n",
      "promo_7: 30419.31\n",
      "std_30_sales: 30326.87\n",
      "promo_0: 26834.35\n",
      "sum_2_promo: 25914.97\n",
      "lag_28_sales: 25759.83\n",
      "std_60_sales: 23258.50\n",
      "promo_4: 22936.70\n",
      "store_city_features: 22430.44\n",
      "lag_2_sales: 21975.22\n",
      "store_type_features: 20874.26\n",
      "lag_56_sales: 16317.66\n",
      "sum_3_promo: 15257.25\n",
      "sum_6_promo: 14880.03\n",
      "std_5_sales: 14528.90\n",
      "promo_1: 13633.86\n",
      "sum_7_promo: 12766.70\n",
      "sum_14_promo: 12560.03\n",
      "promo_9: 12460.05\n",
      "promo_6: 12097.45\n",
      "mean_20_dow3_2017: 9992.48\n",
      "mean_20_dow0_2017: 9857.69\n",
      "promo_14: 8739.86\n",
      "mean_4_dow0_2017: 6236.18\n",
      "mean_20_dow4_2017: 6136.89\n",
      "mean_4_dow4_2017: 5488.47\n",
      "promo_8: 5192.72\n",
      "lag_6_sales: 4727.68\n",
      "std_4_sales: 4671.16\n",
      "sum_21_promo: 4130.07\n",
      "store_state_features: 3942.07\n",
      "mean_20_dow5_2017: 3732.07\n",
      "lag_63_sales: 3706.45\n",
      "std_3_sales: 3023.02\n",
      "mean_4_dow1_2017: 2775.24\n",
      "mean_4_dow3_2017: 2049.25\n",
      "lag_7_sales: 1740.54\n",
      "lag_14_sales: 1046.40\n",
      "mean_4_dow6_2017: 1038.15\n",
      "mean_20_dow6_2017: 913.66\n",
      "promo_13: 887.81\n",
      "promo_10: 776.75\n",
      "promo_12: 746.60\n",
      "lag_42_sales: 660.64\n",
      "promo_15: 540.35\n",
      "mean_4_dow5_2017: 483.32\n",
      "lag_49_sales: 384.64\n",
      "lag_21_sales: 303.21\n",
      "lag_35_sales: 274.76\n",
      "promo_11: 167.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 3/16 [08:54<38:46, 178.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.19083\tvalid_1's l2: 1.1592\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.11268\tvalid_1's l2: 1.08289\n",
      "[3]\ttraining's l2: 1.04277\tvalid_1's l2: 1.01486\n",
      "[4]\ttraining's l2: 0.978612\tvalid_1's l2: 0.95228\n",
      "[5]\ttraining's l2: 0.920892\tvalid_1's l2: 0.895918\n",
      "[6]\ttraining's l2: 0.868428\tvalid_1's l2: 0.844799\n",
      "[7]\ttraining's l2: 0.821413\tvalid_1's l2: 0.799172\n",
      "[8]\ttraining's l2: 0.779019\tvalid_1's l2: 0.757998\n",
      "[9]\ttraining's l2: 0.740127\tvalid_1's l2: 0.720127\n",
      "[10]\ttraining's l2: 0.704699\tvalid_1's l2: 0.68574\n",
      "[11]\ttraining's l2: 0.67276\tvalid_1's l2: 0.654733\n",
      "[12]\ttraining's l2: 0.643769\tvalid_1's l2: 0.626598\n",
      "[13]\ttraining's l2: 0.617532\tvalid_1's l2: 0.601157\n",
      "[14]\ttraining's l2: 0.593692\tvalid_1's l2: 0.578034\n",
      "[15]\ttraining's l2: 0.572111\tvalid_1's l2: 0.557142\n",
      "[16]\ttraining's l2: 0.552602\tvalid_1's l2: 0.538228\n",
      "[17]\ttraining's l2: 0.535085\tvalid_1's l2: 0.521352\n",
      "[18]\ttraining's l2: 0.518964\tvalid_1's l2: 0.505757\n",
      "[19]\ttraining's l2: 0.504421\tvalid_1's l2: 0.4917\n",
      "[20]\ttraining's l2: 0.491265\tvalid_1's l2: 0.479011\n",
      "[21]\ttraining's l2: 0.479489\tvalid_1's l2: 0.467693\n",
      "[22]\ttraining's l2: 0.46888\tvalid_1's l2: 0.45756\n",
      "[23]\ttraining's l2: 0.458929\tvalid_1's l2: 0.447976\n",
      "[24]\ttraining's l2: 0.449983\tvalid_1's l2: 0.439344\n",
      "[25]\ttraining's l2: 0.441755\tvalid_1's l2: 0.431389\n",
      "[26]\ttraining's l2: 0.434493\tvalid_1's l2: 0.424491\n",
      "[27]\ttraining's l2: 0.427717\tvalid_1's l2: 0.418044\n",
      "[28]\ttraining's l2: 0.421603\tvalid_1's l2: 0.412138\n",
      "[29]\ttraining's l2: 0.416188\tvalid_1's l2: 0.407022\n",
      "[30]\ttraining's l2: 0.411107\tvalid_1's l2: 0.402089\n",
      "[31]\ttraining's l2: 0.406585\tvalid_1's l2: 0.397746\n",
      "[32]\ttraining's l2: 0.402521\tvalid_1's l2: 0.393949\n",
      "[33]\ttraining's l2: 0.398674\tvalid_1's l2: 0.390291\n",
      "[34]\ttraining's l2: 0.395332\tvalid_1's l2: 0.387245\n",
      "[35]\ttraining's l2: 0.392134\tvalid_1's l2: 0.384189\n",
      "[36]\ttraining's l2: 0.389239\tvalid_1's l2: 0.381438\n",
      "[37]\ttraining's l2: 0.386696\tvalid_1's l2: 0.379086\n",
      "[38]\ttraining's l2: 0.384204\tvalid_1's l2: 0.376714\n",
      "[39]\ttraining's l2: 0.382095\tvalid_1's l2: 0.374763\n",
      "[40]\ttraining's l2: 0.380136\tvalid_1's l2: 0.372969\n",
      "[41]\ttraining's l2: 0.378196\tvalid_1's l2: 0.371113\n",
      "[42]\ttraining's l2: 0.376498\tvalid_1's l2: 0.369517\n",
      "[43]\ttraining's l2: 0.375038\tvalid_1's l2: 0.368229\n",
      "[44]\ttraining's l2: 0.373543\tvalid_1's l2: 0.366784\n",
      "[45]\ttraining's l2: 0.372153\tvalid_1's l2: 0.365424\n",
      "[46]\ttraining's l2: 0.370912\tvalid_1's l2: 0.364239\n",
      "[47]\ttraining's l2: 0.369756\tvalid_1's l2: 0.363156\n",
      "[48]\ttraining's l2: 0.36877\tvalid_1's l2: 0.362333\n",
      "[49]\ttraining's l2: 0.367771\tvalid_1's l2: 0.361395\n",
      "[50]\ttraining's l2: 0.366852\tvalid_1's l2: 0.360576\n",
      "[51]\ttraining's l2: 0.365963\tvalid_1's l2: 0.359712\n",
      "[52]\ttraining's l2: 0.365196\tvalid_1's l2: 0.359009\n",
      "[53]\ttraining's l2: 0.364444\tvalid_1's l2: 0.358345\n",
      "[54]\ttraining's l2: 0.363747\tvalid_1's l2: 0.357714\n",
      "[55]\ttraining's l2: 0.363128\tvalid_1's l2: 0.357139\n",
      "[56]\ttraining's l2: 0.362516\tvalid_1's l2: 0.356605\n",
      "[57]\ttraining's l2: 0.361951\tvalid_1's l2: 0.356089\n",
      "[58]\ttraining's l2: 0.361447\tvalid_1's l2: 0.355596\n",
      "[59]\ttraining's l2: 0.360966\tvalid_1's l2: 0.35523\n",
      "[60]\ttraining's l2: 0.360486\tvalid_1's l2: 0.354797\n",
      "[61]\ttraining's l2: 0.360031\tvalid_1's l2: 0.354449\n",
      "[62]\ttraining's l2: 0.359605\tvalid_1's l2: 0.354089\n",
      "[63]\ttraining's l2: 0.359206\tvalid_1's l2: 0.353694\n",
      "[64]\ttraining's l2: 0.358848\tvalid_1's l2: 0.353408\n",
      "[65]\ttraining's l2: 0.358491\tvalid_1's l2: 0.353103\n",
      "[66]\ttraining's l2: 0.358167\tvalid_1's l2: 0.35285\n",
      "[67]\ttraining's l2: 0.357856\tvalid_1's l2: 0.352647\n",
      "[68]\ttraining's l2: 0.357528\tvalid_1's l2: 0.352298\n",
      "[69]\ttraining's l2: 0.357262\tvalid_1's l2: 0.352102\n",
      "[70]\ttraining's l2: 0.356948\tvalid_1's l2: 0.351884\n",
      "[71]\ttraining's l2: 0.356679\tvalid_1's l2: 0.35165\n",
      "[72]\ttraining's l2: 0.356385\tvalid_1's l2: 0.35137\n",
      "[73]\ttraining's l2: 0.356117\tvalid_1's l2: 0.351119\n",
      "[74]\ttraining's l2: 0.355859\tvalid_1's l2: 0.350881\n",
      "[75]\ttraining's l2: 0.355662\tvalid_1's l2: 0.350765\n",
      "[76]\ttraining's l2: 0.355422\tvalid_1's l2: 0.350608\n",
      "[77]\ttraining's l2: 0.355235\tvalid_1's l2: 0.350449\n",
      "[78]\ttraining's l2: 0.355004\tvalid_1's l2: 0.35029\n",
      "[79]\ttraining's l2: 0.354799\tvalid_1's l2: 0.350172\n",
      "[80]\ttraining's l2: 0.354602\tvalid_1's l2: 0.350009\n",
      "[81]\ttraining's l2: 0.3544\tvalid_1's l2: 0.349788\n",
      "[82]\ttraining's l2: 0.354248\tvalid_1's l2: 0.349701\n",
      "[83]\ttraining's l2: 0.354075\tvalid_1's l2: 0.349595\n",
      "[84]\ttraining's l2: 0.353897\tvalid_1's l2: 0.349393\n",
      "[85]\ttraining's l2: 0.353733\tvalid_1's l2: 0.3493\n",
      "[86]\ttraining's l2: 0.353545\tvalid_1's l2: 0.349117\n",
      "[87]\ttraining's l2: 0.35339\tvalid_1's l2: 0.349001\n",
      "[88]\ttraining's l2: 0.353213\tvalid_1's l2: 0.348828\n",
      "[89]\ttraining's l2: 0.353062\tvalid_1's l2: 0.348688\n",
      "[90]\ttraining's l2: 0.352871\tvalid_1's l2: 0.348523\n",
      "[91]\ttraining's l2: 0.352708\tvalid_1's l2: 0.34842\n",
      "[92]\ttraining's l2: 0.352578\tvalid_1's l2: 0.348318\n",
      "[93]\ttraining's l2: 0.352454\tvalid_1's l2: 0.348194\n",
      "[94]\ttraining's l2: 0.352341\tvalid_1's l2: 0.348156\n",
      "[95]\ttraining's l2: 0.352184\tvalid_1's l2: 0.348032\n",
      "[96]\ttraining's l2: 0.352077\tvalid_1's l2: 0.34797\n",
      "[97]\ttraining's l2: 0.351947\tvalid_1's l2: 0.347856\n",
      "[98]\ttraining's l2: 0.351843\tvalid_1's l2: 0.347803\n",
      "[99]\ttraining's l2: 0.351715\tvalid_1's l2: 0.347744\n",
      "[100]\ttraining's l2: 0.35162\tvalid_1's l2: 0.34768\n",
      "[101]\ttraining's l2: 0.351434\tvalid_1's l2: 0.34745\n",
      "[102]\ttraining's l2: 0.351338\tvalid_1's l2: 0.347394\n",
      "[103]\ttraining's l2: 0.351239\tvalid_1's l2: 0.347322\n",
      "[104]\ttraining's l2: 0.351126\tvalid_1's l2: 0.347225\n",
      "[105]\ttraining's l2: 0.350967\tvalid_1's l2: 0.347022\n",
      "[106]\ttraining's l2: 0.350847\tvalid_1's l2: 0.346944\n",
      "[107]\ttraining's l2: 0.350759\tvalid_1's l2: 0.346867\n",
      "[108]\ttraining's l2: 0.350682\tvalid_1's l2: 0.346835\n",
      "[109]\ttraining's l2: 0.350578\tvalid_1's l2: 0.346754\n",
      "[110]\ttraining's l2: 0.350445\tvalid_1's l2: 0.34661\n",
      "[111]\ttraining's l2: 0.350375\tvalid_1's l2: 0.346559\n",
      "[112]\ttraining's l2: 0.35024\tvalid_1's l2: 0.34638\n",
      "[113]\ttraining's l2: 0.350096\tvalid_1's l2: 0.346241\n",
      "[114]\ttraining's l2: 0.350013\tvalid_1's l2: 0.346183\n",
      "[115]\ttraining's l2: 0.349931\tvalid_1's l2: 0.346159\n",
      "[116]\ttraining's l2: 0.349857\tvalid_1's l2: 0.346088\n",
      "[117]\ttraining's l2: 0.349774\tvalid_1's l2: 0.345991\n",
      "[118]\ttraining's l2: 0.349721\tvalid_1's l2: 0.345951\n",
      "[119]\ttraining's l2: 0.34963\tvalid_1's l2: 0.345907\n",
      "[120]\ttraining's l2: 0.349574\tvalid_1's l2: 0.345889\n",
      "[121]\ttraining's l2: 0.349502\tvalid_1's l2: 0.345791\n",
      "[122]\ttraining's l2: 0.349434\tvalid_1's l2: 0.345737\n",
      "[123]\ttraining's l2: 0.349325\tvalid_1's l2: 0.345652\n",
      "[124]\ttraining's l2: 0.349226\tvalid_1's l2: 0.345579\n",
      "[125]\ttraining's l2: 0.34916\tvalid_1's l2: 0.345544\n",
      "[126]\ttraining's l2: 0.349062\tvalid_1's l2: 0.345424\n",
      "[127]\ttraining's l2: 0.348981\tvalid_1's l2: 0.345379\n",
      "[128]\ttraining's l2: 0.348919\tvalid_1's l2: 0.345359\n",
      "[129]\ttraining's l2: 0.348854\tvalid_1's l2: 0.345299\n",
      "[130]\ttraining's l2: 0.348798\tvalid_1's l2: 0.345266\n",
      "[131]\ttraining's l2: 0.348724\tvalid_1's l2: 0.34523\n",
      "[132]\ttraining's l2: 0.348649\tvalid_1's l2: 0.34519\n",
      "[133]\ttraining's l2: 0.348594\tvalid_1's l2: 0.345161\n",
      "[134]\ttraining's l2: 0.348548\tvalid_1's l2: 0.345139\n",
      "[135]\ttraining's l2: 0.348439\tvalid_1's l2: 0.345001\n",
      "[136]\ttraining's l2: 0.348351\tvalid_1's l2: 0.344915\n",
      "[137]\ttraining's l2: 0.34826\tvalid_1's l2: 0.344806\n",
      "[138]\ttraining's l2: 0.348183\tvalid_1's l2: 0.344734\n",
      "[139]\ttraining's l2: 0.348154\tvalid_1's l2: 0.344709\n",
      "[140]\ttraining's l2: 0.348104\tvalid_1's l2: 0.344686\n",
      "[141]\ttraining's l2: 0.348059\tvalid_1's l2: 0.344638\n",
      "[142]\ttraining's l2: 0.348011\tvalid_1's l2: 0.344607\n",
      "[143]\ttraining's l2: 0.347947\tvalid_1's l2: 0.344583\n",
      "[144]\ttraining's l2: 0.34789\tvalid_1's l2: 0.344575\n",
      "[145]\ttraining's l2: 0.347854\tvalid_1's l2: 0.344548\n",
      "[146]\ttraining's l2: 0.347775\tvalid_1's l2: 0.344481\n",
      "[147]\ttraining's l2: 0.347746\tvalid_1's l2: 0.344473\n",
      "[148]\ttraining's l2: 0.347681\tvalid_1's l2: 0.344445\n",
      "[149]\ttraining's l2: 0.347608\tvalid_1's l2: 0.344383\n",
      "[150]\ttraining's l2: 0.347547\tvalid_1's l2: 0.344319\n",
      "[151]\ttraining's l2: 0.34749\tvalid_1's l2: 0.344256\n",
      "[152]\ttraining's l2: 0.347442\tvalid_1's l2: 0.344236\n",
      "[153]\ttraining's l2: 0.347396\tvalid_1's l2: 0.344225\n",
      "[154]\ttraining's l2: 0.347342\tvalid_1's l2: 0.344192\n",
      "[155]\ttraining's l2: 0.347311\tvalid_1's l2: 0.344186\n",
      "[156]\ttraining's l2: 0.347239\tvalid_1's l2: 0.344097\n",
      "[157]\ttraining's l2: 0.347163\tvalid_1's l2: 0.344024\n",
      "[158]\ttraining's l2: 0.347084\tvalid_1's l2: 0.343974\n",
      "[159]\ttraining's l2: 0.347007\tvalid_1's l2: 0.34391\n",
      "[160]\ttraining's l2: 0.346958\tvalid_1's l2: 0.343897\n",
      "[161]\ttraining's l2: 0.346915\tvalid_1's l2: 0.343876\n",
      "[162]\ttraining's l2: 0.346881\tvalid_1's l2: 0.343862\n",
      "[163]\ttraining's l2: 0.346835\tvalid_1's l2: 0.343842\n",
      "[164]\ttraining's l2: 0.346793\tvalid_1's l2: 0.343828\n",
      "[165]\ttraining's l2: 0.34674\tvalid_1's l2: 0.343804\n",
      "[166]\ttraining's l2: 0.346713\tvalid_1's l2: 0.343774\n",
      "[167]\ttraining's l2: 0.346663\tvalid_1's l2: 0.343724\n",
      "[168]\ttraining's l2: 0.346612\tvalid_1's l2: 0.343691\n",
      "[169]\ttraining's l2: 0.346586\tvalid_1's l2: 0.343669\n",
      "[170]\ttraining's l2: 0.346531\tvalid_1's l2: 0.34362\n",
      "[171]\ttraining's l2: 0.346495\tvalid_1's l2: 0.343614\n",
      "[172]\ttraining's l2: 0.346458\tvalid_1's l2: 0.343602\n",
      "[173]\ttraining's l2: 0.346416\tvalid_1's l2: 0.343571\n",
      "[174]\ttraining's l2: 0.346381\tvalid_1's l2: 0.343541\n",
      "[175]\ttraining's l2: 0.346338\tvalid_1's l2: 0.343516\n",
      "[176]\ttraining's l2: 0.346318\tvalid_1's l2: 0.343485\n",
      "[177]\ttraining's l2: 0.346293\tvalid_1's l2: 0.343476\n",
      "[178]\ttraining's l2: 0.346242\tvalid_1's l2: 0.343451\n",
      "[179]\ttraining's l2: 0.346193\tvalid_1's l2: 0.34344\n",
      "[180]\ttraining's l2: 0.346169\tvalid_1's l2: 0.343423\n",
      "[181]\ttraining's l2: 0.346119\tvalid_1's l2: 0.343379\n",
      "[182]\ttraining's l2: 0.346075\tvalid_1's l2: 0.343362\n",
      "[183]\ttraining's l2: 0.346036\tvalid_1's l2: 0.343341\n",
      "[184]\ttraining's l2: 0.345989\tvalid_1's l2: 0.343319\n",
      "[185]\ttraining's l2: 0.345964\tvalid_1's l2: 0.343285\n",
      "[186]\ttraining's l2: 0.345923\tvalid_1's l2: 0.343257\n",
      "[187]\ttraining's l2: 0.345873\tvalid_1's l2: 0.343241\n",
      "[188]\ttraining's l2: 0.345832\tvalid_1's l2: 0.343217\n",
      "[189]\ttraining's l2: 0.345784\tvalid_1's l2: 0.343207\n",
      "[190]\ttraining's l2: 0.345755\tvalid_1's l2: 0.343178\n",
      "[191]\ttraining's l2: 0.345696\tvalid_1's l2: 0.343096\n",
      "[192]\ttraining's l2: 0.345659\tvalid_1's l2: 0.343076\n",
      "[193]\ttraining's l2: 0.345612\tvalid_1's l2: 0.343039\n",
      "[194]\ttraining's l2: 0.345577\tvalid_1's l2: 0.343012\n",
      "[195]\ttraining's l2: 0.34555\tvalid_1's l2: 0.343001\n",
      "[196]\ttraining's l2: 0.345515\tvalid_1's l2: 0.342991\n",
      "[197]\ttraining's l2: 0.345482\tvalid_1's l2: 0.34297\n",
      "[198]\ttraining's l2: 0.345428\tvalid_1's l2: 0.342914\n",
      "[199]\ttraining's l2: 0.345394\tvalid_1's l2: 0.342875\n",
      "[200]\ttraining's l2: 0.345361\tvalid_1's l2: 0.342852\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.345361\tvalid_1's l2: 0.342852\n",
      "mean_14_sales: 20494359.68\n",
      "mean_6_sales: 8597046.97\n",
      "mean_5_sales: 6390123.85\n",
      "mean_21_sales: 4838410.88\n",
      "mean_7_sales: 4635140.71\n",
      "mean_20_dow3_2017: 2259666.03\n",
      "mean_30_sales: 1836632.08\n",
      "mean_4_dow3_2017: 1408277.42\n",
      "promo_3: 831767.21\n",
      "mean_60_sales: 652680.91\n",
      "mean_4_sales: 589821.79\n",
      "item_class_features: 291380.94\n",
      "std_14_sales: 271982.15\n",
      "sum_4_promo: 180415.19\n",
      "std_21_sales: 87736.39\n",
      "lag_1_sales: 79814.69\n",
      "lag_4_sales: 78604.95\n",
      "store_cluster_features: 61365.94\n",
      "sum_2_promo: 55037.66\n",
      "promo_7: 55003.30\n",
      "mean_3_sales: 54669.32\n",
      "mean_63_sales: 50540.04\n",
      "std_7_sales: 50066.17\n",
      "promo_5: 49861.87\n",
      "store_city_features: 36887.21\n",
      "promo_2: 35853.53\n",
      "std_6_sales: 35448.22\n",
      "std_30_sales: 34500.40\n",
      "std_5_sales: 32308.05\n",
      "promo_6: 31042.07\n",
      "promo_1: 26672.94\n",
      "promo_4: 26176.14\n",
      "item_family_features: 25887.30\n",
      "sum_3_promo: 25747.96\n",
      "lag_3_sales: 22478.57\n",
      "promo_0: 19166.45\n",
      "std_60_sales: 18905.00\n",
      "sum_6_promo: 18241.74\n",
      "sum_5_promo: 17982.21\n",
      "std_63_sales: 16141.73\n",
      "sum_14_promo: 16004.13\n",
      "mean_20_dow0_2017: 15904.71\n",
      "lag_28_sales: 12790.53\n",
      "std_4_sales: 11473.80\n",
      "sum_7_promo: 10751.60\n",
      "mean_20_dow2_2017: 10682.78\n",
      "promo_14: 9257.33\n",
      "promo_10: 7715.64\n",
      "sum_21_promo: 6641.06\n",
      "std_3_sales: 6452.26\n",
      "lag_56_sales: 5556.47\n",
      "mean_4_dow4_2017: 5364.64\n",
      "store_state_features: 5163.71\n",
      "mean_20_dow4_2017: 4925.49\n",
      "mean_20_dow1_2017: 4885.90\n",
      "lag_2_sales: 4863.86\n",
      "lag_5_sales: 4651.11\n",
      "mean_20_dow5_2017: 4547.53\n",
      "lag_6_sales: 3921.46\n",
      "store_type_features: 3905.57\n",
      "mean_4_dow0_2017: 3763.84\n",
      "mean_4_dow1_2017: 3433.48\n",
      "promo_8: 3416.39\n",
      "promo_9: 3409.89\n",
      "mean_20_dow6_2017: 2931.18\n",
      "lag_63_sales: 1876.76\n",
      "mean_4_dow2_2017: 1871.13\n",
      "lag_7_sales: 723.21\n",
      "mean_4_dow6_2017: 681.54\n",
      "lag_42_sales: 610.13\n",
      "promo_13: 450.51\n",
      "lag_35_sales: 366.28\n",
      "mean_4_dow5_2017: 360.65\n",
      "lag_21_sales: 338.31\n",
      "lag_14_sales: 273.20\n",
      "promo_12: 263.82\n",
      "promo_15: 203.92\n",
      "promo_11: 163.65\n",
      "lag_49_sales: 40.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 4/16 [11:46<35:22, 176.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.25989\tvalid_1's l2: 1.22665\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.18302\tvalid_1's l2: 1.14649\n",
      "[3]\ttraining's l2: 1.11356\tvalid_1's l2: 1.0745\n",
      "[4]\ttraining's l2: 1.05066\tvalid_1's l2: 1.00944\n",
      "[5]\ttraining's l2: 0.993584\tvalid_1's l2: 0.950367\n",
      "[6]\ttraining's l2: 0.94205\tvalid_1's l2: 0.897255\n",
      "[7]\ttraining's l2: 0.895606\tvalid_1's l2: 0.849226\n",
      "[8]\ttraining's l2: 0.853036\tvalid_1's l2: 0.804999\n",
      "[9]\ttraining's l2: 0.81413\tvalid_1's l2: 0.764526\n",
      "[10]\ttraining's l2: 0.778617\tvalid_1's l2: 0.72812\n",
      "[11]\ttraining's l2: 0.746513\tvalid_1's l2: 0.6953\n",
      "[12]\ttraining's l2: 0.717843\tvalid_1's l2: 0.666183\n",
      "[13]\ttraining's l2: 0.691692\tvalid_1's l2: 0.639115\n",
      "[14]\ttraining's l2: 0.667421\tvalid_1's l2: 0.614503\n",
      "[15]\ttraining's l2: 0.645971\tvalid_1's l2: 0.592741\n",
      "[16]\ttraining's l2: 0.626566\tvalid_1's l2: 0.57302\n",
      "[17]\ttraining's l2: 0.608891\tvalid_1's l2: 0.55496\n",
      "[18]\ttraining's l2: 0.592348\tvalid_1's l2: 0.538285\n",
      "[19]\ttraining's l2: 0.577307\tvalid_1's l2: 0.522969\n",
      "[20]\ttraining's l2: 0.564234\tvalid_1's l2: 0.50932\n",
      "[21]\ttraining's l2: 0.552368\tvalid_1's l2: 0.49721\n",
      "[22]\ttraining's l2: 0.540859\tvalid_1's l2: 0.485523\n",
      "[23]\ttraining's l2: 0.530559\tvalid_1's l2: 0.474879\n",
      "[24]\ttraining's l2: 0.52085\tvalid_1's l2: 0.465234\n",
      "[25]\ttraining's l2: 0.51257\tvalid_1's l2: 0.456884\n",
      "[26]\ttraining's l2: 0.504616\tvalid_1's l2: 0.448787\n",
      "[27]\ttraining's l2: 0.497798\tvalid_1's l2: 0.441766\n",
      "[28]\ttraining's l2: 0.491091\tvalid_1's l2: 0.435068\n",
      "[29]\ttraining's l2: 0.484952\tvalid_1's l2: 0.42901\n",
      "[30]\ttraining's l2: 0.47985\tvalid_1's l2: 0.423898\n",
      "[31]\ttraining's l2: 0.474727\tvalid_1's l2: 0.418687\n",
      "[32]\ttraining's l2: 0.469957\tvalid_1's l2: 0.414119\n",
      "[33]\ttraining's l2: 0.466155\tvalid_1's l2: 0.409994\n",
      "[34]\ttraining's l2: 0.462093\tvalid_1's l2: 0.405831\n",
      "[35]\ttraining's l2: 0.458369\tvalid_1's l2: 0.402065\n",
      "[36]\ttraining's l2: 0.454964\tvalid_1's l2: 0.398692\n",
      "[37]\ttraining's l2: 0.451923\tvalid_1's l2: 0.395435\n",
      "[38]\ttraining's l2: 0.44906\tvalid_1's l2: 0.392677\n",
      "[39]\ttraining's l2: 0.446621\tvalid_1's l2: 0.390333\n",
      "[40]\ttraining's l2: 0.444172\tvalid_1's l2: 0.387838\n",
      "[41]\ttraining's l2: 0.442179\tvalid_1's l2: 0.385889\n",
      "[42]\ttraining's l2: 0.440012\tvalid_1's l2: 0.38369\n",
      "[43]\ttraining's l2: 0.438032\tvalid_1's l2: 0.381871\n",
      "[44]\ttraining's l2: 0.436265\tvalid_1's l2: 0.380107\n",
      "[45]\ttraining's l2: 0.434657\tvalid_1's l2: 0.378539\n",
      "[46]\ttraining's l2: 0.433318\tvalid_1's l2: 0.377295\n",
      "[47]\ttraining's l2: 0.432061\tvalid_1's l2: 0.376189\n",
      "[48]\ttraining's l2: 0.430708\tvalid_1's l2: 0.374786\n",
      "[49]\ttraining's l2: 0.429435\tvalid_1's l2: 0.373615\n",
      "[50]\ttraining's l2: 0.428441\tvalid_1's l2: 0.372759\n",
      "[51]\ttraining's l2: 0.427336\tvalid_1's l2: 0.371653\n",
      "[52]\ttraining's l2: 0.426318\tvalid_1's l2: 0.370745\n",
      "[53]\ttraining's l2: 0.425333\tvalid_1's l2: 0.369931\n",
      "[54]\ttraining's l2: 0.424519\tvalid_1's l2: 0.369094\n",
      "[55]\ttraining's l2: 0.423776\tvalid_1's l2: 0.368445\n",
      "[56]\ttraining's l2: 0.423136\tvalid_1's l2: 0.367895\n",
      "[57]\ttraining's l2: 0.422312\tvalid_1's l2: 0.367187\n",
      "[58]\ttraining's l2: 0.421624\tvalid_1's l2: 0.366515\n",
      "[59]\ttraining's l2: 0.420932\tvalid_1's l2: 0.36602\n",
      "[60]\ttraining's l2: 0.420309\tvalid_1's l2: 0.365442\n",
      "[61]\ttraining's l2: 0.419711\tvalid_1's l2: 0.364822\n",
      "[62]\ttraining's l2: 0.419259\tvalid_1's l2: 0.364486\n",
      "[63]\ttraining's l2: 0.418772\tvalid_1's l2: 0.36412\n",
      "[64]\ttraining's l2: 0.418377\tvalid_1's l2: 0.363712\n",
      "[65]\ttraining's l2: 0.417777\tvalid_1's l2: 0.363152\n",
      "[66]\ttraining's l2: 0.417381\tvalid_1's l2: 0.362861\n",
      "[67]\ttraining's l2: 0.416972\tvalid_1's l2: 0.362626\n",
      "[68]\ttraining's l2: 0.416619\tvalid_1's l2: 0.362298\n",
      "[69]\ttraining's l2: 0.416054\tvalid_1's l2: 0.361901\n",
      "[70]\ttraining's l2: 0.415743\tvalid_1's l2: 0.361648\n",
      "[71]\ttraining's l2: 0.415332\tvalid_1's l2: 0.361273\n",
      "[72]\ttraining's l2: 0.414903\tvalid_1's l2: 0.360877\n",
      "[73]\ttraining's l2: 0.414454\tvalid_1's l2: 0.360414\n",
      "[74]\ttraining's l2: 0.414029\tvalid_1's l2: 0.360029\n",
      "[75]\ttraining's l2: 0.41372\tvalid_1's l2: 0.359735\n",
      "[76]\ttraining's l2: 0.413377\tvalid_1's l2: 0.359408\n",
      "[77]\ttraining's l2: 0.413064\tvalid_1's l2: 0.359119\n",
      "[78]\ttraining's l2: 0.412785\tvalid_1's l2: 0.358821\n",
      "[79]\ttraining's l2: 0.412564\tvalid_1's l2: 0.358604\n",
      "[80]\ttraining's l2: 0.412278\tvalid_1's l2: 0.358313\n",
      "[81]\ttraining's l2: 0.412056\tvalid_1's l2: 0.358084\n",
      "[82]\ttraining's l2: 0.411818\tvalid_1's l2: 0.357899\n",
      "[83]\ttraining's l2: 0.411582\tvalid_1's l2: 0.357694\n",
      "[84]\ttraining's l2: 0.4114\tvalid_1's l2: 0.357541\n",
      "[85]\ttraining's l2: 0.411163\tvalid_1's l2: 0.357347\n",
      "[86]\ttraining's l2: 0.410872\tvalid_1's l2: 0.357131\n",
      "[87]\ttraining's l2: 0.410574\tvalid_1's l2: 0.357001\n",
      "[88]\ttraining's l2: 0.410275\tvalid_1's l2: 0.356857\n",
      "[89]\ttraining's l2: 0.410045\tvalid_1's l2: 0.356716\n",
      "[90]\ttraining's l2: 0.409851\tvalid_1's l2: 0.356603\n",
      "[91]\ttraining's l2: 0.40968\tvalid_1's l2: 0.356479\n",
      "[92]\ttraining's l2: 0.409518\tvalid_1's l2: 0.356338\n",
      "[93]\ttraining's l2: 0.409326\tvalid_1's l2: 0.356217\n",
      "[94]\ttraining's l2: 0.409208\tvalid_1's l2: 0.356127\n",
      "[95]\ttraining's l2: 0.409055\tvalid_1's l2: 0.356056\n",
      "[96]\ttraining's l2: 0.408879\tvalid_1's l2: 0.355975\n",
      "[97]\ttraining's l2: 0.408674\tvalid_1's l2: 0.355814\n",
      "[98]\ttraining's l2: 0.408436\tvalid_1's l2: 0.355613\n",
      "[99]\ttraining's l2: 0.408295\tvalid_1's l2: 0.355545\n",
      "[100]\ttraining's l2: 0.408166\tvalid_1's l2: 0.355468\n",
      "[101]\ttraining's l2: 0.407954\tvalid_1's l2: 0.355293\n",
      "[102]\ttraining's l2: 0.407819\tvalid_1's l2: 0.355192\n",
      "[103]\ttraining's l2: 0.407693\tvalid_1's l2: 0.355124\n",
      "[104]\ttraining's l2: 0.407546\tvalid_1's l2: 0.355052\n",
      "[105]\ttraining's l2: 0.407418\tvalid_1's l2: 0.354993\n",
      "[106]\ttraining's l2: 0.407254\tvalid_1's l2: 0.354837\n",
      "[107]\ttraining's l2: 0.406971\tvalid_1's l2: 0.354687\n",
      "[108]\ttraining's l2: 0.406797\tvalid_1's l2: 0.354515\n",
      "[109]\ttraining's l2: 0.406619\tvalid_1's l2: 0.354417\n",
      "[110]\ttraining's l2: 0.406506\tvalid_1's l2: 0.354353\n",
      "[111]\ttraining's l2: 0.406408\tvalid_1's l2: 0.354286\n",
      "[112]\ttraining's l2: 0.406318\tvalid_1's l2: 0.354226\n",
      "[113]\ttraining's l2: 0.406155\tvalid_1's l2: 0.354114\n",
      "[114]\ttraining's l2: 0.406023\tvalid_1's l2: 0.35402\n",
      "[115]\ttraining's l2: 0.405904\tvalid_1's l2: 0.353944\n",
      "[116]\ttraining's l2: 0.405769\tvalid_1's l2: 0.353873\n",
      "[117]\ttraining's l2: 0.405612\tvalid_1's l2: 0.353726\n",
      "[118]\ttraining's l2: 0.405523\tvalid_1's l2: 0.353636\n",
      "[119]\ttraining's l2: 0.405437\tvalid_1's l2: 0.353573\n",
      "[120]\ttraining's l2: 0.405338\tvalid_1's l2: 0.353525\n",
      "[121]\ttraining's l2: 0.405218\tvalid_1's l2: 0.353498\n",
      "[122]\ttraining's l2: 0.40507\tvalid_1's l2: 0.353402\n",
      "[123]\ttraining's l2: 0.404937\tvalid_1's l2: 0.353308\n",
      "[124]\ttraining's l2: 0.404863\tvalid_1's l2: 0.353277\n",
      "[125]\ttraining's l2: 0.40478\tvalid_1's l2: 0.353214\n",
      "[126]\ttraining's l2: 0.404634\tvalid_1's l2: 0.353103\n",
      "[127]\ttraining's l2: 0.404489\tvalid_1's l2: 0.352999\n",
      "[128]\ttraining's l2: 0.404396\tvalid_1's l2: 0.35297\n",
      "[129]\ttraining's l2: 0.404301\tvalid_1's l2: 0.352888\n",
      "[130]\ttraining's l2: 0.404231\tvalid_1's l2: 0.352875\n",
      "[131]\ttraining's l2: 0.404099\tvalid_1's l2: 0.3528\n",
      "[132]\ttraining's l2: 0.404017\tvalid_1's l2: 0.35275\n",
      "[133]\ttraining's l2: 0.403915\tvalid_1's l2: 0.352707\n",
      "[134]\ttraining's l2: 0.403834\tvalid_1's l2: 0.352644\n",
      "[135]\ttraining's l2: 0.40375\tvalid_1's l2: 0.352582\n",
      "[136]\ttraining's l2: 0.403658\tvalid_1's l2: 0.352547\n",
      "[137]\ttraining's l2: 0.403574\tvalid_1's l2: 0.352515\n",
      "[138]\ttraining's l2: 0.403476\tvalid_1's l2: 0.352426\n",
      "[139]\ttraining's l2: 0.403345\tvalid_1's l2: 0.352354\n",
      "[140]\ttraining's l2: 0.403255\tvalid_1's l2: 0.352295\n",
      "[141]\ttraining's l2: 0.40317\tvalid_1's l2: 0.352266\n",
      "[142]\ttraining's l2: 0.403108\tvalid_1's l2: 0.352213\n",
      "[143]\ttraining's l2: 0.402985\tvalid_1's l2: 0.352196\n",
      "[144]\ttraining's l2: 0.402904\tvalid_1's l2: 0.352176\n",
      "[145]\ttraining's l2: 0.402849\tvalid_1's l2: 0.35213\n",
      "[146]\ttraining's l2: 0.402755\tvalid_1's l2: 0.352112\n",
      "[147]\ttraining's l2: 0.402664\tvalid_1's l2: 0.352066\n",
      "[148]\ttraining's l2: 0.402603\tvalid_1's l2: 0.352028\n",
      "[149]\ttraining's l2: 0.402482\tvalid_1's l2: 0.351952\n",
      "[150]\ttraining's l2: 0.402401\tvalid_1's l2: 0.351891\n",
      "[151]\ttraining's l2: 0.402299\tvalid_1's l2: 0.351819\n",
      "[152]\ttraining's l2: 0.402221\tvalid_1's l2: 0.351821\n",
      "[153]\ttraining's l2: 0.402154\tvalid_1's l2: 0.351813\n",
      "[154]\ttraining's l2: 0.402084\tvalid_1's l2: 0.351762\n",
      "[155]\ttraining's l2: 0.401998\tvalid_1's l2: 0.351709\n",
      "[156]\ttraining's l2: 0.401957\tvalid_1's l2: 0.35168\n",
      "[157]\ttraining's l2: 0.401852\tvalid_1's l2: 0.351639\n",
      "[158]\ttraining's l2: 0.401774\tvalid_1's l2: 0.351606\n",
      "[159]\ttraining's l2: 0.40171\tvalid_1's l2: 0.35158\n",
      "[160]\ttraining's l2: 0.401647\tvalid_1's l2: 0.351565\n",
      "[161]\ttraining's l2: 0.401597\tvalid_1's l2: 0.35154\n",
      "[162]\ttraining's l2: 0.401516\tvalid_1's l2: 0.351542\n",
      "[163]\ttraining's l2: 0.401431\tvalid_1's l2: 0.351513\n",
      "[164]\ttraining's l2: 0.401353\tvalid_1's l2: 0.351496\n",
      "[165]\ttraining's l2: 0.401273\tvalid_1's l2: 0.351451\n",
      "[166]\ttraining's l2: 0.401206\tvalid_1's l2: 0.351427\n",
      "[167]\ttraining's l2: 0.401108\tvalid_1's l2: 0.351407\n",
      "[168]\ttraining's l2: 0.40104\tvalid_1's l2: 0.35139\n",
      "[169]\ttraining's l2: 0.400955\tvalid_1's l2: 0.351358\n",
      "[170]\ttraining's l2: 0.400907\tvalid_1's l2: 0.351327\n",
      "[171]\ttraining's l2: 0.400808\tvalid_1's l2: 0.351264\n",
      "[172]\ttraining's l2: 0.400738\tvalid_1's l2: 0.351183\n",
      "[173]\ttraining's l2: 0.400659\tvalid_1's l2: 0.35114\n",
      "[174]\ttraining's l2: 0.400582\tvalid_1's l2: 0.351122\n",
      "[175]\ttraining's l2: 0.400525\tvalid_1's l2: 0.351117\n",
      "[176]\ttraining's l2: 0.400432\tvalid_1's l2: 0.351067\n",
      "[177]\ttraining's l2: 0.400359\tvalid_1's l2: 0.351046\n",
      "[178]\ttraining's l2: 0.400284\tvalid_1's l2: 0.351061\n",
      "[179]\ttraining's l2: 0.40023\tvalid_1's l2: 0.351034\n",
      "[180]\ttraining's l2: 0.400162\tvalid_1's l2: 0.351022\n",
      "[181]\ttraining's l2: 0.400055\tvalid_1's l2: 0.350944\n",
      "[182]\ttraining's l2: 0.39999\tvalid_1's l2: 0.350925\n",
      "[183]\ttraining's l2: 0.399937\tvalid_1's l2: 0.350919\n",
      "[184]\ttraining's l2: 0.399902\tvalid_1's l2: 0.350891\n",
      "[185]\ttraining's l2: 0.399855\tvalid_1's l2: 0.350859\n",
      "[186]\ttraining's l2: 0.399763\tvalid_1's l2: 0.350843\n",
      "[187]\ttraining's l2: 0.39969\tvalid_1's l2: 0.350809\n",
      "[188]\ttraining's l2: 0.399615\tvalid_1's l2: 0.350775\n",
      "[189]\ttraining's l2: 0.39953\tvalid_1's l2: 0.350761\n",
      "[190]\ttraining's l2: 0.399465\tvalid_1's l2: 0.350724\n",
      "[191]\ttraining's l2: 0.399392\tvalid_1's l2: 0.350695\n",
      "[192]\ttraining's l2: 0.399346\tvalid_1's l2: 0.350698\n",
      "[193]\ttraining's l2: 0.399237\tvalid_1's l2: 0.350715\n",
      "[194]\ttraining's l2: 0.399188\tvalid_1's l2: 0.350699\n",
      "[195]\ttraining's l2: 0.399137\tvalid_1's l2: 0.350691\n",
      "[196]\ttraining's l2: 0.399075\tvalid_1's l2: 0.350632\n",
      "[197]\ttraining's l2: 0.399007\tvalid_1's l2: 0.350636\n",
      "[198]\ttraining's l2: 0.398925\tvalid_1's l2: 0.350573\n",
      "[199]\ttraining's l2: 0.398866\tvalid_1's l2: 0.350558\n",
      "[200]\ttraining's l2: 0.398786\tvalid_1's l2: 0.350549\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.398786\tvalid_1's l2: 0.350549\n",
      "mean_4_sales: 18225658.44\n",
      "mean_14_sales: 16300468.72\n",
      "mean_21_sales: 3540799.37\n",
      "mean_20_dow4_2017: 2698885.06\n",
      "mean_5_sales: 2663443.38\n",
      "lag_3_sales: 2422567.31\n",
      "mean_30_sales: 2376875.36\n",
      "mean_60_sales: 1219998.04\n",
      "promo_4: 1091270.82\n",
      "mean_4_dow4_2017: 791332.39\n",
      "mean_3_sales: 517308.45\n",
      "std_14_sales: 456968.51\n",
      "item_class_features: 340230.75\n",
      "promo_3: 279497.17\n",
      "sum_3_promo: 250065.20\n",
      "mean_4_dow3_2017: 215739.96\n",
      "mean_6_sales: 191140.20\n",
      "std_21_sales: 170817.24\n",
      "mean_20_dow3_2017: 127339.42\n",
      "store_cluster_features: 123147.86\n",
      "promo_1: 106141.75\n",
      "promo_5: 83851.70\n",
      "mean_63_sales: 74381.70\n",
      "promo_7: 73875.10\n",
      "store_city_features: 69640.74\n",
      "promo_2: 56882.77\n",
      "sum_4_promo: 49207.39\n",
      "mean_7_sales: 49076.11\n",
      "promo_6: 48215.27\n",
      "item_family_features: 44964.73\n",
      "std_30_sales: 37782.34\n",
      "mean_4_dow5_2017: 34642.40\n",
      "promo_10: 33203.10\n",
      "lag_2_sales: 30145.75\n",
      "std_3_sales: 29135.29\n",
      "promo_0: 28903.15\n",
      "mean_20_dow0_2017: 28236.82\n",
      "sum_2_promo: 26878.68\n",
      "promo_11: 22897.43\n",
      "store_type_features: 22819.01\n",
      "lag_28_sales: 22647.59\n",
      "lag_4_sales: 22096.59\n",
      "lag_63_sales: 21380.81\n",
      "promo_8: 21004.57\n",
      "std_60_sales: 18477.58\n",
      "lag_1_sales: 18289.71\n",
      "std_7_sales: 17460.71\n",
      "sum_14_promo: 17214.76\n",
      "lag_49_sales: 16921.37\n",
      "promo_14: 16419.90\n",
      "std_5_sales: 14022.06\n",
      "std_63_sales: 12459.01\n",
      "std_4_sales: 11947.36\n",
      "std_6_sales: 11469.12\n",
      "sum_21_promo: 9473.04\n",
      "mean_20_dow2_2017: 7343.33\n",
      "mean_20_dow1_2017: 6675.33\n",
      "lag_56_sales: 6540.08\n",
      "mean_20_dow6_2017: 6511.78\n",
      "store_state_features: 6215.21\n",
      "promo_9: 5072.20\n",
      "lag_5_sales: 3772.82\n",
      "lag_6_sales: 3659.17\n",
      "sum_6_promo: 3514.22\n",
      "lag_14_sales: 3033.61\n",
      "promo_13: 2882.82\n",
      "mean_20_dow5_2017: 2876.98\n",
      "mean_4_dow0_2017: 2845.20\n",
      "promo_12: 2568.69\n",
      "sum_7_promo: 2334.29\n",
      "lag_7_sales: 2038.54\n",
      "sum_5_promo: 1861.31\n",
      "mean_4_dow6_2017: 1719.88\n",
      "mean_4_dow1_2017: 1699.42\n",
      "lag_35_sales: 1410.56\n",
      "promo_15: 1213.78\n",
      "lag_42_sales: 945.59\n",
      "mean_4_dow2_2017: 569.44\n",
      "lag_21_sales: 206.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███▏      | 5/16 [14:35<32:01, 174.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.07354\tvalid_1's l2: 1.09782\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.00749\tvalid_1's l2: 1.03077\n",
      "[3]\ttraining's l2: 0.947702\tvalid_1's l2: 0.969456\n",
      "[4]\ttraining's l2: 0.893952\tvalid_1's l2: 0.914075\n",
      "[5]\ttraining's l2: 0.84509\tvalid_1's l2: 0.864\n",
      "[6]\ttraining's l2: 0.800886\tvalid_1's l2: 0.818609\n",
      "[7]\ttraining's l2: 0.760948\tvalid_1's l2: 0.777447\n",
      "[8]\ttraining's l2: 0.724748\tvalid_1's l2: 0.740138\n",
      "[9]\ttraining's l2: 0.691978\tvalid_1's l2: 0.706375\n",
      "[10]\ttraining's l2: 0.662623\tvalid_1's l2: 0.675868\n",
      "[11]\ttraining's l2: 0.636099\tvalid_1's l2: 0.648364\n",
      "[12]\ttraining's l2: 0.612119\tvalid_1's l2: 0.623565\n",
      "[13]\ttraining's l2: 0.589827\tvalid_1's l2: 0.600315\n",
      "[14]\ttraining's l2: 0.569688\tvalid_1's l2: 0.579272\n",
      "[15]\ttraining's l2: 0.551381\tvalid_1's l2: 0.560045\n",
      "[16]\ttraining's l2: 0.53504\tvalid_1's l2: 0.543026\n",
      "[17]\ttraining's l2: 0.52039\tvalid_1's l2: 0.527704\n",
      "[18]\ttraining's l2: 0.5067\tvalid_1's l2: 0.513294\n",
      "[19]\ttraining's l2: 0.494351\tvalid_1's l2: 0.500196\n",
      "[20]\ttraining's l2: 0.483091\tvalid_1's l2: 0.488274\n",
      "[21]\ttraining's l2: 0.472889\tvalid_1's l2: 0.477448\n",
      "[22]\ttraining's l2: 0.463661\tvalid_1's l2: 0.467503\n",
      "[23]\ttraining's l2: 0.455469\tvalid_1's l2: 0.458759\n",
      "[24]\ttraining's l2: 0.447841\tvalid_1's l2: 0.450649\n",
      "[25]\ttraining's l2: 0.440822\tvalid_1's l2: 0.443114\n",
      "[26]\ttraining's l2: 0.434646\tvalid_1's l2: 0.436472\n",
      "[27]\ttraining's l2: 0.428851\tvalid_1's l2: 0.430266\n",
      "[28]\ttraining's l2: 0.423664\tvalid_1's l2: 0.4246\n",
      "[29]\ttraining's l2: 0.419089\tvalid_1's l2: 0.4196\n",
      "[30]\ttraining's l2: 0.414714\tvalid_1's l2: 0.41486\n",
      "[31]\ttraining's l2: 0.410742\tvalid_1's l2: 0.410538\n",
      "[32]\ttraining's l2: 0.407226\tvalid_1's l2: 0.406711\n",
      "[33]\ttraining's l2: 0.404063\tvalid_1's l2: 0.40324\n",
      "[34]\ttraining's l2: 0.401016\tvalid_1's l2: 0.399869\n",
      "[35]\ttraining's l2: 0.398304\tvalid_1's l2: 0.396979\n",
      "[36]\ttraining's l2: 0.395754\tvalid_1's l2: 0.394049\n",
      "[37]\ttraining's l2: 0.393395\tvalid_1's l2: 0.391353\n",
      "[38]\ttraining's l2: 0.391265\tvalid_1's l2: 0.388871\n",
      "[39]\ttraining's l2: 0.389315\tvalid_1's l2: 0.38665\n",
      "[40]\ttraining's l2: 0.387616\tvalid_1's l2: 0.384693\n",
      "[41]\ttraining's l2: 0.386076\tvalid_1's l2: 0.38298\n",
      "[42]\ttraining's l2: 0.38464\tvalid_1's l2: 0.381386\n",
      "[43]\ttraining's l2: 0.383235\tvalid_1's l2: 0.379768\n",
      "[44]\ttraining's l2: 0.382068\tvalid_1's l2: 0.378404\n",
      "[45]\ttraining's l2: 0.380954\tvalid_1's l2: 0.377162\n",
      "[46]\ttraining's l2: 0.379822\tvalid_1's l2: 0.375732\n",
      "[47]\ttraining's l2: 0.378755\tvalid_1's l2: 0.374555\n",
      "[48]\ttraining's l2: 0.377768\tvalid_1's l2: 0.373373\n",
      "[49]\ttraining's l2: 0.376873\tvalid_1's l2: 0.372269\n",
      "[50]\ttraining's l2: 0.376025\tvalid_1's l2: 0.37119\n",
      "[51]\ttraining's l2: 0.375261\tvalid_1's l2: 0.370276\n",
      "[52]\ttraining's l2: 0.374595\tvalid_1's l2: 0.369598\n",
      "[53]\ttraining's l2: 0.373912\tvalid_1's l2: 0.368747\n",
      "[54]\ttraining's l2: 0.373294\tvalid_1's l2: 0.367979\n",
      "[55]\ttraining's l2: 0.372722\tvalid_1's l2: 0.367226\n",
      "[56]\ttraining's l2: 0.372198\tvalid_1's l2: 0.366642\n",
      "[57]\ttraining's l2: 0.371673\tvalid_1's l2: 0.365985\n",
      "[58]\ttraining's l2: 0.371168\tvalid_1's l2: 0.365315\n",
      "[59]\ttraining's l2: 0.370758\tvalid_1's l2: 0.36489\n",
      "[60]\ttraining's l2: 0.370367\tvalid_1's l2: 0.364451\n",
      "[61]\ttraining's l2: 0.369958\tvalid_1's l2: 0.364007\n",
      "[62]\ttraining's l2: 0.36956\tvalid_1's l2: 0.363537\n",
      "[63]\ttraining's l2: 0.369189\tvalid_1's l2: 0.363077\n",
      "[64]\ttraining's l2: 0.368909\tvalid_1's l2: 0.362771\n",
      "[65]\ttraining's l2: 0.368573\tvalid_1's l2: 0.362293\n",
      "[66]\ttraining's l2: 0.368282\tvalid_1's l2: 0.361933\n",
      "[67]\ttraining's l2: 0.367939\tvalid_1's l2: 0.361602\n",
      "[68]\ttraining's l2: 0.367637\tvalid_1's l2: 0.361316\n",
      "[69]\ttraining's l2: 0.367371\tvalid_1's l2: 0.36109\n",
      "[70]\ttraining's l2: 0.367126\tvalid_1's l2: 0.360817\n",
      "[71]\ttraining's l2: 0.366826\tvalid_1's l2: 0.360422\n",
      "[72]\ttraining's l2: 0.366562\tvalid_1's l2: 0.360075\n",
      "[73]\ttraining's l2: 0.366328\tvalid_1's l2: 0.359836\n",
      "[74]\ttraining's l2: 0.366077\tvalid_1's l2: 0.359583\n",
      "[75]\ttraining's l2: 0.365822\tvalid_1's l2: 0.359314\n",
      "[76]\ttraining's l2: 0.365595\tvalid_1's l2: 0.359095\n",
      "[77]\ttraining's l2: 0.365401\tvalid_1's l2: 0.358874\n",
      "[78]\ttraining's l2: 0.365195\tvalid_1's l2: 0.358672\n",
      "[79]\ttraining's l2: 0.365\tvalid_1's l2: 0.358507\n",
      "[80]\ttraining's l2: 0.364795\tvalid_1's l2: 0.358239\n",
      "[81]\ttraining's l2: 0.364624\tvalid_1's l2: 0.358047\n",
      "[82]\ttraining's l2: 0.364435\tvalid_1's l2: 0.357844\n",
      "[83]\ttraining's l2: 0.364263\tvalid_1's l2: 0.3577\n",
      "[84]\ttraining's l2: 0.364127\tvalid_1's l2: 0.357572\n",
      "[85]\ttraining's l2: 0.363928\tvalid_1's l2: 0.357318\n",
      "[86]\ttraining's l2: 0.363755\tvalid_1's l2: 0.357112\n",
      "[87]\ttraining's l2: 0.363604\tvalid_1's l2: 0.357005\n",
      "[88]\ttraining's l2: 0.363466\tvalid_1's l2: 0.356917\n",
      "[89]\ttraining's l2: 0.363302\tvalid_1's l2: 0.356747\n",
      "[90]\ttraining's l2: 0.363151\tvalid_1's l2: 0.356649\n",
      "[91]\ttraining's l2: 0.362997\tvalid_1's l2: 0.356561\n",
      "[92]\ttraining's l2: 0.362888\tvalid_1's l2: 0.356436\n",
      "[93]\ttraining's l2: 0.36271\tvalid_1's l2: 0.356284\n",
      "[94]\ttraining's l2: 0.362581\tvalid_1's l2: 0.356231\n",
      "[95]\ttraining's l2: 0.362436\tvalid_1's l2: 0.356077\n",
      "[96]\ttraining's l2: 0.362303\tvalid_1's l2: 0.355929\n",
      "[97]\ttraining's l2: 0.362221\tvalid_1's l2: 0.355867\n",
      "[98]\ttraining's l2: 0.3621\tvalid_1's l2: 0.355789\n",
      "[99]\ttraining's l2: 0.36196\tvalid_1's l2: 0.355685\n",
      "[100]\ttraining's l2: 0.361789\tvalid_1's l2: 0.355529\n",
      "[101]\ttraining's l2: 0.361688\tvalid_1's l2: 0.355463\n",
      "[102]\ttraining's l2: 0.361594\tvalid_1's l2: 0.355421\n",
      "[103]\ttraining's l2: 0.361438\tvalid_1's l2: 0.355269\n",
      "[104]\ttraining's l2: 0.361316\tvalid_1's l2: 0.35515\n",
      "[105]\ttraining's l2: 0.36115\tvalid_1's l2: 0.355016\n",
      "[106]\ttraining's l2: 0.361016\tvalid_1's l2: 0.354915\n",
      "[107]\ttraining's l2: 0.360915\tvalid_1's l2: 0.354889\n",
      "[108]\ttraining's l2: 0.360811\tvalid_1's l2: 0.354861\n",
      "[109]\ttraining's l2: 0.360707\tvalid_1's l2: 0.354736\n",
      "[110]\ttraining's l2: 0.360635\tvalid_1's l2: 0.354666\n",
      "[111]\ttraining's l2: 0.360544\tvalid_1's l2: 0.354615\n",
      "[112]\ttraining's l2: 0.360459\tvalid_1's l2: 0.354569\n",
      "[113]\ttraining's l2: 0.360383\tvalid_1's l2: 0.354552\n",
      "[114]\ttraining's l2: 0.3603\tvalid_1's l2: 0.354424\n",
      "[115]\ttraining's l2: 0.360222\tvalid_1's l2: 0.354347\n",
      "[116]\ttraining's l2: 0.360072\tvalid_1's l2: 0.354261\n",
      "[117]\ttraining's l2: 0.35999\tvalid_1's l2: 0.354176\n",
      "[118]\ttraining's l2: 0.359913\tvalid_1's l2: 0.354116\n",
      "[119]\ttraining's l2: 0.359831\tvalid_1's l2: 0.354049\n",
      "[120]\ttraining's l2: 0.359745\tvalid_1's l2: 0.354015\n",
      "[121]\ttraining's l2: 0.359693\tvalid_1's l2: 0.353967\n",
      "[122]\ttraining's l2: 0.359633\tvalid_1's l2: 0.353912\n",
      "[123]\ttraining's l2: 0.359519\tvalid_1's l2: 0.353795\n",
      "[124]\ttraining's l2: 0.359468\tvalid_1's l2: 0.353781\n",
      "[125]\ttraining's l2: 0.359377\tvalid_1's l2: 0.353727\n",
      "[126]\ttraining's l2: 0.359282\tvalid_1's l2: 0.353641\n",
      "[127]\ttraining's l2: 0.35922\tvalid_1's l2: 0.353576\n",
      "[128]\ttraining's l2: 0.359147\tvalid_1's l2: 0.353511\n",
      "[129]\ttraining's l2: 0.359097\tvalid_1's l2: 0.35346\n",
      "[130]\ttraining's l2: 0.359032\tvalid_1's l2: 0.353417\n",
      "[131]\ttraining's l2: 0.358942\tvalid_1's l2: 0.353382\n",
      "[132]\ttraining's l2: 0.358876\tvalid_1's l2: 0.353338\n",
      "[133]\ttraining's l2: 0.358815\tvalid_1's l2: 0.353316\n",
      "[134]\ttraining's l2: 0.35874\tvalid_1's l2: 0.353248\n",
      "[135]\ttraining's l2: 0.358641\tvalid_1's l2: 0.353179\n",
      "[136]\ttraining's l2: 0.358515\tvalid_1's l2: 0.353047\n",
      "[137]\ttraining's l2: 0.358459\tvalid_1's l2: 0.353027\n",
      "[138]\ttraining's l2: 0.358358\tvalid_1's l2: 0.352924\n",
      "[139]\ttraining's l2: 0.358313\tvalid_1's l2: 0.352855\n",
      "[140]\ttraining's l2: 0.358255\tvalid_1's l2: 0.352817\n",
      "[141]\ttraining's l2: 0.358185\tvalid_1's l2: 0.352758\n",
      "[142]\ttraining's l2: 0.358123\tvalid_1's l2: 0.352757\n",
      "[143]\ttraining's l2: 0.358064\tvalid_1's l2: 0.352706\n",
      "[144]\ttraining's l2: 0.357954\tvalid_1's l2: 0.352643\n",
      "[145]\ttraining's l2: 0.357877\tvalid_1's l2: 0.352616\n",
      "[146]\ttraining's l2: 0.357819\tvalid_1's l2: 0.35261\n",
      "[147]\ttraining's l2: 0.35776\tvalid_1's l2: 0.352567\n",
      "[148]\ttraining's l2: 0.357699\tvalid_1's l2: 0.352566\n",
      "[149]\ttraining's l2: 0.35764\tvalid_1's l2: 0.352547\n",
      "[150]\ttraining's l2: 0.357575\tvalid_1's l2: 0.352489\n",
      "[151]\ttraining's l2: 0.357532\tvalid_1's l2: 0.352484\n",
      "[152]\ttraining's l2: 0.357482\tvalid_1's l2: 0.352462\n",
      "[153]\ttraining's l2: 0.357436\tvalid_1's l2: 0.352452\n",
      "[154]\ttraining's l2: 0.357402\tvalid_1's l2: 0.352457\n",
      "[155]\ttraining's l2: 0.357351\tvalid_1's l2: 0.35244\n",
      "[156]\ttraining's l2: 0.357306\tvalid_1's l2: 0.352427\n",
      "[157]\ttraining's l2: 0.357241\tvalid_1's l2: 0.352381\n",
      "[158]\ttraining's l2: 0.357194\tvalid_1's l2: 0.352367\n",
      "[159]\ttraining's l2: 0.357162\tvalid_1's l2: 0.352349\n",
      "[160]\ttraining's l2: 0.357074\tvalid_1's l2: 0.352283\n",
      "[161]\ttraining's l2: 0.357039\tvalid_1's l2: 0.352266\n",
      "[162]\ttraining's l2: 0.35698\tvalid_1's l2: 0.352266\n",
      "[163]\ttraining's l2: 0.356914\tvalid_1's l2: 0.352204\n",
      "[164]\ttraining's l2: 0.356861\tvalid_1's l2: 0.352175\n",
      "[165]\ttraining's l2: 0.356818\tvalid_1's l2: 0.352165\n",
      "[166]\ttraining's l2: 0.356744\tvalid_1's l2: 0.352122\n",
      "[167]\ttraining's l2: 0.356683\tvalid_1's l2: 0.352069\n",
      "[168]\ttraining's l2: 0.356637\tvalid_1's l2: 0.352071\n",
      "[169]\ttraining's l2: 0.35656\tvalid_1's l2: 0.35205\n",
      "[170]\ttraining's l2: 0.356518\tvalid_1's l2: 0.35203\n",
      "[171]\ttraining's l2: 0.356478\tvalid_1's l2: 0.352005\n",
      "[172]\ttraining's l2: 0.356428\tvalid_1's l2: 0.351971\n",
      "[173]\ttraining's l2: 0.356384\tvalid_1's l2: 0.351959\n",
      "[174]\ttraining's l2: 0.35635\tvalid_1's l2: 0.351938\n",
      "[175]\ttraining's l2: 0.356317\tvalid_1's l2: 0.351914\n",
      "[176]\ttraining's l2: 0.356281\tvalid_1's l2: 0.351887\n",
      "[177]\ttraining's l2: 0.356235\tvalid_1's l2: 0.351883\n",
      "[178]\ttraining's l2: 0.356193\tvalid_1's l2: 0.351875\n",
      "[179]\ttraining's l2: 0.356154\tvalid_1's l2: 0.35188\n",
      "[180]\ttraining's l2: 0.356115\tvalid_1's l2: 0.35185\n",
      "[181]\ttraining's l2: 0.356064\tvalid_1's l2: 0.35182\n",
      "[182]\ttraining's l2: 0.356031\tvalid_1's l2: 0.351812\n",
      "[183]\ttraining's l2: 0.356001\tvalid_1's l2: 0.351803\n",
      "[184]\ttraining's l2: 0.355947\tvalid_1's l2: 0.351742\n",
      "[185]\ttraining's l2: 0.355912\tvalid_1's l2: 0.351723\n",
      "[186]\ttraining's l2: 0.35588\tvalid_1's l2: 0.351722\n",
      "[187]\ttraining's l2: 0.355843\tvalid_1's l2: 0.351696\n",
      "[188]\ttraining's l2: 0.355798\tvalid_1's l2: 0.35166\n",
      "[189]\ttraining's l2: 0.355757\tvalid_1's l2: 0.351652\n",
      "[190]\ttraining's l2: 0.355728\tvalid_1's l2: 0.351638\n",
      "[191]\ttraining's l2: 0.355693\tvalid_1's l2: 0.351634\n",
      "[192]\ttraining's l2: 0.355655\tvalid_1's l2: 0.351607\n",
      "[193]\ttraining's l2: 0.355618\tvalid_1's l2: 0.351567\n",
      "[194]\ttraining's l2: 0.355579\tvalid_1's l2: 0.351557\n",
      "[195]\ttraining's l2: 0.355551\tvalid_1's l2: 0.351531\n",
      "[196]\ttraining's l2: 0.355504\tvalid_1's l2: 0.351514\n",
      "[197]\ttraining's l2: 0.355478\tvalid_1's l2: 0.351497\n",
      "[198]\ttraining's l2: 0.355457\tvalid_1's l2: 0.351492\n",
      "[199]\ttraining's l2: 0.355411\tvalid_1's l2: 0.351451\n",
      "[200]\ttraining's l2: 0.355372\tvalid_1's l2: 0.351454\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.355372\tvalid_1's l2: 0.351454\n",
      "mean_14_sales: 19414026.18\n",
      "mean_7_sales: 7190469.62\n",
      "mean_30_sales: 5753342.44\n",
      "mean_21_sales: 4031965.19\n",
      "mean_20_dow5_2017: 1555396.53\n",
      "mean_60_sales: 1504627.11\n",
      "mean_3_sales: 1011441.53\n",
      "promo_5: 943496.76\n",
      "mean_4_sales: 790051.85\n",
      "mean_4_dow5_2017: 577034.68\n",
      "mean_6_sales: 552565.45\n",
      "mean_5_sales: 434825.55\n",
      "item_class_features: 310741.99\n",
      "mean_63_sales: 230329.04\n",
      "lag_1_sales: 201602.50\n",
      "mean_4_dow6_2017: 194536.20\n",
      "lag_2_sales: 191227.08\n",
      "std_14_sales: 168523.17\n",
      "std_21_sales: 137781.66\n",
      "sum_2_promo: 110798.83\n",
      "promo_7: 95455.62\n",
      "sum_4_promo: 88755.22\n",
      "lag_3_sales: 66234.28\n",
      "promo_3: 62355.83\n",
      "std_30_sales: 60129.75\n",
      "promo_6: 57516.33\n",
      "mean_4_dow4_2017: 44501.82\n",
      "mean_20_dow6_2017: 41790.60\n",
      "item_family_features: 41115.33\n",
      "lag_56_sales: 35422.29\n",
      "std_3_sales: 18853.60\n",
      "store_cluster_features: 18747.44\n",
      "std_60_sales: 18465.00\n",
      "sum_6_promo: 18453.61\n",
      "mean_20_dow0_2017: 18357.56\n",
      "sum_7_promo: 17422.06\n",
      "std_63_sales: 17246.31\n",
      "promo_0: 15455.68\n",
      "mean_20_dow4_2017: 14773.65\n",
      "sum_3_promo: 14670.50\n",
      "sum_14_promo: 14606.34\n",
      "promo_4: 13940.23\n",
      "promo_1: 13722.48\n",
      "promo_14: 13258.89\n",
      "mean_20_dow3_2017: 12668.82\n",
      "store_city_features: 11851.65\n",
      "promo_2: 9667.94\n",
      "mean_20_dow2_2017: 8607.22\n",
      "lag_42_sales: 8599.40\n",
      "promo_12: 7956.60\n",
      "std_7_sales: 7778.40\n",
      "promo_10: 7741.96\n",
      "sum_21_promo: 6630.94\n",
      "std_5_sales: 5881.11\n",
      "mean_4_dow0_2017: 5485.84\n",
      "std_6_sales: 5111.49\n",
      "std_4_sales: 4485.75\n",
      "lag_28_sales: 4222.38\n",
      "promo_13: 4210.82\n",
      "sum_5_promo: 4155.64\n",
      "lag_63_sales: 3904.60\n",
      "promo_8: 3888.77\n",
      "mean_20_dow1_2017: 3340.80\n",
      "promo_9: 3328.42\n",
      "mean_4_dow2_2017: 3241.84\n",
      "mean_4_dow1_2017: 3150.26\n",
      "mean_4_dow3_2017: 3102.33\n",
      "lag_6_sales: 3079.96\n",
      "lag_14_sales: 2499.10\n",
      "promo_11: 2233.38\n",
      "lag_7_sales: 2187.56\n",
      "store_state_features: 2090.80\n",
      "lag_5_sales: 1381.02\n",
      "lag_4_sales: 1353.26\n",
      "store_type_features: 1346.04\n",
      "lag_49_sales: 1213.53\n",
      "lag_21_sales: 1120.79\n",
      "lag_35_sales: 584.59\n",
      "promo_15: 222.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 6/16 [17:30<29:06, 174.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.03369\tvalid_1's l2: 1.18407\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.97202\tvalid_1's l2: 1.11791\n",
      "[3]\ttraining's l2: 0.91465\tvalid_1's l2: 1.0564\n",
      "[4]\ttraining's l2: 0.862942\tvalid_1's l2: 1.00025\n",
      "[5]\ttraining's l2: 0.81736\tvalid_1's l2: 0.950263\n",
      "[6]\ttraining's l2: 0.774773\tvalid_1's l2: 0.903747\n",
      "[7]\ttraining's l2: 0.737345\tvalid_1's l2: 0.862421\n",
      "[8]\ttraining's l2: 0.702365\tvalid_1's l2: 0.824078\n",
      "[9]\ttraining's l2: 0.670711\tvalid_1's l2: 0.789155\n",
      "[10]\ttraining's l2: 0.642999\tvalid_1's l2: 0.758007\n",
      "[11]\ttraining's l2: 0.617806\tvalid_1's l2: 0.729628\n",
      "[12]\ttraining's l2: 0.594194\tvalid_1's l2: 0.703151\n",
      "[13]\ttraining's l2: 0.573405\tvalid_1's l2: 0.679375\n",
      "[14]\ttraining's l2: 0.554665\tvalid_1's l2: 0.657733\n",
      "[15]\ttraining's l2: 0.536846\tvalid_1's l2: 0.637242\n",
      "[16]\ttraining's l2: 0.521352\tvalid_1's l2: 0.619243\n",
      "[17]\ttraining's l2: 0.507313\tvalid_1's l2: 0.602895\n",
      "[18]\ttraining's l2: 0.493864\tvalid_1's l2: 0.58729\n",
      "[19]\ttraining's l2: 0.481675\tvalid_1's l2: 0.573026\n",
      "[20]\ttraining's l2: 0.470659\tvalid_1's l2: 0.559975\n",
      "[21]\ttraining's l2: 0.460695\tvalid_1's l2: 0.548032\n",
      "[22]\ttraining's l2: 0.451678\tvalid_1's l2: 0.53712\n",
      "[23]\ttraining's l2: 0.443445\tvalid_1's l2: 0.527126\n",
      "[24]\ttraining's l2: 0.436026\tvalid_1's l2: 0.518002\n",
      "[25]\ttraining's l2: 0.429225\tvalid_1's l2: 0.509627\n",
      "[26]\ttraining's l2: 0.423096\tvalid_1's l2: 0.502004\n",
      "[27]\ttraining's l2: 0.41752\tvalid_1's l2: 0.495017\n",
      "[28]\ttraining's l2: 0.412459\tvalid_1's l2: 0.488487\n",
      "[29]\ttraining's l2: 0.408045\tvalid_1's l2: 0.482787\n",
      "[30]\ttraining's l2: 0.404\tvalid_1's l2: 0.477467\n",
      "[31]\ttraining's l2: 0.400158\tvalid_1's l2: 0.472405\n",
      "[32]\ttraining's l2: 0.396608\tvalid_1's l2: 0.467723\n",
      "[33]\ttraining's l2: 0.393416\tvalid_1's l2: 0.463437\n",
      "[34]\ttraining's l2: 0.390633\tvalid_1's l2: 0.459564\n",
      "[35]\ttraining's l2: 0.387937\tvalid_1's l2: 0.455841\n",
      "[36]\ttraining's l2: 0.385409\tvalid_1's l2: 0.452367\n",
      "[37]\ttraining's l2: 0.383284\tvalid_1's l2: 0.449316\n",
      "[38]\ttraining's l2: 0.381191\tvalid_1's l2: 0.446391\n",
      "[39]\ttraining's l2: 0.379272\tvalid_1's l2: 0.443681\n",
      "[40]\ttraining's l2: 0.377659\tvalid_1's l2: 0.44132\n",
      "[41]\ttraining's l2: 0.376027\tvalid_1's l2: 0.43893\n",
      "[42]\ttraining's l2: 0.374518\tvalid_1's l2: 0.43673\n",
      "[43]\ttraining's l2: 0.373097\tvalid_1's l2: 0.434767\n",
      "[44]\ttraining's l2: 0.37175\tvalid_1's l2: 0.432826\n",
      "[45]\ttraining's l2: 0.370594\tvalid_1's l2: 0.431108\n",
      "[46]\ttraining's l2: 0.369592\tvalid_1's l2: 0.429551\n",
      "[47]\ttraining's l2: 0.368594\tvalid_1's l2: 0.428035\n",
      "[48]\ttraining's l2: 0.367675\tvalid_1's l2: 0.426638\n",
      "[49]\ttraining's l2: 0.366859\tvalid_1's l2: 0.425352\n",
      "[50]\ttraining's l2: 0.366116\tvalid_1's l2: 0.42414\n",
      "[51]\ttraining's l2: 0.36532\tvalid_1's l2: 0.422974\n",
      "[52]\ttraining's l2: 0.364675\tvalid_1's l2: 0.421951\n",
      "[53]\ttraining's l2: 0.363948\tvalid_1's l2: 0.420864\n",
      "[54]\ttraining's l2: 0.363201\tvalid_1's l2: 0.419792\n",
      "[55]\ttraining's l2: 0.362544\tvalid_1's l2: 0.418848\n",
      "[56]\ttraining's l2: 0.361916\tvalid_1's l2: 0.417906\n",
      "[57]\ttraining's l2: 0.361413\tvalid_1's l2: 0.417086\n",
      "[58]\ttraining's l2: 0.3608\tvalid_1's l2: 0.416248\n",
      "[59]\ttraining's l2: 0.360347\tvalid_1's l2: 0.415555\n",
      "[60]\ttraining's l2: 0.359884\tvalid_1's l2: 0.414874\n",
      "[61]\ttraining's l2: 0.35939\tvalid_1's l2: 0.414228\n",
      "[62]\ttraining's l2: 0.359013\tvalid_1's l2: 0.413699\n",
      "[63]\ttraining's l2: 0.358672\tvalid_1's l2: 0.413152\n",
      "[64]\ttraining's l2: 0.358388\tvalid_1's l2: 0.412626\n",
      "[65]\ttraining's l2: 0.35791\tvalid_1's l2: 0.412178\n",
      "[66]\ttraining's l2: 0.357603\tvalid_1's l2: 0.411731\n",
      "[67]\ttraining's l2: 0.3572\tvalid_1's l2: 0.411274\n",
      "[68]\ttraining's l2: 0.356893\tvalid_1's l2: 0.410809\n",
      "[69]\ttraining's l2: 0.356569\tvalid_1's l2: 0.410424\n",
      "[70]\ttraining's l2: 0.356325\tvalid_1's l2: 0.410063\n",
      "[71]\ttraining's l2: 0.356048\tvalid_1's l2: 0.409721\n",
      "[72]\ttraining's l2: 0.355822\tvalid_1's l2: 0.409347\n",
      "[73]\ttraining's l2: 0.355636\tvalid_1's l2: 0.409053\n",
      "[74]\ttraining's l2: 0.355364\tvalid_1's l2: 0.408734\n",
      "[75]\ttraining's l2: 0.355085\tvalid_1's l2: 0.408411\n",
      "[76]\ttraining's l2: 0.354862\tvalid_1's l2: 0.408074\n",
      "[77]\ttraining's l2: 0.354683\tvalid_1's l2: 0.407758\n",
      "[78]\ttraining's l2: 0.354475\tvalid_1's l2: 0.407488\n",
      "[79]\ttraining's l2: 0.354178\tvalid_1's l2: 0.407156\n",
      "[80]\ttraining's l2: 0.354018\tvalid_1's l2: 0.406939\n",
      "[81]\ttraining's l2: 0.353815\tvalid_1's l2: 0.406702\n",
      "[82]\ttraining's l2: 0.353609\tvalid_1's l2: 0.406542\n",
      "[83]\ttraining's l2: 0.353435\tvalid_1's l2: 0.406364\n",
      "[84]\ttraining's l2: 0.353287\tvalid_1's l2: 0.40615\n",
      "[85]\ttraining's l2: 0.353088\tvalid_1's l2: 0.406018\n",
      "[86]\ttraining's l2: 0.352884\tvalid_1's l2: 0.405801\n",
      "[87]\ttraining's l2: 0.352702\tvalid_1's l2: 0.405625\n",
      "[88]\ttraining's l2: 0.352563\tvalid_1's l2: 0.405457\n",
      "[89]\ttraining's l2: 0.352432\tvalid_1's l2: 0.405332\n",
      "[90]\ttraining's l2: 0.352279\tvalid_1's l2: 0.405179\n",
      "[91]\ttraining's l2: 0.352163\tvalid_1's l2: 0.404986\n",
      "[92]\ttraining's l2: 0.352035\tvalid_1's l2: 0.404808\n",
      "[93]\ttraining's l2: 0.351874\tvalid_1's l2: 0.404656\n",
      "[94]\ttraining's l2: 0.351731\tvalid_1's l2: 0.404531\n",
      "[95]\ttraining's l2: 0.3516\tvalid_1's l2: 0.404397\n",
      "[96]\ttraining's l2: 0.35152\tvalid_1's l2: 0.404323\n",
      "[97]\ttraining's l2: 0.35142\tvalid_1's l2: 0.404196\n",
      "[98]\ttraining's l2: 0.351318\tvalid_1's l2: 0.404095\n",
      "[99]\ttraining's l2: 0.351208\tvalid_1's l2: 0.403992\n",
      "[100]\ttraining's l2: 0.351099\tvalid_1's l2: 0.403882\n",
      "[101]\ttraining's l2: 0.351005\tvalid_1's l2: 0.4038\n",
      "[102]\ttraining's l2: 0.350911\tvalid_1's l2: 0.403723\n",
      "[103]\ttraining's l2: 0.350835\tvalid_1's l2: 0.403644\n",
      "[104]\ttraining's l2: 0.350694\tvalid_1's l2: 0.403546\n",
      "[105]\ttraining's l2: 0.350508\tvalid_1's l2: 0.403489\n",
      "[106]\ttraining's l2: 0.350312\tvalid_1's l2: 0.403439\n",
      "[107]\ttraining's l2: 0.350232\tvalid_1's l2: 0.403383\n",
      "[108]\ttraining's l2: 0.35011\tvalid_1's l2: 0.403329\n",
      "[109]\ttraining's l2: 0.350027\tvalid_1's l2: 0.403363\n",
      "[110]\ttraining's l2: 0.349941\tvalid_1's l2: 0.403274\n",
      "[111]\ttraining's l2: 0.349841\tvalid_1's l2: 0.403205\n",
      "[112]\ttraining's l2: 0.349721\tvalid_1's l2: 0.403093\n",
      "[113]\ttraining's l2: 0.349547\tvalid_1's l2: 0.403069\n",
      "[114]\ttraining's l2: 0.349453\tvalid_1's l2: 0.403041\n",
      "[115]\ttraining's l2: 0.349387\tvalid_1's l2: 0.402993\n",
      "[116]\ttraining's l2: 0.349314\tvalid_1's l2: 0.403019\n",
      "[117]\ttraining's l2: 0.349231\tvalid_1's l2: 0.403\n",
      "[118]\ttraining's l2: 0.349156\tvalid_1's l2: 0.402938\n",
      "[119]\ttraining's l2: 0.34906\tvalid_1's l2: 0.402836\n",
      "[120]\ttraining's l2: 0.348973\tvalid_1's l2: 0.402744\n",
      "[121]\ttraining's l2: 0.348911\tvalid_1's l2: 0.402727\n",
      "[122]\ttraining's l2: 0.348845\tvalid_1's l2: 0.402709\n",
      "[123]\ttraining's l2: 0.348748\tvalid_1's l2: 0.402643\n",
      "[124]\ttraining's l2: 0.348677\tvalid_1's l2: 0.402639\n",
      "[125]\ttraining's l2: 0.348617\tvalid_1's l2: 0.402597\n",
      "[126]\ttraining's l2: 0.348533\tvalid_1's l2: 0.402504\n",
      "[127]\ttraining's l2: 0.348473\tvalid_1's l2: 0.402451\n",
      "[128]\ttraining's l2: 0.348412\tvalid_1's l2: 0.40245\n",
      "[129]\ttraining's l2: 0.348359\tvalid_1's l2: 0.402524\n",
      "[130]\ttraining's l2: 0.348268\tvalid_1's l2: 0.402468\n",
      "[131]\ttraining's l2: 0.348164\tvalid_1's l2: 0.402415\n",
      "[132]\ttraining's l2: 0.34808\tvalid_1's l2: 0.402363\n",
      "[133]\ttraining's l2: 0.348001\tvalid_1's l2: 0.402316\n",
      "[134]\ttraining's l2: 0.347916\tvalid_1's l2: 0.402361\n",
      "[135]\ttraining's l2: 0.347868\tvalid_1's l2: 0.402362\n",
      "[136]\ttraining's l2: 0.347806\tvalid_1's l2: 0.402298\n",
      "[137]\ttraining's l2: 0.34773\tvalid_1's l2: 0.402247\n",
      "[138]\ttraining's l2: 0.347675\tvalid_1's l2: 0.402211\n",
      "[139]\ttraining's l2: 0.347626\tvalid_1's l2: 0.4022\n",
      "[140]\ttraining's l2: 0.347584\tvalid_1's l2: 0.402266\n",
      "[141]\ttraining's l2: 0.347516\tvalid_1's l2: 0.402252\n",
      "[142]\ttraining's l2: 0.347449\tvalid_1's l2: 0.402225\n",
      "[143]\ttraining's l2: 0.347388\tvalid_1's l2: 0.402224\n",
      "[144]\ttraining's l2: 0.347306\tvalid_1's l2: 0.402214\n",
      "[145]\ttraining's l2: 0.347262\tvalid_1's l2: 0.402321\n",
      "[146]\ttraining's l2: 0.347222\tvalid_1's l2: 0.402303\n",
      "[147]\ttraining's l2: 0.347167\tvalid_1's l2: 0.402265\n",
      "[148]\ttraining's l2: 0.347106\tvalid_1's l2: 0.402294\n",
      "[149]\ttraining's l2: 0.347043\tvalid_1's l2: 0.402292\n",
      "[150]\ttraining's l2: 0.346995\tvalid_1's l2: 0.402282\n",
      "[151]\ttraining's l2: 0.346942\tvalid_1's l2: 0.402266\n",
      "[152]\ttraining's l2: 0.346891\tvalid_1's l2: 0.402356\n",
      "[153]\ttraining's l2: 0.346833\tvalid_1's l2: 0.402351\n",
      "[154]\ttraining's l2: 0.346799\tvalid_1's l2: 0.402361\n",
      "[155]\ttraining's l2: 0.346745\tvalid_1's l2: 0.402332\n",
      "[156]\ttraining's l2: 0.346702\tvalid_1's l2: 0.402333\n",
      "[157]\ttraining's l2: 0.346646\tvalid_1's l2: 0.402324\n",
      "[158]\ttraining's l2: 0.346614\tvalid_1's l2: 0.402316\n",
      "[159]\ttraining's l2: 0.346583\tvalid_1's l2: 0.402288\n",
      "[160]\ttraining's l2: 0.34652\tvalid_1's l2: 0.402268\n",
      "[161]\ttraining's l2: 0.346473\tvalid_1's l2: 0.40225\n",
      "[162]\ttraining's l2: 0.346442\tvalid_1's l2: 0.402328\n",
      "[163]\ttraining's l2: 0.346394\tvalid_1's l2: 0.402318\n",
      "[164]\ttraining's l2: 0.346361\tvalid_1's l2: 0.402396\n",
      "[165]\ttraining's l2: 0.3463\tvalid_1's l2: 0.40239\n",
      "[166]\ttraining's l2: 0.346226\tvalid_1's l2: 0.402358\n",
      "[167]\ttraining's l2: 0.346172\tvalid_1's l2: 0.402343\n",
      "[168]\ttraining's l2: 0.346133\tvalid_1's l2: 0.402313\n",
      "[169]\ttraining's l2: 0.346086\tvalid_1's l2: 0.402298\n",
      "[170]\ttraining's l2: 0.346054\tvalid_1's l2: 0.402286\n",
      "[171]\ttraining's l2: 0.34597\tvalid_1's l2: 0.402328\n",
      "[172]\ttraining's l2: 0.34591\tvalid_1's l2: 0.402275\n",
      "[173]\ttraining's l2: 0.345887\tvalid_1's l2: 0.402277\n",
      "[174]\ttraining's l2: 0.345847\tvalid_1's l2: 0.402271\n",
      "[175]\ttraining's l2: 0.345822\tvalid_1's l2: 0.402259\n",
      "[176]\ttraining's l2: 0.345779\tvalid_1's l2: 0.402243\n",
      "[177]\ttraining's l2: 0.345755\tvalid_1's l2: 0.402233\n",
      "[178]\ttraining's l2: 0.345714\tvalid_1's l2: 0.402196\n",
      "[179]\ttraining's l2: 0.345695\tvalid_1's l2: 0.402167\n",
      "[180]\ttraining's l2: 0.345672\tvalid_1's l2: 0.402147\n",
      "[181]\ttraining's l2: 0.345613\tvalid_1's l2: 0.402102\n",
      "[182]\ttraining's l2: 0.345569\tvalid_1's l2: 0.40207\n",
      "[183]\ttraining's l2: 0.345545\tvalid_1's l2: 0.402055\n",
      "[184]\ttraining's l2: 0.345499\tvalid_1's l2: 0.402051\n",
      "[185]\ttraining's l2: 0.345448\tvalid_1's l2: 0.402098\n",
      "[186]\ttraining's l2: 0.345418\tvalid_1's l2: 0.402212\n",
      "[187]\ttraining's l2: 0.345342\tvalid_1's l2: 0.402178\n",
      "[188]\ttraining's l2: 0.3453\tvalid_1's l2: 0.402187\n",
      "[189]\ttraining's l2: 0.345249\tvalid_1's l2: 0.402162\n",
      "[190]\ttraining's l2: 0.345219\tvalid_1's l2: 0.402165\n",
      "[191]\ttraining's l2: 0.345186\tvalid_1's l2: 0.402155\n",
      "[192]\ttraining's l2: 0.34516\tvalid_1's l2: 0.402112\n",
      "[193]\ttraining's l2: 0.345134\tvalid_1's l2: 0.402102\n",
      "[194]\ttraining's l2: 0.345114\tvalid_1's l2: 0.402106\n",
      "[195]\ttraining's l2: 0.345092\tvalid_1's l2: 0.402084\n",
      "[196]\ttraining's l2: 0.345027\tvalid_1's l2: 0.402034\n",
      "[197]\ttraining's l2: 0.34496\tvalid_1's l2: 0.402028\n",
      "[198]\ttraining's l2: 0.344916\tvalid_1's l2: 0.402005\n",
      "[199]\ttraining's l2: 0.344889\tvalid_1's l2: 0.402\n",
      "[200]\ttraining's l2: 0.344858\tvalid_1's l2: 0.401976\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.344858\tvalid_1's l2: 0.401976\n",
      "mean_14_sales: 17612729.60\n",
      "mean_30_sales: 6807303.20\n",
      "mean_7_sales: 5168868.18\n",
      "mean_21_sales: 4369509.87\n",
      "mean_20_dow6_2017: 2451411.83\n",
      "mean_4_dow6_2017: 1489040.61\n",
      "promo_6: 1374001.74\n",
      "mean_6_sales: 731754.53\n",
      "mean_60_sales: 451588.14\n",
      "lag_1_sales: 447643.65\n",
      "mean_3_sales: 416974.53\n",
      "mean_5_sales: 406956.90\n",
      "item_class_features: 337165.73\n",
      "mean_4_sales: 318244.18\n",
      "mean_63_sales: 277735.28\n",
      "promo_7: 165003.79\n",
      "mean_20_dow5_2017: 129678.48\n",
      "lag_2_sales: 127974.17\n",
      "std_21_sales: 121571.91\n",
      "std_14_sales: 114824.02\n",
      "sum_4_promo: 113132.39\n",
      "std_30_sales: 76939.84\n",
      "item_family_features: 76604.60\n",
      "promo_3: 69785.02\n",
      "promo_5: 59145.45\n",
      "sum_2_promo: 58069.64\n",
      "promo_13: 48729.17\n",
      "mean_4_dow5_2017: 34654.05\n",
      "lag_3_sales: 32788.06\n",
      "std_60_sales: 30674.60\n",
      "store_cluster_features: 29091.02\n",
      "std_63_sales: 27667.20\n",
      "lag_56_sales: 27047.97\n",
      "sum_7_promo: 22990.94\n",
      "sum_14_promo: 21117.21\n",
      "store_type_features: 19720.00\n",
      "sum_3_promo: 19527.76\n",
      "sum_6_promo: 17744.01\n",
      "promo_0: 16730.66\n",
      "std_7_sales: 16475.43\n",
      "mean_4_dow4_2017: 16255.47\n",
      "promo_4: 15213.50\n",
      "promo_1: 15091.77\n",
      "mean_20_dow1_2017: 15090.07\n",
      "promo_14: 14877.99\n",
      "mean_20_dow0_2017: 14678.20\n",
      "mean_20_dow3_2017: 14346.94\n",
      "lag_28_sales: 11677.43\n",
      "store_city_features: 10859.43\n",
      "sum_21_promo: 9854.46\n",
      "mean_4_dow0_2017: 7484.58\n",
      "std_6_sales: 7277.67\n",
      "promo_2: 6953.86\n",
      "mean_4_dow1_2017: 6426.20\n",
      "std_3_sales: 5777.87\n",
      "mean_20_dow2_2017: 5504.48\n",
      "promo_9: 5497.98\n",
      "lag_6_sales: 4878.60\n",
      "lag_42_sales: 4477.56\n",
      "sum_5_promo: 4127.31\n",
      "std_5_sales: 4120.14\n",
      "mean_20_dow4_2017: 3660.64\n",
      "lag_21_sales: 3436.93\n",
      "promo_10: 3306.21\n",
      "lag_49_sales: 3286.98\n",
      "std_4_sales: 3170.40\n",
      "mean_4_dow3_2017: 3145.60\n",
      "lag_63_sales: 2940.26\n",
      "promo_11: 2871.62\n",
      "lag_5_sales: 2512.62\n",
      "promo_15: 2365.54\n",
      "lag_4_sales: 1839.04\n",
      "promo_12: 1825.17\n",
      "promo_8: 1640.55\n",
      "lag_14_sales: 1466.44\n",
      "mean_4_dow2_2017: 1433.99\n",
      "lag_35_sales: 1429.08\n",
      "store_state_features: 846.77\n",
      "lag_7_sales: 844.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 7/16 [20:24<26:11, 174.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.07003\tvalid_1's l2: 1.16028\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.00523\tvalid_1's l2: 1.09296\n",
      "[3]\ttraining's l2: 0.944224\tvalid_1's l2: 1.02958\n",
      "[4]\ttraining's l2: 0.889055\tvalid_1's l2: 0.971868\n",
      "[5]\ttraining's l2: 0.839076\tvalid_1's l2: 0.919784\n",
      "[6]\ttraining's l2: 0.79565\tvalid_1's l2: 0.873716\n",
      "[7]\ttraining's l2: 0.754539\tvalid_1's l2: 0.830509\n",
      "[8]\ttraining's l2: 0.719107\tvalid_1's l2: 0.792679\n",
      "[9]\ttraining's l2: 0.685146\tvalid_1's l2: 0.756975\n",
      "[10]\ttraining's l2: 0.655836\tvalid_1's l2: 0.725487\n",
      "[11]\ttraining's l2: 0.629282\tvalid_1's l2: 0.696891\n",
      "[12]\ttraining's l2: 0.605334\tvalid_1's l2: 0.671052\n",
      "[13]\ttraining's l2: 0.581996\tvalid_1's l2: 0.646089\n",
      "[14]\ttraining's l2: 0.560838\tvalid_1's l2: 0.623402\n",
      "[15]\ttraining's l2: 0.542962\tvalid_1's l2: 0.603713\n",
      "[16]\ttraining's l2: 0.525377\tvalid_1's l2: 0.584809\n",
      "[17]\ttraining's l2: 0.509579\tvalid_1's l2: 0.567735\n",
      "[18]\ttraining's l2: 0.496319\tvalid_1's l2: 0.552704\n",
      "[19]\ttraining's l2: 0.483076\tvalid_1's l2: 0.53828\n",
      "[20]\ttraining's l2: 0.471086\tvalid_1's l2: 0.525249\n",
      "[21]\ttraining's l2: 0.460168\tvalid_1's l2: 0.513357\n",
      "[22]\ttraining's l2: 0.450436\tvalid_1's l2: 0.5025\n",
      "[23]\ttraining's l2: 0.441442\tvalid_1's l2: 0.492441\n",
      "[24]\ttraining's l2: 0.434005\tvalid_1's l2: 0.483716\n",
      "[25]\ttraining's l2: 0.42648\tvalid_1's l2: 0.475298\n",
      "[26]\ttraining's l2: 0.419685\tvalid_1's l2: 0.467485\n",
      "[27]\ttraining's l2: 0.413483\tvalid_1's l2: 0.460301\n",
      "[28]\ttraining's l2: 0.408447\tvalid_1's l2: 0.454305\n",
      "[29]\ttraining's l2: 0.403215\tvalid_1's l2: 0.448208\n",
      "[30]\ttraining's l2: 0.398495\tvalid_1's l2: 0.442856\n",
      "[31]\ttraining's l2: 0.394659\tvalid_1's l2: 0.43811\n",
      "[32]\ttraining's l2: 0.390634\tvalid_1's l2: 0.433454\n",
      "[33]\ttraining's l2: 0.386994\tvalid_1's l2: 0.429153\n",
      "[34]\ttraining's l2: 0.383666\tvalid_1's l2: 0.425035\n",
      "[35]\ttraining's l2: 0.380621\tvalid_1's l2: 0.421337\n",
      "[36]\ttraining's l2: 0.377859\tvalid_1's l2: 0.417893\n",
      "[37]\ttraining's l2: 0.375382\tvalid_1's l2: 0.414812\n",
      "[38]\ttraining's l2: 0.373348\tvalid_1's l2: 0.412193\n",
      "[39]\ttraining's l2: 0.371184\tvalid_1's l2: 0.409513\n",
      "[40]\ttraining's l2: 0.369199\tvalid_1's l2: 0.407001\n",
      "[41]\ttraining's l2: 0.367664\tvalid_1's l2: 0.404953\n",
      "[42]\ttraining's l2: 0.365923\tvalid_1's l2: 0.402741\n",
      "[43]\ttraining's l2: 0.364346\tvalid_1's l2: 0.400693\n",
      "[44]\ttraining's l2: 0.362908\tvalid_1's l2: 0.398794\n",
      "[45]\ttraining's l2: 0.361526\tvalid_1's l2: 0.397029\n",
      "[46]\ttraining's l2: 0.360316\tvalid_1's l2: 0.395292\n",
      "[47]\ttraining's l2: 0.35936\tvalid_1's l2: 0.393988\n",
      "[48]\ttraining's l2: 0.358195\tvalid_1's l2: 0.392482\n",
      "[49]\ttraining's l2: 0.357182\tvalid_1's l2: 0.391222\n",
      "[50]\ttraining's l2: 0.356274\tvalid_1's l2: 0.39\n",
      "[51]\ttraining's l2: 0.355436\tvalid_1's l2: 0.388816\n",
      "[52]\ttraining's l2: 0.354637\tvalid_1's l2: 0.387709\n",
      "[53]\ttraining's l2: 0.353895\tvalid_1's l2: 0.386716\n",
      "[54]\ttraining's l2: 0.353171\tvalid_1's l2: 0.385771\n",
      "[55]\ttraining's l2: 0.352547\tvalid_1's l2: 0.385002\n",
      "[56]\ttraining's l2: 0.351932\tvalid_1's l2: 0.384181\n",
      "[57]\ttraining's l2: 0.351476\tvalid_1's l2: 0.383504\n",
      "[58]\ttraining's l2: 0.350882\tvalid_1's l2: 0.382693\n",
      "[59]\ttraining's l2: 0.350374\tvalid_1's l2: 0.382046\n",
      "[60]\ttraining's l2: 0.349986\tvalid_1's l2: 0.381541\n",
      "[61]\ttraining's l2: 0.349503\tvalid_1's l2: 0.380835\n",
      "[62]\ttraining's l2: 0.34912\tvalid_1's l2: 0.380311\n",
      "[63]\ttraining's l2: 0.348827\tvalid_1's l2: 0.379875\n",
      "[64]\ttraining's l2: 0.348554\tvalid_1's l2: 0.379498\n",
      "[65]\ttraining's l2: 0.348147\tvalid_1's l2: 0.378903\n",
      "[66]\ttraining's l2: 0.34789\tvalid_1's l2: 0.378561\n",
      "[67]\ttraining's l2: 0.347501\tvalid_1's l2: 0.378058\n",
      "[68]\ttraining's l2: 0.347163\tvalid_1's l2: 0.377666\n",
      "[69]\ttraining's l2: 0.346944\tvalid_1's l2: 0.377353\n",
      "[70]\ttraining's l2: 0.346732\tvalid_1's l2: 0.377072\n",
      "[71]\ttraining's l2: 0.346463\tvalid_1's l2: 0.376737\n",
      "[72]\ttraining's l2: 0.346247\tvalid_1's l2: 0.37646\n",
      "[73]\ttraining's l2: 0.346066\tvalid_1's l2: 0.376222\n",
      "[74]\ttraining's l2: 0.345714\tvalid_1's l2: 0.375767\n",
      "[75]\ttraining's l2: 0.34541\tvalid_1's l2: 0.375354\n",
      "[76]\ttraining's l2: 0.345128\tvalid_1's l2: 0.375036\n",
      "[77]\ttraining's l2: 0.344872\tvalid_1's l2: 0.374658\n",
      "[78]\ttraining's l2: 0.344629\tvalid_1's l2: 0.374357\n",
      "[79]\ttraining's l2: 0.344363\tvalid_1's l2: 0.373996\n",
      "[80]\ttraining's l2: 0.344116\tvalid_1's l2: 0.373679\n",
      "[81]\ttraining's l2: 0.343983\tvalid_1's l2: 0.373493\n",
      "[82]\ttraining's l2: 0.343807\tvalid_1's l2: 0.373291\n",
      "[83]\ttraining's l2: 0.343616\tvalid_1's l2: 0.373073\n",
      "[84]\ttraining's l2: 0.34349\tvalid_1's l2: 0.37287\n",
      "[85]\ttraining's l2: 0.343366\tvalid_1's l2: 0.372739\n",
      "[86]\ttraining's l2: 0.343176\tvalid_1's l2: 0.372538\n",
      "[87]\ttraining's l2: 0.343013\tvalid_1's l2: 0.372357\n",
      "[88]\ttraining's l2: 0.342855\tvalid_1's l2: 0.372147\n",
      "[89]\ttraining's l2: 0.342724\tvalid_1's l2: 0.37201\n",
      "[90]\ttraining's l2: 0.342551\tvalid_1's l2: 0.371874\n",
      "[91]\ttraining's l2: 0.342424\tvalid_1's l2: 0.371758\n",
      "[92]\ttraining's l2: 0.342287\tvalid_1's l2: 0.371617\n",
      "[93]\ttraining's l2: 0.342139\tvalid_1's l2: 0.371423\n",
      "[94]\ttraining's l2: 0.341997\tvalid_1's l2: 0.371294\n",
      "[95]\ttraining's l2: 0.341858\tvalid_1's l2: 0.371154\n",
      "[96]\ttraining's l2: 0.341679\tvalid_1's l2: 0.370995\n",
      "[97]\ttraining's l2: 0.341556\tvalid_1's l2: 0.370886\n",
      "[98]\ttraining's l2: 0.341457\tvalid_1's l2: 0.370836\n",
      "[99]\ttraining's l2: 0.341348\tvalid_1's l2: 0.370751\n",
      "[100]\ttraining's l2: 0.34126\tvalid_1's l2: 0.370642\n",
      "[101]\ttraining's l2: 0.341132\tvalid_1's l2: 0.370479\n",
      "[102]\ttraining's l2: 0.341029\tvalid_1's l2: 0.370359\n",
      "[103]\ttraining's l2: 0.340932\tvalid_1's l2: 0.370265\n",
      "[104]\ttraining's l2: 0.340824\tvalid_1's l2: 0.370102\n",
      "[105]\ttraining's l2: 0.340669\tvalid_1's l2: 0.369979\n",
      "[106]\ttraining's l2: 0.340563\tvalid_1's l2: 0.369856\n",
      "[107]\ttraining's l2: 0.340475\tvalid_1's l2: 0.369749\n",
      "[108]\ttraining's l2: 0.340393\tvalid_1's l2: 0.369667\n",
      "[109]\ttraining's l2: 0.340246\tvalid_1's l2: 0.369549\n",
      "[110]\ttraining's l2: 0.340163\tvalid_1's l2: 0.369473\n",
      "[111]\ttraining's l2: 0.340087\tvalid_1's l2: 0.369355\n",
      "[112]\ttraining's l2: 0.339981\tvalid_1's l2: 0.369253\n",
      "[113]\ttraining's l2: 0.339903\tvalid_1's l2: 0.369145\n",
      "[114]\ttraining's l2: 0.339778\tvalid_1's l2: 0.369017\n",
      "[115]\ttraining's l2: 0.339722\tvalid_1's l2: 0.369\n",
      "[116]\ttraining's l2: 0.339655\tvalid_1's l2: 0.368937\n",
      "[117]\ttraining's l2: 0.33959\tvalid_1's l2: 0.368922\n",
      "[118]\ttraining's l2: 0.339471\tvalid_1's l2: 0.368823\n",
      "[119]\ttraining's l2: 0.339355\tvalid_1's l2: 0.368729\n",
      "[120]\ttraining's l2: 0.339243\tvalid_1's l2: 0.368621\n",
      "[121]\ttraining's l2: 0.339166\tvalid_1's l2: 0.368568\n",
      "[122]\ttraining's l2: 0.339084\tvalid_1's l2: 0.368536\n",
      "[123]\ttraining's l2: 0.339007\tvalid_1's l2: 0.368461\n",
      "[124]\ttraining's l2: 0.33893\tvalid_1's l2: 0.36841\n",
      "[125]\ttraining's l2: 0.338849\tvalid_1's l2: 0.368359\n",
      "[126]\ttraining's l2: 0.338791\tvalid_1's l2: 0.36836\n",
      "[127]\ttraining's l2: 0.33873\tvalid_1's l2: 0.368263\n",
      "[128]\ttraining's l2: 0.338662\tvalid_1's l2: 0.368242\n",
      "[129]\ttraining's l2: 0.33861\tvalid_1's l2: 0.368188\n",
      "[130]\ttraining's l2: 0.338532\tvalid_1's l2: 0.36813\n",
      "[131]\ttraining's l2: 0.338473\tvalid_1's l2: 0.368095\n",
      "[132]\ttraining's l2: 0.338388\tvalid_1's l2: 0.368016\n",
      "[133]\ttraining's l2: 0.338292\tvalid_1's l2: 0.367994\n",
      "[134]\ttraining's l2: 0.338204\tvalid_1's l2: 0.367936\n",
      "[135]\ttraining's l2: 0.338148\tvalid_1's l2: 0.367898\n",
      "[136]\ttraining's l2: 0.338088\tvalid_1's l2: 0.367825\n",
      "[137]\ttraining's l2: 0.338003\tvalid_1's l2: 0.36775\n",
      "[138]\ttraining's l2: 0.337943\tvalid_1's l2: 0.367672\n",
      "[139]\ttraining's l2: 0.337893\tvalid_1's l2: 0.367649\n",
      "[140]\ttraining's l2: 0.337841\tvalid_1's l2: 0.367643\n",
      "[141]\ttraining's l2: 0.337787\tvalid_1's l2: 0.367615\n",
      "[142]\ttraining's l2: 0.337732\tvalid_1's l2: 0.36761\n",
      "[143]\ttraining's l2: 0.337686\tvalid_1's l2: 0.367607\n",
      "[144]\ttraining's l2: 0.337634\tvalid_1's l2: 0.367571\n",
      "[145]\ttraining's l2: 0.337572\tvalid_1's l2: 0.367553\n",
      "[146]\ttraining's l2: 0.337524\tvalid_1's l2: 0.367531\n",
      "[147]\ttraining's l2: 0.337471\tvalid_1's l2: 0.367458\n",
      "[148]\ttraining's l2: 0.33742\tvalid_1's l2: 0.367478\n",
      "[149]\ttraining's l2: 0.337372\tvalid_1's l2: 0.367457\n",
      "[150]\ttraining's l2: 0.33732\tvalid_1's l2: 0.367439\n",
      "[151]\ttraining's l2: 0.337265\tvalid_1's l2: 0.367381\n",
      "[152]\ttraining's l2: 0.337205\tvalid_1's l2: 0.367389\n",
      "[153]\ttraining's l2: 0.337144\tvalid_1's l2: 0.367353\n",
      "[154]\ttraining's l2: 0.337091\tvalid_1's l2: 0.367267\n",
      "[155]\ttraining's l2: 0.337022\tvalid_1's l2: 0.367199\n",
      "[156]\ttraining's l2: 0.336983\tvalid_1's l2: 0.367182\n",
      "[157]\ttraining's l2: 0.336935\tvalid_1's l2: 0.367173\n",
      "[158]\ttraining's l2: 0.336851\tvalid_1's l2: 0.367123\n",
      "[159]\ttraining's l2: 0.336799\tvalid_1's l2: 0.367072\n",
      "[160]\ttraining's l2: 0.336775\tvalid_1's l2: 0.367073\n",
      "[161]\ttraining's l2: 0.336721\tvalid_1's l2: 0.367042\n",
      "[162]\ttraining's l2: 0.336653\tvalid_1's l2: 0.367024\n",
      "[163]\ttraining's l2: 0.336594\tvalid_1's l2: 0.366958\n",
      "[164]\ttraining's l2: 0.336545\tvalid_1's l2: 0.36695\n",
      "[165]\ttraining's l2: 0.33649\tvalid_1's l2: 0.366925\n",
      "[166]\ttraining's l2: 0.336435\tvalid_1's l2: 0.366905\n",
      "[167]\ttraining's l2: 0.336368\tvalid_1's l2: 0.366906\n",
      "[168]\ttraining's l2: 0.336322\tvalid_1's l2: 0.366896\n",
      "[169]\ttraining's l2: 0.336277\tvalid_1's l2: 0.366879\n",
      "[170]\ttraining's l2: 0.33624\tvalid_1's l2: 0.366886\n",
      "[171]\ttraining's l2: 0.336203\tvalid_1's l2: 0.36688\n",
      "[172]\ttraining's l2: 0.336161\tvalid_1's l2: 0.36686\n",
      "[173]\ttraining's l2: 0.33611\tvalid_1's l2: 0.366792\n",
      "[174]\ttraining's l2: 0.336068\tvalid_1's l2: 0.366776\n",
      "[175]\ttraining's l2: 0.336035\tvalid_1's l2: 0.366774\n",
      "[176]\ttraining's l2: 0.335992\tvalid_1's l2: 0.366776\n",
      "[177]\ttraining's l2: 0.335963\tvalid_1's l2: 0.366751\n",
      "[178]\ttraining's l2: 0.33592\tvalid_1's l2: 0.366744\n",
      "[179]\ttraining's l2: 0.335862\tvalid_1's l2: 0.366725\n",
      "[180]\ttraining's l2: 0.335799\tvalid_1's l2: 0.366668\n",
      "[181]\ttraining's l2: 0.335762\tvalid_1's l2: 0.366653\n",
      "[182]\ttraining's l2: 0.335708\tvalid_1's l2: 0.366613\n",
      "[183]\ttraining's l2: 0.335656\tvalid_1's l2: 0.366558\n",
      "[184]\ttraining's l2: 0.33561\tvalid_1's l2: 0.366552\n",
      "[185]\ttraining's l2: 0.335578\tvalid_1's l2: 0.366526\n",
      "[186]\ttraining's l2: 0.335521\tvalid_1's l2: 0.366531\n",
      "[187]\ttraining's l2: 0.33548\tvalid_1's l2: 0.366513\n",
      "[188]\ttraining's l2: 0.33544\tvalid_1's l2: 0.366502\n",
      "[189]\ttraining's l2: 0.335396\tvalid_1's l2: 0.366499\n",
      "[190]\ttraining's l2: 0.335369\tvalid_1's l2: 0.366477\n",
      "[191]\ttraining's l2: 0.335313\tvalid_1's l2: 0.366461\n",
      "[192]\ttraining's l2: 0.335264\tvalid_1's l2: 0.366442\n",
      "[193]\ttraining's l2: 0.335234\tvalid_1's l2: 0.366434\n",
      "[194]\ttraining's l2: 0.335205\tvalid_1's l2: 0.366413\n",
      "[195]\ttraining's l2: 0.335174\tvalid_1's l2: 0.3664\n",
      "[196]\ttraining's l2: 0.335142\tvalid_1's l2: 0.36639\n",
      "[197]\ttraining's l2: 0.335073\tvalid_1's l2: 0.366331\n",
      "[198]\ttraining's l2: 0.335024\tvalid_1's l2: 0.366253\n",
      "[199]\ttraining's l2: 0.334998\tvalid_1's l2: 0.366234\n",
      "[200]\ttraining's l2: 0.334965\tvalid_1's l2: 0.366203\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.334965\tvalid_1's l2: 0.366203\n",
      "mean_14_sales: 14726393.07\n",
      "mean_7_sales: 10299550.50\n",
      "mean_21_sales: 7187389.79\n",
      "mean_30_sales: 5142832.67\n",
      "mean_20_dow0_2017: 3376317.56\n",
      "promo_7: 1945547.20\n",
      "mean_63_sales: 878288.81\n",
      "item_class_features: 418972.26\n",
      "mean_4_dow0_2017: 348299.58\n",
      "lag_1_sales: 286200.39\n",
      "mean_60_sales: 273742.88\n",
      "promo_0: 253266.74\n",
      "sum_7_promo: 201851.86\n",
      "std_30_sales: 158265.71\n",
      "mean_5_sales: 143633.59\n",
      "promo_14: 136975.38\n",
      "mean_6_sales: 112360.89\n",
      "item_family_features: 111944.78\n",
      "std_14_sales: 96310.29\n",
      "std_21_sales: 92501.93\n",
      "store_cluster_features: 88408.22\n",
      "lag_2_sales: 82578.49\n",
      "mean_3_sales: 82339.24\n",
      "sum_14_promo: 72522.21\n",
      "std_63_sales: 61667.17\n",
      "promo_6: 59888.50\n",
      "promo_8: 51143.93\n",
      "mean_4_sales: 48503.97\n",
      "lag_21_sales: 39200.88\n",
      "std_7_sales: 33930.56\n",
      "store_type_features: 31761.16\n",
      "mean_4_dow5_2017: 29350.61\n",
      "promo_5: 26585.53\n",
      "std_60_sales: 25569.81\n",
      "lag_56_sales: 24804.86\n",
      "promo_3: 23698.38\n",
      "lag_49_sales: 21912.47\n",
      "sum_21_promo: 21155.88\n",
      "mean_4_dow6_2017: 20491.26\n",
      "promo_9: 20410.99\n",
      "mean_20_dow3_2017: 18860.92\n",
      "mean_20_dow1_2017: 17411.65\n",
      "mean_20_dow2_2017: 16972.45\n",
      "promo_10: 14301.97\n",
      "mean_20_dow6_2017: 14133.87\n",
      "store_city_features: 12922.52\n",
      "sum_4_promo: 12862.42\n",
      "lag_7_sales: 11101.66\n",
      "lag_3_sales: 9661.79\n",
      "promo_4: 9454.22\n",
      "promo_13: 9112.41\n",
      "promo_2: 7754.02\n",
      "promo_12: 7669.66\n",
      "lag_28_sales: 7601.97\n",
      "sum_2_promo: 7278.86\n",
      "lag_35_sales: 5934.31\n",
      "promo_1: 5888.63\n",
      "sum_5_promo: 5702.77\n",
      "lag_6_sales: 5556.21\n",
      "lag_4_sales: 5303.67\n",
      "mean_4_dow4_2017: 5290.96\n",
      "lag_5_sales: 4991.85\n",
      "lag_42_sales: 4955.03\n",
      "mean_20_dow4_2017: 4882.49\n",
      "mean_20_dow5_2017: 4644.66\n",
      "std_4_sales: 4541.51\n",
      "promo_11: 4415.76\n",
      "std_5_sales: 4296.35\n",
      "std_3_sales: 4034.99\n",
      "sum_3_promo: 4034.42\n",
      "std_6_sales: 3478.21\n",
      "lag_63_sales: 3424.01\n",
      "promo_15: 2867.53\n",
      "lag_14_sales: 2698.06\n",
      "mean_4_dow3_2017: 2431.54\n",
      "sum_6_promo: 2133.49\n",
      "mean_4_dow1_2017: 2018.72\n",
      "store_state_features: 1466.81\n",
      "mean_4_dow2_2017: 1242.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 8/16 [23:29<23:42, 177.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.967382\tvalid_1's l2: 0.996903\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.911013\tvalid_1's l2: 0.940222\n",
      "[3]\ttraining's l2: 0.859977\tvalid_1's l2: 0.888418\n",
      "[4]\ttraining's l2: 0.815004\tvalid_1's l2: 0.842225\n",
      "[5]\ttraining's l2: 0.773196\tvalid_1's l2: 0.799516\n",
      "[6]\ttraining's l2: 0.735289\tvalid_1's l2: 0.761281\n",
      "[7]\ttraining's l2: 0.701091\tvalid_1's l2: 0.726081\n",
      "[8]\ttraining's l2: 0.670162\tvalid_1's l2: 0.694354\n",
      "[9]\ttraining's l2: 0.642185\tvalid_1's l2: 0.665582\n",
      "[10]\ttraining's l2: 0.61658\tvalid_1's l2: 0.639576\n",
      "[11]\ttraining's l2: 0.593407\tvalid_1's l2: 0.615763\n",
      "[12]\ttraining's l2: 0.572625\tvalid_1's l2: 0.59412\n",
      "[13]\ttraining's l2: 0.553717\tvalid_1's l2: 0.574509\n",
      "[14]\ttraining's l2: 0.536621\tvalid_1's l2: 0.556583\n",
      "[15]\ttraining's l2: 0.521024\tvalid_1's l2: 0.540504\n",
      "[16]\ttraining's l2: 0.506855\tvalid_1's l2: 0.525802\n",
      "[17]\ttraining's l2: 0.494114\tvalid_1's l2: 0.512628\n",
      "[18]\ttraining's l2: 0.482508\tvalid_1's l2: 0.500483\n",
      "[19]\ttraining's l2: 0.472016\tvalid_1's l2: 0.489401\n",
      "[20]\ttraining's l2: 0.462445\tvalid_1's l2: 0.479328\n",
      "[21]\ttraining's l2: 0.453983\tvalid_1's l2: 0.470323\n",
      "[22]\ttraining's l2: 0.446187\tvalid_1's l2: 0.462003\n",
      "[23]\ttraining's l2: 0.439042\tvalid_1's l2: 0.454349\n",
      "[24]\ttraining's l2: 0.432569\tvalid_1's l2: 0.447441\n",
      "[25]\ttraining's l2: 0.426666\tvalid_1's l2: 0.441058\n",
      "[26]\ttraining's l2: 0.421312\tvalid_1's l2: 0.435243\n",
      "[27]\ttraining's l2: 0.416459\tvalid_1's l2: 0.429928\n",
      "[28]\ttraining's l2: 0.412157\tvalid_1's l2: 0.425218\n",
      "[29]\ttraining's l2: 0.40811\tvalid_1's l2: 0.420753\n",
      "[30]\ttraining's l2: 0.404427\tvalid_1's l2: 0.416575\n",
      "[31]\ttraining's l2: 0.401085\tvalid_1's l2: 0.412869\n",
      "[32]\ttraining's l2: 0.398063\tvalid_1's l2: 0.409455\n",
      "[33]\ttraining's l2: 0.395278\tvalid_1's l2: 0.406337\n",
      "[34]\ttraining's l2: 0.392715\tvalid_1's l2: 0.403475\n",
      "[35]\ttraining's l2: 0.390411\tvalid_1's l2: 0.400866\n",
      "[36]\ttraining's l2: 0.388332\tvalid_1's l2: 0.398504\n",
      "[37]\ttraining's l2: 0.386429\tvalid_1's l2: 0.396312\n",
      "[38]\ttraining's l2: 0.384685\tvalid_1's l2: 0.39438\n",
      "[39]\ttraining's l2: 0.38302\tvalid_1's l2: 0.392425\n",
      "[40]\ttraining's l2: 0.381459\tvalid_1's l2: 0.390596\n",
      "[41]\ttraining's l2: 0.380131\tvalid_1's l2: 0.38909\n",
      "[42]\ttraining's l2: 0.378863\tvalid_1's l2: 0.38756\n",
      "[43]\ttraining's l2: 0.377682\tvalid_1's l2: 0.386107\n",
      "[44]\ttraining's l2: 0.376529\tvalid_1's l2: 0.38477\n",
      "[45]\ttraining's l2: 0.375535\tvalid_1's l2: 0.383593\n",
      "[46]\ttraining's l2: 0.374646\tvalid_1's l2: 0.38253\n",
      "[47]\ttraining's l2: 0.373804\tvalid_1's l2: 0.381534\n",
      "[48]\ttraining's l2: 0.372955\tvalid_1's l2: 0.380538\n",
      "[49]\ttraining's l2: 0.372176\tvalid_1's l2: 0.379649\n",
      "[50]\ttraining's l2: 0.371428\tvalid_1's l2: 0.378802\n",
      "[51]\ttraining's l2: 0.370736\tvalid_1's l2: 0.377969\n",
      "[52]\ttraining's l2: 0.370124\tvalid_1's l2: 0.37725\n",
      "[53]\ttraining's l2: 0.369509\tvalid_1's l2: 0.376536\n",
      "[54]\ttraining's l2: 0.368923\tvalid_1's l2: 0.375868\n",
      "[55]\ttraining's l2: 0.368434\tvalid_1's l2: 0.375318\n",
      "[56]\ttraining's l2: 0.367952\tvalid_1's l2: 0.374727\n",
      "[57]\ttraining's l2: 0.367514\tvalid_1's l2: 0.374174\n",
      "[58]\ttraining's l2: 0.367064\tvalid_1's l2: 0.373613\n",
      "[59]\ttraining's l2: 0.366659\tvalid_1's l2: 0.373128\n",
      "[60]\ttraining's l2: 0.366295\tvalid_1's l2: 0.3727\n",
      "[61]\ttraining's l2: 0.365931\tvalid_1's l2: 0.372268\n",
      "[62]\ttraining's l2: 0.36559\tvalid_1's l2: 0.371918\n",
      "[63]\ttraining's l2: 0.365297\tvalid_1's l2: 0.371551\n",
      "[64]\ttraining's l2: 0.365007\tvalid_1's l2: 0.371237\n",
      "[65]\ttraining's l2: 0.364665\tvalid_1's l2: 0.370853\n",
      "[66]\ttraining's l2: 0.364435\tvalid_1's l2: 0.370581\n",
      "[67]\ttraining's l2: 0.364151\tvalid_1's l2: 0.370332\n",
      "[68]\ttraining's l2: 0.363864\tvalid_1's l2: 0.36997\n",
      "[69]\ttraining's l2: 0.363624\tvalid_1's l2: 0.369699\n",
      "[70]\ttraining's l2: 0.36339\tvalid_1's l2: 0.369473\n",
      "[71]\ttraining's l2: 0.363111\tvalid_1's l2: 0.369185\n",
      "[72]\ttraining's l2: 0.362868\tvalid_1's l2: 0.368959\n",
      "[73]\ttraining's l2: 0.362676\tvalid_1's l2: 0.368747\n",
      "[74]\ttraining's l2: 0.362484\tvalid_1's l2: 0.368543\n",
      "[75]\ttraining's l2: 0.362138\tvalid_1's l2: 0.368232\n",
      "[76]\ttraining's l2: 0.3619\tvalid_1's l2: 0.367977\n",
      "[77]\ttraining's l2: 0.361695\tvalid_1's l2: 0.367758\n",
      "[78]\ttraining's l2: 0.361482\tvalid_1's l2: 0.367616\n",
      "[79]\ttraining's l2: 0.361271\tvalid_1's l2: 0.36747\n",
      "[80]\ttraining's l2: 0.36109\tvalid_1's l2: 0.36726\n",
      "[81]\ttraining's l2: 0.36093\tvalid_1's l2: 0.367096\n",
      "[82]\ttraining's l2: 0.360732\tvalid_1's l2: 0.366892\n",
      "[83]\ttraining's l2: 0.360561\tvalid_1's l2: 0.366749\n",
      "[84]\ttraining's l2: 0.360408\tvalid_1's l2: 0.366626\n",
      "[85]\ttraining's l2: 0.360206\tvalid_1's l2: 0.366458\n",
      "[86]\ttraining's l2: 0.360015\tvalid_1's l2: 0.366294\n",
      "[87]\ttraining's l2: 0.359907\tvalid_1's l2: 0.3662\n",
      "[88]\ttraining's l2: 0.35977\tvalid_1's l2: 0.366074\n",
      "[89]\ttraining's l2: 0.359629\tvalid_1's l2: 0.365969\n",
      "[90]\ttraining's l2: 0.359497\tvalid_1's l2: 0.365857\n",
      "[91]\ttraining's l2: 0.359393\tvalid_1's l2: 0.36576\n",
      "[92]\ttraining's l2: 0.359262\tvalid_1's l2: 0.365596\n",
      "[93]\ttraining's l2: 0.359138\tvalid_1's l2: 0.365485\n",
      "[94]\ttraining's l2: 0.359013\tvalid_1's l2: 0.365399\n",
      "[95]\ttraining's l2: 0.358861\tvalid_1's l2: 0.365266\n",
      "[96]\ttraining's l2: 0.358717\tvalid_1's l2: 0.365168\n",
      "[97]\ttraining's l2: 0.35862\tvalid_1's l2: 0.365049\n",
      "[98]\ttraining's l2: 0.358461\tvalid_1's l2: 0.364874\n",
      "[99]\ttraining's l2: 0.358257\tvalid_1's l2: 0.364707\n",
      "[100]\ttraining's l2: 0.358101\tvalid_1's l2: 0.364627\n",
      "[101]\ttraining's l2: 0.357986\tvalid_1's l2: 0.364548\n",
      "[102]\ttraining's l2: 0.357832\tvalid_1's l2: 0.364409\n",
      "[103]\ttraining's l2: 0.357713\tvalid_1's l2: 0.364308\n",
      "[104]\ttraining's l2: 0.357624\tvalid_1's l2: 0.364226\n",
      "[105]\ttraining's l2: 0.3575\tvalid_1's l2: 0.364188\n",
      "[106]\ttraining's l2: 0.357365\tvalid_1's l2: 0.364093\n",
      "[107]\ttraining's l2: 0.357287\tvalid_1's l2: 0.364025\n",
      "[108]\ttraining's l2: 0.357189\tvalid_1's l2: 0.363914\n",
      "[109]\ttraining's l2: 0.35705\tvalid_1's l2: 0.363841\n",
      "[110]\ttraining's l2: 0.356956\tvalid_1's l2: 0.363785\n",
      "[111]\ttraining's l2: 0.356871\tvalid_1's l2: 0.363744\n",
      "[112]\ttraining's l2: 0.35681\tvalid_1's l2: 0.363701\n",
      "[113]\ttraining's l2: 0.356714\tvalid_1's l2: 0.363687\n",
      "[114]\ttraining's l2: 0.356607\tvalid_1's l2: 0.363596\n",
      "[115]\ttraining's l2: 0.356524\tvalid_1's l2: 0.363561\n",
      "[116]\ttraining's l2: 0.356446\tvalid_1's l2: 0.363503\n",
      "[117]\ttraining's l2: 0.356378\tvalid_1's l2: 0.363451\n",
      "[118]\ttraining's l2: 0.356313\tvalid_1's l2: 0.36342\n",
      "[119]\ttraining's l2: 0.356228\tvalid_1's l2: 0.363337\n",
      "[120]\ttraining's l2: 0.356156\tvalid_1's l2: 0.363311\n",
      "[121]\ttraining's l2: 0.356084\tvalid_1's l2: 0.363242\n",
      "[122]\ttraining's l2: 0.355999\tvalid_1's l2: 0.363184\n",
      "[123]\ttraining's l2: 0.355871\tvalid_1's l2: 0.363122\n",
      "[124]\ttraining's l2: 0.355798\tvalid_1's l2: 0.363091\n",
      "[125]\ttraining's l2: 0.35571\tvalid_1's l2: 0.363037\n",
      "[126]\ttraining's l2: 0.355631\tvalid_1's l2: 0.362988\n",
      "[127]\ttraining's l2: 0.355568\tvalid_1's l2: 0.362976\n",
      "[128]\ttraining's l2: 0.355474\tvalid_1's l2: 0.362886\n",
      "[129]\ttraining's l2: 0.355386\tvalid_1's l2: 0.362822\n",
      "[130]\ttraining's l2: 0.355347\tvalid_1's l2: 0.362806\n",
      "[131]\ttraining's l2: 0.355295\tvalid_1's l2: 0.362796\n",
      "[132]\ttraining's l2: 0.355232\tvalid_1's l2: 0.362777\n",
      "[133]\ttraining's l2: 0.355125\tvalid_1's l2: 0.362654\n",
      "[134]\ttraining's l2: 0.355076\tvalid_1's l2: 0.362628\n",
      "[135]\ttraining's l2: 0.354977\tvalid_1's l2: 0.362589\n",
      "[136]\ttraining's l2: 0.354898\tvalid_1's l2: 0.362548\n",
      "[137]\ttraining's l2: 0.354853\tvalid_1's l2: 0.36254\n",
      "[138]\ttraining's l2: 0.354811\tvalid_1's l2: 0.362537\n",
      "[139]\ttraining's l2: 0.354734\tvalid_1's l2: 0.362481\n",
      "[140]\ttraining's l2: 0.35467\tvalid_1's l2: 0.362446\n",
      "[141]\ttraining's l2: 0.354632\tvalid_1's l2: 0.362434\n",
      "[142]\ttraining's l2: 0.354587\tvalid_1's l2: 0.362413\n",
      "[143]\ttraining's l2: 0.354489\tvalid_1's l2: 0.362297\n",
      "[144]\ttraining's l2: 0.354448\tvalid_1's l2: 0.362282\n",
      "[145]\ttraining's l2: 0.354393\tvalid_1's l2: 0.362274\n",
      "[146]\ttraining's l2: 0.35434\tvalid_1's l2: 0.362222\n",
      "[147]\ttraining's l2: 0.354255\tvalid_1's l2: 0.362184\n",
      "[148]\ttraining's l2: 0.354216\tvalid_1's l2: 0.362155\n",
      "[149]\ttraining's l2: 0.35418\tvalid_1's l2: 0.362137\n",
      "[150]\ttraining's l2: 0.354123\tvalid_1's l2: 0.362115\n",
      "[151]\ttraining's l2: 0.354027\tvalid_1's l2: 0.361998\n",
      "[152]\ttraining's l2: 0.353978\tvalid_1's l2: 0.362006\n",
      "[153]\ttraining's l2: 0.353929\tvalid_1's l2: 0.361977\n",
      "[154]\ttraining's l2: 0.353898\tvalid_1's l2: 0.361965\n",
      "[155]\ttraining's l2: 0.353866\tvalid_1's l2: 0.361951\n",
      "[156]\ttraining's l2: 0.353813\tvalid_1's l2: 0.361944\n",
      "[157]\ttraining's l2: 0.35372\tvalid_1's l2: 0.361906\n",
      "[158]\ttraining's l2: 0.353642\tvalid_1's l2: 0.361879\n",
      "[159]\ttraining's l2: 0.353604\tvalid_1's l2: 0.361848\n",
      "[160]\ttraining's l2: 0.35357\tvalid_1's l2: 0.36184\n",
      "[161]\ttraining's l2: 0.35352\tvalid_1's l2: 0.361816\n",
      "[162]\ttraining's l2: 0.353471\tvalid_1's l2: 0.361806\n",
      "[163]\ttraining's l2: 0.35339\tvalid_1's l2: 0.361743\n",
      "[164]\ttraining's l2: 0.353355\tvalid_1's l2: 0.361732\n",
      "[165]\ttraining's l2: 0.353295\tvalid_1's l2: 0.361706\n",
      "[166]\ttraining's l2: 0.353257\tvalid_1's l2: 0.361688\n",
      "[167]\ttraining's l2: 0.35319\tvalid_1's l2: 0.361606\n",
      "[168]\ttraining's l2: 0.353123\tvalid_1's l2: 0.361536\n",
      "[169]\ttraining's l2: 0.353056\tvalid_1's l2: 0.361511\n",
      "[170]\ttraining's l2: 0.353015\tvalid_1's l2: 0.36149\n",
      "[171]\ttraining's l2: 0.352986\tvalid_1's l2: 0.361491\n",
      "[172]\ttraining's l2: 0.352917\tvalid_1's l2: 0.361459\n",
      "[173]\ttraining's l2: 0.352888\tvalid_1's l2: 0.361434\n",
      "[174]\ttraining's l2: 0.352847\tvalid_1's l2: 0.361422\n",
      "[175]\ttraining's l2: 0.3528\tvalid_1's l2: 0.361421\n",
      "[176]\ttraining's l2: 0.352756\tvalid_1's l2: 0.361405\n",
      "[177]\ttraining's l2: 0.352706\tvalid_1's l2: 0.361356\n",
      "[178]\ttraining's l2: 0.352653\tvalid_1's l2: 0.361345\n",
      "[179]\ttraining's l2: 0.352622\tvalid_1's l2: 0.361341\n",
      "[180]\ttraining's l2: 0.352565\tvalid_1's l2: 0.361327\n",
      "[181]\ttraining's l2: 0.352525\tvalid_1's l2: 0.361316\n",
      "[182]\ttraining's l2: 0.352475\tvalid_1's l2: 0.361315\n",
      "[183]\ttraining's l2: 0.352443\tvalid_1's l2: 0.361315\n",
      "[184]\ttraining's l2: 0.352399\tvalid_1's l2: 0.361302\n",
      "[185]\ttraining's l2: 0.352371\tvalid_1's l2: 0.361285\n",
      "[186]\ttraining's l2: 0.352325\tvalid_1's l2: 0.361261\n",
      "[187]\ttraining's l2: 0.352292\tvalid_1's l2: 0.361263\n",
      "[188]\ttraining's l2: 0.352256\tvalid_1's l2: 0.361247\n",
      "[189]\ttraining's l2: 0.352184\tvalid_1's l2: 0.361201\n",
      "[190]\ttraining's l2: 0.352138\tvalid_1's l2: 0.361166\n",
      "[191]\ttraining's l2: 0.352098\tvalid_1's l2: 0.361159\n",
      "[192]\ttraining's l2: 0.352062\tvalid_1's l2: 0.361142\n",
      "[193]\ttraining's l2: 0.352031\tvalid_1's l2: 0.361135\n",
      "[194]\ttraining's l2: 0.352003\tvalid_1's l2: 0.361127\n",
      "[195]\ttraining's l2: 0.351974\tvalid_1's l2: 0.361102\n",
      "[196]\ttraining's l2: 0.351935\tvalid_1's l2: 0.361102\n",
      "[197]\ttraining's l2: 0.351911\tvalid_1's l2: 0.361091\n",
      "[198]\ttraining's l2: 0.351878\tvalid_1's l2: 0.36107\n",
      "[199]\ttraining's l2: 0.351838\tvalid_1's l2: 0.361071\n",
      "[200]\ttraining's l2: 0.351811\tvalid_1's l2: 0.361059\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.351811\tvalid_1's l2: 0.361059\n",
      "mean_21_sales: 9251516.91\n",
      "mean_14_sales: 8150922.67\n",
      "mean_7_sales: 7299750.15\n",
      "mean_30_sales: 5396331.07\n",
      "mean_63_sales: 2587318.97\n",
      "mean_20_dow1_2017: 1807511.73\n",
      "promo_8: 1328920.62\n",
      "mean_6_sales: 1130181.79\n",
      "item_class_features: 372780.74\n",
      "mean_60_sales: 352921.00\n",
      "lag_1_sales: 231383.52\n",
      "mean_5_sales: 150000.23\n",
      "mean_20_dow2_2017: 139740.44\n",
      "std_30_sales: 116089.32\n",
      "sum_4_promo: 99146.06\n",
      "promo_7: 98206.75\n",
      "std_21_sales: 92469.38\n",
      "std_14_sales: 77104.99\n",
      "promo_10: 73293.38\n",
      "sum_6_promo: 68903.92\n",
      "mean_3_sales: 54433.30\n",
      "mean_4_dow1_2017: 46440.80\n",
      "mean_4_dow6_2017: 39979.69\n",
      "mean_4_sales: 39669.93\n",
      "item_family_features: 39608.21\n",
      "std_63_sales: 39090.37\n",
      "promo_9: 36751.56\n",
      "promo_12: 31061.26\n",
      "std_60_sales: 28074.13\n",
      "sum_7_promo: 27569.95\n",
      "sum_2_promo: 27020.30\n",
      "lag_21_sales: 26171.77\n",
      "promo_14: 24003.76\n",
      "store_city_features: 23667.79\n",
      "store_cluster_features: 20615.58\n",
      "sum_14_promo: 18930.13\n",
      "mean_20_dow0_2017: 18648.25\n",
      "std_7_sales: 17522.98\n",
      "lag_2_sales: 16392.49\n",
      "promo_11: 16074.54\n",
      "promo_1: 16054.67\n",
      "mean_20_dow3_2017: 15387.41\n",
      "mean_20_dow6_2017: 14562.92\n",
      "sum_5_promo: 14318.48\n",
      "lag_49_sales: 12831.17\n",
      "promo_6: 11877.43\n",
      "sum_3_promo: 11443.12\n",
      "promo_13: 11372.97\n",
      "lag_6_sales: 11319.32\n",
      "std_6_sales: 10385.14\n",
      "promo_0: 9671.14\n",
      "sum_21_promo: 9517.90\n",
      "promo_3: 9107.93\n",
      "lag_3_sales: 6903.68\n",
      "lag_5_sales: 6731.11\n",
      "promo_4: 4915.94\n",
      "promo_15: 4899.48\n",
      "mean_20_dow4_2017: 4429.45\n",
      "mean_4_dow4_2017: 4160.50\n",
      "lag_63_sales: 4114.57\n",
      "mean_4_dow0_2017: 3896.20\n",
      "lag_4_sales: 3417.42\n",
      "lag_56_sales: 3284.45\n",
      "std_4_sales: 3047.44\n",
      "lag_35_sales: 2901.97\n",
      "store_state_features: 2738.10\n",
      "std_5_sales: 2658.27\n",
      "mean_4_dow5_2017: 2482.65\n",
      "lag_7_sales: 2470.36\n",
      "promo_5: 2443.71\n",
      "promo_2: 2324.15\n",
      "lag_14_sales: 2296.66\n",
      "mean_4_dow2_2017: 2149.37\n",
      "lag_42_sales: 2140.09\n",
      "mean_4_dow3_2017: 1809.94\n",
      "store_type_features: 1780.19\n",
      "std_3_sales: 1690.06\n",
      "mean_20_dow5_2017: 1326.06\n",
      "lag_28_sales: 526.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▋    | 9/16 [26:21<20:31, 175.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.07044\tvalid_1's l2: 1.07298\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.00562\tvalid_1's l2: 1.00868\n",
      "[3]\ttraining's l2: 0.946523\tvalid_1's l2: 0.949516\n",
      "[4]\ttraining's l2: 0.893218\tvalid_1's l2: 0.896073\n",
      "[5]\ttraining's l2: 0.844858\tvalid_1's l2: 0.847643\n",
      "[6]\ttraining's l2: 0.800881\tvalid_1's l2: 0.803847\n",
      "[7]\ttraining's l2: 0.761353\tvalid_1's l2: 0.764074\n",
      "[8]\ttraining's l2: 0.725399\tvalid_1's l2: 0.72818\n",
      "[9]\ttraining's l2: 0.69299\tvalid_1's l2: 0.695741\n",
      "[10]\ttraining's l2: 0.664145\tvalid_1's l2: 0.66679\n",
      "[11]\ttraining's l2: 0.637281\tvalid_1's l2: 0.63961\n",
      "[12]\ttraining's l2: 0.613734\tvalid_1's l2: 0.616048\n",
      "[13]\ttraining's l2: 0.591541\tvalid_1's l2: 0.593754\n",
      "[14]\ttraining's l2: 0.571425\tvalid_1's l2: 0.573584\n",
      "[15]\ttraining's l2: 0.553205\tvalid_1's l2: 0.555183\n",
      "[16]\ttraining's l2: 0.536709\tvalid_1's l2: 0.538554\n",
      "[17]\ttraining's l2: 0.521742\tvalid_1's l2: 0.523283\n",
      "[18]\ttraining's l2: 0.508168\tvalid_1's l2: 0.509654\n",
      "[19]\ttraining's l2: 0.496161\tvalid_1's l2: 0.497417\n",
      "[20]\ttraining's l2: 0.484894\tvalid_1's l2: 0.485872\n",
      "[21]\ttraining's l2: 0.474584\tvalid_1's l2: 0.475391\n",
      "[22]\ttraining's l2: 0.465395\tvalid_1's l2: 0.465996\n",
      "[23]\ttraining's l2: 0.457277\tvalid_1's l2: 0.457667\n",
      "[24]\ttraining's l2: 0.4495\tvalid_1's l2: 0.449621\n",
      "[25]\ttraining's l2: 0.442494\tvalid_1's l2: 0.442384\n",
      "[26]\ttraining's l2: 0.436327\tvalid_1's l2: 0.436152\n",
      "[27]\ttraining's l2: 0.430732\tvalid_1's l2: 0.430407\n",
      "[28]\ttraining's l2: 0.425361\tvalid_1's l2: 0.424956\n",
      "[29]\ttraining's l2: 0.420445\tvalid_1's l2: 0.419818\n",
      "[30]\ttraining's l2: 0.41622\tvalid_1's l2: 0.415489\n",
      "[31]\ttraining's l2: 0.412085\tvalid_1's l2: 0.411123\n",
      "[32]\ttraining's l2: 0.408286\tvalid_1's l2: 0.40711\n",
      "[33]\ttraining's l2: 0.404799\tvalid_1's l2: 0.40352\n",
      "[34]\ttraining's l2: 0.4017\tvalid_1's l2: 0.4002\n",
      "[35]\ttraining's l2: 0.398862\tvalid_1's l2: 0.397211\n",
      "[36]\ttraining's l2: 0.396237\tvalid_1's l2: 0.394468\n",
      "[37]\ttraining's l2: 0.393821\tvalid_1's l2: 0.391944\n",
      "[38]\ttraining's l2: 0.391716\tvalid_1's l2: 0.389785\n",
      "[39]\ttraining's l2: 0.389733\tvalid_1's l2: 0.387712\n",
      "[40]\ttraining's l2: 0.387784\tvalid_1's l2: 0.385636\n",
      "[41]\ttraining's l2: 0.386062\tvalid_1's l2: 0.38381\n",
      "[42]\ttraining's l2: 0.38443\tvalid_1's l2: 0.382033\n",
      "[43]\ttraining's l2: 0.382928\tvalid_1's l2: 0.380432\n",
      "[44]\ttraining's l2: 0.381643\tvalid_1's l2: 0.379056\n",
      "[45]\ttraining's l2: 0.380369\tvalid_1's l2: 0.377775\n",
      "[46]\ttraining's l2: 0.379258\tvalid_1's l2: 0.376591\n",
      "[47]\ttraining's l2: 0.378183\tvalid_1's l2: 0.375484\n",
      "[48]\ttraining's l2: 0.377242\tvalid_1's l2: 0.374547\n",
      "[49]\ttraining's l2: 0.376362\tvalid_1's l2: 0.373627\n",
      "[50]\ttraining's l2: 0.375525\tvalid_1's l2: 0.37281\n",
      "[51]\ttraining's l2: 0.374648\tvalid_1's l2: 0.371904\n",
      "[52]\ttraining's l2: 0.373836\tvalid_1's l2: 0.370993\n",
      "[53]\ttraining's l2: 0.373056\tvalid_1's l2: 0.370134\n",
      "[54]\ttraining's l2: 0.372311\tvalid_1's l2: 0.369287\n",
      "[55]\ttraining's l2: 0.371668\tvalid_1's l2: 0.368636\n",
      "[56]\ttraining's l2: 0.371026\tvalid_1's l2: 0.367927\n",
      "[57]\ttraining's l2: 0.370561\tvalid_1's l2: 0.367416\n",
      "[58]\ttraining's l2: 0.370051\tvalid_1's l2: 0.366915\n",
      "[59]\ttraining's l2: 0.369609\tvalid_1's l2: 0.366455\n",
      "[60]\ttraining's l2: 0.369111\tvalid_1's l2: 0.366026\n",
      "[61]\ttraining's l2: 0.368645\tvalid_1's l2: 0.365555\n",
      "[62]\ttraining's l2: 0.368184\tvalid_1's l2: 0.365136\n",
      "[63]\ttraining's l2: 0.367749\tvalid_1's l2: 0.364649\n",
      "[64]\ttraining's l2: 0.367353\tvalid_1's l2: 0.3642\n",
      "[65]\ttraining's l2: 0.366973\tvalid_1's l2: 0.363746\n",
      "[66]\ttraining's l2: 0.366672\tvalid_1's l2: 0.363516\n",
      "[67]\ttraining's l2: 0.366307\tvalid_1's l2: 0.363243\n",
      "[68]\ttraining's l2: 0.365884\tvalid_1's l2: 0.362812\n",
      "[69]\ttraining's l2: 0.365529\tvalid_1's l2: 0.362459\n",
      "[70]\ttraining's l2: 0.365241\tvalid_1's l2: 0.362234\n",
      "[71]\ttraining's l2: 0.364948\tvalid_1's l2: 0.362012\n",
      "[72]\ttraining's l2: 0.364586\tvalid_1's l2: 0.361667\n",
      "[73]\ttraining's l2: 0.364264\tvalid_1's l2: 0.361335\n",
      "[74]\ttraining's l2: 0.363987\tvalid_1's l2: 0.361098\n",
      "[75]\ttraining's l2: 0.3637\tvalid_1's l2: 0.360892\n",
      "[76]\ttraining's l2: 0.363378\tvalid_1's l2: 0.360528\n",
      "[77]\ttraining's l2: 0.363134\tvalid_1's l2: 0.360312\n",
      "[78]\ttraining's l2: 0.362914\tvalid_1's l2: 0.36013\n",
      "[79]\ttraining's l2: 0.362708\tvalid_1's l2: 0.359998\n",
      "[80]\ttraining's l2: 0.362473\tvalid_1's l2: 0.35986\n",
      "[81]\ttraining's l2: 0.362275\tvalid_1's l2: 0.359693\n",
      "[82]\ttraining's l2: 0.362108\tvalid_1's l2: 0.359518\n",
      "[83]\ttraining's l2: 0.361929\tvalid_1's l2: 0.359345\n",
      "[84]\ttraining's l2: 0.361704\tvalid_1's l2: 0.359093\n",
      "[85]\ttraining's l2: 0.361533\tvalid_1's l2: 0.358983\n",
      "[86]\ttraining's l2: 0.361296\tvalid_1's l2: 0.358763\n",
      "[87]\ttraining's l2: 0.361089\tvalid_1's l2: 0.35851\n",
      "[88]\ttraining's l2: 0.360928\tvalid_1's l2: 0.3584\n",
      "[89]\ttraining's l2: 0.360661\tvalid_1's l2: 0.358165\n",
      "[90]\ttraining's l2: 0.360511\tvalid_1's l2: 0.358078\n",
      "[91]\ttraining's l2: 0.360352\tvalid_1's l2: 0.357987\n",
      "[92]\ttraining's l2: 0.36019\tvalid_1's l2: 0.357807\n",
      "[93]\ttraining's l2: 0.360044\tvalid_1's l2: 0.357688\n",
      "[94]\ttraining's l2: 0.359891\tvalid_1's l2: 0.357607\n",
      "[95]\ttraining's l2: 0.359755\tvalid_1's l2: 0.357526\n",
      "[96]\ttraining's l2: 0.359497\tvalid_1's l2: 0.35732\n",
      "[97]\ttraining's l2: 0.359331\tvalid_1's l2: 0.357141\n",
      "[98]\ttraining's l2: 0.359155\tvalid_1's l2: 0.356982\n",
      "[99]\ttraining's l2: 0.359006\tvalid_1's l2: 0.356922\n",
      "[100]\ttraining's l2: 0.358858\tvalid_1's l2: 0.356784\n",
      "[101]\ttraining's l2: 0.358716\tvalid_1's l2: 0.356636\n",
      "[102]\ttraining's l2: 0.358585\tvalid_1's l2: 0.356601\n",
      "[103]\ttraining's l2: 0.358464\tvalid_1's l2: 0.356492\n",
      "[104]\ttraining's l2: 0.358337\tvalid_1's l2: 0.35637\n",
      "[105]\ttraining's l2: 0.358219\tvalid_1's l2: 0.356266\n",
      "[106]\ttraining's l2: 0.358073\tvalid_1's l2: 0.356167\n",
      "[107]\ttraining's l2: 0.357945\tvalid_1's l2: 0.356074\n",
      "[108]\ttraining's l2: 0.357831\tvalid_1's l2: 0.355993\n",
      "[109]\ttraining's l2: 0.357736\tvalid_1's l2: 0.355952\n",
      "[110]\ttraining's l2: 0.357595\tvalid_1's l2: 0.355854\n",
      "[111]\ttraining's l2: 0.357493\tvalid_1's l2: 0.355775\n",
      "[112]\ttraining's l2: 0.357381\tvalid_1's l2: 0.355745\n",
      "[113]\ttraining's l2: 0.357238\tvalid_1's l2: 0.355645\n",
      "[114]\ttraining's l2: 0.357125\tvalid_1's l2: 0.355556\n",
      "[115]\ttraining's l2: 0.357055\tvalid_1's l2: 0.355509\n",
      "[116]\ttraining's l2: 0.356947\tvalid_1's l2: 0.355458\n",
      "[117]\ttraining's l2: 0.356831\tvalid_1's l2: 0.355374\n",
      "[118]\ttraining's l2: 0.356723\tvalid_1's l2: 0.355317\n",
      "[119]\ttraining's l2: 0.35663\tvalid_1's l2: 0.355285\n",
      "[120]\ttraining's l2: 0.356532\tvalid_1's l2: 0.355218\n",
      "[121]\ttraining's l2: 0.356467\tvalid_1's l2: 0.355162\n",
      "[122]\ttraining's l2: 0.356361\tvalid_1's l2: 0.355043\n",
      "[123]\ttraining's l2: 0.356298\tvalid_1's l2: 0.35498\n",
      "[124]\ttraining's l2: 0.356208\tvalid_1's l2: 0.354906\n",
      "[125]\ttraining's l2: 0.356155\tvalid_1's l2: 0.354886\n",
      "[126]\ttraining's l2: 0.356081\tvalid_1's l2: 0.35484\n",
      "[127]\ttraining's l2: 0.355989\tvalid_1's l2: 0.354785\n",
      "[128]\ttraining's l2: 0.35591\tvalid_1's l2: 0.354727\n",
      "[129]\ttraining's l2: 0.35585\tvalid_1's l2: 0.354684\n",
      "[130]\ttraining's l2: 0.355791\tvalid_1's l2: 0.354647\n",
      "[131]\ttraining's l2: 0.355685\tvalid_1's l2: 0.354621\n",
      "[132]\ttraining's l2: 0.355568\tvalid_1's l2: 0.354601\n",
      "[133]\ttraining's l2: 0.355501\tvalid_1's l2: 0.354575\n",
      "[134]\ttraining's l2: 0.355439\tvalid_1's l2: 0.354556\n",
      "[135]\ttraining's l2: 0.355318\tvalid_1's l2: 0.354474\n",
      "[136]\ttraining's l2: 0.35523\tvalid_1's l2: 0.354387\n",
      "[137]\ttraining's l2: 0.355182\tvalid_1's l2: 0.354359\n",
      "[138]\ttraining's l2: 0.355113\tvalid_1's l2: 0.354316\n",
      "[139]\ttraining's l2: 0.355054\tvalid_1's l2: 0.354304\n",
      "[140]\ttraining's l2: 0.354999\tvalid_1's l2: 0.354292\n",
      "[141]\ttraining's l2: 0.354907\tvalid_1's l2: 0.354275\n",
      "[142]\ttraining's l2: 0.354852\tvalid_1's l2: 0.354258\n",
      "[143]\ttraining's l2: 0.354788\tvalid_1's l2: 0.354207\n",
      "[144]\ttraining's l2: 0.354738\tvalid_1's l2: 0.354174\n",
      "[145]\ttraining's l2: 0.354662\tvalid_1's l2: 0.354113\n",
      "[146]\ttraining's l2: 0.354586\tvalid_1's l2: 0.354075\n",
      "[147]\ttraining's l2: 0.354544\tvalid_1's l2: 0.354053\n",
      "[148]\ttraining's l2: 0.354494\tvalid_1's l2: 0.354028\n",
      "[149]\ttraining's l2: 0.354419\tvalid_1's l2: 0.353995\n",
      "[150]\ttraining's l2: 0.354357\tvalid_1's l2: 0.353973\n",
      "[151]\ttraining's l2: 0.354301\tvalid_1's l2: 0.353918\n",
      "[152]\ttraining's l2: 0.354262\tvalid_1's l2: 0.353897\n",
      "[153]\ttraining's l2: 0.354217\tvalid_1's l2: 0.353883\n",
      "[154]\ttraining's l2: 0.354169\tvalid_1's l2: 0.353875\n",
      "[155]\ttraining's l2: 0.354135\tvalid_1's l2: 0.353865\n",
      "[156]\ttraining's l2: 0.354077\tvalid_1's l2: 0.353845\n",
      "[157]\ttraining's l2: 0.354012\tvalid_1's l2: 0.353805\n",
      "[158]\ttraining's l2: 0.353966\tvalid_1's l2: 0.35378\n",
      "[159]\ttraining's l2: 0.353906\tvalid_1's l2: 0.353721\n",
      "[160]\ttraining's l2: 0.353856\tvalid_1's l2: 0.3537\n",
      "[161]\ttraining's l2: 0.353806\tvalid_1's l2: 0.353685\n",
      "[162]\ttraining's l2: 0.353749\tvalid_1's l2: 0.353672\n",
      "[163]\ttraining's l2: 0.353694\tvalid_1's l2: 0.353645\n",
      "[164]\ttraining's l2: 0.353656\tvalid_1's l2: 0.353599\n",
      "[165]\ttraining's l2: 0.35358\tvalid_1's l2: 0.353523\n",
      "[166]\ttraining's l2: 0.353514\tvalid_1's l2: 0.353506\n",
      "[167]\ttraining's l2: 0.353467\tvalid_1's l2: 0.353493\n",
      "[168]\ttraining's l2: 0.353392\tvalid_1's l2: 0.353455\n",
      "[169]\ttraining's l2: 0.353344\tvalid_1's l2: 0.353424\n",
      "[170]\ttraining's l2: 0.353299\tvalid_1's l2: 0.353403\n",
      "[171]\ttraining's l2: 0.353269\tvalid_1's l2: 0.353373\n",
      "[172]\ttraining's l2: 0.353199\tvalid_1's l2: 0.353376\n",
      "[173]\ttraining's l2: 0.353173\tvalid_1's l2: 0.353361\n",
      "[174]\ttraining's l2: 0.353122\tvalid_1's l2: 0.353337\n",
      "[175]\ttraining's l2: 0.353069\tvalid_1's l2: 0.353305\n",
      "[176]\ttraining's l2: 0.353024\tvalid_1's l2: 0.35328\n",
      "[177]\ttraining's l2: 0.352982\tvalid_1's l2: 0.353265\n",
      "[178]\ttraining's l2: 0.352945\tvalid_1's l2: 0.353253\n",
      "[179]\ttraining's l2: 0.352897\tvalid_1's l2: 0.353257\n",
      "[180]\ttraining's l2: 0.352859\tvalid_1's l2: 0.353249\n",
      "[181]\ttraining's l2: 0.35281\tvalid_1's l2: 0.353242\n",
      "[182]\ttraining's l2: 0.352744\tvalid_1's l2: 0.353223\n",
      "[183]\ttraining's l2: 0.352697\tvalid_1's l2: 0.353171\n",
      "[184]\ttraining's l2: 0.352618\tvalid_1's l2: 0.353112\n",
      "[185]\ttraining's l2: 0.352565\tvalid_1's l2: 0.353047\n",
      "[186]\ttraining's l2: 0.35253\tvalid_1's l2: 0.353039\n",
      "[187]\ttraining's l2: 0.352488\tvalid_1's l2: 0.353035\n",
      "[188]\ttraining's l2: 0.352454\tvalid_1's l2: 0.353028\n",
      "[189]\ttraining's l2: 0.352429\tvalid_1's l2: 0.35301\n",
      "[190]\ttraining's l2: 0.352392\tvalid_1's l2: 0.352982\n",
      "[191]\ttraining's l2: 0.352348\tvalid_1's l2: 0.352955\n",
      "[192]\ttraining's l2: 0.352288\tvalid_1's l2: 0.352922\n",
      "[193]\ttraining's l2: 0.352249\tvalid_1's l2: 0.352905\n",
      "[194]\ttraining's l2: 0.352216\tvalid_1's l2: 0.352895\n",
      "[195]\ttraining's l2: 0.352186\tvalid_1's l2: 0.35289\n",
      "[196]\ttraining's l2: 0.352145\tvalid_1's l2: 0.352892\n",
      "[197]\ttraining's l2: 0.352089\tvalid_1's l2: 0.352866\n",
      "[198]\ttraining's l2: 0.352062\tvalid_1's l2: 0.352845\n",
      "[199]\ttraining's l2: 0.352037\tvalid_1's l2: 0.352832\n",
      "[200]\ttraining's l2: 0.351998\tvalid_1's l2: 0.352828\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.351998\tvalid_1's l2: 0.352828\n",
      "mean_21_sales: 14422330.16\n",
      "mean_14_sales: 6844071.26\n",
      "mean_7_sales: 6722890.01\n",
      "mean_20_dow2_2017: 6257780.28\n",
      "mean_30_sales: 3252636.87\n",
      "mean_6_sales: 1796813.25\n",
      "promo_9: 1666942.25\n",
      "mean_4_dow2_2017: 936016.82\n",
      "item_class_features: 655973.18\n",
      "mean_63_sales: 646596.25\n",
      "mean_5_sales: 549369.85\n",
      "mean_60_sales: 258199.96\n",
      "sum_5_promo: 190108.15\n",
      "std_30_sales: 171223.24\n",
      "std_21_sales: 138460.55\n",
      "lag_1_sales: 132055.10\n",
      "promo_10: 121009.87\n",
      "item_family_features: 115747.68\n",
      "store_cluster_features: 103803.60\n",
      "std_14_sales: 91425.13\n",
      "mean_20_dow1_2017: 79951.90\n",
      "std_63_sales: 78986.07\n",
      "promo_14: 74478.42\n",
      "promo_7: 67514.85\n",
      "promo_8: 62142.65\n",
      "lag_5_sales: 59039.83\n",
      "promo_2: 55716.00\n",
      "std_60_sales: 43657.42\n",
      "mean_4_sales: 42943.12\n",
      "promo_12: 41762.84\n",
      "lag_49_sales: 31682.98\n",
      "sum_4_promo: 30627.32\n",
      "mean_3_sales: 27767.67\n",
      "promo_11: 26201.79\n",
      "sum_6_promo: 24500.08\n",
      "store_city_features: 24246.46\n",
      "mean_20_dow3_2017: 19811.70\n",
      "sum_7_promo: 19351.95\n",
      "mean_20_dow0_2017: 17829.40\n",
      "promo_13: 17212.84\n",
      "sum_14_promo: 16986.20\n",
      "sum_2_promo: 15743.54\n",
      "std_5_sales: 15285.56\n",
      "sum_3_promo: 14269.01\n",
      "store_type_features: 14141.13\n",
      "lag_21_sales: 13254.00\n",
      "std_6_sales: 11867.86\n",
      "std_7_sales: 10243.80\n",
      "mean_20_dow4_2017: 8634.47\n",
      "promo_15: 8275.56\n",
      "lag_63_sales: 7296.11\n",
      "sum_21_promo: 6284.67\n",
      "mean_4_dow0_2017: 5346.34\n",
      "promo_6: 5324.89\n",
      "lag_4_sales: 5283.72\n",
      "lag_6_sales: 5266.70\n",
      "store_state_features: 4740.95\n",
      "lag_3_sales: 4618.98\n",
      "lag_56_sales: 4011.77\n",
      "promo_0: 3993.26\n",
      "lag_2_sales: 3356.90\n",
      "mean_4_dow3_2017: 3332.79\n",
      "lag_42_sales: 2970.17\n",
      "mean_20_dow5_2017: 2941.31\n",
      "lag_14_sales: 2728.72\n",
      "mean_4_dow4_2017: 2533.18\n",
      "mean_4_dow1_2017: 2270.20\n",
      "mean_20_dow6_2017: 2172.91\n",
      "promo_3: 1956.29\n",
      "mean_4_dow6_2017: 1602.75\n",
      "promo_1: 1575.43\n",
      "std_4_sales: 1562.18\n",
      "lag_35_sales: 1540.76\n",
      "lag_7_sales: 996.44\n",
      "std_3_sales: 804.06\n",
      "promo_4: 303.08\n",
      "lag_28_sales: 301.01\n",
      "mean_4_dow5_2017: 240.47\n",
      "promo_5: 162.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▎   | 10/16 [29:11<17:24, 174.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.19382\tvalid_1's l2: 1.14372\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.11906\tvalid_1's l2: 1.07066\n",
      "[3]\ttraining's l2: 1.05176\tvalid_1's l2: 1.00505\n",
      "[4]\ttraining's l2: 0.990856\tvalid_1's l2: 0.945437\n",
      "[5]\ttraining's l2: 0.936269\tvalid_1's l2: 0.892257\n",
      "[6]\ttraining's l2: 0.885953\tvalid_1's l2: 0.843242\n",
      "[7]\ttraining's l2: 0.841211\tvalid_1's l2: 0.799543\n",
      "[8]\ttraining's l2: 0.799959\tvalid_1's l2: 0.759422\n",
      "[9]\ttraining's l2: 0.76272\tvalid_1's l2: 0.723289\n",
      "[10]\ttraining's l2: 0.728871\tvalid_1's l2: 0.690633\n",
      "[11]\ttraining's l2: 0.698337\tvalid_1's l2: 0.661102\n",
      "[12]\ttraining's l2: 0.670549\tvalid_1's l2: 0.634355\n",
      "[13]\ttraining's l2: 0.645531\tvalid_1's l2: 0.610284\n",
      "[14]\ttraining's l2: 0.622811\tvalid_1's l2: 0.588406\n",
      "[15]\ttraining's l2: 0.602523\tvalid_1's l2: 0.568997\n",
      "[16]\ttraining's l2: 0.583798\tvalid_1's l2: 0.551033\n",
      "[17]\ttraining's l2: 0.566837\tvalid_1's l2: 0.534738\n",
      "[18]\ttraining's l2: 0.551371\tvalid_1's l2: 0.51988\n",
      "[19]\ttraining's l2: 0.53765\tvalid_1's l2: 0.50671\n",
      "[20]\ttraining's l2: 0.525032\tvalid_1's l2: 0.494828\n",
      "[21]\ttraining's l2: 0.513537\tvalid_1's l2: 0.483883\n",
      "[22]\ttraining's l2: 0.503318\tvalid_1's l2: 0.474221\n",
      "[23]\ttraining's l2: 0.493768\tvalid_1's l2: 0.465143\n",
      "[24]\ttraining's l2: 0.485355\tvalid_1's l2: 0.457216\n",
      "[25]\ttraining's l2: 0.477403\tvalid_1's l2: 0.449563\n",
      "[26]\ttraining's l2: 0.470242\tvalid_1's l2: 0.442756\n",
      "[27]\ttraining's l2: 0.463695\tvalid_1's l2: 0.436562\n",
      "[28]\ttraining's l2: 0.457765\tvalid_1's l2: 0.430968\n",
      "[29]\ttraining's l2: 0.452401\tvalid_1's l2: 0.425928\n",
      "[30]\ttraining's l2: 0.447493\tvalid_1's l2: 0.421249\n",
      "[31]\ttraining's l2: 0.443071\tvalid_1's l2: 0.417115\n",
      "[32]\ttraining's l2: 0.438994\tvalid_1's l2: 0.413293\n",
      "[33]\ttraining's l2: 0.435251\tvalid_1's l2: 0.409862\n",
      "[34]\ttraining's l2: 0.431875\tvalid_1's l2: 0.406727\n",
      "[35]\ttraining's l2: 0.42881\tvalid_1's l2: 0.403863\n",
      "[36]\ttraining's l2: 0.42599\tvalid_1's l2: 0.401205\n",
      "[37]\ttraining's l2: 0.423419\tvalid_1's l2: 0.398783\n",
      "[38]\ttraining's l2: 0.421088\tvalid_1's l2: 0.396661\n",
      "[39]\ttraining's l2: 0.418927\tvalid_1's l2: 0.394694\n",
      "[40]\ttraining's l2: 0.416958\tvalid_1's l2: 0.392924\n",
      "[41]\ttraining's l2: 0.415102\tvalid_1's l2: 0.391222\n",
      "[42]\ttraining's l2: 0.413369\tvalid_1's l2: 0.389599\n",
      "[43]\ttraining's l2: 0.411784\tvalid_1's l2: 0.38815\n",
      "[44]\ttraining's l2: 0.41036\tvalid_1's l2: 0.386848\n",
      "[45]\ttraining's l2: 0.409087\tvalid_1's l2: 0.385785\n",
      "[46]\ttraining's l2: 0.407913\tvalid_1's l2: 0.384708\n",
      "[47]\ttraining's l2: 0.406827\tvalid_1's l2: 0.383791\n",
      "[48]\ttraining's l2: 0.405782\tvalid_1's l2: 0.382816\n",
      "[49]\ttraining's l2: 0.404831\tvalid_1's l2: 0.382004\n",
      "[50]\ttraining's l2: 0.403942\tvalid_1's l2: 0.381244\n",
      "[51]\ttraining's l2: 0.403072\tvalid_1's l2: 0.38047\n",
      "[52]\ttraining's l2: 0.40228\tvalid_1's l2: 0.379806\n",
      "[53]\ttraining's l2: 0.401522\tvalid_1's l2: 0.379123\n",
      "[54]\ttraining's l2: 0.400849\tvalid_1's l2: 0.378564\n",
      "[55]\ttraining's l2: 0.400155\tvalid_1's l2: 0.377896\n",
      "[56]\ttraining's l2: 0.399555\tvalid_1's l2: 0.377392\n",
      "[57]\ttraining's l2: 0.399061\tvalid_1's l2: 0.377006\n",
      "[58]\ttraining's l2: 0.398545\tvalid_1's l2: 0.376596\n",
      "[59]\ttraining's l2: 0.398014\tvalid_1's l2: 0.376095\n",
      "[60]\ttraining's l2: 0.397581\tvalid_1's l2: 0.37573\n",
      "[61]\ttraining's l2: 0.397103\tvalid_1's l2: 0.375288\n",
      "[62]\ttraining's l2: 0.396619\tvalid_1's l2: 0.374925\n",
      "[63]\ttraining's l2: 0.396181\tvalid_1's l2: 0.374504\n",
      "[64]\ttraining's l2: 0.395797\tvalid_1's l2: 0.37418\n",
      "[65]\ttraining's l2: 0.395432\tvalid_1's l2: 0.373858\n",
      "[66]\ttraining's l2: 0.395134\tvalid_1's l2: 0.373597\n",
      "[67]\ttraining's l2: 0.394762\tvalid_1's l2: 0.373303\n",
      "[68]\ttraining's l2: 0.394461\tvalid_1's l2: 0.373113\n",
      "[69]\ttraining's l2: 0.394189\tvalid_1's l2: 0.372888\n",
      "[70]\ttraining's l2: 0.393892\tvalid_1's l2: 0.372637\n",
      "[71]\ttraining's l2: 0.393552\tvalid_1's l2: 0.372448\n",
      "[72]\ttraining's l2: 0.393259\tvalid_1's l2: 0.372236\n",
      "[73]\ttraining's l2: 0.392968\tvalid_1's l2: 0.371982\n",
      "[74]\ttraining's l2: 0.392691\tvalid_1's l2: 0.37176\n",
      "[75]\ttraining's l2: 0.392405\tvalid_1's l2: 0.371602\n",
      "[76]\ttraining's l2: 0.392103\tvalid_1's l2: 0.37134\n",
      "[77]\ttraining's l2: 0.391814\tvalid_1's l2: 0.371064\n",
      "[78]\ttraining's l2: 0.391527\tvalid_1's l2: 0.370843\n",
      "[79]\ttraining's l2: 0.3913\tvalid_1's l2: 0.370666\n",
      "[80]\ttraining's l2: 0.391059\tvalid_1's l2: 0.370492\n",
      "[81]\ttraining's l2: 0.390834\tvalid_1's l2: 0.370317\n",
      "[82]\ttraining's l2: 0.390617\tvalid_1's l2: 0.370119\n",
      "[83]\ttraining's l2: 0.390406\tvalid_1's l2: 0.370022\n",
      "[84]\ttraining's l2: 0.39021\tvalid_1's l2: 0.369933\n",
      "[85]\ttraining's l2: 0.38999\tvalid_1's l2: 0.369784\n",
      "[86]\ttraining's l2: 0.389837\tvalid_1's l2: 0.36968\n",
      "[87]\ttraining's l2: 0.38962\tvalid_1's l2: 0.369518\n",
      "[88]\ttraining's l2: 0.389458\tvalid_1's l2: 0.369348\n",
      "[89]\ttraining's l2: 0.389208\tvalid_1's l2: 0.36916\n",
      "[90]\ttraining's l2: 0.389016\tvalid_1's l2: 0.36906\n",
      "[91]\ttraining's l2: 0.388848\tvalid_1's l2: 0.368933\n",
      "[92]\ttraining's l2: 0.388677\tvalid_1's l2: 0.368831\n",
      "[93]\ttraining's l2: 0.388544\tvalid_1's l2: 0.368708\n",
      "[94]\ttraining's l2: 0.388381\tvalid_1's l2: 0.368603\n",
      "[95]\ttraining's l2: 0.388251\tvalid_1's l2: 0.368505\n",
      "[96]\ttraining's l2: 0.388095\tvalid_1's l2: 0.368415\n",
      "[97]\ttraining's l2: 0.387972\tvalid_1's l2: 0.368336\n",
      "[98]\ttraining's l2: 0.387739\tvalid_1's l2: 0.368144\n",
      "[99]\ttraining's l2: 0.387575\tvalid_1's l2: 0.368084\n",
      "[100]\ttraining's l2: 0.38745\tvalid_1's l2: 0.367986\n",
      "[101]\ttraining's l2: 0.387326\tvalid_1's l2: 0.367911\n",
      "[102]\ttraining's l2: 0.38713\tvalid_1's l2: 0.367836\n",
      "[103]\ttraining's l2: 0.38696\tvalid_1's l2: 0.367704\n",
      "[104]\ttraining's l2: 0.386803\tvalid_1's l2: 0.36755\n",
      "[105]\ttraining's l2: 0.386681\tvalid_1's l2: 0.367507\n",
      "[106]\ttraining's l2: 0.38655\tvalid_1's l2: 0.367441\n",
      "[107]\ttraining's l2: 0.386447\tvalid_1's l2: 0.367348\n",
      "[108]\ttraining's l2: 0.386367\tvalid_1's l2: 0.367301\n",
      "[109]\ttraining's l2: 0.386175\tvalid_1's l2: 0.367191\n",
      "[110]\ttraining's l2: 0.386076\tvalid_1's l2: 0.36714\n",
      "[111]\ttraining's l2: 0.386008\tvalid_1's l2: 0.367088\n",
      "[112]\ttraining's l2: 0.385812\tvalid_1's l2: 0.366955\n",
      "[113]\ttraining's l2: 0.385726\tvalid_1's l2: 0.366929\n",
      "[114]\ttraining's l2: 0.385506\tvalid_1's l2: 0.366776\n",
      "[115]\ttraining's l2: 0.385422\tvalid_1's l2: 0.36673\n",
      "[116]\ttraining's l2: 0.385346\tvalid_1's l2: 0.366712\n",
      "[117]\ttraining's l2: 0.385165\tvalid_1's l2: 0.366548\n",
      "[118]\ttraining's l2: 0.385084\tvalid_1's l2: 0.366505\n",
      "[119]\ttraining's l2: 0.384894\tvalid_1's l2: 0.366377\n",
      "[120]\ttraining's l2: 0.384798\tvalid_1's l2: 0.366337\n",
      "[121]\ttraining's l2: 0.384723\tvalid_1's l2: 0.366312\n",
      "[122]\ttraining's l2: 0.384593\tvalid_1's l2: 0.366207\n",
      "[123]\ttraining's l2: 0.384452\tvalid_1's l2: 0.366129\n",
      "[124]\ttraining's l2: 0.384386\tvalid_1's l2: 0.366112\n",
      "[125]\ttraining's l2: 0.384221\tvalid_1's l2: 0.36605\n",
      "[126]\ttraining's l2: 0.384139\tvalid_1's l2: 0.366007\n",
      "[127]\ttraining's l2: 0.384045\tvalid_1's l2: 0.365946\n",
      "[128]\ttraining's l2: 0.383963\tvalid_1's l2: 0.365908\n",
      "[129]\ttraining's l2: 0.38391\tvalid_1's l2: 0.365876\n",
      "[130]\ttraining's l2: 0.383855\tvalid_1's l2: 0.365861\n",
      "[131]\ttraining's l2: 0.383716\tvalid_1's l2: 0.365803\n",
      "[132]\ttraining's l2: 0.383558\tvalid_1's l2: 0.365735\n",
      "[133]\ttraining's l2: 0.38351\tvalid_1's l2: 0.365716\n",
      "[134]\ttraining's l2: 0.383446\tvalid_1's l2: 0.365702\n",
      "[135]\ttraining's l2: 0.383318\tvalid_1's l2: 0.365662\n",
      "[136]\ttraining's l2: 0.383262\tvalid_1's l2: 0.365633\n",
      "[137]\ttraining's l2: 0.383207\tvalid_1's l2: 0.365604\n",
      "[138]\ttraining's l2: 0.383059\tvalid_1's l2: 0.365554\n",
      "[139]\ttraining's l2: 0.38292\tvalid_1's l2: 0.365508\n",
      "[140]\ttraining's l2: 0.382825\tvalid_1's l2: 0.365451\n",
      "[141]\ttraining's l2: 0.382708\tvalid_1's l2: 0.365393\n",
      "[142]\ttraining's l2: 0.382616\tvalid_1's l2: 0.365339\n",
      "[143]\ttraining's l2: 0.38256\tvalid_1's l2: 0.365321\n",
      "[144]\ttraining's l2: 0.382473\tvalid_1's l2: 0.365253\n",
      "[145]\ttraining's l2: 0.38241\tvalid_1's l2: 0.365211\n",
      "[146]\ttraining's l2: 0.382316\tvalid_1's l2: 0.365176\n",
      "[147]\ttraining's l2: 0.382253\tvalid_1's l2: 0.365161\n",
      "[148]\ttraining's l2: 0.382195\tvalid_1's l2: 0.365149\n",
      "[149]\ttraining's l2: 0.382108\tvalid_1's l2: 0.365138\n",
      "[150]\ttraining's l2: 0.382048\tvalid_1's l2: 0.365128\n",
      "[151]\ttraining's l2: 0.381961\tvalid_1's l2: 0.365072\n",
      "[152]\ttraining's l2: 0.381915\tvalid_1's l2: 0.365034\n",
      "[153]\ttraining's l2: 0.381876\tvalid_1's l2: 0.365013\n",
      "[154]\ttraining's l2: 0.381831\tvalid_1's l2: 0.364993\n",
      "[155]\ttraining's l2: 0.381718\tvalid_1's l2: 0.364913\n",
      "[156]\ttraining's l2: 0.381671\tvalid_1's l2: 0.364892\n",
      "[157]\ttraining's l2: 0.381635\tvalid_1's l2: 0.364872\n",
      "[158]\ttraining's l2: 0.381531\tvalid_1's l2: 0.364827\n",
      "[159]\ttraining's l2: 0.381474\tvalid_1's l2: 0.364784\n",
      "[160]\ttraining's l2: 0.381434\tvalid_1's l2: 0.364769\n",
      "[161]\ttraining's l2: 0.381319\tvalid_1's l2: 0.364699\n",
      "[162]\ttraining's l2: 0.381257\tvalid_1's l2: 0.364682\n",
      "[163]\ttraining's l2: 0.381209\tvalid_1's l2: 0.364674\n",
      "[164]\ttraining's l2: 0.381139\tvalid_1's l2: 0.364627\n",
      "[165]\ttraining's l2: 0.381099\tvalid_1's l2: 0.364603\n",
      "[166]\ttraining's l2: 0.381026\tvalid_1's l2: 0.364574\n",
      "[167]\ttraining's l2: 0.38094\tvalid_1's l2: 0.364527\n",
      "[168]\ttraining's l2: 0.380906\tvalid_1's l2: 0.364501\n",
      "[169]\ttraining's l2: 0.380811\tvalid_1's l2: 0.364475\n",
      "[170]\ttraining's l2: 0.380765\tvalid_1's l2: 0.364431\n",
      "[171]\ttraining's l2: 0.380721\tvalid_1's l2: 0.364411\n",
      "[172]\ttraining's l2: 0.380655\tvalid_1's l2: 0.364387\n",
      "[173]\ttraining's l2: 0.380607\tvalid_1's l2: 0.36436\n",
      "[174]\ttraining's l2: 0.380551\tvalid_1's l2: 0.364334\n",
      "[175]\ttraining's l2: 0.380498\tvalid_1's l2: 0.364286\n",
      "[176]\ttraining's l2: 0.380463\tvalid_1's l2: 0.364274\n",
      "[177]\ttraining's l2: 0.380413\tvalid_1's l2: 0.364235\n",
      "[178]\ttraining's l2: 0.380361\tvalid_1's l2: 0.364208\n",
      "[179]\ttraining's l2: 0.380291\tvalid_1's l2: 0.364177\n",
      "[180]\ttraining's l2: 0.380245\tvalid_1's l2: 0.364145\n",
      "[181]\ttraining's l2: 0.380191\tvalid_1's l2: 0.364132\n",
      "[182]\ttraining's l2: 0.380152\tvalid_1's l2: 0.364114\n",
      "[183]\ttraining's l2: 0.380061\tvalid_1's l2: 0.364079\n",
      "[184]\ttraining's l2: 0.380033\tvalid_1's l2: 0.364072\n",
      "[185]\ttraining's l2: 0.379984\tvalid_1's l2: 0.364043\n",
      "[186]\ttraining's l2: 0.379937\tvalid_1's l2: 0.364023\n",
      "[187]\ttraining's l2: 0.379887\tvalid_1's l2: 0.364017\n",
      "[188]\ttraining's l2: 0.379848\tvalid_1's l2: 0.363997\n",
      "[189]\ttraining's l2: 0.379802\tvalid_1's l2: 0.363994\n",
      "[190]\ttraining's l2: 0.379763\tvalid_1's l2: 0.363964\n",
      "[191]\ttraining's l2: 0.379699\tvalid_1's l2: 0.363947\n",
      "[192]\ttraining's l2: 0.379651\tvalid_1's l2: 0.363938\n",
      "[193]\ttraining's l2: 0.379613\tvalid_1's l2: 0.363915\n",
      "[194]\ttraining's l2: 0.379584\tvalid_1's l2: 0.363892\n",
      "[195]\ttraining's l2: 0.379547\tvalid_1's l2: 0.363863\n",
      "[196]\ttraining's l2: 0.379509\tvalid_1's l2: 0.363852\n",
      "[197]\ttraining's l2: 0.379463\tvalid_1's l2: 0.363829\n",
      "[198]\ttraining's l2: 0.379422\tvalid_1's l2: 0.363809\n",
      "[199]\ttraining's l2: 0.379369\tvalid_1's l2: 0.363802\n",
      "[200]\ttraining's l2: 0.379319\tvalid_1's l2: 0.363778\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.379319\tvalid_1's l2: 0.363778\n",
      "mean_21_sales: 18494214.85\n",
      "mean_14_sales: 6668018.64\n",
      "mean_6_sales: 5660833.53\n",
      "mean_20_dow3_2017: 3948952.96\n",
      "mean_30_sales: 3918979.30\n",
      "mean_5_sales: 3203490.10\n",
      "mean_60_sales: 2854381.70\n",
      "mean_7_sales: 2594045.32\n",
      "promo_10: 1286132.19\n",
      "mean_4_dow3_2017: 1001577.33\n",
      "mean_4_sales: 577513.75\n",
      "item_class_features: 460680.90\n",
      "std_21_sales: 166415.78\n",
      "std_30_sales: 162445.82\n",
      "sum_4_promo: 135723.73\n",
      "mean_63_sales: 131442.80\n",
      "std_14_sales: 98511.07\n",
      "promo_14: 95224.49\n",
      "store_cluster_features: 76248.20\n",
      "promo_9: 66559.95\n",
      "promo_7: 66331.84\n",
      "promo_12: 56040.84\n",
      "item_family_features: 52143.91\n",
      "promo_13: 43173.29\n",
      "std_63_sales: 41028.77\n",
      "promo_11: 38624.05\n",
      "store_city_features: 37670.06\n",
      "promo_8: 35982.54\n",
      "lag_4_sales: 33836.86\n",
      "lag_3_sales: 30885.23\n",
      "sum_2_promo: 29121.53\n",
      "std_60_sales: 28649.10\n",
      "mean_3_sales: 28514.21\n",
      "sum_6_promo: 26457.53\n",
      "lag_1_sales: 25233.56\n",
      "promo_3: 23281.62\n",
      "sum_3_promo: 22264.26\n",
      "sum_7_promo: 21229.48\n",
      "sum_14_promo: 20767.59\n",
      "mean_20_dow0_2017: 17279.34\n",
      "mean_20_dow4_2017: 17003.52\n",
      "mean_20_dow2_2017: 15937.37\n",
      "std_5_sales: 12834.32\n",
      "sum_5_promo: 12586.62\n",
      "lag_49_sales: 9959.23\n",
      "lag_21_sales: 9049.74\n",
      "std_4_sales: 8945.50\n",
      "std_3_sales: 8455.59\n",
      "sum_21_promo: 8187.17\n",
      "mean_20_dow1_2017: 6967.34\n",
      "promo_6: 6835.08\n",
      "store_type_features: 6403.38\n",
      "lag_63_sales: 6342.74\n",
      "store_state_features: 6328.39\n",
      "std_7_sales: 6120.41\n",
      "mean_20_dow6_2017: 5989.33\n",
      "lag_5_sales: 4418.21\n",
      "std_6_sales: 3465.82\n",
      "mean_4_dow0_2017: 3391.28\n",
      "promo_2: 3194.56\n",
      "lag_14_sales: 2725.91\n",
      "promo_15: 2630.47\n",
      "mean_4_dow4_2017: 2522.43\n",
      "mean_4_dow6_2017: 2419.43\n",
      "lag_6_sales: 2372.09\n",
      "lag_56_sales: 2168.39\n",
      "promo_0: 2159.28\n",
      "mean_4_dow1_2017: 2150.11\n",
      "lag_2_sales: 2127.25\n",
      "mean_4_dow2_2017: 1567.83\n",
      "lag_35_sales: 1305.99\n",
      "lag_42_sales: 1259.32\n",
      "mean_20_dow5_2017: 1232.94\n",
      "promo_4: 1218.11\n",
      "lag_7_sales: 1133.13\n",
      "promo_1: 516.74\n",
      "promo_5: 515.24\n",
      "mean_4_dow5_2017: 366.99\n",
      "lag_28_sales: 179.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 11/16 [31:57<14:19, 171.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.26198\tvalid_1's l2: 1.21428\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.18959\tvalid_1's l2: 1.1393\n",
      "[3]\ttraining's l2: 1.1241\tvalid_1's l2: 1.07124\n",
      "[4]\ttraining's l2: 1.06472\tvalid_1's l2: 1.00939\n",
      "[5]\ttraining's l2: 1.01119\tvalid_1's l2: 0.953765\n",
      "[6]\ttraining's l2: 0.962481\tvalid_1's l2: 0.902896\n",
      "[7]\ttraining's l2: 0.919341\tvalid_1's l2: 0.857838\n",
      "[8]\ttraining's l2: 0.87915\tvalid_1's l2: 0.816046\n",
      "[9]\ttraining's l2: 0.843772\tvalid_1's l2: 0.778949\n",
      "[10]\ttraining's l2: 0.811726\tvalid_1's l2: 0.745126\n",
      "[11]\ttraining's l2: 0.781382\tvalid_1's l2: 0.713972\n",
      "[12]\ttraining's l2: 0.755143\tvalid_1's l2: 0.686188\n",
      "[13]\ttraining's l2: 0.730226\tvalid_1's l2: 0.660616\n",
      "[14]\ttraining's l2: 0.707496\tvalid_1's l2: 0.637043\n",
      "[15]\ttraining's l2: 0.687046\tvalid_1's l2: 0.615873\n",
      "[16]\ttraining's l2: 0.66827\tvalid_1's l2: 0.596736\n",
      "[17]\ttraining's l2: 0.651376\tvalid_1's l2: 0.579009\n",
      "[18]\ttraining's l2: 0.636677\tvalid_1's l2: 0.563734\n",
      "[19]\ttraining's l2: 0.622682\tvalid_1's l2: 0.549592\n",
      "[20]\ttraining's l2: 0.609961\tvalid_1's l2: 0.535989\n",
      "[21]\ttraining's l2: 0.599008\tvalid_1's l2: 0.524461\n",
      "[22]\ttraining's l2: 0.588943\tvalid_1's l2: 0.51358\n",
      "[23]\ttraining's l2: 0.579123\tvalid_1's l2: 0.503415\n",
      "[24]\ttraining's l2: 0.570358\tvalid_1's l2: 0.494291\n",
      "[25]\ttraining's l2: 0.562232\tvalid_1's l2: 0.485861\n",
      "[26]\ttraining's l2: 0.554812\tvalid_1's l2: 0.478126\n",
      "[27]\ttraining's l2: 0.548491\tvalid_1's l2: 0.471324\n",
      "[28]\ttraining's l2: 0.542691\tvalid_1's l2: 0.465232\n",
      "[29]\ttraining's l2: 0.537005\tvalid_1's l2: 0.459391\n",
      "[30]\ttraining's l2: 0.531677\tvalid_1's l2: 0.454008\n",
      "[31]\ttraining's l2: 0.527326\tvalid_1's l2: 0.449345\n",
      "[32]\ttraining's l2: 0.523261\tvalid_1's l2: 0.445018\n",
      "[33]\ttraining's l2: 0.51907\tvalid_1's l2: 0.440567\n",
      "[34]\ttraining's l2: 0.515256\tvalid_1's l2: 0.43674\n",
      "[35]\ttraining's l2: 0.511855\tvalid_1's l2: 0.433166\n",
      "[36]\ttraining's l2: 0.50869\tvalid_1's l2: 0.429913\n",
      "[37]\ttraining's l2: 0.506094\tvalid_1's l2: 0.426982\n",
      "[38]\ttraining's l2: 0.503405\tvalid_1's l2: 0.424325\n",
      "[39]\ttraining's l2: 0.50099\tvalid_1's l2: 0.421767\n",
      "[40]\ttraining's l2: 0.498723\tvalid_1's l2: 0.419511\n",
      "[41]\ttraining's l2: 0.496629\tvalid_1's l2: 0.417276\n",
      "[42]\ttraining's l2: 0.494611\tvalid_1's l2: 0.415117\n",
      "[43]\ttraining's l2: 0.492918\tvalid_1's l2: 0.413299\n",
      "[44]\ttraining's l2: 0.491196\tvalid_1's l2: 0.411534\n",
      "[45]\ttraining's l2: 0.489711\tvalid_1's l2: 0.409893\n",
      "[46]\ttraining's l2: 0.488229\tvalid_1's l2: 0.40836\n",
      "[47]\ttraining's l2: 0.486941\tvalid_1's l2: 0.407131\n",
      "[48]\ttraining's l2: 0.485668\tvalid_1's l2: 0.405805\n",
      "[49]\ttraining's l2: 0.484561\tvalid_1's l2: 0.404596\n",
      "[50]\ttraining's l2: 0.483341\tvalid_1's l2: 0.403392\n",
      "[51]\ttraining's l2: 0.482319\tvalid_1's l2: 0.402305\n",
      "[52]\ttraining's l2: 0.481377\tvalid_1's l2: 0.401367\n",
      "[53]\ttraining's l2: 0.48051\tvalid_1's l2: 0.400371\n",
      "[54]\ttraining's l2: 0.479711\tvalid_1's l2: 0.399433\n",
      "[55]\ttraining's l2: 0.478977\tvalid_1's l2: 0.398535\n",
      "[56]\ttraining's l2: 0.478328\tvalid_1's l2: 0.397845\n",
      "[57]\ttraining's l2: 0.477587\tvalid_1's l2: 0.397131\n",
      "[58]\ttraining's l2: 0.476885\tvalid_1's l2: 0.396344\n",
      "[59]\ttraining's l2: 0.476242\tvalid_1's l2: 0.395685\n",
      "[60]\ttraining's l2: 0.475595\tvalid_1's l2: 0.395108\n",
      "[61]\ttraining's l2: 0.475062\tvalid_1's l2: 0.394507\n",
      "[62]\ttraining's l2: 0.474443\tvalid_1's l2: 0.393991\n",
      "[63]\ttraining's l2: 0.473883\tvalid_1's l2: 0.393318\n",
      "[64]\ttraining's l2: 0.47343\tvalid_1's l2: 0.392753\n",
      "[65]\ttraining's l2: 0.472833\tvalid_1's l2: 0.392115\n",
      "[66]\ttraining's l2: 0.472421\tvalid_1's l2: 0.391702\n",
      "[67]\ttraining's l2: 0.471911\tvalid_1's l2: 0.391346\n",
      "[68]\ttraining's l2: 0.471444\tvalid_1's l2: 0.390907\n",
      "[69]\ttraining's l2: 0.470954\tvalid_1's l2: 0.390498\n",
      "[70]\ttraining's l2: 0.470409\tvalid_1's l2: 0.389992\n",
      "[71]\ttraining's l2: 0.470084\tvalid_1's l2: 0.389701\n",
      "[72]\ttraining's l2: 0.469587\tvalid_1's l2: 0.389284\n",
      "[73]\ttraining's l2: 0.46926\tvalid_1's l2: 0.38892\n",
      "[74]\ttraining's l2: 0.46881\tvalid_1's l2: 0.388567\n",
      "[75]\ttraining's l2: 0.46838\tvalid_1's l2: 0.388211\n",
      "[76]\ttraining's l2: 0.468007\tvalid_1's l2: 0.387901\n",
      "[77]\ttraining's l2: 0.467702\tvalid_1's l2: 0.387537\n",
      "[78]\ttraining's l2: 0.467403\tvalid_1's l2: 0.387274\n",
      "[79]\ttraining's l2: 0.467054\tvalid_1's l2: 0.38697\n",
      "[80]\ttraining's l2: 0.466751\tvalid_1's l2: 0.386718\n",
      "[81]\ttraining's l2: 0.466427\tvalid_1's l2: 0.386467\n",
      "[82]\ttraining's l2: 0.466111\tvalid_1's l2: 0.386203\n",
      "[83]\ttraining's l2: 0.465873\tvalid_1's l2: 0.386027\n",
      "[84]\ttraining's l2: 0.46566\tvalid_1's l2: 0.385813\n",
      "[85]\ttraining's l2: 0.465351\tvalid_1's l2: 0.385592\n",
      "[86]\ttraining's l2: 0.465131\tvalid_1's l2: 0.385465\n",
      "[87]\ttraining's l2: 0.464906\tvalid_1's l2: 0.385229\n",
      "[88]\ttraining's l2: 0.464562\tvalid_1's l2: 0.384953\n",
      "[89]\ttraining's l2: 0.464342\tvalid_1's l2: 0.384721\n",
      "[90]\ttraining's l2: 0.464015\tvalid_1's l2: 0.384509\n",
      "[91]\ttraining's l2: 0.463812\tvalid_1's l2: 0.384323\n",
      "[92]\ttraining's l2: 0.463647\tvalid_1's l2: 0.384174\n",
      "[93]\ttraining's l2: 0.463411\tvalid_1's l2: 0.383915\n",
      "[94]\ttraining's l2: 0.463234\tvalid_1's l2: 0.383775\n",
      "[95]\ttraining's l2: 0.463077\tvalid_1's l2: 0.383633\n",
      "[96]\ttraining's l2: 0.462899\tvalid_1's l2: 0.383504\n",
      "[97]\ttraining's l2: 0.462699\tvalid_1's l2: 0.383293\n",
      "[98]\ttraining's l2: 0.462554\tvalid_1's l2: 0.38314\n",
      "[99]\ttraining's l2: 0.46233\tvalid_1's l2: 0.383036\n",
      "[100]\ttraining's l2: 0.462074\tvalid_1's l2: 0.382857\n",
      "[101]\ttraining's l2: 0.461912\tvalid_1's l2: 0.382748\n",
      "[102]\ttraining's l2: 0.461788\tvalid_1's l2: 0.38265\n",
      "[103]\ttraining's l2: 0.461544\tvalid_1's l2: 0.382414\n",
      "[104]\ttraining's l2: 0.461217\tvalid_1's l2: 0.382204\n",
      "[105]\ttraining's l2: 0.460966\tvalid_1's l2: 0.382001\n",
      "[106]\ttraining's l2: 0.460759\tvalid_1's l2: 0.381859\n",
      "[107]\ttraining's l2: 0.460641\tvalid_1's l2: 0.381747\n",
      "[108]\ttraining's l2: 0.460463\tvalid_1's l2: 0.381667\n",
      "[109]\ttraining's l2: 0.460243\tvalid_1's l2: 0.381454\n",
      "[110]\ttraining's l2: 0.45999\tvalid_1's l2: 0.381295\n",
      "[111]\ttraining's l2: 0.459881\tvalid_1's l2: 0.38121\n",
      "[112]\ttraining's l2: 0.459722\tvalid_1's l2: 0.381212\n",
      "[113]\ttraining's l2: 0.459606\tvalid_1's l2: 0.381125\n",
      "[114]\ttraining's l2: 0.459489\tvalid_1's l2: 0.38105\n",
      "[115]\ttraining's l2: 0.459395\tvalid_1's l2: 0.380981\n",
      "[116]\ttraining's l2: 0.459258\tvalid_1's l2: 0.380936\n",
      "[117]\ttraining's l2: 0.459028\tvalid_1's l2: 0.380739\n",
      "[118]\ttraining's l2: 0.458894\tvalid_1's l2: 0.380707\n",
      "[119]\ttraining's l2: 0.458704\tvalid_1's l2: 0.380623\n",
      "[120]\ttraining's l2: 0.458616\tvalid_1's l2: 0.380572\n",
      "[121]\ttraining's l2: 0.458445\tvalid_1's l2: 0.380475\n",
      "[122]\ttraining's l2: 0.458298\tvalid_1's l2: 0.380368\n",
      "[123]\ttraining's l2: 0.458096\tvalid_1's l2: 0.380297\n",
      "[124]\ttraining's l2: 0.45802\tvalid_1's l2: 0.380227\n",
      "[125]\ttraining's l2: 0.45784\tvalid_1's l2: 0.380163\n",
      "[126]\ttraining's l2: 0.457728\tvalid_1's l2: 0.380092\n",
      "[127]\ttraining's l2: 0.457626\tvalid_1's l2: 0.380023\n",
      "[128]\ttraining's l2: 0.457472\tvalid_1's l2: 0.379925\n",
      "[129]\ttraining's l2: 0.457385\tvalid_1's l2: 0.379883\n",
      "[130]\ttraining's l2: 0.457301\tvalid_1's l2: 0.37982\n",
      "[131]\ttraining's l2: 0.457246\tvalid_1's l2: 0.379777\n",
      "[132]\ttraining's l2: 0.457155\tvalid_1's l2: 0.379731\n",
      "[133]\ttraining's l2: 0.457035\tvalid_1's l2: 0.379704\n",
      "[134]\ttraining's l2: 0.456957\tvalid_1's l2: 0.379674\n",
      "[135]\ttraining's l2: 0.456828\tvalid_1's l2: 0.379607\n",
      "[136]\ttraining's l2: 0.456678\tvalid_1's l2: 0.379504\n",
      "[137]\ttraining's l2: 0.45653\tvalid_1's l2: 0.379476\n",
      "[138]\ttraining's l2: 0.456437\tvalid_1's l2: 0.379449\n",
      "[139]\ttraining's l2: 0.456342\tvalid_1's l2: 0.379432\n",
      "[140]\ttraining's l2: 0.456225\tvalid_1's l2: 0.37936\n",
      "[141]\ttraining's l2: 0.456152\tvalid_1's l2: 0.379311\n",
      "[142]\ttraining's l2: 0.456084\tvalid_1's l2: 0.379281\n",
      "[143]\ttraining's l2: 0.455956\tvalid_1's l2: 0.379218\n",
      "[144]\ttraining's l2: 0.455862\tvalid_1's l2: 0.379206\n",
      "[145]\ttraining's l2: 0.455799\tvalid_1's l2: 0.379135\n",
      "[146]\ttraining's l2: 0.455709\tvalid_1's l2: 0.379077\n",
      "[147]\ttraining's l2: 0.455623\tvalid_1's l2: 0.37907\n",
      "[148]\ttraining's l2: 0.455535\tvalid_1's l2: 0.379001\n",
      "[149]\ttraining's l2: 0.455403\tvalid_1's l2: 0.378941\n",
      "[150]\ttraining's l2: 0.455324\tvalid_1's l2: 0.378905\n",
      "[151]\ttraining's l2: 0.455207\tvalid_1's l2: 0.378824\n",
      "[152]\ttraining's l2: 0.455115\tvalid_1's l2: 0.378779\n",
      "[153]\ttraining's l2: 0.455019\tvalid_1's l2: 0.378737\n",
      "[154]\ttraining's l2: 0.454968\tvalid_1's l2: 0.378692\n",
      "[155]\ttraining's l2: 0.45488\tvalid_1's l2: 0.378682\n",
      "[156]\ttraining's l2: 0.454794\tvalid_1's l2: 0.378604\n",
      "[157]\ttraining's l2: 0.4547\tvalid_1's l2: 0.378558\n",
      "[158]\ttraining's l2: 0.454616\tvalid_1's l2: 0.378517\n",
      "[159]\ttraining's l2: 0.454565\tvalid_1's l2: 0.378496\n",
      "[160]\ttraining's l2: 0.45449\tvalid_1's l2: 0.378469\n",
      "[161]\ttraining's l2: 0.454365\tvalid_1's l2: 0.378379\n",
      "[162]\ttraining's l2: 0.454246\tvalid_1's l2: 0.37834\n",
      "[163]\ttraining's l2: 0.454174\tvalid_1's l2: 0.378333\n",
      "[164]\ttraining's l2: 0.454114\tvalid_1's l2: 0.378304\n",
      "[165]\ttraining's l2: 0.454062\tvalid_1's l2: 0.378282\n",
      "[166]\ttraining's l2: 0.453998\tvalid_1's l2: 0.378253\n",
      "[167]\ttraining's l2: 0.45393\tvalid_1's l2: 0.378242\n",
      "[168]\ttraining's l2: 0.453853\tvalid_1's l2: 0.37822\n",
      "[169]\ttraining's l2: 0.453789\tvalid_1's l2: 0.378198\n",
      "[170]\ttraining's l2: 0.45367\tvalid_1's l2: 0.378175\n",
      "[171]\ttraining's l2: 0.453606\tvalid_1's l2: 0.378143\n",
      "[172]\ttraining's l2: 0.453536\tvalid_1's l2: 0.378141\n",
      "[173]\ttraining's l2: 0.453496\tvalid_1's l2: 0.378122\n",
      "[174]\ttraining's l2: 0.453411\tvalid_1's l2: 0.378094\n",
      "[175]\ttraining's l2: 0.45334\tvalid_1's l2: 0.378095\n",
      "[176]\ttraining's l2: 0.453261\tvalid_1's l2: 0.378085\n",
      "[177]\ttraining's l2: 0.45318\tvalid_1's l2: 0.378034\n",
      "[178]\ttraining's l2: 0.453113\tvalid_1's l2: 0.378019\n",
      "[179]\ttraining's l2: 0.453043\tvalid_1's l2: 0.377994\n",
      "[180]\ttraining's l2: 0.453\tvalid_1's l2: 0.377948\n",
      "[181]\ttraining's l2: 0.452927\tvalid_1's l2: 0.377921\n",
      "[182]\ttraining's l2: 0.452855\tvalid_1's l2: 0.377865\n",
      "[183]\ttraining's l2: 0.452815\tvalid_1's l2: 0.377847\n",
      "[184]\ttraining's l2: 0.452752\tvalid_1's l2: 0.377854\n",
      "[185]\ttraining's l2: 0.452665\tvalid_1's l2: 0.377782\n",
      "[186]\ttraining's l2: 0.452564\tvalid_1's l2: 0.377744\n",
      "[187]\ttraining's l2: 0.452515\tvalid_1's l2: 0.377723\n",
      "[188]\ttraining's l2: 0.452453\tvalid_1's l2: 0.3777\n",
      "[189]\ttraining's l2: 0.452392\tvalid_1's l2: 0.377688\n",
      "[190]\ttraining's l2: 0.452338\tvalid_1's l2: 0.377665\n",
      "[191]\ttraining's l2: 0.452262\tvalid_1's l2: 0.377609\n",
      "[192]\ttraining's l2: 0.452213\tvalid_1's l2: 0.377591\n",
      "[193]\ttraining's l2: 0.452164\tvalid_1's l2: 0.377593\n",
      "[194]\ttraining's l2: 0.4521\tvalid_1's l2: 0.377561\n",
      "[195]\ttraining's l2: 0.452051\tvalid_1's l2: 0.377541\n",
      "[196]\ttraining's l2: 0.452003\tvalid_1's l2: 0.377536\n",
      "[197]\ttraining's l2: 0.451952\tvalid_1's l2: 0.377484\n",
      "[198]\ttraining's l2: 0.451894\tvalid_1's l2: 0.377433\n",
      "[199]\ttraining's l2: 0.451809\tvalid_1's l2: 0.377427\n",
      "[200]\ttraining's l2: 0.451715\tvalid_1's l2: 0.377389\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.451715\tvalid_1's l2: 0.377389\n",
      "mean_30_sales: 17683830.53\n",
      "mean_21_sales: 6546948.75\n",
      "mean_20_dow4_2017: 3959474.92\n",
      "mean_60_sales: 3821085.59\n",
      "mean_4_sales: 3792903.71\n",
      "mean_14_sales: 3669440.44\n",
      "mean_5_sales: 3020508.21\n",
      "mean_7_sales: 2180018.38\n",
      "promo_11: 1626127.74\n",
      "mean_6_sales: 764643.98\n",
      "mean_63_sales: 584939.22\n",
      "item_class_features: 582946.66\n",
      "promo_10: 448465.87\n",
      "mean_20_dow3_2017: 409422.69\n",
      "lag_3_sales: 402546.82\n",
      "mean_4_dow3_2017: 317588.83\n",
      "sum_3_promo: 188347.65\n",
      "store_cluster_features: 176031.21\n",
      "std_30_sales: 136288.58\n",
      "std_21_sales: 130046.36\n",
      "promo_8: 126736.76\n",
      "promo_14: 114484.02\n",
      "promo_12: 112547.56\n",
      "mean_4_dow4_2017: 108225.84\n",
      "lag_4_sales: 102452.42\n",
      "mean_4_dow5_2017: 93379.59\n",
      "promo_9: 92056.10\n",
      "store_city_features: 91448.07\n",
      "item_family_features: 73252.01\n",
      "promo_13: 70818.89\n",
      "promo_7: 70466.98\n",
      "std_14_sales: 66294.43\n",
      "store_type_features: 46262.99\n",
      "std_63_sales: 43662.81\n",
      "mean_3_sales: 38653.06\n",
      "std_3_sales: 35476.74\n",
      "lag_42_sales: 29865.46\n",
      "std_60_sales: 27612.71\n",
      "lag_56_sales: 27114.23\n",
      "mean_20_dow0_2017: 24502.64\n",
      "sum_14_promo: 19774.39\n",
      "lag_1_sales: 17084.93\n",
      "mean_20_dow5_2017: 14693.58\n",
      "promo_4: 14688.35\n",
      "sum_21_promo: 13877.04\n",
      "sum_4_promo: 13848.65\n",
      "mean_20_dow2_2017: 12044.50\n",
      "mean_20_dow1_2017: 9887.11\n",
      "sum_7_promo: 9623.83\n",
      "std_4_sales: 9608.18\n",
      "sum_5_promo: 9005.96\n",
      "std_7_sales: 8867.34\n",
      "mean_4_dow0_2017: 7481.33\n",
      "mean_20_dow6_2017: 6735.84\n",
      "lag_63_sales: 6639.14\n",
      "mean_4_dow6_2017: 6128.85\n",
      "promo_6: 6047.21\n",
      "promo_15: 5690.68\n",
      "promo_3: 5464.27\n",
      "sum_2_promo: 5373.21\n",
      "store_state_features: 5286.42\n",
      "lag_21_sales: 4848.29\n",
      "std_6_sales: 4602.54\n",
      "std_5_sales: 4256.66\n",
      "lag_49_sales: 2965.48\n",
      "promo_1: 2295.25\n",
      "lag_5_sales: 2172.97\n",
      "mean_4_dow2_2017: 2114.35\n",
      "lag_2_sales: 1959.70\n",
      "promo_5: 1907.05\n",
      "mean_4_dow1_2017: 1814.83\n",
      "promo_0: 1547.91\n",
      "lag_35_sales: 1461.38\n",
      "promo_2: 1342.80\n",
      "lag_14_sales: 1232.25\n",
      "lag_6_sales: 870.52\n",
      "lag_7_sales: 722.25\n",
      "lag_28_sales: 421.36\n",
      "sum_6_promo: 407.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 12/16 [34:44<11:21, 170.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.07744\tvalid_1's l2: 1.04901\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.01347\tvalid_1's l2: 0.986234\n",
      "[3]\ttraining's l2: 0.956816\tvalid_1's l2: 0.929802\n",
      "[4]\ttraining's l2: 0.905519\tvalid_1's l2: 0.878633\n",
      "[5]\ttraining's l2: 0.859044\tvalid_1's l2: 0.83244\n",
      "[6]\ttraining's l2: 0.815908\tvalid_1's l2: 0.789843\n",
      "[7]\ttraining's l2: 0.77789\tvalid_1's l2: 0.752172\n",
      "[8]\ttraining's l2: 0.742587\tvalid_1's l2: 0.717195\n",
      "[9]\ttraining's l2: 0.710504\tvalid_1's l2: 0.685638\n",
      "[10]\ttraining's l2: 0.682313\tvalid_1's l2: 0.6576\n",
      "[11]\ttraining's l2: 0.655954\tvalid_1's l2: 0.631549\n",
      "[12]\ttraining's l2: 0.632037\tvalid_1's l2: 0.608185\n",
      "[13]\ttraining's l2: 0.610364\tvalid_1's l2: 0.586812\n",
      "[14]\ttraining's l2: 0.590691\tvalid_1's l2: 0.567519\n",
      "[15]\ttraining's l2: 0.572858\tvalid_1's l2: 0.550032\n",
      "[16]\ttraining's l2: 0.556674\tvalid_1's l2: 0.534137\n",
      "[17]\ttraining's l2: 0.542454\tvalid_1's l2: 0.520015\n",
      "[18]\ttraining's l2: 0.52917\tvalid_1's l2: 0.506918\n",
      "[19]\ttraining's l2: 0.517119\tvalid_1's l2: 0.495048\n",
      "[20]\ttraining's l2: 0.506157\tvalid_1's l2: 0.484245\n",
      "[21]\ttraining's l2: 0.496201\tvalid_1's l2: 0.474481\n",
      "[22]\ttraining's l2: 0.487261\tvalid_1's l2: 0.465601\n",
      "[23]\ttraining's l2: 0.479125\tvalid_1's l2: 0.457548\n",
      "[24]\ttraining's l2: 0.471729\tvalid_1's l2: 0.450233\n",
      "[25]\ttraining's l2: 0.464955\tvalid_1's l2: 0.443602\n",
      "[26]\ttraining's l2: 0.458947\tvalid_1's l2: 0.437685\n",
      "[27]\ttraining's l2: 0.453332\tvalid_1's l2: 0.432162\n",
      "[28]\ttraining's l2: 0.448375\tvalid_1's l2: 0.427302\n",
      "[29]\ttraining's l2: 0.443839\tvalid_1's l2: 0.422855\n",
      "[30]\ttraining's l2: 0.439552\tvalid_1's l2: 0.418665\n",
      "[31]\ttraining's l2: 0.43584\tvalid_1's l2: 0.415058\n",
      "[32]\ttraining's l2: 0.432268\tvalid_1's l2: 0.41156\n",
      "[33]\ttraining's l2: 0.429032\tvalid_1's l2: 0.408393\n",
      "[34]\ttraining's l2: 0.426088\tvalid_1's l2: 0.40547\n",
      "[35]\ttraining's l2: 0.423393\tvalid_1's l2: 0.402722\n",
      "[36]\ttraining's l2: 0.420939\tvalid_1's l2: 0.40031\n",
      "[37]\ttraining's l2: 0.418691\tvalid_1's l2: 0.398057\n",
      "[38]\ttraining's l2: 0.416719\tvalid_1's l2: 0.396174\n",
      "[39]\ttraining's l2: 0.414814\tvalid_1's l2: 0.394252\n",
      "[40]\ttraining's l2: 0.413086\tvalid_1's l2: 0.392645\n",
      "[41]\ttraining's l2: 0.411466\tvalid_1's l2: 0.391062\n",
      "[42]\ttraining's l2: 0.409998\tvalid_1's l2: 0.389577\n",
      "[43]\ttraining's l2: 0.408633\tvalid_1's l2: 0.388188\n",
      "[44]\ttraining's l2: 0.407358\tvalid_1's l2: 0.38691\n",
      "[45]\ttraining's l2: 0.406207\tvalid_1's l2: 0.385798\n",
      "[46]\ttraining's l2: 0.405131\tvalid_1's l2: 0.384734\n",
      "[47]\ttraining's l2: 0.404085\tvalid_1's l2: 0.383821\n",
      "[48]\ttraining's l2: 0.403169\tvalid_1's l2: 0.382955\n",
      "[49]\ttraining's l2: 0.402292\tvalid_1's l2: 0.382084\n",
      "[50]\ttraining's l2: 0.401494\tvalid_1's l2: 0.381336\n",
      "[51]\ttraining's l2: 0.400739\tvalid_1's l2: 0.380601\n",
      "[52]\ttraining's l2: 0.400076\tvalid_1's l2: 0.379955\n",
      "[53]\ttraining's l2: 0.399417\tvalid_1's l2: 0.379304\n",
      "[54]\ttraining's l2: 0.398838\tvalid_1's l2: 0.378746\n",
      "[55]\ttraining's l2: 0.398296\tvalid_1's l2: 0.378266\n",
      "[56]\ttraining's l2: 0.397762\tvalid_1's l2: 0.377723\n",
      "[57]\ttraining's l2: 0.397292\tvalid_1's l2: 0.377211\n",
      "[58]\ttraining's l2: 0.396846\tvalid_1's l2: 0.376809\n",
      "[59]\ttraining's l2: 0.396454\tvalid_1's l2: 0.376435\n",
      "[60]\ttraining's l2: 0.396061\tvalid_1's l2: 0.376102\n",
      "[61]\ttraining's l2: 0.395596\tvalid_1's l2: 0.375741\n",
      "[62]\ttraining's l2: 0.395162\tvalid_1's l2: 0.375401\n",
      "[63]\ttraining's l2: 0.394766\tvalid_1's l2: 0.375047\n",
      "[64]\ttraining's l2: 0.394378\tvalid_1's l2: 0.374734\n",
      "[65]\ttraining's l2: 0.394061\tvalid_1's l2: 0.37442\n",
      "[66]\ttraining's l2: 0.393807\tvalid_1's l2: 0.374208\n",
      "[67]\ttraining's l2: 0.393509\tvalid_1's l2: 0.373936\n",
      "[68]\ttraining's l2: 0.393254\tvalid_1's l2: 0.373748\n",
      "[69]\ttraining's l2: 0.392932\tvalid_1's l2: 0.373474\n",
      "[70]\ttraining's l2: 0.392512\tvalid_1's l2: 0.373144\n",
      "[71]\ttraining's l2: 0.392217\tvalid_1's l2: 0.372875\n",
      "[72]\ttraining's l2: 0.391839\tvalid_1's l2: 0.372605\n",
      "[73]\ttraining's l2: 0.39159\tvalid_1's l2: 0.372456\n",
      "[74]\ttraining's l2: 0.391287\tvalid_1's l2: 0.372245\n",
      "[75]\ttraining's l2: 0.391018\tvalid_1's l2: 0.372069\n",
      "[76]\ttraining's l2: 0.390758\tvalid_1's l2: 0.371859\n",
      "[77]\ttraining's l2: 0.390544\tvalid_1's l2: 0.371669\n",
      "[78]\ttraining's l2: 0.390344\tvalid_1's l2: 0.371547\n",
      "[79]\ttraining's l2: 0.390155\tvalid_1's l2: 0.371436\n",
      "[80]\ttraining's l2: 0.38998\tvalid_1's l2: 0.371304\n",
      "[81]\ttraining's l2: 0.389803\tvalid_1's l2: 0.371207\n",
      "[82]\ttraining's l2: 0.389667\tvalid_1's l2: 0.371061\n",
      "[83]\ttraining's l2: 0.389493\tvalid_1's l2: 0.37096\n",
      "[84]\ttraining's l2: 0.389301\tvalid_1's l2: 0.370782\n",
      "[85]\ttraining's l2: 0.389132\tvalid_1's l2: 0.370695\n",
      "[86]\ttraining's l2: 0.388974\tvalid_1's l2: 0.370602\n",
      "[87]\ttraining's l2: 0.388812\tvalid_1's l2: 0.370488\n",
      "[88]\ttraining's l2: 0.388648\tvalid_1's l2: 0.370336\n",
      "[89]\ttraining's l2: 0.38853\tvalid_1's l2: 0.370272\n",
      "[90]\ttraining's l2: 0.388334\tvalid_1's l2: 0.370144\n",
      "[91]\ttraining's l2: 0.388196\tvalid_1's l2: 0.370066\n",
      "[92]\ttraining's l2: 0.388088\tvalid_1's l2: 0.369975\n",
      "[93]\ttraining's l2: 0.387938\tvalid_1's l2: 0.369836\n",
      "[94]\ttraining's l2: 0.387826\tvalid_1's l2: 0.369788\n",
      "[95]\ttraining's l2: 0.38771\tvalid_1's l2: 0.369747\n",
      "[96]\ttraining's l2: 0.387549\tvalid_1's l2: 0.369656\n",
      "[97]\ttraining's l2: 0.387439\tvalid_1's l2: 0.369543\n",
      "[98]\ttraining's l2: 0.387327\tvalid_1's l2: 0.369446\n",
      "[99]\ttraining's l2: 0.387239\tvalid_1's l2: 0.369384\n",
      "[100]\ttraining's l2: 0.387124\tvalid_1's l2: 0.369321\n",
      "[101]\ttraining's l2: 0.386933\tvalid_1's l2: 0.369158\n",
      "[102]\ttraining's l2: 0.3868\tvalid_1's l2: 0.369064\n",
      "[103]\ttraining's l2: 0.386587\tvalid_1's l2: 0.368897\n",
      "[104]\ttraining's l2: 0.38652\tvalid_1's l2: 0.368863\n",
      "[105]\ttraining's l2: 0.386279\tvalid_1's l2: 0.368747\n",
      "[106]\ttraining's l2: 0.386089\tvalid_1's l2: 0.368614\n",
      "[107]\ttraining's l2: 0.38598\tvalid_1's l2: 0.368538\n",
      "[108]\ttraining's l2: 0.385898\tvalid_1's l2: 0.368513\n",
      "[109]\ttraining's l2: 0.385829\tvalid_1's l2: 0.368476\n",
      "[110]\ttraining's l2: 0.385757\tvalid_1's l2: 0.368452\n",
      "[111]\ttraining's l2: 0.385642\tvalid_1's l2: 0.368375\n",
      "[112]\ttraining's l2: 0.385572\tvalid_1's l2: 0.368327\n",
      "[113]\ttraining's l2: 0.385445\tvalid_1's l2: 0.368269\n",
      "[114]\ttraining's l2: 0.385334\tvalid_1's l2: 0.368191\n",
      "[115]\ttraining's l2: 0.385281\tvalid_1's l2: 0.368168\n",
      "[116]\ttraining's l2: 0.38513\tvalid_1's l2: 0.368095\n",
      "[117]\ttraining's l2: 0.385065\tvalid_1's l2: 0.368059\n",
      "[118]\ttraining's l2: 0.384939\tvalid_1's l2: 0.367991\n",
      "[119]\ttraining's l2: 0.384838\tvalid_1's l2: 0.367947\n",
      "[120]\ttraining's l2: 0.384747\tvalid_1's l2: 0.367901\n",
      "[121]\ttraining's l2: 0.384688\tvalid_1's l2: 0.367867\n",
      "[122]\ttraining's l2: 0.384607\tvalid_1's l2: 0.367816\n",
      "[123]\ttraining's l2: 0.384507\tvalid_1's l2: 0.367766\n",
      "[124]\ttraining's l2: 0.384411\tvalid_1's l2: 0.367717\n",
      "[125]\ttraining's l2: 0.384335\tvalid_1's l2: 0.367686\n",
      "[126]\ttraining's l2: 0.384275\tvalid_1's l2: 0.367647\n",
      "[127]\ttraining's l2: 0.384191\tvalid_1's l2: 0.367581\n",
      "[128]\ttraining's l2: 0.384148\tvalid_1's l2: 0.367565\n",
      "[129]\ttraining's l2: 0.384098\tvalid_1's l2: 0.367536\n",
      "[130]\ttraining's l2: 0.383966\tvalid_1's l2: 0.367457\n",
      "[131]\ttraining's l2: 0.383875\tvalid_1's l2: 0.367391\n",
      "[132]\ttraining's l2: 0.383826\tvalid_1's l2: 0.36737\n",
      "[133]\ttraining's l2: 0.383734\tvalid_1's l2: 0.367344\n",
      "[134]\ttraining's l2: 0.383673\tvalid_1's l2: 0.367316\n",
      "[135]\ttraining's l2: 0.383544\tvalid_1's l2: 0.367264\n",
      "[136]\ttraining's l2: 0.383444\tvalid_1's l2: 0.367178\n",
      "[137]\ttraining's l2: 0.383345\tvalid_1's l2: 0.367127\n",
      "[138]\ttraining's l2: 0.383282\tvalid_1's l2: 0.367104\n",
      "[139]\ttraining's l2: 0.383205\tvalid_1's l2: 0.367047\n",
      "[140]\ttraining's l2: 0.383144\tvalid_1's l2: 0.367035\n",
      "[141]\ttraining's l2: 0.383081\tvalid_1's l2: 0.367018\n",
      "[142]\ttraining's l2: 0.383006\tvalid_1's l2: 0.366985\n",
      "[143]\ttraining's l2: 0.382883\tvalid_1's l2: 0.366889\n",
      "[144]\ttraining's l2: 0.382822\tvalid_1's l2: 0.366872\n",
      "[145]\ttraining's l2: 0.38277\tvalid_1's l2: 0.366857\n",
      "[146]\ttraining's l2: 0.382679\tvalid_1's l2: 0.366821\n",
      "[147]\ttraining's l2: 0.382619\tvalid_1's l2: 0.366803\n",
      "[148]\ttraining's l2: 0.382549\tvalid_1's l2: 0.36678\n",
      "[149]\ttraining's l2: 0.382495\tvalid_1's l2: 0.366761\n",
      "[150]\ttraining's l2: 0.382434\tvalid_1's l2: 0.366741\n",
      "[151]\ttraining's l2: 0.382348\tvalid_1's l2: 0.366687\n",
      "[152]\ttraining's l2: 0.382294\tvalid_1's l2: 0.366668\n",
      "[153]\ttraining's l2: 0.382251\tvalid_1's l2: 0.36665\n",
      "[154]\ttraining's l2: 0.382213\tvalid_1's l2: 0.36663\n",
      "[155]\ttraining's l2: 0.382167\tvalid_1's l2: 0.366589\n",
      "[156]\ttraining's l2: 0.382125\tvalid_1's l2: 0.366573\n",
      "[157]\ttraining's l2: 0.382078\tvalid_1's l2: 0.366562\n",
      "[158]\ttraining's l2: 0.382043\tvalid_1's l2: 0.366549\n",
      "[159]\ttraining's l2: 0.381964\tvalid_1's l2: 0.366512\n",
      "[160]\ttraining's l2: 0.381911\tvalid_1's l2: 0.366484\n",
      "[161]\ttraining's l2: 0.381858\tvalid_1's l2: 0.366458\n",
      "[162]\ttraining's l2: 0.381823\tvalid_1's l2: 0.366448\n",
      "[163]\ttraining's l2: 0.381715\tvalid_1's l2: 0.366405\n",
      "[164]\ttraining's l2: 0.3816\tvalid_1's l2: 0.366346\n",
      "[165]\ttraining's l2: 0.381544\tvalid_1's l2: 0.366313\n",
      "[166]\ttraining's l2: 0.381505\tvalid_1's l2: 0.3663\n",
      "[167]\ttraining's l2: 0.38147\tvalid_1's l2: 0.366268\n",
      "[168]\ttraining's l2: 0.381427\tvalid_1's l2: 0.366245\n",
      "[169]\ttraining's l2: 0.38136\tvalid_1's l2: 0.366235\n",
      "[170]\ttraining's l2: 0.381326\tvalid_1's l2: 0.366225\n",
      "[171]\ttraining's l2: 0.381265\tvalid_1's l2: 0.366204\n",
      "[172]\ttraining's l2: 0.381236\tvalid_1's l2: 0.366195\n",
      "[173]\ttraining's l2: 0.381183\tvalid_1's l2: 0.366169\n",
      "[174]\ttraining's l2: 0.381134\tvalid_1's l2: 0.366155\n",
      "[175]\ttraining's l2: 0.381099\tvalid_1's l2: 0.366132\n",
      "[176]\ttraining's l2: 0.381065\tvalid_1's l2: 0.366125\n",
      "[177]\ttraining's l2: 0.381006\tvalid_1's l2: 0.366069\n",
      "[178]\ttraining's l2: 0.380963\tvalid_1's l2: 0.366058\n",
      "[179]\ttraining's l2: 0.3809\tvalid_1's l2: 0.366024\n",
      "[180]\ttraining's l2: 0.380854\tvalid_1's l2: 0.366\n",
      "[181]\ttraining's l2: 0.380805\tvalid_1's l2: 0.365995\n",
      "[182]\ttraining's l2: 0.380764\tvalid_1's l2: 0.365979\n",
      "[183]\ttraining's l2: 0.380715\tvalid_1's l2: 0.365971\n",
      "[184]\ttraining's l2: 0.380653\tvalid_1's l2: 0.365922\n",
      "[185]\ttraining's l2: 0.38062\tvalid_1's l2: 0.365906\n",
      "[186]\ttraining's l2: 0.380594\tvalid_1's l2: 0.365886\n",
      "[187]\ttraining's l2: 0.380558\tvalid_1's l2: 0.365871\n",
      "[188]\ttraining's l2: 0.380524\tvalid_1's l2: 0.365867\n",
      "[189]\ttraining's l2: 0.380445\tvalid_1's l2: 0.365814\n",
      "[190]\ttraining's l2: 0.380395\tvalid_1's l2: 0.365802\n",
      "[191]\ttraining's l2: 0.380355\tvalid_1's l2: 0.365782\n",
      "[192]\ttraining's l2: 0.380317\tvalid_1's l2: 0.365756\n",
      "[193]\ttraining's l2: 0.380245\tvalid_1's l2: 0.365728\n",
      "[194]\ttraining's l2: 0.380214\tvalid_1's l2: 0.365701\n",
      "[195]\ttraining's l2: 0.380188\tvalid_1's l2: 0.365685\n",
      "[196]\ttraining's l2: 0.380162\tvalid_1's l2: 0.365678\n",
      "[197]\ttraining's l2: 0.380123\tvalid_1's l2: 0.365663\n",
      "[198]\ttraining's l2: 0.380058\tvalid_1's l2: 0.365596\n",
      "[199]\ttraining's l2: 0.380007\tvalid_1's l2: 0.365553\n",
      "[200]\ttraining's l2: 0.379972\tvalid_1's l2: 0.36555\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.379972\tvalid_1's l2: 0.36555\n",
      "mean_21_sales: 15207839.50\n",
      "mean_30_sales: 5899252.85\n",
      "mean_14_sales: 5508807.20\n",
      "mean_7_sales: 4065387.19\n",
      "mean_60_sales: 3626511.27\n",
      "mean_20_dow5_2017: 2537262.18\n",
      "mean_3_sales: 1257517.13\n",
      "promo_12: 1224650.21\n",
      "mean_6_sales: 1154748.04\n",
      "mean_63_sales: 993920.61\n",
      "mean_4_sales: 871525.08\n",
      "item_class_features: 444810.21\n",
      "mean_5_sales: 359388.23\n",
      "promo_13: 168987.97\n",
      "promo_14: 152835.20\n",
      "mean_4_dow5_2017: 149566.22\n",
      "std_30_sales: 130189.79\n",
      "std_21_sales: 114796.57\n",
      "lag_1_sales: 89283.02\n",
      "sum_2_promo: 86299.97\n",
      "promo_10: 83653.43\n",
      "item_family_features: 69810.99\n",
      "sum_4_promo: 67846.53\n",
      "mean_20_dow6_2017: 62614.72\n",
      "lag_2_sales: 56623.94\n",
      "lag_49_sales: 40829.96\n",
      "std_63_sales: 37919.24\n",
      "std_60_sales: 30953.56\n",
      "store_cluster_features: 30751.25\n",
      "promo_8: 26681.09\n",
      "promo_9: 25977.72\n",
      "promo_7: 22412.32\n",
      "mean_20_dow4_2017: 21424.92\n",
      "mean_20_dow0_2017: 20649.54\n",
      "std_14_sales: 20571.94\n",
      "promo_11: 20114.38\n",
      "sum_7_promo: 16358.32\n",
      "mean_20_dow3_2017: 16350.95\n",
      "sum_14_promo: 14057.82\n",
      "sum_6_promo: 13462.88\n",
      "promo_0: 12007.65\n",
      "sum_21_promo: 11308.03\n",
      "promo_15: 10644.87\n",
      "mean_4_dow6_2017: 10305.51\n",
      "store_city_features: 9656.63\n",
      "mean_20_dow2_2017: 9272.51\n",
      "mean_20_dow1_2017: 8430.67\n",
      "promo_5: 8264.41\n",
      "lag_63_sales: 7899.89\n",
      "lag_3_sales: 7217.36\n",
      "promo_3: 6455.60\n",
      "std_7_sales: 6420.65\n",
      "mean_4_dow0_2017: 5930.44\n",
      "std_6_sales: 5582.45\n",
      "sum_3_promo: 5104.67\n",
      "lag_6_sales: 4738.89\n",
      "std_3_sales: 4729.17\n",
      "lag_42_sales: 4512.48\n",
      "mean_4_dow4_2017: 4484.41\n",
      "promo_6: 4330.67\n",
      "sum_5_promo: 4255.66\n",
      "mean_4_dow3_2017: 3851.48\n",
      "std_4_sales: 3834.20\n",
      "lag_35_sales: 3643.66\n",
      "store_state_features: 3141.89\n",
      "mean_4_dow1_2017: 2972.26\n",
      "lag_4_sales: 2966.75\n",
      "std_5_sales: 2630.28\n",
      "lag_56_sales: 2500.88\n",
      "lag_28_sales: 2452.86\n",
      "promo_4: 1960.36\n",
      "lag_14_sales: 1834.34\n",
      "store_type_features: 1782.23\n",
      "lag_21_sales: 1764.22\n",
      "mean_4_dow2_2017: 1347.63\n",
      "promo_2: 1274.28\n",
      "lag_5_sales: 1032.04\n",
      "promo_1: 789.90\n",
      "lag_7_sales: 678.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████▏ | 13/16 [37:31<08:28, 169.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.0409\tvalid_1's l2: 0.993613\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.981002\tvalid_1's l2: 0.935266\n",
      "[3]\ttraining's l2: 0.926916\tvalid_1's l2: 0.882259\n",
      "[4]\ttraining's l2: 0.876247\tvalid_1's l2: 0.833017\n",
      "[5]\ttraining's l2: 0.830395\tvalid_1's l2: 0.788324\n",
      "[6]\ttraining's l2: 0.788815\tvalid_1's l2: 0.747915\n",
      "[7]\ttraining's l2: 0.752458\tvalid_1's l2: 0.7126\n",
      "[8]\ttraining's l2: 0.718289\tvalid_1's l2: 0.679626\n",
      "[9]\ttraining's l2: 0.688588\tvalid_1's l2: 0.6509\n",
      "[10]\ttraining's l2: 0.660531\tvalid_1's l2: 0.623888\n",
      "[11]\ttraining's l2: 0.635085\tvalid_1's l2: 0.599385\n",
      "[12]\ttraining's l2: 0.612048\tvalid_1's l2: 0.57736\n",
      "[13]\ttraining's l2: 0.591167\tvalid_1's l2: 0.557271\n",
      "[14]\ttraining's l2: 0.572114\tvalid_1's l2: 0.538884\n",
      "[15]\ttraining's l2: 0.554922\tvalid_1's l2: 0.522307\n",
      "[16]\ttraining's l2: 0.539289\tvalid_1's l2: 0.50731\n",
      "[17]\ttraining's l2: 0.525227\tvalid_1's l2: 0.493879\n",
      "[18]\ttraining's l2: 0.512459\tvalid_1's l2: 0.481744\n",
      "[19]\ttraining's l2: 0.500825\tvalid_1's l2: 0.470562\n",
      "[20]\ttraining's l2: 0.49061\tvalid_1's l2: 0.460833\n",
      "[21]\ttraining's l2: 0.481051\tvalid_1's l2: 0.45165\n",
      "[22]\ttraining's l2: 0.472696\tvalid_1's l2: 0.443709\n",
      "[23]\ttraining's l2: 0.46466\tvalid_1's l2: 0.436088\n",
      "[24]\ttraining's l2: 0.457676\tvalid_1's l2: 0.429539\n",
      "[25]\ttraining's l2: 0.451008\tvalid_1's l2: 0.423214\n",
      "[26]\ttraining's l2: 0.44501\tvalid_1's l2: 0.417556\n",
      "[27]\ttraining's l2: 0.43982\tvalid_1's l2: 0.412703\n",
      "[28]\ttraining's l2: 0.43507\tvalid_1's l2: 0.408304\n",
      "[29]\ttraining's l2: 0.430464\tvalid_1's l2: 0.403971\n",
      "[30]\ttraining's l2: 0.426285\tvalid_1's l2: 0.400017\n",
      "[31]\ttraining's l2: 0.422609\tvalid_1's l2: 0.39664\n",
      "[32]\ttraining's l2: 0.419097\tvalid_1's l2: 0.393388\n",
      "[33]\ttraining's l2: 0.415911\tvalid_1's l2: 0.390378\n",
      "[34]\ttraining's l2: 0.412955\tvalid_1's l2: 0.38765\n",
      "[35]\ttraining's l2: 0.410311\tvalid_1's l2: 0.385221\n",
      "[36]\ttraining's l2: 0.407814\tvalid_1's l2: 0.382909\n",
      "[37]\ttraining's l2: 0.405596\tvalid_1's l2: 0.380838\n",
      "[38]\ttraining's l2: 0.403563\tvalid_1's l2: 0.379005\n",
      "[39]\ttraining's l2: 0.401658\tvalid_1's l2: 0.377204\n",
      "[40]\ttraining's l2: 0.399941\tvalid_1's l2: 0.375714\n",
      "[41]\ttraining's l2: 0.398333\tvalid_1's l2: 0.374259\n",
      "[42]\ttraining's l2: 0.396903\tvalid_1's l2: 0.372975\n",
      "[43]\ttraining's l2: 0.39553\tvalid_1's l2: 0.37176\n",
      "[44]\ttraining's l2: 0.394256\tvalid_1's l2: 0.37062\n",
      "[45]\ttraining's l2: 0.393105\tvalid_1's l2: 0.369564\n",
      "[46]\ttraining's l2: 0.392011\tvalid_1's l2: 0.368608\n",
      "[47]\ttraining's l2: 0.390944\tvalid_1's l2: 0.367699\n",
      "[48]\ttraining's l2: 0.390026\tvalid_1's l2: 0.366886\n",
      "[49]\ttraining's l2: 0.389055\tvalid_1's l2: 0.366053\n",
      "[50]\ttraining's l2: 0.388215\tvalid_1's l2: 0.365317\n",
      "[51]\ttraining's l2: 0.387456\tvalid_1's l2: 0.364746\n",
      "[52]\ttraining's l2: 0.386752\tvalid_1's l2: 0.364134\n",
      "[53]\ttraining's l2: 0.38611\tvalid_1's l2: 0.363585\n",
      "[54]\ttraining's l2: 0.385389\tvalid_1's l2: 0.36301\n",
      "[55]\ttraining's l2: 0.384838\tvalid_1's l2: 0.362554\n",
      "[56]\ttraining's l2: 0.384289\tvalid_1's l2: 0.362122\n",
      "[57]\ttraining's l2: 0.383811\tvalid_1's l2: 0.3617\n",
      "[58]\ttraining's l2: 0.383415\tvalid_1's l2: 0.36142\n",
      "[59]\ttraining's l2: 0.382994\tvalid_1's l2: 0.361051\n",
      "[60]\ttraining's l2: 0.382582\tvalid_1's l2: 0.360709\n",
      "[61]\ttraining's l2: 0.382037\tvalid_1's l2: 0.360314\n",
      "[62]\ttraining's l2: 0.381611\tvalid_1's l2: 0.359986\n",
      "[63]\ttraining's l2: 0.381242\tvalid_1's l2: 0.359659\n",
      "[64]\ttraining's l2: 0.3808\tvalid_1's l2: 0.359293\n",
      "[65]\ttraining's l2: 0.380548\tvalid_1's l2: 0.359087\n",
      "[66]\ttraining's l2: 0.380278\tvalid_1's l2: 0.358895\n",
      "[67]\ttraining's l2: 0.379888\tvalid_1's l2: 0.358586\n",
      "[68]\ttraining's l2: 0.379562\tvalid_1's l2: 0.358348\n",
      "[69]\ttraining's l2: 0.379187\tvalid_1's l2: 0.358048\n",
      "[70]\ttraining's l2: 0.378841\tvalid_1's l2: 0.357788\n",
      "[71]\ttraining's l2: 0.378525\tvalid_1's l2: 0.357605\n",
      "[72]\ttraining's l2: 0.378194\tvalid_1's l2: 0.357365\n",
      "[73]\ttraining's l2: 0.377907\tvalid_1's l2: 0.35715\n",
      "[74]\ttraining's l2: 0.377627\tvalid_1's l2: 0.356987\n",
      "[75]\ttraining's l2: 0.377408\tvalid_1's l2: 0.356844\n",
      "[76]\ttraining's l2: 0.377085\tvalid_1's l2: 0.356618\n",
      "[77]\ttraining's l2: 0.376914\tvalid_1's l2: 0.3565\n",
      "[78]\ttraining's l2: 0.376686\tvalid_1's l2: 0.356377\n",
      "[79]\ttraining's l2: 0.376492\tvalid_1's l2: 0.356267\n",
      "[80]\ttraining's l2: 0.376328\tvalid_1's l2: 0.35615\n",
      "[81]\ttraining's l2: 0.376068\tvalid_1's l2: 0.355996\n",
      "[82]\ttraining's l2: 0.375966\tvalid_1's l2: 0.355932\n",
      "[83]\ttraining's l2: 0.375791\tvalid_1's l2: 0.355816\n",
      "[84]\ttraining's l2: 0.375596\tvalid_1's l2: 0.355729\n",
      "[85]\ttraining's l2: 0.375448\tvalid_1's l2: 0.355672\n",
      "[86]\ttraining's l2: 0.375273\tvalid_1's l2: 0.355539\n",
      "[87]\ttraining's l2: 0.37511\tvalid_1's l2: 0.355436\n",
      "[88]\ttraining's l2: 0.374986\tvalid_1's l2: 0.355332\n",
      "[89]\ttraining's l2: 0.374753\tvalid_1's l2: 0.355202\n",
      "[90]\ttraining's l2: 0.374607\tvalid_1's l2: 0.355111\n",
      "[91]\ttraining's l2: 0.374485\tvalid_1's l2: 0.355051\n",
      "[92]\ttraining's l2: 0.374349\tvalid_1's l2: 0.354916\n",
      "[93]\ttraining's l2: 0.374255\tvalid_1's l2: 0.354862\n",
      "[94]\ttraining's l2: 0.374099\tvalid_1's l2: 0.354742\n",
      "[95]\ttraining's l2: 0.373957\tvalid_1's l2: 0.354672\n",
      "[96]\ttraining's l2: 0.37385\tvalid_1's l2: 0.354604\n",
      "[97]\ttraining's l2: 0.373672\tvalid_1's l2: 0.354476\n",
      "[98]\ttraining's l2: 0.373585\tvalid_1's l2: 0.354406\n",
      "[99]\ttraining's l2: 0.373441\tvalid_1's l2: 0.354294\n",
      "[100]\ttraining's l2: 0.373261\tvalid_1's l2: 0.354171\n",
      "[101]\ttraining's l2: 0.373121\tvalid_1's l2: 0.354056\n",
      "[102]\ttraining's l2: 0.372937\tvalid_1's l2: 0.353943\n",
      "[103]\ttraining's l2: 0.372762\tvalid_1's l2: 0.35378\n",
      "[104]\ttraining's l2: 0.372685\tvalid_1's l2: 0.353724\n",
      "[105]\ttraining's l2: 0.372517\tvalid_1's l2: 0.353598\n",
      "[106]\ttraining's l2: 0.37241\tvalid_1's l2: 0.353541\n",
      "[107]\ttraining's l2: 0.372325\tvalid_1's l2: 0.353489\n",
      "[108]\ttraining's l2: 0.37219\tvalid_1's l2: 0.353399\n",
      "[109]\ttraining's l2: 0.372043\tvalid_1's l2: 0.35329\n",
      "[110]\ttraining's l2: 0.371946\tvalid_1's l2: 0.353238\n",
      "[111]\ttraining's l2: 0.371849\tvalid_1's l2: 0.353151\n",
      "[112]\ttraining's l2: 0.37177\tvalid_1's l2: 0.353134\n",
      "[113]\ttraining's l2: 0.37158\tvalid_1's l2: 0.352998\n",
      "[114]\ttraining's l2: 0.371481\tvalid_1's l2: 0.352948\n",
      "[115]\ttraining's l2: 0.371388\tvalid_1's l2: 0.352909\n",
      "[116]\ttraining's l2: 0.371319\tvalid_1's l2: 0.352888\n",
      "[117]\ttraining's l2: 0.371243\tvalid_1's l2: 0.352829\n",
      "[118]\ttraining's l2: 0.371175\tvalid_1's l2: 0.352796\n",
      "[119]\ttraining's l2: 0.3711\tvalid_1's l2: 0.352762\n",
      "[120]\ttraining's l2: 0.370973\tvalid_1's l2: 0.352683\n",
      "[121]\ttraining's l2: 0.370879\tvalid_1's l2: 0.352626\n",
      "[122]\ttraining's l2: 0.370822\tvalid_1's l2: 0.352582\n",
      "[123]\ttraining's l2: 0.370718\tvalid_1's l2: 0.352537\n",
      "[124]\ttraining's l2: 0.370648\tvalid_1's l2: 0.35251\n",
      "[125]\ttraining's l2: 0.370584\tvalid_1's l2: 0.352489\n",
      "[126]\ttraining's l2: 0.370513\tvalid_1's l2: 0.35245\n",
      "[127]\ttraining's l2: 0.370451\tvalid_1's l2: 0.352418\n",
      "[128]\ttraining's l2: 0.370399\tvalid_1's l2: 0.352408\n",
      "[129]\ttraining's l2: 0.370346\tvalid_1's l2: 0.352376\n",
      "[130]\ttraining's l2: 0.370287\tvalid_1's l2: 0.352356\n",
      "[131]\ttraining's l2: 0.370242\tvalid_1's l2: 0.352348\n",
      "[132]\ttraining's l2: 0.370139\tvalid_1's l2: 0.352288\n",
      "[133]\ttraining's l2: 0.370087\tvalid_1's l2: 0.352273\n",
      "[134]\ttraining's l2: 0.370025\tvalid_1's l2: 0.352242\n",
      "[135]\ttraining's l2: 0.369967\tvalid_1's l2: 0.352238\n",
      "[136]\ttraining's l2: 0.369834\tvalid_1's l2: 0.352155\n",
      "[137]\ttraining's l2: 0.369781\tvalid_1's l2: 0.352146\n",
      "[138]\ttraining's l2: 0.36973\tvalid_1's l2: 0.352135\n",
      "[139]\ttraining's l2: 0.369688\tvalid_1's l2: 0.35211\n",
      "[140]\ttraining's l2: 0.369648\tvalid_1's l2: 0.352087\n",
      "[141]\ttraining's l2: 0.36955\tvalid_1's l2: 0.35202\n",
      "[142]\ttraining's l2: 0.369504\tvalid_1's l2: 0.35201\n",
      "[143]\ttraining's l2: 0.369441\tvalid_1's l2: 0.351989\n",
      "[144]\ttraining's l2: 0.369387\tvalid_1's l2: 0.351986\n",
      "[145]\ttraining's l2: 0.369333\tvalid_1's l2: 0.351965\n",
      "[146]\ttraining's l2: 0.369242\tvalid_1's l2: 0.3519\n",
      "[147]\ttraining's l2: 0.369203\tvalid_1's l2: 0.351893\n",
      "[148]\ttraining's l2: 0.369127\tvalid_1's l2: 0.351863\n",
      "[149]\ttraining's l2: 0.369082\tvalid_1's l2: 0.351851\n",
      "[150]\ttraining's l2: 0.369046\tvalid_1's l2: 0.351841\n",
      "[151]\ttraining's l2: 0.368991\tvalid_1's l2: 0.351791\n",
      "[152]\ttraining's l2: 0.368947\tvalid_1's l2: 0.351781\n",
      "[153]\ttraining's l2: 0.368862\tvalid_1's l2: 0.351732\n",
      "[154]\ttraining's l2: 0.368818\tvalid_1's l2: 0.351717\n",
      "[155]\ttraining's l2: 0.368772\tvalid_1's l2: 0.351698\n",
      "[156]\ttraining's l2: 0.368734\tvalid_1's l2: 0.351686\n",
      "[157]\ttraining's l2: 0.368639\tvalid_1's l2: 0.351647\n",
      "[158]\ttraining's l2: 0.368582\tvalid_1's l2: 0.351639\n",
      "[159]\ttraining's l2: 0.368534\tvalid_1's l2: 0.351617\n",
      "[160]\ttraining's l2: 0.368487\tvalid_1's l2: 0.351604\n",
      "[161]\ttraining's l2: 0.368452\tvalid_1's l2: 0.351588\n",
      "[162]\ttraining's l2: 0.368351\tvalid_1's l2: 0.351531\n",
      "[163]\ttraining's l2: 0.368282\tvalid_1's l2: 0.351502\n",
      "[164]\ttraining's l2: 0.368238\tvalid_1's l2: 0.351483\n",
      "[165]\ttraining's l2: 0.368178\tvalid_1's l2: 0.351438\n",
      "[166]\ttraining's l2: 0.368095\tvalid_1's l2: 0.351388\n",
      "[167]\ttraining's l2: 0.368051\tvalid_1's l2: 0.351373\n",
      "[168]\ttraining's l2: 0.368011\tvalid_1's l2: 0.35137\n",
      "[169]\ttraining's l2: 0.367973\tvalid_1's l2: 0.351357\n",
      "[170]\ttraining's l2: 0.367917\tvalid_1's l2: 0.351345\n",
      "[171]\ttraining's l2: 0.367869\tvalid_1's l2: 0.351325\n",
      "[172]\ttraining's l2: 0.367826\tvalid_1's l2: 0.351306\n",
      "[173]\ttraining's l2: 0.367785\tvalid_1's l2: 0.351293\n",
      "[174]\ttraining's l2: 0.367747\tvalid_1's l2: 0.351276\n",
      "[175]\ttraining's l2: 0.367717\tvalid_1's l2: 0.351266\n",
      "[176]\ttraining's l2: 0.367688\tvalid_1's l2: 0.35126\n",
      "[177]\ttraining's l2: 0.36764\tvalid_1's l2: 0.351245\n",
      "[178]\ttraining's l2: 0.367597\tvalid_1's l2: 0.351227\n",
      "[179]\ttraining's l2: 0.367538\tvalid_1's l2: 0.351207\n",
      "[180]\ttraining's l2: 0.367507\tvalid_1's l2: 0.351193\n",
      "[181]\ttraining's l2: 0.367463\tvalid_1's l2: 0.351166\n",
      "[182]\ttraining's l2: 0.367422\tvalid_1's l2: 0.351154\n",
      "[183]\ttraining's l2: 0.367389\tvalid_1's l2: 0.35114\n",
      "[184]\ttraining's l2: 0.367315\tvalid_1's l2: 0.35109\n",
      "[185]\ttraining's l2: 0.367282\tvalid_1's l2: 0.351078\n",
      "[186]\ttraining's l2: 0.367249\tvalid_1's l2: 0.351064\n",
      "[187]\ttraining's l2: 0.367219\tvalid_1's l2: 0.351065\n",
      "[188]\ttraining's l2: 0.367191\tvalid_1's l2: 0.351053\n",
      "[189]\ttraining's l2: 0.367169\tvalid_1's l2: 0.351044\n",
      "[190]\ttraining's l2: 0.367141\tvalid_1's l2: 0.351028\n",
      "[191]\ttraining's l2: 0.367109\tvalid_1's l2: 0.351027\n",
      "[192]\ttraining's l2: 0.367059\tvalid_1's l2: 0.351013\n",
      "[193]\ttraining's l2: 0.367028\tvalid_1's l2: 0.350997\n",
      "[194]\ttraining's l2: 0.366999\tvalid_1's l2: 0.350991\n",
      "[195]\ttraining's l2: 0.366937\tvalid_1's l2: 0.350974\n",
      "[196]\ttraining's l2: 0.36691\tvalid_1's l2: 0.350967\n",
      "[197]\ttraining's l2: 0.366878\tvalid_1's l2: 0.350956\n",
      "[198]\ttraining's l2: 0.36683\tvalid_1's l2: 0.350932\n",
      "[199]\ttraining's l2: 0.366803\tvalid_1's l2: 0.350921\n",
      "[200]\ttraining's l2: 0.366762\tvalid_1's l2: 0.350906\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.366762\tvalid_1's l2: 0.350906\n",
      "mean_21_sales: 14651100.99\n",
      "mean_30_sales: 5618612.78\n",
      "mean_14_sales: 4299092.73\n",
      "mean_20_dow6_2017: 4193238.01\n",
      "mean_7_sales: 3362862.21\n",
      "mean_60_sales: 2251385.93\n",
      "mean_6_sales: 1765197.38\n",
      "promo_13: 1730727.23\n",
      "mean_3_sales: 1149020.37\n",
      "mean_63_sales: 874888.95\n",
      "mean_4_dow6_2017: 528524.86\n",
      "mean_4_sales: 525616.28\n",
      "item_class_features: 454895.61\n",
      "promo_14: 254920.83\n",
      "std_30_sales: 194725.10\n",
      "mean_20_dow5_2017: 166348.68\n",
      "lag_1_sales: 142711.54\n",
      "mean_5_sales: 111851.23\n",
      "promo_12: 100240.71\n",
      "item_family_features: 99064.94\n",
      "std_21_sales: 78907.23\n",
      "promo_6: 67527.45\n",
      "sum_4_promo: 64825.64\n",
      "promo_10: 62517.87\n",
      "std_60_sales: 46319.41\n",
      "mean_20_dow1_2017: 43113.99\n",
      "std_63_sales: 42943.52\n",
      "lag_49_sales: 39111.54\n",
      "store_cluster_features: 38505.82\n",
      "sum_2_promo: 35403.56\n",
      "sum_7_promo: 33721.57\n",
      "lag_2_sales: 28484.93\n",
      "mean_20_dow0_2017: 27639.02\n",
      "sum_6_promo: 25375.28\n",
      "std_14_sales: 22656.51\n",
      "promo_0: 19236.55\n",
      "mean_20_dow3_2017: 18563.29\n",
      "promo_9: 17291.05\n",
      "promo_11: 14888.31\n",
      "promo_8: 14312.45\n",
      "store_city_features: 13842.54\n",
      "sum_21_promo: 13413.08\n",
      "sum_14_promo: 13360.63\n",
      "promo_7: 13242.07\n",
      "sum_5_promo: 11726.41\n",
      "store_type_features: 11364.95\n",
      "std_7_sales: 9819.50\n",
      "mean_20_dow2_2017: 9262.43\n",
      "lag_63_sales: 8646.16\n",
      "lag_6_sales: 7090.17\n",
      "promo_15: 6909.48\n",
      "lag_42_sales: 6651.76\n",
      "mean_4_dow5_2017: 6371.93\n",
      "lag_3_sales: 6315.21\n",
      "lag_21_sales: 5440.70\n",
      "mean_20_dow4_2017: 5423.44\n",
      "mean_4_dow4_2017: 4761.48\n",
      "std_3_sales: 4532.02\n",
      "std_5_sales: 3996.96\n",
      "lag_35_sales: 3601.75\n",
      "sum_3_promo: 3506.95\n",
      "lag_14_sales: 3228.01\n",
      "mean_4_dow0_2017: 3216.97\n",
      "std_6_sales: 3075.82\n",
      "mean_4_dow3_2017: 2934.71\n",
      "lag_4_sales: 2841.93\n",
      "lag_7_sales: 2605.95\n",
      "lag_56_sales: 2365.65\n",
      "mean_4_dow1_2017: 2106.74\n",
      "mean_4_dow2_2017: 2095.32\n",
      "lag_28_sales: 2029.38\n",
      "store_state_features: 1862.37\n",
      "std_4_sales: 1661.37\n",
      "lag_5_sales: 1287.28\n",
      "promo_3: 1138.01\n",
      "promo_2: 951.00\n",
      "promo_1: 841.04\n",
      "promo_4: 566.04\n",
      "promo_5: 259.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 14/16 [40:18<05:37, 168.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 1.07583\tvalid_1's l2: 1.0079\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 1.01041\tvalid_1's l2: 0.945488\n",
      "[3]\ttraining's l2: 0.95114\tvalid_1's l2: 0.888773\n",
      "[4]\ttraining's l2: 0.89986\tvalid_1's l2: 0.839439\n",
      "[5]\ttraining's l2: 0.853454\tvalid_1's l2: 0.794972\n",
      "[6]\ttraining's l2: 0.80896\tvalid_1's l2: 0.752569\n",
      "[7]\ttraining's l2: 0.768806\tvalid_1's l2: 0.714672\n",
      "[8]\ttraining's l2: 0.732376\tvalid_1's l2: 0.679898\n",
      "[9]\ttraining's l2: 0.701204\tvalid_1's l2: 0.650276\n",
      "[10]\ttraining's l2: 0.671246\tvalid_1's l2: 0.621866\n",
      "[11]\ttraining's l2: 0.645545\tvalid_1's l2: 0.597639\n",
      "[12]\ttraining's l2: 0.622346\tvalid_1's l2: 0.575651\n",
      "[13]\ttraining's l2: 0.601335\tvalid_1's l2: 0.555841\n",
      "[14]\ttraining's l2: 0.580557\tvalid_1's l2: 0.536427\n",
      "[15]\ttraining's l2: 0.561837\tvalid_1's l2: 0.518929\n",
      "[16]\ttraining's l2: 0.544773\tvalid_1's l2: 0.503201\n",
      "[17]\ttraining's l2: 0.529382\tvalid_1's l2: 0.488836\n",
      "[18]\ttraining's l2: 0.516501\tvalid_1's l2: 0.47688\n",
      "[19]\ttraining's l2: 0.503562\tvalid_1's l2: 0.465021\n",
      "[20]\ttraining's l2: 0.491895\tvalid_1's l2: 0.454276\n",
      "[21]\ttraining's l2: 0.48222\tvalid_1's l2: 0.445374\n",
      "[22]\ttraining's l2: 0.472605\tvalid_1's l2: 0.436569\n",
      "[23]\ttraining's l2: 0.463723\tvalid_1's l2: 0.428534\n",
      "[24]\ttraining's l2: 0.455585\tvalid_1's l2: 0.421179\n",
      "[25]\ttraining's l2: 0.448948\tvalid_1's l2: 0.415199\n",
      "[26]\ttraining's l2: 0.44218\tvalid_1's l2: 0.409098\n",
      "[27]\ttraining's l2: 0.435971\tvalid_1's l2: 0.403569\n",
      "[28]\ttraining's l2: 0.43037\tvalid_1's l2: 0.398563\n",
      "[29]\ttraining's l2: 0.425202\tvalid_1's l2: 0.393924\n",
      "[30]\ttraining's l2: 0.420511\tvalid_1's l2: 0.389674\n",
      "[31]\ttraining's l2: 0.416174\tvalid_1's l2: 0.385845\n",
      "[32]\ttraining's l2: 0.412317\tvalid_1's l2: 0.382443\n",
      "[33]\ttraining's l2: 0.409158\tvalid_1's l2: 0.379629\n",
      "[34]\ttraining's l2: 0.405823\tvalid_1's l2: 0.376654\n",
      "[35]\ttraining's l2: 0.403179\tvalid_1's l2: 0.374375\n",
      "[36]\ttraining's l2: 0.400308\tvalid_1's l2: 0.371887\n",
      "[37]\ttraining's l2: 0.39777\tvalid_1's l2: 0.369648\n",
      "[38]\ttraining's l2: 0.395397\tvalid_1's l2: 0.367642\n",
      "[39]\ttraining's l2: 0.3932\tvalid_1's l2: 0.365762\n",
      "[40]\ttraining's l2: 0.391149\tvalid_1's l2: 0.364043\n",
      "[41]\ttraining's l2: 0.389271\tvalid_1's l2: 0.362441\n",
      "[42]\ttraining's l2: 0.387825\tvalid_1's l2: 0.361246\n",
      "[43]\ttraining's l2: 0.386256\tvalid_1's l2: 0.359879\n",
      "[44]\ttraining's l2: 0.384735\tvalid_1's l2: 0.358641\n",
      "[45]\ttraining's l2: 0.38362\tvalid_1's l2: 0.357749\n",
      "[46]\ttraining's l2: 0.382332\tvalid_1's l2: 0.356656\n",
      "[47]\ttraining's l2: 0.381176\tvalid_1's l2: 0.355729\n",
      "[48]\ttraining's l2: 0.380043\tvalid_1's l2: 0.354807\n",
      "[49]\ttraining's l2: 0.379024\tvalid_1's l2: 0.353987\n",
      "[50]\ttraining's l2: 0.378015\tvalid_1's l2: 0.353198\n",
      "[51]\ttraining's l2: 0.377142\tvalid_1's l2: 0.352485\n",
      "[52]\ttraining's l2: 0.376354\tvalid_1's l2: 0.351842\n",
      "[53]\ttraining's l2: 0.375553\tvalid_1's l2: 0.351243\n",
      "[54]\ttraining's l2: 0.374794\tvalid_1's l2: 0.350692\n",
      "[55]\ttraining's l2: 0.37425\tvalid_1's l2: 0.350296\n",
      "[56]\ttraining's l2: 0.373714\tvalid_1's l2: 0.349919\n",
      "[57]\ttraining's l2: 0.373268\tvalid_1's l2: 0.349575\n",
      "[58]\ttraining's l2: 0.37283\tvalid_1's l2: 0.349272\n",
      "[59]\ttraining's l2: 0.372416\tvalid_1's l2: 0.348985\n",
      "[60]\ttraining's l2: 0.372002\tvalid_1's l2: 0.348718\n",
      "[61]\ttraining's l2: 0.371474\tvalid_1's l2: 0.348318\n",
      "[62]\ttraining's l2: 0.370929\tvalid_1's l2: 0.347854\n",
      "[63]\ttraining's l2: 0.370466\tvalid_1's l2: 0.347478\n",
      "[64]\ttraining's l2: 0.369968\tvalid_1's l2: 0.347058\n",
      "[65]\ttraining's l2: 0.369688\tvalid_1's l2: 0.346914\n",
      "[66]\ttraining's l2: 0.369407\tvalid_1's l2: 0.346757\n",
      "[67]\ttraining's l2: 0.369036\tvalid_1's l2: 0.346525\n",
      "[68]\ttraining's l2: 0.368756\tvalid_1's l2: 0.346344\n",
      "[69]\ttraining's l2: 0.368288\tvalid_1's l2: 0.345944\n",
      "[70]\ttraining's l2: 0.367918\tvalid_1's l2: 0.34568\n",
      "[71]\ttraining's l2: 0.367574\tvalid_1's l2: 0.345405\n",
      "[72]\ttraining's l2: 0.367214\tvalid_1's l2: 0.345124\n",
      "[73]\ttraining's l2: 0.366902\tvalid_1's l2: 0.34493\n",
      "[74]\ttraining's l2: 0.366582\tvalid_1's l2: 0.344677\n",
      "[75]\ttraining's l2: 0.366282\tvalid_1's l2: 0.344491\n",
      "[76]\ttraining's l2: 0.365983\tvalid_1's l2: 0.344274\n",
      "[77]\ttraining's l2: 0.365753\tvalid_1's l2: 0.344073\n",
      "[78]\ttraining's l2: 0.365511\tvalid_1's l2: 0.343907\n",
      "[79]\ttraining's l2: 0.365244\tvalid_1's l2: 0.34375\n",
      "[80]\ttraining's l2: 0.365036\tvalid_1's l2: 0.34359\n",
      "[81]\ttraining's l2: 0.364777\tvalid_1's l2: 0.343428\n",
      "[82]\ttraining's l2: 0.36464\tvalid_1's l2: 0.343347\n",
      "[83]\ttraining's l2: 0.364421\tvalid_1's l2: 0.343176\n",
      "[84]\ttraining's l2: 0.364244\tvalid_1's l2: 0.343069\n",
      "[85]\ttraining's l2: 0.364056\tvalid_1's l2: 0.342964\n",
      "[86]\ttraining's l2: 0.363932\tvalid_1's l2: 0.342897\n",
      "[87]\ttraining's l2: 0.36378\tvalid_1's l2: 0.342829\n",
      "[88]\ttraining's l2: 0.363638\tvalid_1's l2: 0.342771\n",
      "[89]\ttraining's l2: 0.363372\tvalid_1's l2: 0.342559\n",
      "[90]\ttraining's l2: 0.363177\tvalid_1's l2: 0.342418\n",
      "[91]\ttraining's l2: 0.363036\tvalid_1's l2: 0.342332\n",
      "[92]\ttraining's l2: 0.362902\tvalid_1's l2: 0.342253\n",
      "[93]\ttraining's l2: 0.362813\tvalid_1's l2: 0.342216\n",
      "[94]\ttraining's l2: 0.362663\tvalid_1's l2: 0.342135\n",
      "[95]\ttraining's l2: 0.362569\tvalid_1's l2: 0.342112\n",
      "[96]\ttraining's l2: 0.362448\tvalid_1's l2: 0.34205\n",
      "[97]\ttraining's l2: 0.362284\tvalid_1's l2: 0.341882\n",
      "[98]\ttraining's l2: 0.362149\tvalid_1's l2: 0.341827\n",
      "[99]\ttraining's l2: 0.362054\tvalid_1's l2: 0.341766\n",
      "[100]\ttraining's l2: 0.361866\tvalid_1's l2: 0.341626\n",
      "[101]\ttraining's l2: 0.361768\tvalid_1's l2: 0.341576\n",
      "[102]\ttraining's l2: 0.361686\tvalid_1's l2: 0.341543\n",
      "[103]\ttraining's l2: 0.361514\tvalid_1's l2: 0.341398\n",
      "[104]\ttraining's l2: 0.361418\tvalid_1's l2: 0.341319\n",
      "[105]\ttraining's l2: 0.361252\tvalid_1's l2: 0.341182\n",
      "[106]\ttraining's l2: 0.361101\tvalid_1's l2: 0.341074\n",
      "[107]\ttraining's l2: 0.360998\tvalid_1's l2: 0.340983\n",
      "[108]\ttraining's l2: 0.360862\tvalid_1's l2: 0.340898\n",
      "[109]\ttraining's l2: 0.360776\tvalid_1's l2: 0.340847\n",
      "[110]\ttraining's l2: 0.360627\tvalid_1's l2: 0.340749\n",
      "[111]\ttraining's l2: 0.360553\tvalid_1's l2: 0.34068\n",
      "[112]\ttraining's l2: 0.360446\tvalid_1's l2: 0.340596\n",
      "[113]\ttraining's l2: 0.360363\tvalid_1's l2: 0.340555\n",
      "[114]\ttraining's l2: 0.360226\tvalid_1's l2: 0.340435\n",
      "[115]\ttraining's l2: 0.360145\tvalid_1's l2: 0.340381\n",
      "[116]\ttraining's l2: 0.360064\tvalid_1's l2: 0.34032\n",
      "[117]\ttraining's l2: 0.359982\tvalid_1's l2: 0.340283\n",
      "[118]\ttraining's l2: 0.359912\tvalid_1's l2: 0.340194\n",
      "[119]\ttraining's l2: 0.359838\tvalid_1's l2: 0.340183\n",
      "[120]\ttraining's l2: 0.359768\tvalid_1's l2: 0.340146\n",
      "[121]\ttraining's l2: 0.359699\tvalid_1's l2: 0.340124\n",
      "[122]\ttraining's l2: 0.35964\tvalid_1's l2: 0.340073\n",
      "[123]\ttraining's l2: 0.359532\tvalid_1's l2: 0.340017\n",
      "[124]\ttraining's l2: 0.359428\tvalid_1's l2: 0.339949\n",
      "[125]\ttraining's l2: 0.35935\tvalid_1's l2: 0.339929\n",
      "[126]\ttraining's l2: 0.359295\tvalid_1's l2: 0.339905\n",
      "[127]\ttraining's l2: 0.359197\tvalid_1's l2: 0.339831\n",
      "[128]\ttraining's l2: 0.359115\tvalid_1's l2: 0.339805\n",
      "[129]\ttraining's l2: 0.359056\tvalid_1's l2: 0.339739\n",
      "[130]\ttraining's l2: 0.358995\tvalid_1's l2: 0.33967\n",
      "[131]\ttraining's l2: 0.358932\tvalid_1's l2: 0.339646\n",
      "[132]\ttraining's l2: 0.358869\tvalid_1's l2: 0.339629\n",
      "[133]\ttraining's l2: 0.358753\tvalid_1's l2: 0.339548\n",
      "[134]\ttraining's l2: 0.35871\tvalid_1's l2: 0.339546\n",
      "[135]\ttraining's l2: 0.358624\tvalid_1's l2: 0.33949\n",
      "[136]\ttraining's l2: 0.358555\tvalid_1's l2: 0.339441\n",
      "[137]\ttraining's l2: 0.358467\tvalid_1's l2: 0.339404\n",
      "[138]\ttraining's l2: 0.358366\tvalid_1's l2: 0.339345\n",
      "[139]\ttraining's l2: 0.358299\tvalid_1's l2: 0.339306\n",
      "[140]\ttraining's l2: 0.358246\tvalid_1's l2: 0.33929\n",
      "[141]\ttraining's l2: 0.358185\tvalid_1's l2: 0.339255\n",
      "[142]\ttraining's l2: 0.358111\tvalid_1's l2: 0.339207\n",
      "[143]\ttraining's l2: 0.358059\tvalid_1's l2: 0.339197\n",
      "[144]\ttraining's l2: 0.358\tvalid_1's l2: 0.339192\n",
      "[145]\ttraining's l2: 0.357944\tvalid_1's l2: 0.339152\n",
      "[146]\ttraining's l2: 0.357904\tvalid_1's l2: 0.339121\n",
      "[147]\ttraining's l2: 0.35785\tvalid_1's l2: 0.339112\n",
      "[148]\ttraining's l2: 0.35779\tvalid_1's l2: 0.33909\n",
      "[149]\ttraining's l2: 0.357732\tvalid_1's l2: 0.339065\n",
      "[150]\ttraining's l2: 0.35767\tvalid_1's l2: 0.339036\n",
      "[151]\ttraining's l2: 0.357622\tvalid_1's l2: 0.339006\n",
      "[152]\ttraining's l2: 0.357554\tvalid_1's l2: 0.338978\n",
      "[153]\ttraining's l2: 0.357499\tvalid_1's l2: 0.338953\n",
      "[154]\ttraining's l2: 0.357445\tvalid_1's l2: 0.338938\n",
      "[155]\ttraining's l2: 0.357378\tvalid_1's l2: 0.338894\n",
      "[156]\ttraining's l2: 0.357323\tvalid_1's l2: 0.338874\n",
      "[157]\ttraining's l2: 0.357268\tvalid_1's l2: 0.338855\n",
      "[158]\ttraining's l2: 0.357224\tvalid_1's l2: 0.338849\n",
      "[159]\ttraining's l2: 0.357172\tvalid_1's l2: 0.338807\n",
      "[160]\ttraining's l2: 0.357114\tvalid_1's l2: 0.338783\n",
      "[161]\ttraining's l2: 0.35707\tvalid_1's l2: 0.338764\n",
      "[162]\ttraining's l2: 0.357032\tvalid_1's l2: 0.338742\n",
      "[163]\ttraining's l2: 0.356979\tvalid_1's l2: 0.338726\n",
      "[164]\ttraining's l2: 0.356933\tvalid_1's l2: 0.33869\n",
      "[165]\ttraining's l2: 0.356885\tvalid_1's l2: 0.338672\n",
      "[166]\ttraining's l2: 0.356845\tvalid_1's l2: 0.338643\n",
      "[167]\ttraining's l2: 0.356805\tvalid_1's l2: 0.338615\n",
      "[168]\ttraining's l2: 0.356769\tvalid_1's l2: 0.338604\n",
      "[169]\ttraining's l2: 0.356675\tvalid_1's l2: 0.338515\n",
      "[170]\ttraining's l2: 0.356618\tvalid_1's l2: 0.338487\n",
      "[171]\ttraining's l2: 0.356567\tvalid_1's l2: 0.33848\n",
      "[172]\ttraining's l2: 0.356524\tvalid_1's l2: 0.338459\n",
      "[173]\ttraining's l2: 0.356475\tvalid_1's l2: 0.338443\n",
      "[174]\ttraining's l2: 0.356447\tvalid_1's l2: 0.338432\n",
      "[175]\ttraining's l2: 0.356418\tvalid_1's l2: 0.338417\n",
      "[176]\ttraining's l2: 0.356374\tvalid_1's l2: 0.338398\n",
      "[177]\ttraining's l2: 0.356322\tvalid_1's l2: 0.33838\n",
      "[178]\ttraining's l2: 0.356268\tvalid_1's l2: 0.338363\n",
      "[179]\ttraining's l2: 0.356237\tvalid_1's l2: 0.338347\n",
      "[180]\ttraining's l2: 0.356201\tvalid_1's l2: 0.338331\n",
      "[181]\ttraining's l2: 0.356157\tvalid_1's l2: 0.338327\n",
      "[182]\ttraining's l2: 0.356111\tvalid_1's l2: 0.338303\n",
      "[183]\ttraining's l2: 0.356066\tvalid_1's l2: 0.338278\n",
      "[184]\ttraining's l2: 0.355998\tvalid_1's l2: 0.338242\n",
      "[185]\ttraining's l2: 0.355956\tvalid_1's l2: 0.338219\n",
      "[186]\ttraining's l2: 0.355888\tvalid_1's l2: 0.338193\n",
      "[187]\ttraining's l2: 0.355844\tvalid_1's l2: 0.338183\n",
      "[188]\ttraining's l2: 0.355816\tvalid_1's l2: 0.338168\n",
      "[189]\ttraining's l2: 0.355788\tvalid_1's l2: 0.338154\n",
      "[190]\ttraining's l2: 0.35575\tvalid_1's l2: 0.338145\n",
      "[191]\ttraining's l2: 0.355723\tvalid_1's l2: 0.338133\n",
      "[192]\ttraining's l2: 0.355678\tvalid_1's l2: 0.338115\n",
      "[193]\ttraining's l2: 0.355646\tvalid_1's l2: 0.338103\n",
      "[194]\ttraining's l2: 0.355623\tvalid_1's l2: 0.338099\n",
      "[195]\ttraining's l2: 0.355575\tvalid_1's l2: 0.338065\n",
      "[196]\ttraining's l2: 0.355524\tvalid_1's l2: 0.338062\n",
      "[197]\ttraining's l2: 0.355488\tvalid_1's l2: 0.33805\n",
      "[198]\ttraining's l2: 0.355456\tvalid_1's l2: 0.338032\n",
      "[199]\ttraining's l2: 0.355421\tvalid_1's l2: 0.338035\n",
      "[200]\ttraining's l2: 0.355382\tvalid_1's l2: 0.338018\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.355382\tvalid_1's l2: 0.338018\n",
      "mean_21_sales: 15485223.68\n",
      "mean_14_sales: 7522601.97\n",
      "mean_20_dow0_2017: 5152564.04\n",
      "mean_30_sales: 4166392.54\n",
      "mean_7_sales: 3697019.47\n",
      "promo_14: 2320967.50\n",
      "mean_60_sales: 1963323.21\n",
      "mean_63_sales: 1802396.10\n",
      "item_class_features: 569830.19\n",
      "mean_3_sales: 517160.30\n",
      "mean_5_sales: 503701.18\n",
      "mean_4_dow0_2017: 286139.18\n",
      "item_family_features: 168943.04\n",
      "std_30_sales: 162226.53\n",
      "promo_13: 154839.19\n",
      "sum_7_promo: 154524.24\n",
      "lag_1_sales: 136655.56\n",
      "promo_7: 134256.34\n",
      "std_21_sales: 124268.14\n",
      "promo_0: 118920.96\n",
      "store_cluster_features: 103792.45\n",
      "promo_15: 87049.70\n",
      "mean_6_sales: 84741.86\n",
      "std_63_sales: 76430.06\n",
      "mean_20_dow2_2017: 70460.33\n",
      "mean_4_sales: 62709.50\n",
      "sum_14_promo: 59435.71\n",
      "std_60_sales: 56981.23\n",
      "promo_12: 51293.75\n",
      "sum_21_promo: 49314.29\n",
      "std_14_sales: 42618.92\n",
      "lag_14_sales: 40345.01\n",
      "lag_42_sales: 36114.11\n",
      "store_type_features: 33919.53\n",
      "promo_10: 30606.48\n",
      "lag_49_sales: 27917.27\n",
      "lag_2_sales: 26545.66\n",
      "mean_20_dow1_2017: 26510.06\n",
      "promo_9: 24966.61\n",
      "mean_20_dow3_2017: 21968.84\n",
      "sum_4_promo: 15500.18\n",
      "store_city_features: 15222.18\n",
      "std_7_sales: 14887.64\n",
      "sum_2_promo: 14160.73\n",
      "sum_5_promo: 14120.05\n",
      "promo_8: 12805.16\n",
      "mean_20_dow5_2017: 12571.52\n",
      "promo_11: 11659.82\n",
      "mean_20_dow6_2017: 9968.81\n",
      "lag_63_sales: 8646.03\n",
      "mean_20_dow4_2017: 8125.85\n",
      "mean_4_dow6_2017: 6785.26\n",
      "lag_56_sales: 6001.15\n",
      "lag_28_sales: 5684.63\n",
      "lag_35_sales: 5397.81\n",
      "sum_6_promo: 4348.63\n",
      "std_5_sales: 4166.17\n",
      "lag_21_sales: 3709.50\n",
      "mean_4_dow4_2017: 3565.77\n",
      "mean_4_dow3_2017: 3535.74\n",
      "sum_3_promo: 3358.33\n",
      "promo_6: 3257.48\n",
      "lag_3_sales: 3100.33\n",
      "lag_7_sales: 2989.95\n",
      "store_state_features: 2604.46\n",
      "mean_4_dow2_2017: 2533.19\n",
      "std_6_sales: 2440.71\n",
      "promo_2: 2411.86\n",
      "lag_4_sales: 1701.67\n",
      "std_3_sales: 1511.70\n",
      "lag_5_sales: 1393.11\n",
      "mean_4_dow1_2017: 1334.34\n",
      "lag_6_sales: 1263.20\n",
      "promo_3: 790.62\n",
      "mean_4_dow5_2017: 647.94\n",
      "std_4_sales: 387.48\n",
      "promo_1: 169.65\n",
      "promo_4: 129.07\n",
      "promo_5: 68.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 15/16 [43:07<02:48, 168.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 0.973227\tvalid_1's l2: 0.938425\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's l2: 0.918028\tvalid_1's l2: 0.884992\n",
      "[3]\ttraining's l2: 0.868152\tvalid_1's l2: 0.836293\n",
      "[4]\ttraining's l2: 0.823111\tvalid_1's l2: 0.792309\n",
      "[5]\ttraining's l2: 0.782324\tvalid_1's l2: 0.752467\n",
      "[6]\ttraining's l2: 0.74538\tvalid_1's l2: 0.716414\n",
      "[7]\ttraining's l2: 0.711998\tvalid_1's l2: 0.683923\n",
      "[8]\ttraining's l2: 0.681776\tvalid_1's l2: 0.65449\n",
      "[9]\ttraining's l2: 0.65538\tvalid_1's l2: 0.628725\n",
      "[10]\ttraining's l2: 0.630533\tvalid_1's l2: 0.604585\n",
      "[11]\ttraining's l2: 0.608015\tvalid_1's l2: 0.582848\n",
      "[12]\ttraining's l2: 0.58769\tvalid_1's l2: 0.56306\n",
      "[13]\ttraining's l2: 0.569309\tvalid_1's l2: 0.545149\n",
      "[14]\ttraining's l2: 0.552576\tvalid_1's l2: 0.528897\n",
      "[15]\ttraining's l2: 0.537457\tvalid_1's l2: 0.514256\n",
      "[16]\ttraining's l2: 0.523696\tvalid_1's l2: 0.501021\n",
      "[17]\ttraining's l2: 0.511242\tvalid_1's l2: 0.489024\n",
      "[18]\ttraining's l2: 0.49993\tvalid_1's l2: 0.478099\n",
      "[19]\ttraining's l2: 0.489655\tvalid_1's l2: 0.46818\n",
      "[20]\ttraining's l2: 0.48059\tvalid_1's l2: 0.459455\n",
      "[21]\ttraining's l2: 0.472082\tvalid_1's l2: 0.451356\n",
      "[22]\ttraining's l2: 0.464445\tvalid_1's l2: 0.444023\n",
      "[23]\ttraining's l2: 0.457481\tvalid_1's l2: 0.437373\n",
      "[24]\ttraining's l2: 0.451113\tvalid_1's l2: 0.431312\n",
      "[25]\ttraining's l2: 0.445355\tvalid_1's l2: 0.425785\n",
      "[26]\ttraining's l2: 0.440101\tvalid_1's l2: 0.420778\n",
      "[27]\ttraining's l2: 0.435372\tvalid_1's l2: 0.416298\n",
      "[28]\ttraining's l2: 0.43104\tvalid_1's l2: 0.412222\n",
      "[29]\ttraining's l2: 0.427079\tvalid_1's l2: 0.408433\n",
      "[30]\ttraining's l2: 0.423464\tvalid_1's l2: 0.405076\n",
      "[31]\ttraining's l2: 0.420136\tvalid_1's l2: 0.401934\n",
      "[32]\ttraining's l2: 0.417167\tvalid_1's l2: 0.399138\n",
      "[33]\ttraining's l2: 0.414442\tvalid_1's l2: 0.396577\n",
      "[34]\ttraining's l2: 0.411968\tvalid_1's l2: 0.394226\n",
      "[35]\ttraining's l2: 0.409663\tvalid_1's l2: 0.392049\n",
      "[36]\ttraining's l2: 0.407538\tvalid_1's l2: 0.390085\n",
      "[37]\ttraining's l2: 0.405629\tvalid_1's l2: 0.388293\n",
      "[38]\ttraining's l2: 0.403875\tvalid_1's l2: 0.386737\n",
      "[39]\ttraining's l2: 0.402253\tvalid_1's l2: 0.385215\n",
      "[40]\ttraining's l2: 0.400717\tvalid_1's l2: 0.38379\n",
      "[41]\ttraining's l2: 0.39933\tvalid_1's l2: 0.382521\n",
      "[42]\ttraining's l2: 0.398071\tvalid_1's l2: 0.381342\n",
      "[43]\ttraining's l2: 0.396919\tvalid_1's l2: 0.380259\n",
      "[44]\ttraining's l2: 0.395874\tvalid_1's l2: 0.379274\n",
      "[45]\ttraining's l2: 0.394928\tvalid_1's l2: 0.378379\n",
      "[46]\ttraining's l2: 0.393999\tvalid_1's l2: 0.377567\n",
      "[47]\ttraining's l2: 0.393112\tvalid_1's l2: 0.376729\n",
      "[48]\ttraining's l2: 0.392313\tvalid_1's l2: 0.376025\n",
      "[49]\ttraining's l2: 0.391497\tvalid_1's l2: 0.375316\n",
      "[50]\ttraining's l2: 0.390763\tvalid_1's l2: 0.374687\n",
      "[51]\ttraining's l2: 0.390062\tvalid_1's l2: 0.374052\n",
      "[52]\ttraining's l2: 0.389436\tvalid_1's l2: 0.373514\n",
      "[53]\ttraining's l2: 0.3888\tvalid_1's l2: 0.373006\n",
      "[54]\ttraining's l2: 0.388215\tvalid_1's l2: 0.372493\n",
      "[55]\ttraining's l2: 0.387709\tvalid_1's l2: 0.372038\n",
      "[56]\ttraining's l2: 0.387232\tvalid_1's l2: 0.371621\n",
      "[57]\ttraining's l2: 0.386826\tvalid_1's l2: 0.371275\n",
      "[58]\ttraining's l2: 0.386409\tvalid_1's l2: 0.370905\n",
      "[59]\ttraining's l2: 0.386049\tvalid_1's l2: 0.370605\n",
      "[60]\ttraining's l2: 0.385675\tvalid_1's l2: 0.370295\n",
      "[61]\ttraining's l2: 0.385295\tvalid_1's l2: 0.369996\n",
      "[62]\ttraining's l2: 0.38493\tvalid_1's l2: 0.369683\n",
      "[63]\ttraining's l2: 0.384562\tvalid_1's l2: 0.369368\n",
      "[64]\ttraining's l2: 0.384213\tvalid_1's l2: 0.369087\n",
      "[65]\ttraining's l2: 0.383944\tvalid_1's l2: 0.368837\n",
      "[66]\ttraining's l2: 0.38371\tvalid_1's l2: 0.368629\n",
      "[67]\ttraining's l2: 0.383406\tvalid_1's l2: 0.368419\n",
      "[68]\ttraining's l2: 0.383167\tvalid_1's l2: 0.368199\n",
      "[69]\ttraining's l2: 0.382903\tvalid_1's l2: 0.367993\n",
      "[70]\ttraining's l2: 0.382612\tvalid_1's l2: 0.367738\n",
      "[71]\ttraining's l2: 0.382326\tvalid_1's l2: 0.367498\n",
      "[72]\ttraining's l2: 0.38205\tvalid_1's l2: 0.367289\n",
      "[73]\ttraining's l2: 0.381825\tvalid_1's l2: 0.367117\n",
      "[74]\ttraining's l2: 0.381594\tvalid_1's l2: 0.366941\n",
      "[75]\ttraining's l2: 0.381323\tvalid_1's l2: 0.36675\n",
      "[76]\ttraining's l2: 0.381126\tvalid_1's l2: 0.36661\n",
      "[77]\ttraining's l2: 0.380932\tvalid_1's l2: 0.366431\n",
      "[78]\ttraining's l2: 0.380724\tvalid_1's l2: 0.366305\n",
      "[79]\ttraining's l2: 0.380557\tvalid_1's l2: 0.366183\n",
      "[80]\ttraining's l2: 0.380364\tvalid_1's l2: 0.366029\n",
      "[81]\ttraining's l2: 0.380157\tvalid_1's l2: 0.365875\n",
      "[82]\ttraining's l2: 0.380021\tvalid_1's l2: 0.365765\n",
      "[83]\ttraining's l2: 0.37983\tvalid_1's l2: 0.365649\n",
      "[84]\ttraining's l2: 0.379681\tvalid_1's l2: 0.365553\n",
      "[85]\ttraining's l2: 0.37948\tvalid_1's l2: 0.365398\n",
      "[86]\ttraining's l2: 0.379348\tvalid_1's l2: 0.365302\n",
      "[87]\ttraining's l2: 0.379228\tvalid_1's l2: 0.36523\n",
      "[88]\ttraining's l2: 0.379115\tvalid_1's l2: 0.365141\n",
      "[89]\ttraining's l2: 0.378936\tvalid_1's l2: 0.365005\n",
      "[90]\ttraining's l2: 0.378811\tvalid_1's l2: 0.364909\n",
      "[91]\ttraining's l2: 0.378646\tvalid_1's l2: 0.364794\n",
      "[92]\ttraining's l2: 0.378528\tvalid_1's l2: 0.364677\n",
      "[93]\ttraining's l2: 0.378444\tvalid_1's l2: 0.364597\n",
      "[94]\ttraining's l2: 0.378324\tvalid_1's l2: 0.364507\n",
      "[95]\ttraining's l2: 0.378179\tvalid_1's l2: 0.36442\n",
      "[96]\ttraining's l2: 0.378087\tvalid_1's l2: 0.364372\n",
      "[97]\ttraining's l2: 0.377982\tvalid_1's l2: 0.364298\n",
      "[98]\ttraining's l2: 0.377867\tvalid_1's l2: 0.364202\n",
      "[99]\ttraining's l2: 0.377779\tvalid_1's l2: 0.364112\n",
      "[100]\ttraining's l2: 0.377608\tvalid_1's l2: 0.364014\n",
      "[101]\ttraining's l2: 0.377525\tvalid_1's l2: 0.363954\n",
      "[102]\ttraining's l2: 0.377395\tvalid_1's l2: 0.363829\n",
      "[103]\ttraining's l2: 0.377261\tvalid_1's l2: 0.363737\n",
      "[104]\ttraining's l2: 0.377187\tvalid_1's l2: 0.363698\n",
      "[105]\ttraining's l2: 0.377022\tvalid_1's l2: 0.363595\n",
      "[106]\ttraining's l2: 0.3769\tvalid_1's l2: 0.363512\n",
      "[107]\ttraining's l2: 0.376798\tvalid_1's l2: 0.363443\n",
      "[108]\ttraining's l2: 0.376733\tvalid_1's l2: 0.363393\n",
      "[109]\ttraining's l2: 0.376653\tvalid_1's l2: 0.363372\n",
      "[110]\ttraining's l2: 0.376534\tvalid_1's l2: 0.363314\n",
      "[111]\ttraining's l2: 0.376436\tvalid_1's l2: 0.363273\n",
      "[112]\ttraining's l2: 0.376316\tvalid_1's l2: 0.36323\n",
      "[113]\ttraining's l2: 0.376218\tvalid_1's l2: 0.363174\n",
      "[114]\ttraining's l2: 0.376106\tvalid_1's l2: 0.363081\n",
      "[115]\ttraining's l2: 0.37602\tvalid_1's l2: 0.362998\n",
      "[116]\ttraining's l2: 0.375883\tvalid_1's l2: 0.362924\n",
      "[117]\ttraining's l2: 0.375786\tvalid_1's l2: 0.362836\n",
      "[118]\ttraining's l2: 0.375746\tvalid_1's l2: 0.362774\n",
      "[119]\ttraining's l2: 0.375688\tvalid_1's l2: 0.362736\n",
      "[120]\ttraining's l2: 0.375625\tvalid_1's l2: 0.362696\n",
      "[121]\ttraining's l2: 0.375548\tvalid_1's l2: 0.362666\n",
      "[122]\ttraining's l2: 0.375483\tvalid_1's l2: 0.362611\n",
      "[123]\ttraining's l2: 0.375389\tvalid_1's l2: 0.36254\n",
      "[124]\ttraining's l2: 0.375286\tvalid_1's l2: 0.362481\n",
      "[125]\ttraining's l2: 0.375246\tvalid_1's l2: 0.362448\n",
      "[126]\ttraining's l2: 0.375171\tvalid_1's l2: 0.362404\n",
      "[127]\ttraining's l2: 0.375136\tvalid_1's l2: 0.362354\n",
      "[128]\ttraining's l2: 0.375072\tvalid_1's l2: 0.362338\n",
      "[129]\ttraining's l2: 0.37501\tvalid_1's l2: 0.362294\n",
      "[130]\ttraining's l2: 0.374918\tvalid_1's l2: 0.362234\n",
      "[131]\ttraining's l2: 0.374834\tvalid_1's l2: 0.362191\n",
      "[132]\ttraining's l2: 0.374755\tvalid_1's l2: 0.362135\n",
      "[133]\ttraining's l2: 0.374684\tvalid_1's l2: 0.362095\n",
      "[134]\ttraining's l2: 0.374632\tvalid_1's l2: 0.362061\n",
      "[135]\ttraining's l2: 0.374575\tvalid_1's l2: 0.362023\n",
      "[136]\ttraining's l2: 0.374486\tvalid_1's l2: 0.361983\n",
      "[137]\ttraining's l2: 0.374403\tvalid_1's l2: 0.361935\n",
      "[138]\ttraining's l2: 0.374347\tvalid_1's l2: 0.361895\n",
      "[139]\ttraining's l2: 0.374305\tvalid_1's l2: 0.361863\n",
      "[140]\ttraining's l2: 0.374221\tvalid_1's l2: 0.361798\n",
      "[141]\ttraining's l2: 0.374167\tvalid_1's l2: 0.361772\n",
      "[142]\ttraining's l2: 0.374121\tvalid_1's l2: 0.36175\n",
      "[143]\ttraining's l2: 0.374066\tvalid_1's l2: 0.361727\n",
      "[144]\ttraining's l2: 0.374019\tvalid_1's l2: 0.361713\n",
      "[145]\ttraining's l2: 0.373972\tvalid_1's l2: 0.361682\n",
      "[146]\ttraining's l2: 0.373929\tvalid_1's l2: 0.361647\n",
      "[147]\ttraining's l2: 0.373885\tvalid_1's l2: 0.361637\n",
      "[148]\ttraining's l2: 0.373814\tvalid_1's l2: 0.361582\n",
      "[149]\ttraining's l2: 0.373765\tvalid_1's l2: 0.361581\n",
      "[150]\ttraining's l2: 0.373714\tvalid_1's l2: 0.361552\n",
      "[151]\ttraining's l2: 0.37365\tvalid_1's l2: 0.361514\n",
      "[152]\ttraining's l2: 0.373593\tvalid_1's l2: 0.361489\n",
      "[153]\ttraining's l2: 0.373533\tvalid_1's l2: 0.361483\n",
      "[154]\ttraining's l2: 0.3735\tvalid_1's l2: 0.361441\n",
      "[155]\ttraining's l2: 0.373459\tvalid_1's l2: 0.361425\n",
      "[156]\ttraining's l2: 0.373408\tvalid_1's l2: 0.361413\n",
      "[157]\ttraining's l2: 0.373342\tvalid_1's l2: 0.361374\n",
      "[158]\ttraining's l2: 0.373287\tvalid_1's l2: 0.361354\n",
      "[159]\ttraining's l2: 0.373227\tvalid_1's l2: 0.361306\n",
      "[160]\ttraining's l2: 0.373191\tvalid_1's l2: 0.361294\n",
      "[161]\ttraining's l2: 0.373138\tvalid_1's l2: 0.361261\n",
      "[162]\ttraining's l2: 0.373112\tvalid_1's l2: 0.361239\n",
      "[163]\ttraining's l2: 0.373039\tvalid_1's l2: 0.36121\n",
      "[164]\ttraining's l2: 0.372996\tvalid_1's l2: 0.361193\n",
      "[165]\ttraining's l2: 0.372931\tvalid_1's l2: 0.361164\n",
      "[166]\ttraining's l2: 0.372895\tvalid_1's l2: 0.361151\n",
      "[167]\ttraining's l2: 0.372859\tvalid_1's l2: 0.361136\n",
      "[168]\ttraining's l2: 0.37282\tvalid_1's l2: 0.361119\n",
      "[169]\ttraining's l2: 0.372784\tvalid_1's l2: 0.361109\n",
      "[170]\ttraining's l2: 0.372749\tvalid_1's l2: 0.361098\n",
      "[171]\ttraining's l2: 0.372699\tvalid_1's l2: 0.361074\n",
      "[172]\ttraining's l2: 0.372653\tvalid_1's l2: 0.361055\n",
      "[173]\ttraining's l2: 0.372605\tvalid_1's l2: 0.36104\n",
      "[174]\ttraining's l2: 0.372559\tvalid_1's l2: 0.361016\n",
      "[175]\ttraining's l2: 0.372498\tvalid_1's l2: 0.360972\n",
      "[176]\ttraining's l2: 0.372455\tvalid_1's l2: 0.360948\n",
      "[177]\ttraining's l2: 0.372427\tvalid_1's l2: 0.360932\n",
      "[178]\ttraining's l2: 0.372388\tvalid_1's l2: 0.360913\n",
      "[179]\ttraining's l2: 0.372349\tvalid_1's l2: 0.360885\n",
      "[180]\ttraining's l2: 0.372313\tvalid_1's l2: 0.360868\n",
      "[181]\ttraining's l2: 0.372275\tvalid_1's l2: 0.360853\n",
      "[182]\ttraining's l2: 0.372239\tvalid_1's l2: 0.360845\n",
      "[183]\ttraining's l2: 0.372197\tvalid_1's l2: 0.360828\n",
      "[184]\ttraining's l2: 0.372166\tvalid_1's l2: 0.360811\n",
      "[185]\ttraining's l2: 0.372115\tvalid_1's l2: 0.360763\n",
      "[186]\ttraining's l2: 0.372084\tvalid_1's l2: 0.36072\n",
      "[187]\ttraining's l2: 0.372044\tvalid_1's l2: 0.360709\n",
      "[188]\ttraining's l2: 0.372021\tvalid_1's l2: 0.360706\n",
      "[189]\ttraining's l2: 0.371996\tvalid_1's l2: 0.360668\n",
      "[190]\ttraining's l2: 0.371941\tvalid_1's l2: 0.360667\n",
      "[191]\ttraining's l2: 0.371909\tvalid_1's l2: 0.360654\n",
      "[192]\ttraining's l2: 0.371879\tvalid_1's l2: 0.360649\n",
      "[193]\ttraining's l2: 0.371846\tvalid_1's l2: 0.360632\n",
      "[194]\ttraining's l2: 0.371819\tvalid_1's l2: 0.360613\n",
      "[195]\ttraining's l2: 0.371785\tvalid_1's l2: 0.360581\n",
      "[196]\ttraining's l2: 0.371748\tvalid_1's l2: 0.360577\n",
      "[197]\ttraining's l2: 0.371711\tvalid_1's l2: 0.360578\n",
      "[198]\ttraining's l2: 0.371665\tvalid_1's l2: 0.360558\n",
      "[199]\ttraining's l2: 0.371641\tvalid_1's l2: 0.360534\n",
      "[200]\ttraining's l2: 0.371609\tvalid_1's l2: 0.360534\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's l2: 0.371609\tvalid_1's l2: 0.360534\n",
      "mean_21_sales: 11148865.13\n",
      "mean_14_sales: 6804274.81\n",
      "mean_30_sales: 6052649.73\n",
      "mean_63_sales: 2863793.99\n",
      "mean_20_dow1_2017: 2667843.30\n",
      "mean_60_sales: 2603573.65\n",
      "promo_15: 1571440.45\n",
      "mean_6_sales: 1422038.97\n",
      "mean_7_sales: 1070215.46\n",
      "item_class_features: 485317.32\n",
      "mean_5_sales: 216091.83\n",
      "mean_20_dow2_2017: 199388.55\n",
      "promo_14: 166306.30\n",
      "lag_1_sales: 126503.60\n",
      "std_30_sales: 109368.40\n",
      "mean_3_sales: 108181.45\n",
      "std_21_sales: 104317.98\n",
      "mean_4_sales: 88901.59\n",
      "sum_4_promo: 65785.35\n",
      "item_family_features: 63858.70\n",
      "std_63_sales: 58863.00\n",
      "std_60_sales: 46365.41\n",
      "sum_6_promo: 42217.96\n",
      "mean_4_dow1_2017: 35301.84\n",
      "std_14_sales: 33526.29\n",
      "lag_42_sales: 28646.08\n",
      "promo_13: 27677.66\n",
      "mean_20_dow0_2017: 27549.32\n",
      "store_cluster_features: 23819.17\n",
      "sum_7_promo: 23081.07\n",
      "store_city_features: 22052.73\n",
      "promo_8: 21938.08\n",
      "mean_20_dow6_2017: 21370.94\n",
      "promo_10: 18931.64\n",
      "lag_14_sales: 18663.06\n",
      "sum_2_promo: 18422.10\n",
      "promo_12: 16349.65\n",
      "sum_14_promo: 16305.36\n",
      "mean_20_dow3_2017: 16178.30\n",
      "promo_0: 14089.81\n",
      "promo_9: 13076.57\n",
      "sum_21_promo: 12835.31\n",
      "promo_7: 10574.40\n",
      "lag_63_sales: 9379.70\n",
      "sum_5_promo: 8791.79\n",
      "std_7_sales: 8754.68\n",
      "mean_4_dow6_2017: 8508.57\n",
      "std_6_sales: 8189.11\n",
      "lag_49_sales: 8068.72\n",
      "promo_1: 7587.05\n",
      "std_5_sales: 7294.96\n",
      "lag_28_sales: 6352.25\n",
      "promo_11: 6164.94\n",
      "mean_20_dow4_2017: 4405.73\n",
      "store_state_features: 3935.43\n",
      "store_type_features: 3638.74\n",
      "lag_7_sales: 3539.34\n",
      "lag_6_sales: 3433.41\n",
      "mean_4_dow0_2017: 3249.54\n",
      "lag_5_sales: 3182.51\n",
      "mean_4_dow3_2017: 3174.92\n",
      "promo_6: 3070.53\n",
      "lag_3_sales: 3040.09\n",
      "lag_56_sales: 2913.37\n",
      "mean_4_dow4_2017: 2772.99\n",
      "lag_4_sales: 2654.23\n",
      "promo_3: 2555.62\n",
      "lag_35_sales: 2374.87\n",
      "mean_4_dow5_2017: 2216.32\n",
      "sum_3_promo: 2073.53\n",
      "lag_2_sales: 1944.93\n",
      "lag_21_sales: 1544.71\n",
      "promo_2: 1289.49\n",
      "mean_4_dow2_2017: 1251.90\n",
      "std_4_sales: 1188.05\n",
      "std_3_sales: 887.45\n",
      "mean_20_dow5_2017: 694.60\n",
      "promo_5: 300.65\n",
      "promo_4: 52.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [45:55<00:00, 168.34s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(16)):\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * nbr_weeks) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "\n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=MAX_ROUNDS,\n",
    "#         verbose_eval = False,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50)\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 0.35123858092295934\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "\n",
    "mlflow.set_experiment('grocery forecasting')\n",
    "with mlflow.start_run(run_name='lgbm'):\n",
    "    mlflow.log_param('model', 'lgbm')\n",
    "    mlflow.log_param('train starts', train_start)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param('lagging', LAG_DICT.values())\n",
    "    mlflow.log_param('slidingWindows', SLIDING_DICT.values())\n",
    "    mlflow.log_param('item_info', 'Yes')\n",
    "    mlflow.log_param('store_info', 'Yes')\n",
    "    mlflow.log_param('private score', 0.52193)\n",
    "    mlflow.log_param('private rank', '14%')\n",
    "    mlflow.log_param('public score', 0.51609)\n",
    "\n",
    "    mlflow.log_metric('mse', mse)\n",
    "    \n",
    "print(\"Validation mse:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_train.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('lgb.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
